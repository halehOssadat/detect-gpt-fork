{"name": "perturbation_10_z", "predictions": {"real": [0.0, 0.6288742999776468, -0.2552189831938132, 0.0, 0.2876494639352227, 0.18019219416054968, 0.0, 0.0, 0.0, -0.3011593150020627, 0.0, -1.1867544324378458, 0.0, 0.9766054508258804, 0.0, 0.0, 0.37645221251585714, 0.0, 0.0, 0.0, -0.6001675082671206, 0.0, 0.0, 0.0, 0.05283662024531574, 0.25635076289495484, 0.0, 0.0, -0.7574546884220065, 0.0, -0.4853038406614315, 3.905722360751144, 0.0, -0.05947782862565373, 0.09623062237210718, 0.0, 0.0, -0.3936512113807676, 0.0, 0.0, 0.0, 0.0, 0.10465852097460175, 0.0, -0.6155743965315648, -0.16481280456458797, 0.5172641885390908, -0.605461604639396, 0.0, 0.0, 0.0, 0.06766409714020251, 0.0, 0.0, 0.0, 0.0, 0.6249935913096485, 0.0, 0.25821832785942705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.15039821625531233, 0.0, 0.10481255536002208, 0.0, -0.08925097990912198, 0.0, 0.0, 0.0, 0.0, 0.6036409869239847, -0.4437993458770291, 0.1713894464746961, -0.608153486437043, 1.124321625516579, -0.12108256401597611, 0.0, -0.2711263565903641, 0.0, 0.47153953079603217, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.6512968340908607, 0.0, 0.0, 0.0, -0.23310203774037155, -0.45918872280368067, 0.7829197021469259, -0.273651731890446, 0.0, 0.0, 0.0, 0.7729200636052226, -0.24552651983802115, 0.0, 0.0, 0.0, 0.5021378605050034, 0.0, 0.0, 0.11854916149175752, 0.0, 0.0, -0.7762019436342859, -0.02369219499592332, 0.0, 0.0, -0.23833245713951245, 0.0, 0.6431702377898616, 0.0, -0.44439447697287765, -0.3265240347570753, 0.0, -0.5680568281861763, 0.6213555622899676, 0.0, 0.3650043106900416, 0.8597214261635866, -0.04429979167498341, 0.0, 0.0, 0.0, 0.743670764253546, -0.6609507866315394, 0.0, 0.0, 0.0, -0.1766430921254842, 0.0, 0.0, 0.8684988337629144, 0.0, 0.47928067087436044, 0.0, 0.0, 0.0, 0.0, 0.4006588498660953, 0.0, 0.08875413314284655, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.8390509503712313, 0.24402530574876338, -0.36895332917243895, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28670146543485775, -0.6489413433336608, 0.0, 0.0, 0.2615855181528626, -0.6556252807939298, 0.0, 0.0, 0.8755752402061522, 0.0, 0.0, 0.0, 0.41524497451891157, 0.0, 0.0, 0.0, 0.0, -0.09527676426045452, -1.230125007953263, 0.0, 0.0, -0.2440808164530914, 0.0, -0.47298912182390807, -0.568147647095646, -0.01611785462910655, -0.4317363914032549, 0.13677355901045823, 0.35939581855152153, 0.0, 0.1264705128143075, 0.0, 0.34680074227504704], "samples": [0.0, 0.3152443281171369, 1.1476151212705652, 0.0, 0.4054765566958867, 1.0802219874230232, 0.0, 0.0, 0.0, 0.7128528370134412, 0.0, 1.1761618325026504, 0.0, 1.2346658483524742, 0.0, 0.0, 0.28594090824133783, 0.0, 0.0, 0.0, 0.11320290085720237, 0.0, 0.0, 0.0, 0.29589019561509006, -0.11671068262660758, 0.0, 0.0, -0.5358923580090296, 0.0, 2.502488101896869, 1.4888113101026559, 0.0, -0.1520556475463005, 0.3083175470256203, 0.0, 0.0, -0.48718793025663615, 0.0, 0.0, 0.0, 0.0, 0.3365735323731422, 0.0, 0.09976975424765987, -0.6181349274243091, 0.7396488599322503, -0.01440250679275726, 0.0, 0.0, 0.0, 0.4766756793728354, 0.0, 0.0, 0.0, 0.0, 1.150062263402588, 0.0, -0.2657168050283235, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015261841313698267, 0.0, 1.087417004911599, 0.0, -0.7727904378470873, 0.0, 0.0, 0.0, 0.0, 1.2773352219761438, -0.22504940295010975, 0.607431376495128, 0.5554799216077406, 0.2709558596247474, 0.3501096235458154, 0.0, 1.7689194538403539, 0.0, 1.0318622895239842, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3478448026530223, 0.0, 0.0, 0.0, 0.20807571392028965, 0.6601013757479742, -0.0771885956460936, 1.3794187422017472, 0.0, 0.0, 0.0, 2.65049909972626, 0.6118471337453061, 0.0, 0.0, 0.0, 1.0261257566720814, 0.0, 0.0, 0.481086454668407, 0.0, 0.0, 0.2910524702813492, 0.2940422056158604, 0.0, 0.0, -0.23661375049098796, 0.0, -0.7457181334950624, 0.0, 1.0814620421787915, 1.3170301254443526, 0.0, 0.9777100048166454, 0.5930867327278074, 0.0, 0.7028875954769733, 0.30454695003607735, -0.2004477431581722, 0.0, 0.0, 0.0, 0.8146805034494097, -0.9774068732060837, 0.0, 0.0, 0.0, 0.5896739984473791, 0.0, 0.0, 0.09253163087485386, 0.0, 1.1697405825081388, 0.0, 0.0, 0.0, 0.0, 0.7163667728401618, 0.0, 0.10502582566144, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10856988992173926, -0.5932856235689379, -1.2552803480801107, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013872839815211913, -0.7300336703992533, 0.0, 0.0, 0.9959217968594494, 0.32594061403412733, 0.0, 0.0, -0.31900339597712085, 0.0, 0.0, 0.0, 2.02608163603519, 0.0, 0.0, 0.0, 0.0, 0.7019155566723367, 1.1779799957199977, 0.0, 0.0, -0.0006114998586077251, 0.0, -0.7458632876807938, 0.25697597138732736, -0.39081069908288774, 1.102292457511952, 0.2914528997780574, 4.898138383695968, 0.0, 0.1670665039641214, 0.0, 0.28486096761989044]}, "info": {"pct_words_masked": 0.3, "span_length": 2, "n_perturbations": 10, "n_samples": 200}, "raw_results": [{"original": "Fix timezone display for logs on UI (#23075)", "sampled": "Fix timezone display for logs on UI (#23075)This", "perturbed_sampled": ["Fix timezone display for logs on UI (#23075)This", "Fix timezone display for logs on UI (#23075)This", "Fix timezone display for logs on UI (#23075)This", "Fix timezone display for logs on UI (#23075)This", "Fix timezone display for logs on UI (#23075)This", "Fix timezone display for logs on UI (#23075)This", "Fix timezone display for logs on UI (#23075)This", "Fix timezone display for logs on UI (#23075)This", "Fix timezone display for logs on UI (#23075)This", "Fix timezone display for logs on UI (#23075)This"], "perturbed_original": ["Fix timezone display for logs on UI (#23075)", "Fix timezone display for logs on UI (#23075)", "Fix timezone display for logs on UI (#23075)", "Fix timezone display for logs on UI (#23075)", "Fix timezone display for logs on UI (#23075)", "Fix timezone display for logs on UI (#23075)", "Fix timezone display for logs on UI (#23075)", "Fix timezone display for logs on UI (#23075)", "Fix timezone display for logs on UI (#23075)", "Fix timezone display for logs on UI (#23075)"], "original_ll": -6.2345428466796875, "sampled_ll": -6.880313873291016, "all_perturbed_sampled_ll": [-6.880313873291016, -6.880313873291016, -6.880313873291016, -6.880313873291016, -6.880313873291016, -6.880313873291016, -6.880313873291016, -6.880313873291016, -6.880313873291016, -6.880313873291016], "all_perturbed_original_ll": [-6.2345428466796875, -6.2345428466796875, -6.2345428466796875, -6.2345428466796875, -6.2345428466796875, -6.2345428466796875, -6.2345428466796875, -6.2345428466796875, -6.2345428466796875, -6.2345428466796875], "perturbed_sampled_ll": -6.880313873291016, "perturbed_original_ll": -6.2345428466796875, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Fix crash when clearing run with task from normal to mapped (#31352) Co-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com> Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "sampled": "Fix crash when clearing run with task from normal to mapped (#31352) Co-authored-by: Jed Cunningham <66968678+jed@bae.com> Signed-off-by: Jeremy Stebbins <jeremy@bae.com>", "perturbed_sampled": ["Fix crash when clearing run with task from normal to mapped (#31352) by: Jeremy Cunningham <66968678+jed@bae.com> Signed-off-by: Jeremy Stebbins <jeremy@bae.com>", "Fix crash when clearing run with task from normal to mapped (#31352) Co-authored-by: Jed Cunningham , Jeremy Stebbins <jeremy@bae.com>", "logged when clearing run with task from normal to mapped (#31352) Co-authored-by: Jed Cunningham <66968678+jed@bae.com> Signed-off-by: Jeremy Stebbins <jeremy@bae.com>", "Fix crash when trying to load or spawn a task with task from normal to mapped (#31352) Co-authored-by: Jed Cunningham <66968678+jed@bae.com> Signed-off-by: Jeremy Stebbins <jeremy@bae.com>", "Fix crash when converting with task from normal to mapped (#31352) Co-authored-by: Jed Cunningham <66968678+jed@bae.com> Signed-off-by: Jeremy Stebbins <jeremy@bae.com>", "Fix crash when clearing run with task object to mapped (#31352) Co-authored-by: Jed Cunningham <66968678+jed@bae.com> Signed-off-by: Jeremy Stebbins <jeremy@bae.com>", "Fix crash when clearing run with task from normal execution (#31352) Co-authored-by: Jed Cunningham <66968678+jed@bae.com> Signed-off-by: Jeremy Stebbins <jeremy@bae.com>", "Fix crash when clearing to map task from normal to mapped (#31352) Co-authored-by: Jed Cunningham <66968678+jed@bae.com> Signed-off-by: Jeremy Stebbins <jeremy@bae.com>", "Fix crash when clearing run with mapped to normal to mapped (#31352) Co-authored-by: Jed Cunningham <66968678+jed@bae.com> Signed-off-by: Jeremy Stebbins <jeremy@bae.com>", "Fix crash when clearing run with task from normal to mapped (#31352) Signed-off by: Jed Cunningham <66968678+jed@bae.com> Signed-off-by: Jeremy Stebbins <jeremy@bae.com>"], "perturbed_original": ["Fix crash when clearing run with task from normal to mapped (#31352) Co-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com> ; Uranus Chung <uranusjr@gmail.com>", "Fix crash when clearing run with task from normal to mapped (#31352) by: Sean Cunningham <66968678+jedcunningham@users.noreply.github.com> Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Fix crash when clearing run time data from normal to mapped (#31352) Co-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com> Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Fix crash when clearing run with task from normal to mapped (#31352) - Jeed Cunningham <66968678+jedcunningham@users.noreply.github.com> Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Fix es clearing run with task from normal to mapped (#31352) Co-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com> Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Fix crash when clearing run with task from normal to debug. Co-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com> Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Fix crash when change file, if you with task from normal to mapped (#31352) Co-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com> Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Fix crash when clearing run with task from normal to mapped (#31352) Co-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com> & Uranus Chung <uranusjr@gmail.com>", "Fix crash when clearing run with a change from normal to mapped (#31352) Co-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com> Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", ". Warning when clearing run with task from normal to mapped (#31352) Co-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com> Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>"], "original_ll": -4.04397439956665, "sampled_ll": -3.9412343502044678, "all_perturbed_sampled_ll": [-4.195772171020508, -4.795058727264404, -3.9943959712982178, -3.847935438156128, -3.8135247230529785, -3.980321168899536, -3.7994277477264404, -3.8016552925109863, -4.059837818145752, -4.017665863037109], "all_perturbed_original_ll": [-4.428353309631348, -4.491555690765381, -3.9269604682922363, -4.544942855834961, -4.258328437805176, -3.8189520835876465, -4.061654090881348, -4.4068284034729, -3.91399884223938, -4.15985107421875], "perturbed_sampled_ll": -4.030559492111206, "perturbed_original_ll": -4.201142525672912, "perturbed_sampled_ll_std": 0.28335209848263304, "perturbed_original_ll_std": 0.2499197790589445}, {"original": "Slack: use default_conn_name by default (#34548) * Slack: use default_conn_name by default It's convenient not to define connection name if there is only one global or default connection. This is what is usually done in other hooks like `HttpHook` * Populate default in other places", "sampled": "Slack: use default_conn_name by default (#34548) * Slack: use default_conn_name by default It's convenient not to have to set one particular default when using slack-dev. This is especially useful on the production server/deployment. You'll only need to set this whenever you need a different default.", "perturbed_sampled": ["Slack: use default_login by default (#34548) * Slack: use default_conn_name by default It's convenient not to have to set one particular default when using various devices. This is especially useful on the production server/deployment. You'll only need to set this field if you need a different default.", "Slack: use default_conn_name by default (#34548) * Slack: use default_conn_name by default It's convenient not to have just one particular default when using Slack and is especially useful on the production server/deployment. You'll only need to set this if you need a different default.", "Slack: use default_conn_name by default (#34548) * Slack: use default_conn_nick by default It's very useful to have to set one particular default when using slack-dev. This is especially useful on the production server/deployment. You'll only need to set this whenever you need a different default.", "Slack: use default_conn_name by default (#34548) * Slack: use default_user_name by default It's convenient not to have to specify one particular configuration using slack-dev. This is especially useful on the production server/deployment. You'll only need to set this whenever you need a different default.", "Use default_conn_name by default \u2013 Slack: use default_conn_name by default It's convenient not to need to set one particular default when using slack-dev. This is especially useful on the production server/deployment. You'll only need to set this whenever you need a different default.", "Slack: use default_conn_name by default (#34548) * Slack: use default_conn_name by default It's convenient not to have to change that particular default when using slack-dev. This is especially useful on the production server/deployment. You'll only need to do this whenever you need a different default.", "Slack: use default_conn_name by default (#34548) * Slack: use default_conn_name by default It's convenient to only have to set this by default when using slack-dev. This is especially useful for production server/deployment. You'll only need to set this whenever you need a different default.", "Slack: use default_conn_name by default (#34548) * Slack: use default_conn_name by default It's convenient not to have to set one particular default when using slack-dev. This is especially useful on the production desktop, where you only need to set this when you need a different default.", "Slack: use default_conn_name by default (#34548) * Slack: use default_conn_name by default It's convenient not to have to set one particular default when using Slack. This is especially useful on the production server/deployment. You only need to set this whenever you need a different default.", "Slack: use default_conn_name by default (#34548) * Slack: use default_conn_name by default It would be convenient not to have to set one particular default when using slack-dev. This is especially useful for making configuration decisions for your production server/deployment. You'll only have to set this whenever you need a different default."], "perturbed_original": ["Slack: use default_conn_name by default (#34548) * Use default_conn_name by default It's convenient not to define connection name if there is only one global or custom name This is what is usually done in other hooks like `HttpHook` * Populate default in other places", "Slack: use default_conn_name by default (#34548) * Slack: use default_conn_name by default It's convenient not to define connection name if there is only one global or default connection. This is what is usually done in other places by default. `HttpHook` * Populate default in other places", "Slack: use default_conn_name by default * Slack: use default_conn_name by default It's convenient not to define connection name if there is only one global or default connection. This is what is usually done by other hooks like the slack hook and Populate default in other places", "Slack: use default_conn_name by default (#34548) * Slack: use default_conn_name by default It's not necessary for Slack to define connection name if there is only one global or default name that is what is usually done in other hooks like `HttpHook` * Populate default in other places", "Slack: use default_conn_name by default (#34548) * Add hook to use default_conn_name by default It's easier to define connection name if there is only one global or default connection. This is what is done in other hooks like `HttpHook` * Populate default in other places", "Slack: use default_conn_name by default. * (#34548) * Slack: use default_conn_name by default It's convenient not to define connection name if there is only one global or default connection. This is what is usually done by hooks like `HttpHook` * Populate default connection names to suitable places", "Slack: use default_conn_name by default * Slack: use default_conn_name by default It's convenient not to use the connection name if there is only one global or default connection. This is what is usually done in other hooks like `HttpHook` * Populate default _conn_name all the places", "Slack: use default_conn_name by default (#34548) * Slack: use default_conn_name by default It's convenient not to define connection name if there is already a global or default connection. This task is usually done in other hooks like `HttpHook` or is done by default in other places", "Slack: use default_conn_name by default (#34548) Slack: use default_conn_name by default It's convenient not to define connection name if there is only one or default connection. This is what is usually done in other hooks , so it seems appropriate to use default by default. * Populate default in other places", "Slack: use default_conn_name by default (#34548) Slack: use default_conn_name by default It's a great feature to define connection name if there is only one global name for all connection. This is what is usually done in other hooks like `HttpHook` * Populate default in other places"], "original_ll": -3.7116546630859375, "sampled_ll": -2.9482884407043457, "all_perturbed_sampled_ll": [-3.235041618347168, -3.1818509101867676, -3.112643241882324, -3.240513801574707, -2.936800718307495, -2.9949846267700195, -2.9596025943756104, -3.0711829662323, -2.9513466358184814, -3.0574564933776855], "all_perturbed_original_ll": [-3.8838651180267334, -3.6049344539642334, -3.6919796466827393, -3.792032480239868, -3.6187517642974854, -3.778892993927002, -3.4654288291931152, -3.6694047451019287, -3.5696074962615967, -3.744185209274292], "perturbed_sampled_ll": -3.0741423606872558, "perturbed_original_ll": -3.6819082736968993, "perturbed_sampled_ll_std": 0.10966561667780461, "perturbed_original_ll_std": 0.11655241713132593}, {"original": "Fix dag-processor fetch metabase config (#23575)", "sampled": "Fix dag-processor fetch metabase config (#23575)We", "perturbed_sampled": ["Fix dag-processor fetch metabase config (#23575)We", "Fix dag-processor fetch metabase config (#23575)We", "Fix dag-processor fetch metabase config (#23575)We", "Fix dag-processor fetch metabase config (#23575)We", "Fix dag-processor fetch metabase config (#23575)We", "Fix dag-processor fetch metabase config (#23575)We", "Fix dag-processor fetch metabase config (#23575)We", "Fix dag-processor fetch metabase config (#23575)We", "Fix dag-processor fetch metabase config (#23575)We", "Fix dag-processor fetch metabase config (#23575)We"], "perturbed_original": ["Fix dag-processor fetch metabase config (#23575)", "Fix dag-processor fetch metabase config (#23575)", "Fix dag-processor fetch metabase config (#23575)", "Fix dag-processor fetch metabase config (#23575)", "Fix dag-processor fetch metabase config (#23575)", "Fix dag-processor fetch metabase config (#23575)", "Fix dag-processor fetch metabase config (#23575)", "Fix dag-processor fetch metabase config (#23575)", "Fix dag-processor fetch metabase config (#23575)", "Fix dag-processor fetch metabase config (#23575)"], "original_ll": -7.863487720489502, "sampled_ll": -8.541749000549316, "all_perturbed_sampled_ll": [-8.541749000549316, -8.541749000549316, -8.541749000549316, -8.541749000549316, -8.541749000549316, -8.541749000549316, -8.541749000549316, -8.541749000549316, -8.541749000549316, -8.541749000549316], "all_perturbed_original_ll": [-7.863487720489502, -7.863487720489502, -7.863487720489502, -7.863487720489502, -7.863487720489502, -7.863487720489502, -7.863487720489502, -7.863487720489502, -7.863487720489502, -7.863487720489502], "perturbed_sampled_ll": -8.541749000549316, "perturbed_original_ll": -7.863487720489502, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Upgrade to Pydantic v2 (#35551) * Replace deprecated Config with ConfigDict * Drop Pydantic v1 compatibility as bumping it to 2.3.0", "sampled": "Upgrade to Pydantic v2 (#35551) * Replace deprecated Config with ConfigDict * Drop Pydantic v1 compatibility as bumping is no longer", "perturbed_sampled": ["Upgrade to 5.2.1 (#35551) * Replace deprecated Config with ConfigDict * Drop Pydantic v1 compatibility as bumping is no longer", "* Encode Pydantic v2 (#35551) * Replace deprecated Config with ConfigDict * Drop Pydantic v1 compatibility as bumping is no longer", "* Pull in Pydantic v2 (#35551) * Replace deprecated Config with ConfigDict * Drop Pydantic v1 compatibility as bumping is no longer", "Upgrade to Pydantic v2 * Replace deprecated Config with ConfigDict * Drop Pydantic v1 compatibility as bumping is no longer", "Upgrade to Pydantic v2 (#35551) * Replace deprecated Config with ConfigDict * Drop Pydantic v1 compatibility as bumping is no longer", "Upgrade to Pydantic v2 (#35551) * Replace Config with ConfigDict * Drop Pydantic v1 compatibility as bumping is no longer", "Upgrade to Pydantic v2 (#35551) * Replace deprecated ConfigurationDict with ConfigDict * Drop Pydantic v1 compatibility as bumping is no longer", "Upgrade to Pydantic v2 (#35551) * Replace deprecated Config with ConfigDict * Drop Pydantic v1 compatibility as the API will no longer", "Upgrade to Pydantic v2 (#35551) * Replace deprecated Config with ConfigDict * Drop Pydantic v1 as bumping is no longer", "Upgrade to Pydantic v2 ** Replace deprecated Config with ConfigDict * Drop Pydantic v1 compatibility as bumping is no longer"], "perturbed_original": ["Upgrade to Pydantic v2 (#35551) * Replace deprecated Config with ConfigDict * Drop Pydantic v1 compatibility as of package upgrade to 2.3.0", "Upgrade to Pydantic v2 (#35551) * Replace deprecated Config with ConfigDict * Drop Pydantic v1 compatibility and change it to 2.3.0", "Upgrade to Pydantic v2 (#35551) * Replace the deprecated Config with ConfigDict * Drop Pydantic v1 compatibility as bumping it to 2.3.0", "* Uninstall Pydantic v2 (#35551) * Replace deprecated Config with ConfigDict * Drop Pydantic v1 compatibility as bumping it to 2.3.0", "Upgrade to Pydantic v2 (#35551) * Replace deprecated Config with Default * Drop Pydantic v1 compatibility as bumping it to 2.3.0", "Upgrade to Pydantic v2 (#35551) * Replace deprecated Config with ConfigDict * Drop Pydantic v1 compatibility as of 1.4.1 Release to 2.3.0", "Upgrade to Pydantic v2 (#35551) * Replace deprecated Config with ConfigDict * Default Pydantic v1 compatibility as bumping it to 2.3.0", "Upgrade to Pydantic v2 compatibility * Replace deprecated Config with ConfigDict * Drop Pydantic v1 compatibility as bumping it to 2.3.0", "Upgrade to Pydantic v2 (#35551) * Replace deprecated Config with new version * Drop Pydantic v1 compatibility as bumping it to 2.3.0", "Upgrade to Pydantic v2 (#35551) * Replace deprecated Config with ConfigDict * Drop Pydantic v1 compatibility as bumping it to 2.3.0"], "original_ll": -4.272580146789551, "sampled_ll": -4.609838962554932, "all_perturbed_sampled_ll": [-4.5310258865356445, -4.762887477874756, -4.949789524078369, -4.596824645996094, -4.609838962554932, -4.696011543273926, -4.517030239105225, -4.460330963134766, -4.737083911895752, -4.829628944396973], "all_perturbed_original_ll": [-4.385553359985352, -4.180369853973389, -4.261488914489746, -4.373875617980957, -4.443565845489502, -4.082677364349365, -4.4180521965026855, -4.293484687805176, -4.317715644836426, -4.272580146789551], "perturbed_sampled_ll": -4.6690452098846436, "perturbed_original_ll": -4.302936363220215, "perturbed_sampled_ll_std": 0.14601644990814464, "perturbed_original_ll_std": 0.10553197636933527}, {"original": "Fix bad merge conflict on test-name-parameter-change (#30456) We've added a new reference to test-types in #30450 and it clashed with parameter rename in #30424. This resulted in bad merge (not too dangerous, just causing missing optimisation in collection elapsed time in case only a subset of test types were to be executed.", "sampled": "Fix bad merge conflict on test-name-parameter-change (#30456) We've added a new reference to test-types in #30459, and changed the test function name to test-types. That makes it easier to distinguish these from test-type::test-parameter, because when you want to make a change to test-type-parameter, you know that there is a new reference to", "perturbed_sampled": ["Fix naming conflict on test-name-parameter-change (#30456) We've added a new reference to test-types in #30459, and changed the test function name to test-types. That makes it easier to distinguish these from each other, because when you want to make a change , you know that there is a new reference to", "Fix ing a name-parameter conflict on test-name-parameter-change (#30456) We've added a new reference to test-types in #30459, and changed the test function name to test-types. That makes it easier to distinguish these from test-type::test-parameter, because when you want to make a change to test-type-parameter, you now have to remember that there is a new reference to", "Fix bad merge conflict on test-name-parameter-change (#30456) We've added a new reference to test-types in #30459, and changed the test function name to test-types. That makes it easier to distinguish these from test-type::test-parameter, because when you want to make a new reference to test-type-parameter, you know that there is a new reference to", "Fix bad merge conflict on test-name-parameter-change (#30456) We've added a new reference to test-types in #30459, and changed the function name to test-types. That makes it easier to read these from test-type::test-parameter, because when you want to make a change to test-type-parameter, you know that it has a new reference to", "Add merge conflict on test-name-parameter-change (#30456) We've added a new reference to test-types in test function names, and changed the test function name to test-types. That makes it easier to distinguish these from test-type::test-parameter, because when you want to perform a change to test-type-parameter, you know that there is a new reference to", "Fix bad merge conflict on test-name-parameter-change (#30456) We've added a new reference for test-type-parameter in #30459, and changed the test function names to test-types. That makes it easier to distinguish these from test-type::test-parameter, because when you want to make a change to test-type-parameter, you can verify that there is a new reference to", "Fix bad merge conflict with #11234 (#30456) : Added a new test function to test-types in #30459, and changed the test function name to test-types. That makes it easier to distinguish these from test-type::test-parameter, because when you want to make a change to test-type-parameter, you know that there is a new reference to", "Fix bad merge conflict . (#30456) We've added a new reference to the test function in the test function set test-type according to #30459, and changed the test function name to test-types. That makes it easier to distinguish these from test-type::test-parameter, because when you want to make a change to test-type-parameter, you know that there is a reference to", "Fix bad merge conflict on test-name-parameter-change (#30456) We've added a new reference to test-types (the test-types project) and changed the test function name to test-types. That makes it easier to distinguish these from test-type::test-parameter, because when you merge and make a change , you know that there is a new reference to", "Fix bad merge conflict on test-name-parameter-change (#30456) We've added a new reference to test-types in that merge and changed the test function names in that list to test-types. That makes it easier to distinguish these from test-type::test-parameter, because when you want to make a change to test-type-parameter, you know that there is a new reference to"], "perturbed_original": ["Fix bad merge conflict on test-name-parameter-change (#30456) We've added a new reference to call parameter name in #30450 and it clashed with parameter rename in #30424. This resulted in bad merge (not too dangerous, just causing missing optimisation in collection elapsed time in #30447) and a subset of test types were not executed.", "Fix bad merge conflict on test-name-parameter-change (#30456) We've added a new reference test in #30450 and it clashed with a test parameter rename in #30424. This resulted in bad merge (not too dangerous, just causing missing optimisation in collection elapsed time in case a subset of test types were to be executed.", "Fix bad merge conflict on test-name-parameter-change (#30456) We've added a new reference to test-types in #30450 , which clashed with parameter rename in #30424. This resulted in bad merge (not too dangerous, just causing missing optimisation in collection of test types), in case only a subset of the old test types were to be executed.", "Fix bad merge conflict : (#30456) We've added a new reference to test-types , and it clashed with parameter rename in #30424. This resulted in bad merge (not too dangerous, just causing missing optimisation in the merge()). This might cause excessive execution time in case only a subset of test types were to be executed.", "bad merge conflict on test-name-parameter-change (#30456) We've added a new reference to test-types in #30450 and it clashed with parameter rename in #30424. This resulted in bad merge (not too dangerous, just causing missing optimisation in collection ) in case only a subset of test -types need to be executed.", "Fix bad merge conflict on test-types. We've added a new call to test-types in #30450 and it clashed with parameter rename in #30424. This resulted in bad merge (not too dangerous, just causing missing optimisation in collection elapsed time in case only a subset of test types were to be executed.", "Fix bad merge conflict on test-name-parameter-change (#30456) We've added a new reference to test-types in #30450 , clashed with parameter rename in #30424. This resulted in bad merge (not too dangerous, just causing missing optimisation in collection elapsed time .) which caused only a subset of test -types to be executed.", "Fix bad merge conflict on #30450. We've added a parameter to test-types in #30450 . But it clashed with parameter rename in #30424. This resulted in bad merge (not too dangerous, just causing missing optimisation in collection elapsed time in case only a subset of test types were to be executed.", "Fix bad merge in test-name-parameter-change (#30456) We've added a new reference to test-types in #30450 and it clashed with parameter rename in #30456 which resulted in bad merge (not too dangerous, just causing missing optimisation in collection elapsed time in case only a subset of test types should be executed.", "Fix bad merge conflict on test-name-parameter-change (#30456) We've added a new reference to test-types in #30450 and it required parameter rename in #30424. This resulted in bad merge (not too dangerous, just causing missing optimisation in collection ) in case only a subset of test types were to be executed."], "original_ll": -4.458536148071289, "sampled_ll": -2.9402613639831543, "all_perturbed_sampled_ll": [-3.3065826892852783, -2.938892126083374, -2.9557812213897705, -3.0491833686828613, -2.9797773361206055, -2.935784101486206, -3.2353591918945312, -3.150425910949707, -3.344050884246826, -3.0870020389556885], "all_perturbed_original_ll": [-4.388318061828613, -4.560362815856934, -4.305733680725098, -4.495120048522949, -4.433979511260986, -4.519049644470215, -4.6627020835876465, -4.6604905128479, -4.410622596740723, -4.3581318855285645], "perturbed_sampled_ll": -3.098283886909485, "perturbed_original_ll": -4.479451084136963, "perturbed_sampled_ll_std": 0.1462870824387763, "perturbed_original_ll_std": 0.11607015588610435}, {"original": "Chart: Default to Airflow 2.3.3 (#24947)", "sampled": "Chart: Default to Airflow 2.3.3 (#24947)One", "perturbed_sampled": ["Chart: Default to Airflow 2.3.3 (#24947)One", "Chart: Default to Airflow 2.3.3 (#24947)One", "Chart: Default to Airflow 2.3.3 (#24947)One", "Chart: Default to Airflow 2.3.3 (#24947)One", "Chart: Default to Airflow 2.3.3 (#24947)One", "Chart: Default to Airflow 2.3.3 (#24947)One", "Chart: Default to Airflow 2.3.3 (#24947)One", "Chart: Default to Airflow 2.3.3 (#24947)One", "Chart: Default to Airflow 2.3.3 (#24947)One", "Chart: Default to Airflow 2.3.3 (#24947)One"], "perturbed_original": ["Chart: Default to Airflow 2.3.3 (#24947)", "Chart: Default to Airflow 2.3.3 (#24947)", "Chart: Default to Airflow 2.3.3 (#24947)", "Chart: Default to Airflow 2.3.3 (#24947)", "Chart: Default to Airflow 2.3.3 (#24947)", "Chart: Default to Airflow 2.3.3 (#24947)", "Chart: Default to Airflow 2.3.3 (#24947)", "Chart: Default to Airflow 2.3.3 (#24947)", "Chart: Default to Airflow 2.3.3 (#24947)", "Chart: Default to Airflow 2.3.3 (#24947)"], "original_ll": -4.683969974517822, "sampled_ll": -5.241433143615723, "all_perturbed_sampled_ll": [-5.241433143615723, -5.241433143615723, -5.241433143615723, -5.241433143615723, -5.241433143615723, -5.241433143615723, -5.241433143615723, -5.241433143615723, -5.241433143615723, -5.241433143615723], "all_perturbed_original_ll": [-4.683969974517822, -4.683969974517822, -4.683969974517822, -4.683969974517822, -4.683969974517822, -4.683969974517822, -4.683969974517822, -4.683969974517822, -4.683969974517822, -4.683969974517822], "perturbed_sampled_ll": -5.241433143615723, "perturbed_original_ll": -4.683969974517822, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Fix get_log_events() in AWS logs hook (#33290)", "sampled": "Fix get_log_events() in AWS logs hook (#33290)A", "perturbed_sampled": ["Fix get_log_events() in AWS logs hook (#33290)A", "Fix get_log_events() in AWS logs hook (#33290)A", "Fix get_log_events() in AWS logs hook (#33290)A", "Fix get_log_events() in AWS logs hook (#33290)A", "Fix get_log_events() in AWS logs hook (#33290)A", "Fix get_log_events() in AWS logs hook (#33290)A", "Fix get_log_events() in AWS logs hook (#33290)A", "Fix get_log_events() in AWS logs hook (#33290)A", "Fix get_log_events() in AWS logs hook (#33290)A", "Fix get_log_events() in AWS logs hook (#33290)A"], "perturbed_original": ["Fix get_log_events() in AWS logs hook (#33290)", "Fix get_log_events() in AWS logs hook (#33290)", "Fix get_log_events() in AWS logs hook (#33290)", "Fix get_log_events() in AWS logs hook (#33290)", "Fix get_log_events() in AWS logs hook (#33290)", "Fix get_log_events() in AWS logs hook (#33290)", "Fix get_log_events() in AWS logs hook (#33290)", "Fix get_log_events() in AWS logs hook (#33290)", "Fix get_log_events() in AWS logs hook (#33290)", "Fix get_log_events() in AWS logs hook (#33290)"], "original_ll": -5.497379302978516, "sampled_ll": -6.091218948364258, "all_perturbed_sampled_ll": [-6.091218948364258, -6.091218948364258, -6.091218948364258, -6.091218948364258, -6.091218948364258, -6.091218948364258, -6.091218948364258, -6.091218948364258, -6.091218948364258, -6.091218948364258], "all_perturbed_original_ll": [-5.497379302978516, -5.497379302978516, -5.497379302978516, -5.497379302978516, -5.497379302978516, -5.497379302978516, -5.497379302978516, -5.497379302978516, -5.497379302978516, -5.497379302978516], "perturbed_sampled_ll": -6.091218948364258, "perturbed_original_ll": -5.497379302978516, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Regenerate breeze help images on commmand option changes (#32624)", "sampled": "Regenerate breeze help images on commmand option changes (#32624)A", "perturbed_sampled": ["Regenerate breeze help images on commmand option changes (#32624)A", "Regenerate breeze help images on commmand option changes (#32624)A", "Regenerate breeze help images on commmand option changes (#32624)A", "Regenerate breeze help images on commmand option changes (#32624)A", "Regenerate breeze help images on commmand option changes (#32624)A", "Regenerate breeze help images on commmand option changes (#32624)A", "Regenerate breeze help images on commmand option changes (#32624)A", "Regenerate breeze help images on commmand option changes (#32624)A", "Regenerate breeze help images on commmand option changes (#32624)A", "Regenerate breeze help images on commmand option changes (#32624)A"], "perturbed_original": ["Regenerate breeze help images on commmand option changes (#32624)", "Regenerate breeze help images on commmand option changes (#32624)", "Regenerate breeze help images on commmand option changes (#32624)", "Regenerate breeze help images on commmand option changes (#32624)", "Regenerate breeze help images on commmand option changes (#32624)", "Regenerate breeze help images on commmand option changes (#32624)", "Regenerate breeze help images on commmand option changes (#32624)", "Regenerate breeze help images on commmand option changes (#32624)", "Regenerate breeze help images on commmand option changes (#32624)", "Regenerate breeze help images on commmand option changes (#32624)"], "original_ll": -7.068216800689697, "sampled_ll": -7.531179904937744, "all_perturbed_sampled_ll": [-7.531179904937744, -7.531179904937744, -7.531179904937744, -7.531179904937744, -7.531179904937744, -7.531179904937744, -7.531179904937744, -7.531179904937744, -7.531179904937744, -7.531179904937744], "all_perturbed_original_ll": [-7.068216800689697, -7.068216800689697, -7.068216800689697, -7.068216800689697, -7.068216800689697, -7.068216800689697, -7.068216800689697, -7.068216800689697, -7.068216800689697, -7.068216800689697], "perturbed_sampled_ll": -7.531179904937744, "perturbed_original_ll": -7.068216800689697, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse (#35697) * Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse * Remove es from OVERLOOKED_TESTS", "sampled": "Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse (#35697) * Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse (#35697) - Fix the JSONFormatter::getDefaultFields()", "perturbed_sampled": ["Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse (#35697) * Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse (#35697) Add unittest on the JSONFormatter::getDefaultFields()", "Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse (#35697) * Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse - Fix the JSONFormatter::getDefaultFields()", "Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse (#35697) * Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse (#35697) - Delete JSONFormatter::getDefaultFields()", "Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse. * Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse (#35697) - Fix the JSONFormatter::getDefaultFields()", "Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse (#35697) * Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse (#35697) - Fix the JSONFormatter::getDefaultFields()", "Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse (#35697) * Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse (#35697) - Fix the JSONFormatter::getDefaultFields()", "* Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse (#35697) * Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse (#35697) - Fix the JSONFormatter::getDefaultFields()", "Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse. * Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse (#35697) - Fix the JSONFormatter::getDefaultFields()", "* Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse (#35697) * Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse (#35697) - Fix the JSONFormatter::getDefaultFields()", "Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse (#35697) * Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse (#35697) - Fix the JSONFormatter::getDefaultFields()"], "perturbed_original": ["Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse (#35697) * Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse * Remove unittest for OVERLOOKED_TESTS", "Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse (#35697) * Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse * Remove es from OVERLOOKED_TESTS", "Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse (#35697) * Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse * Remove unittest from OVERLOOKED_TESTS", "Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse (#35697) * Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse * Remove es from OVERLOOKED_TESTS", "Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse (#35697) * Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse * Remove es from OVERLOOKED_TESTS", "Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse (#35697) * Add unittest for ElasticSearchJSONFormatter (#36989) * Remove es from OVERLOOKED_TESTS", "Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse (#35697) * Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse * Remove es from OVERLOOKED_TESTS", "Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse (#35697) * Remove unittest for ElasticSearchJSONFormatter and ElasticSearchResponse * Remove es from OVERLOOKED_TESTS", "Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse (#35697) * Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse * Remove es from OVERLOOKED_TESTS", "Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse (#35697) * Add unittest for ElasticSearchJSONFormatter and ElasticSearchResponse * Remove es from OVERLOOKED_TESTS"], "original_ll": -3.6142776012420654, "sampled_ll": -2.9625749588012695, "all_perturbed_sampled_ll": [-3.0411689281463623, -3.2619073390960693, -3.0311279296875, -3.1987924575805664, -2.9625749588012695, -2.9625749588012695, -2.928133964538574, -3.1987924575805664, -2.928133964538574, -2.9625749588012695], "all_perturbed_original_ll": [-3.2108359336853027, -3.6142776012420654, -3.234203577041626, -3.6142776012420654, -3.6142776012420654, -3.78786301612854, -3.6142776012420654, -3.690070152282715, -3.6142776012420654, -3.6142776012420654], "perturbed_sampled_ll": -3.0475781917572022, "perturbed_original_ll": -3.5608638286590577, "perturbed_sampled_ll_std": 0.11924373242598169, "perturbed_original_ll_std": 0.1773605195729771}, {"original": "Remove run_in_gke_cluster flag", "sampled": "Remove run_in_gke_cluster flagThe", "perturbed_sampled": ["Remove run_in_gke_cluster flagThe", "Remove run_in_gke_cluster flagThe", "Remove run_in_gke_cluster flagThe", "Remove run_in_gke_cluster flagThe", "Remove run_in_gke_cluster flagThe", "Remove run_in_gke_cluster flagThe", "Remove run_in_gke_cluster flagThe", "Remove run_in_gke_cluster flagThe", "Remove run_in_gke_cluster flagThe", "Remove run_in_gke_cluster flagThe"], "perturbed_original": ["Remove run_in_gke_cluster flag", "Remove run_in_gke_cluster flag", "Remove run_in_gke_cluster flag", "Remove run_in_gke_cluster flag", "Remove run_in_gke_cluster flag", "Remove run_in_gke_cluster flag", "Remove run_in_gke_cluster flag", "Remove run_in_gke_cluster flag", "Remove run_in_gke_cluster flag", "Remove run_in_gke_cluster flag"], "original_ll": -5.61243200302124, "sampled_ll": -6.164299011230469, "all_perturbed_sampled_ll": [-6.164299011230469, -6.164299011230469, -6.164299011230469, -6.164299011230469, -6.164299011230469, -6.164299011230469, -6.164299011230469, -6.164299011230469, -6.164299011230469, -6.164299011230469], "all_perturbed_original_ll": [-5.61243200302124, -5.61243200302124, -5.61243200302124, -5.61243200302124, -5.61243200302124, -5.61243200302124, -5.61243200302124, -5.61243200302124, -5.61243200302124, -5.61243200302124], "perturbed_sampled_ll": -6.164299011230469, "perturbed_original_ll": -5.61243200302124, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Split PROD image verification to a separate step in CI (#33140) The PROD image verification happens after the images are pulled in the \"wait for PROD images\" step. This verification is pretty helpful in detecting cases where there are some \"installed airflow\" problems (for example recently it helped to avoid a circular import problem in #33081 as one of the tests failed when images were verified. However PROD image wait might fail for other reasons and sometimes might be \"neglected\" as temporary failure. Separating verification will allow to clearly surface that the problem is with verification, not pulling the images.", "sampled": "Split PROD image verification to a separate step in CI (#33140) The PROD image verification happens after the images are pulled in the \"wait for results\" phase of the CI run and must now happen in the actual \"image validation process\".\n\nAdd \"image validation process\" step to the CI (PROD image verification) workflow as step(s) in the image validation process (#33130) \"image validation process\" is intended as a feature that could easily be added to both the \"image verification process\" and \"wait for results\" steps.\n\nThe ability to create separate workflow files that are used for image validation process and wait for", "perturbed_sampled": ["Split PROD image verification into a separate step in CI (#33140) The PROD image verification happens after the images are pulled in the \"wait for results\" phase of the CI run and must now be a separate step in the actual \"image validation process\".\n\nAdd \"image validation process\" to the CI (PROD ) workflow as step(s) in the image validation process (#33130) \"image validation process\" is intended as a feature that could easily be added to both the \"image verification process\" and \"wait for results\" steps.\n\nThe ability to create separate workflow files that are used for image verification and wait for", "Move image verification to a separate step in CI (#33140) Currently, image verification happens after the images are pulled in the \"wait for results step\" of the CI run and must now happen in the actual \"image validation process\".\n\nAdd \"image validation process\" step to CI (PROD image verification) workflow as step(s) in the image validation process (#33130) \"image validation process\" is now a feature that could easily be added to all of the \"image verification process\" and \"wait for results\" steps.\n\nThe ability to create separate workflow files that are used for image validation process and wait for", "Split PROD image verification to a separate step in CI (#33140) The PROD image verification happens after the images are pulled in the \"wait for results\" phase of the CI run and must now happen in the \"image validation process\".\n\nAdd \"image validation process\" step to the CI (prod image verification) workflow as step(s) in the image validation process (#33130) \"image validation process\" was suggested as a feature that could be added to both the \"image verification process\" and \"wait for results\" steps.\n\nThe ability to edit workflow files that are used for image validation process with JNI is also recommended for", "Split PROD image verification to a separate step in CI (#33140) The PROD image verification steps that occur after the images are processed are no longer to be included in the \"wait for results\" phase of CI run and must now happen in the actual \"image validation process\".\n\nAdd \"image validation process\" to the CI (PROD image verification) process step(s) in the image validation process (#33130) \"image validation process\" is seen as a feature that could easily be added to both the \"image verification process\" and \"wait for results\" process. The ability to create separate workflow files that are used for image validation process and wait for", "Split PROD image verification to a separate step in CI workflow PROD image verification happens after the images are pulled in the \"wait for results\" phase of the CI run and must now happen in the \"image validation process\".\n\nAdd \"image validation process\" step to CI (PROD image verification) workflow as step(s) in a separate workflow. PROD image verification and Image validation process (#33130) \"image validation process\" is intended as a feature that could easily be added to both the \"image verification process\" and \"wait for results\" steps.\n\nThe ability to create separate workflow s that are used for image validation process and wait for", "Move PROD image verification to a separate step in CI (#33140) The PROD image verification happens after the images are added to the \"wait for results\" phase of the CI run and enables it to happen in the actual \"image validation process\". Add \"image validation process\" step to the CI (PROD image verification as step(s) in CI) -> image validation process (#33130) \"image validation process\" is intended as a feature that could easily be added to both the \"image verification process\" and \"wait for results\" steps.\n\nThe ability to create separate workflow files that are used for image validation process and wait for", "Split PROD image verification to a separate step in CI (#33140) The PROD image verification happens after the images are pulled in the \"wait for results\" phase of the CI workflow and must now happen in the actual \"image validation process\".\n\nAdd \"image validation process\" step to the CI (PROD image verification) workflow as step(s) in the image verification process (#33130) \"image validation process\" is intended as a feature that could easily be added to both the \"image verification process\" and \"wait for results\" steps.\n\nThe ability to create separate workflow files that are used for image validation process and wait for", "Split PROD image verification process into a separate step in CI (#33140) The PROD image verification step was being used to take place after the images are pulled in the \"wait for results\" phase of the image validation process and must now happen in the actual \"image validation process\".\n\nAdd \"image validation process\" step to the CI (PROD image verification) workflow as step(s) in the image validation process (#33130) \"image validation process\" is intended as a feature that could easily be added to both the \"prod image verification process\" and \"wait for results\" steps.\n\nThe ability to create separate workflow files that are used for image validation and wait for", "Split PROD image verification into separate step in CI (#33140) The PROD image verification step used to happen after the images are pulled in the \"wait for results\" phase of the CI run and must now happen in the actual \"image validation process\".\n\nAdd \"image validation process\" step to the CI (PROD image verification) workflow file in the image validation process (#33130) \"image validation process\" step was intended as a separate step that would be added between the \"image verification process\" and \"wait for results\" steps.\n\nThe ability to create separate workflow files that are used for image validation process and wait for", "Split PROD image verification to a separate step in CI (#33140) The PROD image verification happens after images are pulled in the \"wait for results\" step of the CI run and does not happen in the actual \"image validation process\".\n\nAdd \"image validation process\" step to the CI (PROD image verification) workflow as step(s) in the image validation process (#33130) \"image validation process\" is intended as a feature that could easily be added to both the \"image verification \" step and \"wait for results\" steps.\n\nThe ability to create files after an image verification step (e.g. files that are used for image validation process and wait for"], "perturbed_original": ["Split PROD image verification to a separate step in CI (#33140) The PROD image verification happens after the images are pulled in the \"wait for PROD images\" step. This verification is pretty helpful in detecting cases where there are some \"installed airflow\" problems (for example, it helped to avoid a circular import problem in CI in which one of the tests failed when images were imported). However PROD image wait might fail for other reasons and sometimes might be a temporary failure. Separating verification from the image pull helps to clearly surface that the problem is with verification, not the images.", "Split PROD image verification to a separate procedure in CI (#33140) The PROD image verification happens after the images are pulled in the \"wait for PROD images\" step. This verification is very useful in detecting cases where there are some \"installed airflow\" problems (for example recently with CI we were able to avoid a circular import problem in #33081 ) because only some of the tests failed when images were verified. However PROD image verification can fail for other reasons and sometimes might be \"neglected\" because of another failure. Separating verification will allow the user to know from the error surface that the problem is with verification, not pulling the images.", "Split PROD verification to a test step in CI (#33140) The PROD image verification is also called \"pull check\" and the PROD images are pulled in the \"wait for PROD images\" step. This is pretty helpful in cases where there are some \"installed airflow\" problems (for example recently it helped to avoid a circular import problem in #33081 as one of the tests failed when images were verified. However PROD image wait might fail for other reasons and sometimes might be \"neglected\" as temporary failure. Separating verification will allow to clearly surface that the problem is with verification, not pulling the images.", "Split PROD image verification to a separate step in CI (#33140) The PROD image verification happens after the images are pulled in the \"wait for PROD images\" step. This verification is pretty helpful in detecting cases where the test might fail due to some \"installed airflow\" problems (for example recently was suggested to avoid a circular import problem in #33081 as some of the tests failed when the images were not immediately verified. However PROD image wait might fail for other reasons such as the update or sometimes might be \"neglected\" as temporary failure. Separating verification will allow to clearly surface that the problem deals with verification, not pulling the images.", "Split PROD image verification to a separate step in CI (#33140) The PROD image verification happens after the images are pulled in the \"wait for images\" step. This verification is pretty helpful in detecting cases where there are some \"installed airflow\" problems (for example recently it helped to identify some circular import problem in CI) or when one of the tests failed when images were verified. However PROD image wait might fail for other reason, the verification process sometimes might fail both as temporary failure. Separating verification will allow to clearly surface that the problem is with verification, not with the images.", "Split PROD image verification to a separate test in CI (#33140) The PROD image verification happens when the PROD images are pulled in the \"wait for PROD images\" step. This verification is pretty helpful in detecting cases where there are \"hot airflow\" problems (for example recently it helped to avoid an import problem in #33081 as one of the tests failed when PROD images are not verified. However PROD image wait might fail for other reasons and the check might be \"neglected\" as temporary failure. Separating verification will allow to clearly surface that the problem is with verification, not with the images.", "Split PROD image verification to a separate step in CI (#33140) The PROD image verification happens after the images are pulled in the \"wait for PROD images\" step. This verification is pretty helpful in detecting cases where there are \"installed airflow\" problems (for example recently it helped to spot a circular import problem in #33081 as one of the tests failed when images were not pulled). However verification during the wait might fail for other reasons and sometimes might be \"neglected\" as temporary failure. Separating verification will allow to clearly surface that the problem is with verification, not pulling the images.", "Split PROD image verification to a separate step in CI (#33140) The PROD image verification happens after the images are extracted and the \"wait for PROD images\" test does nothing. This step is pretty good in detecting cases where there are some \"installed airflow\" problems (for example recently it helped to avoid a circular import problem in #33081 as one of the tests failed when images were not imported). However PROD image wait might fail for other reasons and sometimes might be \"neglected\" as temporary failure. Separating verification will more clearly surface that the problem is with verification, not pulling the images.", "Split PROD image verification to a separate step in CI (#33140) The PROD image verification happens after the images are pulled in the \"Request PROD images\" step. This verification is pretty helpful in detecting cases where there are some \"installed airflow\" problems (for example it helped to fix circular problem in #33081 as one of the tests failed when images were not pulled). However PROD image wait might fail for various reasons, and sometimes might be \"neglected\" as temporary failure. Separating verification will more clearly surface that the problem is with verification, not pulling the images.", "Split PROD image verification to a separate step in the import process. The PROD verification happens after the images are pulled in the \"wait for PROD images\" step. This can be pretty helpful in detecting cases where there are some \"installed airflow\" bugs. For example recently it helped to avoid a circular import problem in #33081 as one of the tests failed when images were verified. However PROD image wait might fail for other reasons too or might be \"neglected\" as temporary failure. Separating verification will allow to clearly surface that the problem is in not pulling the images."], "original_ll": -4.433444976806641, "sampled_ll": -2.779688835144043, "all_perturbed_sampled_ll": [-2.8243818283081055, -3.0349819660186768, -2.997791051864624, -2.8223791122436523, -2.908972978591919, -3.0068001747131348, -2.762227773666382, -2.8347718715667725, -2.7909579277038574, -2.896066904067993], "all_perturbed_original_ll": [-4.095662593841553, -4.053795337677002, -4.248096942901611, -4.415895462036133, -4.432178020477295, -4.068053722381592, -4.31789493560791, -4.382513046264648, -4.297558307647705, -4.375189304351807], "perturbed_sampled_ll": -2.8879331588745116, "perturbed_original_ll": -4.268683767318725, "perturbed_sampled_ll_std": 0.09203182822226527, "perturbed_original_ll_std": 0.13883344774997877}, {"original": "Standardize AWS lambda naming (#29749) closes: https://github.com/apache/airflow/issues/29677", "sampled": "Standardize AWS lambda naming (#29749) closes: https://github.com/apache/airflow/issues/29677When", "perturbed_sampled": ["Standardize AWS lambda naming (#29749) closes: https://github.com/apache/airflow/issues/29677When", "Standardize AWS lambda naming (#29749) closes: https://github.com/apache/airflow/issues/29677When", "Standardize AWS lambda naming (#29749) closes: https://github.com/apache/airflow/issues/29677When", "Standardize AWS lambda naming (#29749) closes: https://github.com/apache/airflow/issues/29677When", "Standardize AWS lambda naming (#29749) closes: https://github.com/apache/airflow/issues/29677When", "Standardize AWS lambda naming (#29749) closes: https://github.com/apache/airflow/issues/29677When", "Standardize AWS lambda naming (#29749) closes: https://github.com/apache/airflow/issues/29677When", "Standardize AWS lambda naming (#29749) closes: https://github.com/apache/airflow/issues/29677When", "Standardize AWS lambda naming (#29749) closes: https://github.com/apache/airflow/issues/29677When", "Standardize AWS lambda naming (#29749) closes: https://github.com/apache/airflow/issues/29677When"], "perturbed_original": ["Standardize AWS lambda naming (#29749) closes: https://github.com/apache/airflow/issues/29677", "Standardize AWS lambda naming (#29749) closes: https://github.com/apache/airflow/issues/29677", "Standardize AWS lambda naming (#29749) closes: https://github.com/apache/airflow/issues/29677", "Standardize AWS lambda naming (#29749) closes: https://github.com/apache/airflow/issues/29677", "Standardize AWS lambda naming (#29749) closes: https://github.com/apache/airflow/issues/29677", "Standardize AWS lambda naming (#29749) closes: https://github.com/apache/airflow/issues/29677", "Standardize AWS lambda naming (#29749) closes: https://github.com/apache/airflow/issues/29677", "Standardize AWS lambda naming (#29749) closes: https://github.com/apache/airflow/issues/29677", "Standardize AWS lambda naming (#29749) closes: https://github.com/apache/airflow/issues/29677", "Standardize AWS lambda naming (#29749) closes: https://github.com/apache/airflow/issues/29677"], "original_ll": -4.03464412689209, "sampled_ll": -4.379626750946045, "all_perturbed_sampled_ll": [-4.379626750946045, -4.379626750946045, -4.379626750946045, -4.379626750946045, -4.379626750946045, -4.379626750946045, -4.379626750946045, -4.379626750946045, -4.379626750946045, -4.379626750946045], "all_perturbed_original_ll": [-4.03464412689209, -4.03464412689209, -4.03464412689209, -4.03464412689209, -4.03464412689209, -4.03464412689209, -4.03464412689209, -4.03464412689209, -4.03464412689209, -4.03464412689209], "perturbed_sampled_ll": -4.379626750946045, "perturbed_original_ll": -4.03464412689209, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Add `sql_hook_params` parameter to `S3ToSqlOperator` (#33427) Adding `sql_hook_params` parameter to `SqlToS3Operator`. This will allow you to pass extra config params to the underlying SQL hook. This uses the same \"sql_hook_params\" parameter name as already used in `SqlToSlackOperator`.", "sampled": "Add `sql_hook_params` parameter to `S3ToSqlOperator` (#33427) Adding `sql_hook_params` parameter to `get_field` (#32379) Adding `sql_hook_params` parameter to `list_field` (#31506) Removed the `--no-fetch-from` option (#33629) Updated libsql to 3.2 (#30973)\n\nRemoved the `--no-fetch-from` option (#33629) Updated libsql to 3.2 (#30973)", "perturbed_sampled": ["Add `sql_hook_params` parameter to `S3ToSqlOperator` (#33427) Adding `sql_hook_params` parameter to `get_field` (#32379) Adding `sql_hook_params` parameter to `list_field` (#31506) Removed the `--no-fetch-from` option (#32624) Updated libsql to 3.0.2 Removed the `--no-fetch-from` option (#33629) Updated libsql to 3.2 (#30973)", "Add `sql_hook_params` parameter to `S3ToSqlOperator` (#33427) Adding `sql_hook_params` parameter to `get_field` (#32379) Adding `sql_hook_params` parameter to <unk>get<unk> (#30094) Removed the default operator (#33629) Updated libsql to 3.2 (#30973)\n\nRemoved the `--no-fetch-from` option (#33629) Updated libsql to 3.2 (#30973)", "Add `sql_hook_params` parameter to `S3ToSqlOperator` (#33427) Adding this parameter to `get_field` (#32379) Adding `sql_hook_params` parameter to `list_field` (#31506) Removed the `--no-fetch-from` option (#33629) Updated libsql to 3.2 (#30973)\n\nRemoved the `--no-fetch-from` option (#33629) Updated libsql to 3.2 (#30973)", "Add `sql_hook_params` parameter to `S3ToSqlOperator` (#33427) Adding `sql_hook_params` parameter to `get_field` (#32379) Adding `sql_hook_params` parameter to `list_field` (#31506) Removed the `--no-fetch-from` option (#33629) Updated libsql to 3.2 (#30973)\n\nRemoved the `--no-fetch-from` option (#33629) Updated libsql to 3.2 (#30973)", "Add `sql_hook_params` parameter to `S3ToSqlOperator` (#33427) Adding one parameter to `get_field` (#32379) Adding one parameter to `list_field` (#31506) Removed the `--no-fetch-from` option (#33629) Updated libsql to 3.2 (#30973)\n\nRemoved the `--no-fetch-from` option (#33629) Updated libsql to 3.2 (#30973)", "Add `sql_hook_params` parameter to `S3ToSqlOperator` (#33427) Adding `sql_hook_params` parameter to `get_field` (#32379) Adding `sql_hook_params` parameter to <unk>show<unk> (#31506) Removed the `--no-fetch-from` option (#33629) Updated libsql to 3.2 (#30973)\n\nRemoved the `--no-fetch-from` option (#33629) Updated libsql to 3.2 (#30973)", "Add `sql_hook_params` parameter to `S3ToSqlOperator` (#33427) Adding `sql_hook_params` parameter to `get_field` (#32379) Adding `sql_hook_params` parameter to <unk>report<unk> (#31506) Removed the `--no-fetch-from` option (#33629) Updated libsql to 3.2 (#30973)\n\nRemoved the `--no-fetch-from` option (#33629) Updated libsql to 3.2 (#30973)", "Add `sql_hook_params` parameter to `S3ToSqlOperator` (#33427) Adding `sql_hook_params` parameter to `get_field` (#33429) Adding `sql_hook_params` parameter to `list_field` (#31506) Removed the `--no-fetch-from` option (#33629) Updated libsql to 3.2 (#30973)\n\nRemoved the `--no-fetch-from` option (#33629) Updated libsql to 3.2 (#30973)", "Add interface to `S3ToSqlOperator` (#33427) Adding `sql_hook_params` parameter to `get_field` (#32379) Adding `sql_hook_params` parameter to `list_field` (#31506) Removed the `--no-fetch-from` option (#33629) Updated libsql to 3.2 (#30973)\n\nRemoved the `--no-fetch-from` option (#33629) Updated libsql to 3.2 (#30973)", "Add `sql_hook_params` parameter to <unk>ct*<unk> (#33427) Adding `sql_hook_params` parameter to `get_field` (#32379) Adding `sql_hook_params` parameter to `list_field` (#31506) Removed the `--no-fetch-from` option (#33629) Updated libsql to 3.2 (#30973)\n\nRemoved the `--no-fetch-from` option (#33629) Updated libsql to 3.2 (#30973)"], "perturbed_original": ["Add `sql_hook_params` parameter to `S3ToSqlOperator` (#33427) . add <unk>sql_hook_params<unk> parameter to `SqlToS3Operator`. This will allow you to pass extra config params to the SQL hook. This uses the same \"sql_hook_params\" parameter name as already used in `SqlToSlackOperator`.", "Add `sql_hook_params` parameter to S3Operator. (#33427) Adding `sql_hook_params` parameter to `SqlToS3Operator`. This allows you to pass extra config params to the underlying SQL hook. This uses the same \"sql_hook_params\" parameter name as already used in `SqlToSlackOperator`.", "Add `sql_hook_params` parameter to `S3ToSqlOperator` (#33427) Adding `sql_hook_params` parameter to `SqlToS3Operator`. This will allow you to pass extra config params to the underlying SQL hook. This uses the same \"sql_hook_params\" parameter as already used in `SqlToSlackOperator`.", "Add `sql_hook_params` parameter to `S3ToSqlOperator` (#33427) Adding `sql_hook_params` parameter to `SqlToS3Operator`. This will allow S32 SQL hook operators to pass extra config params to the underlying SQL hook. This uses the same \"sql_hook_params\" parameter name as already used in `SqlToSlackOperator`.", "Add `sql_hook_params` parameter to `S3ToSqlOperator` (#33427) Adding `sql_hook_params` parameter to `SqlToS3Operator`. This will allow you to pass config params to the underlying SQL hook. This uses the same \"sql_hook_params\" parameter name as already used in `SqlToSlackOperator`.", "Add `sql_hook_params` parameter to `S3ToSqlOperator` (#33427) Adding `sql_hook_params` parameter to S3ToSqlOperator will allow you to pass SQL hook params to the underlying SQL hook. This uses the same \"sql_hook_params\" parameter name as already used in `SqlToSlackOperator`.", "Add `sql_hook_params` parameter to `S3ToSqlOperator` (#33427) Adding `sql_hook_params` parameter is now implemented in <unk>S3ToSqlOperator<unk>. This will allow you to pass extra config params to the underlying SQL hook. This has the same \"sql_hook_params\" parameter name as already used in `SqlToSlackOperator`.", "Add `sql_hook_params` parameter to `S3ToSqlOperator` (#33427) Adding `sql_hook_params` parameter to `SqlToS3Operator`. This will allow you to provide extra config params to the underlying SQL hook. This parameter provides the same \"sql_hook_params\" parameter name as already used in `SqlToSlackOperator`.", "Add `sql_hook_params` parameter to <unk>SqlToS3Operator<unk>. Adding `sql_hook_params` parameter to `SqlToS3Operator`. This will allow you to pass extra config params to the underlying SQL hook. This uses the same \"sql_hook_params\" parameter name as already used in `SqlToSlackOperator`.", "Add `sql_hook_params` parameter to `S3ToSqlOperator` (#33427) Adding `sql_hook_params` parameter to `SqlToS3Operator`. This will allow you to pass extra config params to be specified in the SQL () method, which uses the same \"sql_hook_params\" parameter name as already used in `SqlToSlackOperator`."], "original_ll": -2.8887763023376465, "sampled_ll": -2.027217149734497, "all_perturbed_sampled_ll": [-2.3368148803710938, -2.8024635314941406, -2.2665841579437256, -2.027217149734497, -2.372972249984741, -2.3998537063598633, -2.4185216426849365, -2.009028911590576, -2.1874356269836426, -2.1510465145111084], "all_perturbed_original_ll": [-3.1752536296844482, -2.9811573028564453, -2.86761736869812, -3.109912872314453, -2.8768718242645264, -2.829488754272461, -3.2334744930267334, -3.0303280353546143, -2.9790854454040527, -3.04414963722229], "perturbed_sampled_ll": -2.2971938371658327, "perturbed_original_ll": -3.0127339363098145, "perturbed_sampled_ll_std": 0.21866376865577827, "perturbed_original_ll_std": 0.12692703472762867}, {"original": "Ensure Beam Go file downloaded from GCS still exists when referenced (#28664)", "sampled": "Ensure Beam Go file downloaded from GCS still exists when referenced (#28664)We", "perturbed_sampled": ["Ensure Beam Go file downloaded from GCS still exists when referenced (#28664)We", "Ensure Beam Go file downloaded from GCS still exists when referenced (#28664)We", "Ensure Beam Go file downloaded from GCS still exists when referenced (#28664)We", "Ensure Beam Go file downloaded from GCS still exists when referenced (#28664)We", "Ensure Beam Go file downloaded from GCS still exists when referenced (#28664)We", "Ensure Beam Go file downloaded from GCS still exists when referenced (#28664)We", "Ensure Beam Go file downloaded from GCS still exists when referenced (#28664)We", "Ensure Beam Go file downloaded from GCS still exists when referenced (#28664)We", "Ensure Beam Go file downloaded from GCS still exists when referenced (#28664)We", "Ensure Beam Go file downloaded from GCS still exists when referenced (#28664)We"], "perturbed_original": ["Ensure Beam Go file downloaded from GCS still exists when referenced (#28664)", "Ensure Beam Go file downloaded from GCS still exists when referenced (#28664)", "Ensure Beam Go file downloaded from GCS still exists when referenced (#28664)", "Ensure Beam Go file downloaded from GCS still exists when referenced (#28664)", "Ensure Beam Go file downloaded from GCS still exists when referenced (#28664)", "Ensure Beam Go file downloaded from GCS still exists when referenced (#28664)", "Ensure Beam Go file downloaded from GCS still exists when referenced (#28664)", "Ensure Beam Go file downloaded from GCS still exists when referenced (#28664)", "Ensure Beam Go file downloaded from GCS still exists when referenced (#28664)", "Ensure Beam Go file downloaded from GCS still exists when referenced (#28664)"], "original_ll": -7.441502094268799, "sampled_ll": -7.8964691162109375, "all_perturbed_sampled_ll": [-7.8964691162109375, -7.8964691162109375, -7.8964691162109375, -7.8964691162109375, -7.8964691162109375, -7.8964691162109375, -7.8964691162109375, -7.8964691162109375, -7.8964691162109375, -7.8964691162109375], "all_perturbed_original_ll": [-7.441502094268799, -7.441502094268799, -7.441502094268799, -7.441502094268799, -7.441502094268799, -7.441502094268799, -7.441502094268799, -7.441502094268799, -7.441502094268799, -7.441502094268799], "perturbed_sampled_ll": -7.8964691162109375, "perturbed_original_ll": -7.441502094268799, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Update callbacks documentation (errors and context) (#31116)", "sampled": "Update callbacks documentation (errors and context) (#31116)For", "perturbed_sampled": ["Update callbacks documentation (errors and context) (#31116)For", "Update callbacks documentation (errors and context) (#31116)For", "Update callbacks documentation (errors and context) (#31116)For", "Update callbacks documentation (errors and context) (#31116)For", "Update callbacks documentation (errors and context) (#31116)For", "Update callbacks documentation (errors and context) (#31116)For", "Update callbacks documentation (errors and context) (#31116)For", "Update callbacks documentation (errors and context) (#31116)For", "Update callbacks documentation (errors and context) (#31116)For", "Update callbacks documentation (errors and context) (#31116)For"], "perturbed_original": ["Update callbacks documentation (errors and context) (#31116)", "Update callbacks documentation (errors and context) (#31116)", "Update callbacks documentation (errors and context) (#31116)", "Update callbacks documentation (errors and context) (#31116)", "Update callbacks documentation (errors and context) (#31116)", "Update callbacks documentation (errors and context) (#31116)", "Update callbacks documentation (errors and context) (#31116)", "Update callbacks documentation (errors and context) (#31116)", "Update callbacks documentation (errors and context) (#31116)", "Update callbacks documentation (errors and context) (#31116)"], "original_ll": -5.859376907348633, "sampled_ll": -6.637690544128418, "all_perturbed_sampled_ll": [-6.637690544128418, -6.637690544128418, -6.637690544128418, -6.637690544128418, -6.637690544128418, -6.637690544128418, -6.637690544128418, -6.637690544128418, -6.637690544128418, -6.637690544128418], "all_perturbed_original_ll": [-5.859376907348633, -5.859376907348633, -5.859376907348633, -5.859376907348633, -5.859376907348633, -5.859376907348633, -5.859376907348633, -5.859376907348633, -5.859376907348633, -5.859376907348633], "perturbed_sampled_ll": -6.637690544128418, "perturbed_original_ll": -5.859376907348633, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Doc: Explicitly specify Py 3.10 will be supported from Airflow 2.3.0 (#22602) Based on the feedback in https://github.com/apache/airflow/issues/19059#issuecomment-1080597936 -- this PR makes it explicit", "sampled": "Doc: Explicitly specify Py 3.10 will be supported from Airflow 2.3.0 (#22602) Based on the feedback in https://www.reddit.com/r/Celery/comments/49d6xv/explicitly_specify_py_3_10_will_be_supported_from_airflow_2_3/ and https://www.stackoverflow.com/a/277527/256516/ This commit fixes an", "perturbed_sampled": ["Doc: Explicitly specify Py 3.10 will be supported from Airflow 2.3.0 (#22602) Based on the feedback in https://www.reddit.com/r/Celery/comments/49d6xv/explicitly_specify_py_3_10_will_be_supported_from_airflow_2_3/ . This commit fixes an", "Doc: Explicitly specify Py 3.10 will be supported from Airflow 2.3.0 (#22602) Based on the comments on https://www.reddit.com/r/Celery/comments/49d6xv/explicitly_specify_py_3_10_will_be_supported_from_airflow_2_3/ and https://www.stackoverflow.com/a/277527/256516/ This commit fixes an", "Doc: Explicitly specify Py3_10 will be supported from Airflow 2.3.0 (#22602) Based on the feedback in https://www.reddit.com/r/Celery/comments/49d6xv/explicitly_specify_py_3_10_will_be_supported_from_airflow_2_3/ and https://www.stackoverflow.com/a/277527/256516/ This commit fixes an", "Doc: Explicitly specify Py 3.10 will be supported from Airflow 2.3. Based on the feedback in https://www.reddit.com/r/Celery/comments/49d6xv/explicitly_specify_py_3_10_will_be_supported_from_airflow_2_3/ and https://www.stackoverflow.com/a/277527/256516/ This commit fixes an", "Doc: Explicitly specify Py 3.10 will be supported from Airflow 2.3.0 (#22602) ; this commit should be included in the Airflow 2.3.0 release. This commit builds upon the feedback in https://www.reddit.com/r/Celery/comments/49d6xv/explicitly_specify_py_3_10_will_be_supported_from_airflow_2_3/ and https://www.stackoverflow.com/a/277527/256516/ This commit fixes an", "Doc: Explicitly specify Py 3.10 will be supported from Airflow 2.3.0 (#22602) Based on the feedback in https://www.reddit.com/r/Celery/comments/49d6xv/explicitly_specify_py_3_10_will_be_supported_from_airflow_2_3/ and https://www.stackoverflow.com/a/277527/256516/ This commit fixes an", "Doc: Explicitly specify that Py3-10 will be supported from Airflow 2.3.0 (#22602) Based on the feedback in https://www.reddit.com/r/Celery/comments/49d6xv/explicitly_specify_py_3_10_will_be_supported_from_airflow_2_3/ and https://www.stackoverflow.com/a/277527/256516/ This commit fixes an", "Doc: Explicitly specify Py 3.10 will be supported from Airflow 2.3.0 (#22602) Based on the feedback in https://www.reddit.com/r/Celery/comments/49d6xv/explicitly_specify_py_3_10_will_be_supported_from_airflow_2_3/ and https://www.stackoverflow.com/a/277527/256516/ This commit fixes an", "Doc: Explicitly specify Py 3.10 will be supported from Airflow 2.3.0 . Based on the feedback in https://www.reddit.com/r/Celery/comments/49d6xv/explicitly_specify_py_3_10_will_be_supported_from_airflow_2_3/ and https://www.stackoverflow.com/a/277527/256516/ This commit fixes an", "directly specify Py 3.10 will be supported from Airflow 2.3.0 (#22602) Based on the feedback in https://www.reddit.com/r/Celery/comments/49d6xv/explicitly_specify_py_3_10_will_be_supported_from_airflow_2_3/ and https://www.stackoverflow.com/a/277527/256516/ This commit fixes an"], "perturbed_original": ["Doc: Explicitly specify Py 3.10 will be supported from Airflow 2.3.0 (#22602) Specifically I am using the feedback in https://github.com/apache/airflow/issues/19059#issuecomment-1080597936 -- this PR makes it explicit", "Doc: Explicitly specify Py 3.10 will be upgraded from Airflow 2.3.0 (#22602) Based on the feedback in https://github.com/apache/airflow/issues/19059#issuecomment-1080597936 -- this PR makes it explicit", "Doc: Explicitly specify Py 3.10 will be supported from Airflow 2.3.0 . Based on the feedback in https://github.com/apache/airflow/issues/19059#issuecomment-1080597936 -- this PR makes it explicit", "Doc: Explicitly specify Py 3.10 will be supported from Airflow 2.3.0 . Based on the feedback in https://github.com/apache/airflow/issues/19059#issuecomment-1080597936 -- this PR makes it explicit", "Doc: Explicitly specify Py 3.10 will be supported from Airflow 2.3.0 (#22602) Based on feedback in https://github.com/apache/airflow/issues/19059#issuecomment-1080597936 -- this PR makes it explicit", "Doc: Explicitly specify Py 3.10 will be supported from Airflow 2.3.0 . Based on the feedback in https://github.com/apache/airflow/issues/19059#issuecomment-1080597936 -- this PR makes it explicit", "Doc: Explicitly specify Py 3.10 will inherit from Airflow 2.3.0 (#22602) Based on the feedback in https://github.com/apache/airflow/issues/19059#issuecomment-1080597936 -- this PR makes it explicit", "Doc: Explicitly specify Py 3.10 will be supported from Airflow 2.3.0 (#22602) Based on feedback in https://github.com/apache/airflow/issues/19059#issuecomment-1080597936 -- this PR makes it explicit", "Doc: Explicitly specify Py 3.10 will be supported from Airflow 2.3.0 (#22602) Based on feedback in https://github.com/apache/airflow/issues/19059#issuecomment-1080597936 -- this PR makes it explicit", "Doc: Explicitly specify Py 3.10 will be supported from Airflow 2.3.0 (#22602) Based on the feedback in the mail this PR makes it explicit"], "original_ll": -3.683952808380127, "sampled_ll": -2.2651777267456055, "all_perturbed_sampled_ll": [-2.2929670810699463, -2.2315640449523926, -2.381133794784546, -2.1837403774261475, -2.2654237747192383, -2.2651777267456055, -2.352524757385254, -2.2651777267456055, -2.2138009071350098, -2.3907973766326904], "all_perturbed_original_ll": [-3.9053473472595215, -3.7521331310272217, -3.6043150424957275, -3.6043150424957275, -3.7086257934570312, -3.6043150424957275, -3.7014079093933105, -3.7086257934570312, -3.7086257934570312, -4.4872941970825195], "perturbed_sampled_ll": -2.2842307567596434, "perturbed_original_ll": -3.778500509262085, "perturbed_sampled_ll_std": 0.06663275335880553, "perturbed_original_ll_std": 0.25115458944998387}, {"original": "Align documentation of `MSSQLToGCSOperator` (#35715) Co-authored-by: hasan.guercan <hasan.guercan@bonial.com>", "sampled": "Align documentation of `MSSQLToGCSOperator` (#35715) Co-authored-by: hasan.guercan@gmail.com\n\n@InProceedings{gcm2shq6201a007:2015, author", "perturbed_sampled": ["Align documentation of `MSSQLToGCSOperator` (#35715) Co-authored-by: hasan.guercan@gmail.com\n\n@InProceedings{gcm2shq6201a007:2015, author", "Align documentation of `MSSQLToGCSOperator` (#35715) Co-authored-by: hasan.guercan@gmail.com\n\n@InProceedings{gcm2shq6201a007:2015, author", "Align documentation of `MSSQLToGCSOperator` (#35715) Co-authored-by: hasan.guercan@gmail.com\n\n@InProceedings{gcm2shq6201a007:2015, author", "Align documentation of `MSSQLToGCSOperator` (#35715) Co-authored-by: hasan.guercan@gmail.com\n\n@InProceedings{gcm2shq6201a007:2015, author", "Align documentation of `MSSQLToGCSOperator` (#35715) Co-authored-by: hasan.guercan@gmail.com\n\n@InProceedings{gcm2shq6201a007:2015, author", "Align documentation of `MSSQLToGCSOperator` (#35715) Co-authored-by: hasan.guercan@gmail.com\n\n@InProceedings{gcm2shq6201a007:2015, author", "Align documentation of `MSSQLToGCSOperator` (#35715) Co-authored-by: hasan.guercan@gmail.com\n\n@InProceedings{gcm2shq6201a007:2015, author", "Align documentation of `MSSQLToGCSOperator` (#35715) Co-authored-by: hasan.guercan@gmail.com\n\n@InProceedings{gcm2shq6201a007:2015, author", "Align documentation of `MSSQLToGCSOperator` (#35715) Co-authored-by: hasan.guercan@gmail.com\n\n@InProceedings{gcm2shq6201a007:2015, author", "Align documentation of `MSSQLToGCSOperator` (#35715) Co-authored-by: hasan.guercan@gmail.com\n\n@InProceedings{gcm2shq6201a007:2015, author"], "perturbed_original": ["Align documentation of `MSSQLToGCSOperator` (#35715) Co-authored-by: hasan.guercan <hasan.guercan@bonial.com>", "Align documentation of `MSSQLToGCSOperator` (#35715) Co-authored-by: hasan.guercan <hasan.guercan@bonial.com>", "Align documentation of `MSSQLToGCSOperator` (#35715) Co-authored-by: hasan.guercan <hasan.guercan@bonial.com>", "Align documentation of `MSSQLToGCSOperator` (#35715) Co-authored-by: hasan.guercan <hasan.guercan@bonial.com>", "Align documentation of `MSSQLToGCSOperator` (#35715) Co-authored-by: hasan.guercan <hasan.guercan@bonial.com>", "Align documentation of `MSSQLToGCSOperator` (#35715) Co-authored-by: hasan.guercan <hasan.guercan@bonial.com>", "Align documentation of `MSSQLToGCSOperator` (#35715) Co-authored-by: hasan.guercan <hasan.guercan@bonial.com>", "Align documentation of `MSSQLToGCSOperator` (#35715) Co-authored-by: hasan.guercan <hasan.guercan@bonial.com>", "Align documentation of `MSSQLToGCSOperator` (#35715) Co-authored-by: hasan.guercan <hasan.guercan@bonial.com>", "Align documentation of `MSSQLToGCSOperator` (#35715) Co-authored-by: hasan.guercan <hasan.guercan@bonial.com>"], "original_ll": -4.493741512298584, "sampled_ll": -4.128293514251709, "all_perturbed_sampled_ll": [-4.128293514251709, -4.128293514251709, -4.128293514251709, -4.128293514251709, -4.128293514251709, -4.128293514251709, -4.128293514251709, -4.128293514251709, -4.128293514251709, -4.128293514251709], "all_perturbed_original_ll": [-4.493741512298584, -4.493741512298584, -4.493741512298584, -4.493741512298584, -4.493741512298584, -4.493741512298584, -4.493741512298584, -4.493741512298584, -4.493741512298584, -4.493741512298584], "perturbed_sampled_ll": -4.128293514251709, "perturbed_original_ll": -4.493741512298584, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Add extraVolumeMounts to sidecars too (#27420) Co-authored-by: Triomphe Jules, INI-DNA-INF <Jules.Triomphe@swisscom.com>", "sampled": "Add extraVolumeMounts to sidecars too (#27420) Co-authored-by: Triomphe Jules, INI-DNA-Granite\n\n3.4.0 Fixes:\n\n-", "perturbed_sampled": ["Add extraVolumeMounts to sidecars too (#27420) Co-authored-by: Triomphe Jules, INI-DNA-Granite\n\n3.4.0 Fixes:\n\n-", "Add extraVolumeMounts to sidecars too (#27420) Co-authored-by: Triomphe Jules, INI-DNA-Granite\n\n3.4.0 Fixes:\n\n-", "Add extraVolumeMounts to sidecars too (#27420) Co-authored-by: Triomphe Jules, INI-DNA-Granite\n\n3.4.0 Fixes:\n\n-", "Add extraVolumeMounts to sidecars too (#27420) Co-authored-by: Triomphe Jules, INI-DNA-Granite\n\n3.4.0 Fixes:\n\n-", "Add extraVolumeMounts to sidecars too (#27420) Co-authored-by: Triomphe Jules, INI-DNA-Granite\n\n3.4.0 Fixes:\n\n-", "Add extraVolumeMounts to sidecars too (#27420) Co-authored-by: Triomphe Jules, INI-DNA-Granite\n\n3.4.0 Fixes:\n\n-", "Add extraVolumeMounts to sidecars too (#27420) Co-authored-by: Triomphe Jules, INI-DNA-Granite\n\n3.4.0 Fixes:\n\n-", "Add extraVolumeMounts to sidecars too (#27420) Co-authored-by: Triomphe Jules, INI-DNA-Granite\n\n3.4.0 Fixes:\n\n-", "Add extraVolumeMounts to sidecars too (#27420) Co-authored-by: Triomphe Jules, INI-DNA-Granite\n\n3.4.0 Fixes:\n\n-", "Add extraVolumeMounts to sidecars too (#27420) Co-authored-by: Triomphe Jules, INI-DNA-Granite\n\n3.4.0 Fixes:\n\n-"], "perturbed_original": ["Add extraVolumeMounts to sidecars too (#27420) Co-authored-by: Triomphe Jules, INI-DNA-INF <Jules.Triomphe@swisscom.com>", "Add extraVolumeMounts to sidecars too (#27420) Co-authored-by: Triomphe Jules, INI-DNA-INF <Jules.Triomphe@swisscom.com>", "Add extraVolumeMounts to sidecars too (#27420) Co-authored-by: Triomphe Jules, INI-DNA-INF <Jules.Triomphe@swisscom.com>", "Add extraVolumeMounts to sidecars too (#27420) Co-authored-by: Triomphe Jules, INI-DNA-INF <Jules.Triomphe@swisscom.com>", "Add extraVolumeMounts to sidecars too (#27420) Co-authored-by: Triomphe Jules, INI-DNA-INF <Jules.Triomphe@swisscom.com>", "Add extraVolumeMounts to sidecars too (#27420) Co-authored-by: Triomphe Jules, INI-DNA-INF <Jules.Triomphe@swisscom.com>", "Add extraVolumeMounts to sidecars too (#27420) Co-authored-by: Triomphe Jules, INI-DNA-INF <Jules.Triomphe@swisscom.com>", "Add extraVolumeMounts to sidecars too (#27420) Co-authored-by: Triomphe Jules, INI-DNA-INF <Jules.Triomphe@swisscom.com>", "Add extraVolumeMounts to sidecars too (#27420) Co-authored-by: Triomphe Jules, INI-DNA-INF <Jules.Triomphe@swisscom.com>", "Add extraVolumeMounts to sidecars too (#27420) Co-authored-by: Triomphe Jules, INI-DNA-INF <Jules.Triomphe@swisscom.com>"], "original_ll": -4.7904276847839355, "sampled_ll": -4.5839691162109375, "all_perturbed_sampled_ll": [-4.5839691162109375, -4.5839691162109375, -4.5839691162109375, -4.5839691162109375, -4.5839691162109375, -4.5839691162109375, -4.5839691162109375, -4.5839691162109375, -4.5839691162109375, -4.5839691162109375], "all_perturbed_original_ll": [-4.7904276847839355, -4.7904276847839355, -4.7904276847839355, -4.7904276847839355, -4.7904276847839355, -4.7904276847839355, -4.7904276847839355, -4.7904276847839355, -4.7904276847839355, -4.7904276847839355], "perturbed_sampled_ll": -4.5839691162109375, "perturbed_original_ll": -4.7904276847839355, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Refresh GKE OAuth2 tokens (#32673) * Refresh token for sync mode", "sampled": "Refresh GKE OAuth2 tokens (#32673) * Refresh token for sync modeRouter.get(\"oauth2://token#\"", "perturbed_sampled": ["Refresh GKE OAuth2 tokens (#32673) * Refresh token for sync modeRouter.get(\"oauth2://token#\"", "Refresh GKE OAuth2 tokens (#32673) * Refresh token for sync modeRouter.get(\"oauth2://token#\"", "Refresh GKE OAuth2 tokens (#32673) * Refresh token for sync modeRouter.get(\"oauth2://token#\"", "Refresh GKE OAuth2 tokens (#32673) * Refresh token for sync modeRouter.get(\"oauth2://token#\"", "Refresh GKE OAuth2 tokens (#32673) * Refresh token for sync modeRouter.get(\"oauth2://token#\"", "Refresh GKE OAuth2 tokens (#32673) * Refresh token for sync modeRouter.get(\"oauth2://token#\"", "Refresh GKE OAuth2 tokens (#32673) * Refresh token for sync modeRouter.get(\"oauth2://token#\"", "Refresh GKE OAuth2 tokens (#32673) * Refresh token for sync modeRouter.get(\"oauth2://token#\"", "Refresh GKE OAuth2 tokens (#32673) * Refresh token for sync modeRouter.get(\"oauth2://token#\"", "Refresh GKE OAuth2 tokens (#32673) * Refresh token for sync modeRouter.get(\"oauth2://token#\""], "perturbed_original": ["Refresh GKE OAuth2 tokens (#32673) * Refresh token for sync mode", "Refresh GKE OAuth2 tokens (#32673) * Refresh token for sync mode", "Refresh GKE OAuth2 tokens (#32673) * Refresh token for sync mode", "Refresh GKE OAuth2 tokens (#32673) * Refresh token for sync mode", "Refresh GKE OAuth2 tokens (#32673) * Refresh token for sync mode", "Refresh GKE OAuth2 tokens (#32673) * Refresh token for sync mode", "Refresh GKE OAuth2 tokens (#32673) * Refresh token for sync mode", "Refresh GKE OAuth2 tokens (#32673) * Refresh token for sync mode", "Refresh GKE OAuth2 tokens (#32673) * Refresh token for sync mode", "Refresh GKE OAuth2 tokens (#32673) * Refresh token for sync mode"], "original_ll": -5.767279624938965, "sampled_ll": -4.948594570159912, "all_perturbed_sampled_ll": [-4.948594570159912, -4.948594570159912, -4.948594570159912, -4.948594570159912, -4.948594570159912, -4.948594570159912, -4.948594570159912, -4.948594570159912, -4.948594570159912, -4.948594570159912], "all_perturbed_original_ll": [-5.767279624938965, -5.767279624938965, -5.767279624938965, -5.767279624938965, -5.767279624938965, -5.767279624938965, -5.767279624938965, -5.767279624938965, -5.767279624938965, -5.767279624938965], "perturbed_sampled_ll": -4.948594570159912, "perturbed_original_ll": -5.767279624938965, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "D205 Support - Auto-fixes and Stragglers (#32212) Includes anything ruff could automatically fix and anything I saw that was only one or two files in the directory.", "sampled": "D205 Support - Auto-fixes and Stragglers (#32212) Includes anything ruff could automatically fix and anything I saw that was only one kind of error. [bug#32212]\n\nv2.0.3 (September 5th", "perturbed_sampled": ["D205 Support - Auto-fixes and Stragglers (#32212) Includes anything I could get right and anything I saw that was only one kind of error. [bug#32212]\n\nv2.0.3 (September 5th", "D205 Support - Auto-fixes and Stragglers (#32212) Includes anything ruff I was able to fix and anything I saw that was only apparent in the case of error. [bug#32212]\n\nv2.0.3 (September 5th", "D205 Support - Auto-fixes and Stragglers (#32212) Includes anything ruff could find and anything I saw that was only one kind of Stragler. Patch [bug#32212]\n\nv2.0.3 (September 5th", "D205 Support - Auto-fixes and errors. Includes anything ruff could automatically fix and anything I could fix that I thought was only one kind of error. [bug#32212]\n\nv2.0.3 (September 5th", "D205 Support : Manuals and Stragglers (#32212) Includes everything I could automatically fix and anything I saw that was only one kind of error. [bug#32212]\n\nv2.0.3 (September 5th", "D205 Support - Auto-fixes and Stragglers (#32212) Includes anything ruff could automatically fix and anything I saw that was an automatic fix for some kind of error. March 5th", "D205 Support - Auto-fixes and Stragglers (#32212) Includes anything ruff could automatically fix and /or adjust -- I saw that was only one common error. [bug#32212]\n\nv2.0.3 (September 5th", "D205 Support - Multiple Stragglers (#32212) Includes anything ruff could automatically fix and anything I saw that was only a random source of error. [bug#32212]\n\nv2.0.3 (September 5th", "D205 Support - Sliding Stragglers (#32212) Includes everything I could automatically fix and anything I saw that was only one kind of error. [bug#32212]\n\nv2.0.3 (September 5th", "D205 Support - Auto-fixes and Stragglers (#32212) Includes anything I can automatically fix and anything I saw that was only one kind of error. Published on Tuesday, February 5th"], "perturbed_original": ["D205 Support - Auto-fixes D205 (#32212) Includes anything I could automatically fix and anything I saw that was only one or two files in the directory.", "D205 Support by Strappers and Stragglers (#32212) Includes anything ruff could automatically fix and anything I saw that needs to be fixed with one or two files in the directory.", "D205 Support - Auto-fixes and Stragglers (#32212) Includes D205 Support. I could automatically fix anything I saw that was only one or two files in the directory.", "D205 Support - Auto-fixes and Stragglers (#32212) Includes anything ruff could automatically fix and anything else that was only available via two files in the directory.", "D205 Support - Auto-fixes and Stragglers (#32212) Includes anything ruff could automatically fix and anything else that was only one or two things in the directory.", "D205 Support - Auto-fixes and Stragglers (#32212) Includes anything ruff could automatically fix or help you fix. The only thing I saw that was missing were one or two files in the directory.", "D205 : Ruff Auto-fixes and Stragglers (#32212) Includes anything ruff could automatically fix and change a saw that was only one or two files in the directory.", "D205 Support - Auto-fixes directory. (#32212) Includes anything ruff could automatically fix and anything I saw that was only one of the files in the directory.", "D205 Support - Auto-fixes and Stragglers (#32212) Includes anything ruff that was a auto fix and anything I saw that was only one of many D205 files in the directory.", "D205 Support - Auto-fixes . (#32212) Includes anything ruff could automatically fix and anything I saw that needed to fix one or two files in the directory."], "original_ll": -5.535980224609375, "sampled_ll": -4.566303253173828, "all_perturbed_sampled_ll": [-4.234372138977051, -4.271688461303711, -4.622015476226807, -4.336594581604004, -4.447640419006348, -5.346246242523193, -4.846004486083984, -4.603898525238037, -4.288971424102783, -5.06869649887085], "all_perturbed_original_ll": [-5.053308010101318, -5.387103080749512, -4.8532586097717285, -5.661377429962158, -5.554559230804443, -4.910756587982178, -5.673279285430908, -5.477283477783203, -5.423056125640869, -5.606894493103027], "perturbed_sampled_ll": -4.606612825393677, "perturbed_original_ll": -5.360087633132935, "perturbed_sampled_ll_std": 0.3560825024324838, "perturbed_original_ll_std": 0.29307249901664906}, {"original": "feat(provider/azure): add managed identity support to asb hook (#35324)", "sampled": "feat(provider/azure): add managed identity support to asb hook (#35324)For", "perturbed_sampled": ["feat(provider/azure): add managed identity support to asb hook (#35324)For", "feat(provider/azure): add managed identity support to asb hook (#35324)For", "feat(provider/azure): add managed identity support to asb hook (#35324)For", "feat(provider/azure): add managed identity support to asb hook (#35324)For", "feat(provider/azure): add managed identity support to asb hook (#35324)For", "feat(provider/azure): add managed identity support to asb hook (#35324)For", "feat(provider/azure): add managed identity support to asb hook (#35324)For", "feat(provider/azure): add managed identity support to asb hook (#35324)For", "feat(provider/azure): add managed identity support to asb hook (#35324)For", "feat(provider/azure): add managed identity support to asb hook (#35324)For"], "perturbed_original": ["feat(provider/azure): add managed identity support to asb hook (#35324)", "feat(provider/azure): add managed identity support to asb hook (#35324)", "feat(provider/azure): add managed identity support to asb hook (#35324)", "feat(provider/azure): add managed identity support to asb hook (#35324)", "feat(provider/azure): add managed identity support to asb hook (#35324)", "feat(provider/azure): add managed identity support to asb hook (#35324)", "feat(provider/azure): add managed identity support to asb hook (#35324)", "feat(provider/azure): add managed identity support to asb hook (#35324)", "feat(provider/azure): add managed identity support to asb hook (#35324)", "feat(provider/azure): add managed identity support to asb hook (#35324)"], "original_ll": -5.699498176574707, "sampled_ll": -6.178793907165527, "all_perturbed_sampled_ll": [-6.178793907165527, -6.178793907165527, -6.178793907165527, -6.178793907165527, -6.178793907165527, -6.178793907165527, -6.178793907165527, -6.178793907165527, -6.178793907165527, -6.178793907165527], "all_perturbed_original_ll": [-5.699498176574707, -5.699498176574707, -5.699498176574707, -5.699498176574707, -5.699498176574707, -5.699498176574707, -5.699498176574707, -5.699498176574707, -5.699498176574707, -5.699498176574707], "perturbed_sampled_ll": -6.178793907165527, "perturbed_original_ll": -5.699498176574707, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Add all airflow image cache (#35410)", "sampled": "Add all airflow image cache (#35410)How", "perturbed_sampled": ["Add all airflow image cache (#35410)How", "Add all airflow image cache (#35410)How", "Add all airflow image cache (#35410)How", "Add all airflow image cache (#35410)How", "Add all airflow image cache (#35410)How", "Add all airflow image cache (#35410)How", "Add all airflow image cache (#35410)How", "Add all airflow image cache (#35410)How", "Add all airflow image cache (#35410)How", "Add all airflow image cache (#35410)How"], "perturbed_original": ["Add all airflow image cache (#35410)", "Add all airflow image cache (#35410)", "Add all airflow image cache (#35410)", "Add all airflow image cache (#35410)", "Add all airflow image cache (#35410)", "Add all airflow image cache (#35410)", "Add all airflow image cache (#35410)", "Add all airflow image cache (#35410)", "Add all airflow image cache (#35410)", "Add all airflow image cache (#35410)"], "original_ll": -8.044133186340332, "sampled_ll": -8.891788482666016, "all_perturbed_sampled_ll": [-8.891788482666016, -8.891788482666016, -8.891788482666016, -8.891788482666016, -8.891788482666016, -8.891788482666016, -8.891788482666016, -8.891788482666016, -8.891788482666016, -8.891788482666016], "all_perturbed_original_ll": [-8.044133186340332, -8.044133186340332, -8.044133186340332, -8.044133186340332, -8.044133186340332, -8.044133186340332, -8.044133186340332, -8.044133186340332, -8.044133186340332, -8.044133186340332], "perturbed_sampled_ll": -8.891788482666016, "perturbed_original_ll": -8.044133186340332, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Improve past depends handling in Airflow CLI tasks.run command (#28113)", "sampled": "Improve past depends handling in Airflow CLI tasks.run command (#28113)The", "perturbed_sampled": ["Improve past depends handling in Airflow CLI tasks.run command (#28113)The", "Improve past depends handling in Airflow CLI tasks.run command (#28113)The", "Improve past depends handling in Airflow CLI tasks.run command (#28113)The", "Improve past depends handling in Airflow CLI tasks.run command (#28113)The", "Improve past depends handling in Airflow CLI tasks.run command (#28113)The", "Improve past depends handling in Airflow CLI tasks.run command (#28113)The", "Improve past depends handling in Airflow CLI tasks.run command (#28113)The", "Improve past depends handling in Airflow CLI tasks.run command (#28113)The", "Improve past depends handling in Airflow CLI tasks.run command (#28113)The", "Improve past depends handling in Airflow CLI tasks.run command (#28113)The"], "perturbed_original": ["Improve past depends handling in Airflow CLI tasks.run command (#28113)", "Improve past depends handling in Airflow CLI tasks.run command (#28113)", "Improve past depends handling in Airflow CLI tasks.run command (#28113)", "Improve past depends handling in Airflow CLI tasks.run command (#28113)", "Improve past depends handling in Airflow CLI tasks.run command (#28113)", "Improve past depends handling in Airflow CLI tasks.run command (#28113)", "Improve past depends handling in Airflow CLI tasks.run command (#28113)", "Improve past depends handling in Airflow CLI tasks.run command (#28113)", "Improve past depends handling in Airflow CLI tasks.run command (#28113)", "Improve past depends handling in Airflow CLI tasks.run command (#28113)"], "original_ll": -7.6937336921691895, "sampled_ll": -8.011857032775879, "all_perturbed_sampled_ll": [-8.011857032775879, -8.011857032775879, -8.011857032775879, -8.011857032775879, -8.011857032775879, -8.011857032775879, -8.011857032775879, -8.011857032775879, -8.011857032775879, -8.011857032775879], "all_perturbed_original_ll": [-7.6937336921691895, -7.6937336921691895, -7.6937336921691895, -7.6937336921691895, -7.6937336921691895, -7.6937336921691895, -7.6937336921691895, -7.6937336921691895, -7.6937336921691895, -7.6937336921691895], "perturbed_sampled_ll": -8.011857032775879, "perturbed_original_ll": -7.6937336921691895, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Fix incorrect data interval alignment due to assumption on input time alignment (#22658) * Fix incorrect data_interval_start due to DAG's schedule changed This PR fixes the incorrect first run of data_interval_start after changing the scheduling time. * Added _align_to_prev function for scheduling alignment after time change. * renamed _align to _align_to_next. Co-authored-by: wanlce <who@foxmail.com> Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "sampled": "Fix incorrect data interval alignment due to assumption on input time alignment (#22658) * Fix incorrect data_interval_start due to DAG's default value * Fix incorrect data_interval_end due to defaults for input mode, error_code and current_interval * Fix incorrect clock_start due to default values and use of correct default start for time_frame values when in use * Fix incorrect", "perturbed_sampled": ["Fix incorrect data _interval_stop due to assumption on input time alignment (#22658) * Fix incorrect data_interval_start due to DAG's default value * Fix incorrect data_interval_end due to wrong input values for input mode, error_code and current_interval * Fix incorrect clock_start due to default values and use of correct format for time_frame values when data_time_passing * Fix incorrect", "Fix incorrect data _interval_limit due to assumption on input mode (#22658) * Fix incorrect data_interval_start due to DAG's default value * Fix incorrect data_interval_end due to defaults for input mode, and current_interval * Fix incorrect clock_start due to default values and not always needed * Fix incorrect correct default start for time_frame values when in use * Fix incorrect", "Fix incorrect data interval alignment due to value and input mode * Correct output of input parameters as needed (#22658) * Fix incorrect data_interval_start due to DAG's default value * Fix incorrect data_interval_end due to incorrect input mode, error_code and current_interval * Fix incorrect clock_start due to default values and use of correct values for time_frame values when in use * Fix incorrect", "Fix incorrect data interval alignment due to assumption on input time alignment (#22658) * Fix incorrect data_interval_start due to DAG's default values and use of correct outputs * Fix incorrect data_interval_end due to defaults for input mode, error_code and outputs * Fix incorrect clock_start due to default values and use of correct inputs for time_frame values when in use * Fix incorrect", "Fix incorrect data interval alignment due to incorrect assumption on input time alignment (#22658) * Fix incorrect data_interval_start due to DAG's default value * Fix incorrect clock_start due to defaults for input mode, error_code and delay * Fix incorrect clock_start due to default values * Fix default of correct default start for time_frame values when in use * Fix incorrect", "* Fix incorrect data interval alignment due to DAG error on input time alignment * Fix incorrect data_interval_start due to DAG's default value * Fix incorrect data_interval_end due to defaults for input mode, error_code and current_interval * Fix incorrect clock_start due to default values and use of correct default start for time_frame values when in use * Fix incorrect", "Fix incorrect data interval alignment due to assumption of wrong time alignment (#22658) * Fix incorrect data() values due to DAG's default value * Fix incorrect data_interval_end due to defaults for input mode, error_code and current_interval * Fix incorrect clock_start due to default values and use of correct default start for time_frame values when using a custom start time * Fix incorrect", "Fix incorrect data interval alignment due to assumption on input time alignment (#22658) * Fix incorrect data_interval_start due to DAG's default value * Fix incorrect data_interval_end due to input time value causing assumptions on input mode, error_code and current_interval * Fix incorrect clock_start due to default values and use of correct default start and end values when in use * Fix incorrect", "Fix incorrect data interval alignment due to assumption on input time alignment (#22658) * Fix incorrect data_interval_start due to DAG's default value * Fix incorrect data_interval_end due to defaults for input mode, error_code and current_interval * Fix incorrect clock_start due to custom values and use of correct default start for each when available (#224569) * Fix incorrect", "Fix incorrect data _input_time due to assumption on input time alignment (#22658) * Fix incorrect data_interval_start due to DAG's default value * Fix incorrect data_start due to defaults for input mode, error_code and current_interval * Fix incorrect data_interval_start due to user error and use of correct default start for time_frame values when in use * Fix incorrect"], "perturbed_original": ["Fix incorrect data interval alignment due to assumption of time alignment (#22658) * Correct the incorrect first run of data_interval_start due to DAG's schedule changed This PR fixes the incorrect first run of data_interval_start due to assumption of the scheduling time. * Added _align_to_prev function for scheduling alignment after time change. * Moves scheduling alignment to _align_to_next. Co-authored-by: wanlce <who@foxmail.com> Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Fix incorrect data interval alignment due to assumption on time alignment (#22658) * Fix incorrect first run of data_interval_start due to DAG's schedule changed This PR fixes the incorrect first run of data_interval_start after changing the scheduling time. * Added _align_to_prev function for adjustment after time change. * renamed _align _to_end function. Co-authored-by: wanlce <who@foxmail.com> Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Fix incorrect data interval alignment due to assumption on input time alignment . Fix incorrect data_interval_start due to DAG's schedule changed This PR fixes the incorrect first run of data interval alignment after changing the scheduling time. * Added support for scheduling alignment after time change. * renamed to _align_to_next. Co-authored-by: wanlce <who@foxmail.com> Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Fix incorrect data interval alignment due to assumption on input time . * Fix incorrect data_interval_start due to DAG's schedule changed This PR fixes the incorrect first run of data_interval_start after changing the scheduling time. * Added _align_to_prev function for scheduling change time , renamed _align to _align_to_next. Co-authored-by: Tzu-ping Chung Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Fix incorrect data interval alignment due to assumption for time alignment (#22658) * Fix incorrect data interval alignment due to DAG's schedule changed This PR should fix incorrect first run of data_interval_start after changing the scheduling . Added _align_to_prev function for scheduling alignment after time change. * renamed _align to _align_to_next. Co-authored-by: wanlce <who@foxmail.com> Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Fix incorrect data interval alignment due to assumption on input time . * Fix incorrect data interval alignment due to DAG's schedule changed This PR fixes the incorrect first run of data_interval_start after changing the scheduling time. * Added _align_to_prev function for scheduling alignment after timed changes. * renamed _align to _align_to_next. Co-authored-by: Kozo Sao <unk>kazoss@aol.com>. Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Fix incorrect data interval alignment due to assumption on input time alignment (#22658) * Fix incorrect data interval alignment due to data interval schedule changed . * This patch fixes the alignment problem and avoids repeating the same run of data_interval_start after changing the scheduling time. * Added _align_to_prev function for scheduling alignment after time change. * renamed _align to _align_to_next. Co-authored-by: wanlce <who@foxmail.com> Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Fix incorrect data interval alignment due to assumption for correct scheduling time alignment (#22658) * Fix incorrect data_interval_start due to DAG's schedule changed This PR fixes the incorrect first time data_interval_start after changing the scheduling time. * Added _align_to_prev function for data interval alignment after time changes. * Deleted obsolete macros and renamed _align to _align_to_next. Co-authored-by: wanlce <who@foxmail.com> Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Fix incorrect data interval alignment due to assumption on input time alignment (#22658) * Fix incorrect data_interval_start due to DAG's schedule changed This PR fixes the incorrect first run of a data interval due to changing the scheduling DAG. * Added _align_to_prev which will fix scheduling alignment to next change. * renamed _align to _align_to_next. Co-authored-by: wanlce <who@foxmail.com> Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Fix incorrect data interval alignment due to assumption on data interval alignment (#22658) * Fix incorrect data_interval_start due to DAG's schedule changed This PR fixes the incorrect first run of data_interval_start after changing the scheduling time. * Added _align_to_prev function for data_interval_start after time change. * renamed _align to _align_to_next. Co-authored-by: <unk> Co-authored-by: <unk> <unk> <unk>, <uranusjr@gmail.com>"], "original_ll": -3.9075732231140137, "sampled_ll": -3.444697618484497, "all_perturbed_sampled_ll": [-3.327418327331543, -3.345950126647949, -3.4758048057556152, -3.4743175506591797, -3.736407518386841, -3.3166770935058594, -3.782564163208008, -3.4657161235809326, -3.554875373840332, -3.4196133613586426], "all_perturbed_original_ll": [-3.8413820266723633, -4.031151294708252, -4.166566848754883, -3.7206647396087646, -4.0908284187316895, -4.201992988586426, -3.7937145233154297, -3.8248984813690186, -3.9861538410186768, -3.5257010459899902], "perturbed_sampled_ll": -3.4899344444274902, "perturbed_original_ll": -3.9183054208755492, "perturbed_sampled_ll_std": 0.15288382857348767, "perturbed_original_ll_std": 0.20312044395926374}, {"original": "Fix mapped task immutability after clear (#23667) We should be able to detect if the structure of mapped task has changed and verify the integrity. This PR ensures this Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "sampled": "Fix mapped task immutability after clear (#23667) We should be able to detect if the structure of mapped task has changed and verify the integrity of the object at that point by calling", "perturbed_sampled": ["Fix mapped task immutability after clear (#23667) We should be able to detect if the structure of mapped task has changed and verify the integrity of the object at that time. This cannot happen when still calling", "Fix for immutability after clear (#23667) We should be able to detect if the structure of the object has changed and verify the integrity of the object at that point by calling", "Fix mapped task immutability after clear (#23667) We should be able to detect if the structure of mapped task or task.json have changed and verify the integrity of the object at that time after calling", "Fix mapped task immutability after clear (#23667) We should be able to detect if the structure of mapped task has changed, and verify the integrity of the object at that time, without calling", "Fix mapped task after clear ()? This class should be able to detect if the structure of mapped task has changed and verify the integrity of the object at that point by calling", "Fix mapped task immutability after using \"Mapped TaskMap()\". We should be able to detect when the structure of mapped task has changed and verify the integrity of the object at that point by calling", "Fix mapped task immutability after clear (#23667) We should be able to detect when the structure of mapped task has changed and check out integrity of the object at that point by calling", "Fix mapped task structure change after clear (#23667) We should be able to detect if the structure of mapped task has changed and verify the integrity of the object at this point by calling", "Fix mapped task immutability after clear (#23667) We should be able to detect if the value of a mapped task has changed and verify the integrity of the object . We can check that point by calling", "Fix mapped task immutability after clear (#23667) : The method should be able to detect if the structure of mapped task has changed and preserve the integrity of the object at that point by calling"], "perturbed_original": ["Fix mapped task immutability after clear (#23667) We should be able to check if the structure of mapped task is changed and verify the integrity. This PR ensures this Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "mappings: test task immutability after clear (#23667) We should be able to detect if the structure of mapped tasks has changed and verify the integrity. This PR ensures this Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Fix mapped task immutability after clear (#23667) . We need to be able to detect if the structure of mapped task has changed and verify the integrity. This work under this Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Fix mapped task immutability after clear (#23667) We should be able to detect if the structure of mapped task has changed and maintain its integrity. This PR ensures this Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Fix mapped task immutability after clear (#23667) We should be able to detect if the structure of mapped task has changed and verify the integrity. This workaround is in this Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Fix mapped task immutability after clear (#23667) We should be able to notice the structure of mapped task has changed and verify the integrity. a fix with #23667 ensures this Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Fix mapped task immutability after clear (#23667) We are still able to detect if the structure of mapped task has changed and verify the integrity. This PR ensures this Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Fix mapped task immutability after clear (#23667) We want to be easily able to detect if the structure of mapped task is changed at runtime and verify the integrity. This PR ensures this Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Fix mapped task immutability after clear (#23667) We should be able to detect if the structure of the eviction has changed and verify the integrity. This PR ensures this Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Fix mapped task integrity after clear (#23667) We should be able to verify whether the structure of mapped task has changed and verify the integrity. This PR ensures this Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>"], "original_ll": -4.537261962890625, "sampled_ll": -4.181219100952148, "all_perturbed_sampled_ll": [-4.2614054679870605, -3.5230581760406494, -4.489469051361084, -4.1070051193237305, -4.215482234954834, -3.781804323196411, -4.41892147064209, -4.359029769897461, -4.142323017120361, -4.187760353088379], "all_perturbed_original_ll": [-4.570166110992432, -4.575573921203613, -4.437866687774658, -4.437632083892822, -4.3890180587768555, -4.717904567718506, -4.707512378692627, -4.572761058807373, -4.638051986694336, -4.5995683670043945], "perturbed_sampled_ll": -4.148625898361206, "perturbed_original_ll": -4.5646055221557615, "perturbed_sampled_ll_std": 0.27926494693907306, "perturbed_original_ll_std": 0.10666462996383258}, {"original": "added contributors (#26950)", "sampled": "added contributors (#26950)I", "perturbed_sampled": ["added contributors (#26950)I", "added contributors (#26950)I", "added contributors (#26950)I", "added contributors (#26950)I", "added contributors (#26950)I", "added contributors (#26950)I", "added contributors (#26950)I", "added contributors (#26950)I", "added contributors (#26950)I", "added contributors (#26950)I"], "perturbed_original": ["added contributors (#26950)", "added contributors (#26950)", "added contributors (#26950)", "added contributors (#26950)", "added contributors (#26950)", "added contributors (#26950)", "added contributors (#26950)", "added contributors (#26950)", "added contributors (#26950)", "added contributors (#26950)"], "original_ll": -7.380965232849121, "sampled_ll": -8.614940643310547, "all_perturbed_sampled_ll": [-8.614940643310547, -8.614940643310547, -8.614940643310547, -8.614940643310547, -8.614940643310547, -8.614940643310547, -8.614940643310547, -8.614940643310547, -8.614940643310547, -8.614940643310547], "all_perturbed_original_ll": [-7.380965232849121, -7.380965232849121, -7.380965232849121, -7.380965232849121, -7.380965232849121, -7.380965232849121, -7.380965232849121, -7.380965232849121, -7.380965232849121, -7.380965232849121], "perturbed_sampled_ll": -8.614940643310547, "perturbed_original_ll": -7.380965232849121, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Add Export Format to Template Fields in BigQueryToGCSOperator (#27910)", "sampled": "Add Export Format to Template Fields in BigQueryToGCSOperator (#27910)Get", "perturbed_sampled": ["Add Export Format to Template Fields in BigQueryToGCSOperator (#27910)Get", "Add Export Format to Template Fields in BigQueryToGCSOperator (#27910)Get", "Add Export Format to Template Fields in BigQueryToGCSOperator (#27910)Get", "Add Export Format to Template Fields in BigQueryToGCSOperator (#27910)Get", "Add Export Format to Template Fields in BigQueryToGCSOperator (#27910)Get", "Add Export Format to Template Fields in BigQueryToGCSOperator (#27910)Get", "Add Export Format to Template Fields in BigQueryToGCSOperator (#27910)Get", "Add Export Format to Template Fields in BigQueryToGCSOperator (#27910)Get", "Add Export Format to Template Fields in BigQueryToGCSOperator (#27910)Get", "Add Export Format to Template Fields in BigQueryToGCSOperator (#27910)Get"], "perturbed_original": ["Add Export Format to Template Fields in BigQueryToGCSOperator (#27910)", "Add Export Format to Template Fields in BigQueryToGCSOperator (#27910)", "Add Export Format to Template Fields in BigQueryToGCSOperator (#27910)", "Add Export Format to Template Fields in BigQueryToGCSOperator (#27910)", "Add Export Format to Template Fields in BigQueryToGCSOperator (#27910)", "Add Export Format to Template Fields in BigQueryToGCSOperator (#27910)", "Add Export Format to Template Fields in BigQueryToGCSOperator (#27910)", "Add Export Format to Template Fields in BigQueryToGCSOperator (#27910)", "Add Export Format to Template Fields in BigQueryToGCSOperator (#27910)", "Add Export Format to Template Fields in BigQueryToGCSOperator (#27910)"], "original_ll": -6.134578704833984, "sampled_ll": -6.660810470581055, "all_perturbed_sampled_ll": [-6.660810470581055, -6.660810470581055, -6.660810470581055, -6.660810470581055, -6.660810470581055, -6.660810470581055, -6.660810470581055, -6.660810470581055, -6.660810470581055, -6.660810470581055], "all_perturbed_original_ll": [-6.134578704833984, -6.134578704833984, -6.134578704833984, -6.134578704833984, -6.134578704833984, -6.134578704833984, -6.134578704833984, -6.134578704833984, -6.134578704833984, -6.134578704833984], "perturbed_sampled_ll": -6.660810470581055, "perturbed_original_ll": -6.134578704833984, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Update BREEZE.rst with different test example (#36234) Updating the breeze docs with different pytest example as the function mentioned in the example is removed from the test_core.py", "sampled": "Update BREEZE.rst with different test example (#36234) Updating the breeze docs with different pytest example as the function mentioned in the README. More tests against our code", "perturbed_sampled": ["Update BREEZE.rst with different test example (#36234) . Update the breeze docs with different example as the function mentioned in the README. More tests against our code", "Update BREEZE.rst with different test example (#36234) Updating the breeze docs with different pytest example as the one already described in the README. Checking all that against our code", "Update BREEZE.rst with different test example . Updated the breeze docs with different pytest example as the function mentioned in BREEZE README. More tests against our code", "Update BREEZE.rst with different test example (#36234) Updating the breeze docs with the pytest example as the function mentioned in #36235. More tests against our code", "Update BREEZE.rst with different test example (#36234) Updating the BREEZE.rst with different pytest example as the one cited in the README. More tests against our code", "Update BREEZE.rst with different test example (#36234) Updating the breeze docs with different pytest examples For the function mentioned in the README. php we were testing against our code", "Update BREEZE.rst with different test example (#36234) Updating the breeeze.rst with different pytest example as the function mentioned in the README. More tests against our code", "README with different test example (#36234) Updating the breeze module with different pytest example as the function mentioned in the README. More tests against our code", "Update BREEZE.rst with different test example (#36234) Updating the breeze docs into a new pytest example as the function description is removed from the README. More tests against our code", "Updates with different test example (#36234) Updating the tests with different pytest example as the function mentioned in the README. More tests against our code"], "perturbed_original": ["Update BREEZE.rst with different test example (#36234) Updating the breeze docs . Also removing the pytest example as the function mentioned in the example is removed in test_core.py", "Update BREEZE.rst with different test example . Updated the breeze docs with different pytest example . The test_core function mentioned in the example is removed from the test_core.py", "Update BREEZE.rst with different test example (#36234) Updating the breeze docs with different pytest examples As of now the function mentioned in the example is not included in the test_core.py", "Update BREEZE.rst with different test example (#36234) Updating the breeze docs to remove the code that uses the pytest example as the function calling it in the example is removed from the test_core.py", "Update with different test example (#36234) Updating the breeze docs with different pytest example . Every single function mentioned in the example is removed from the test_core.py", "Update BREEZE.rst with different test example as explained as described. Updating the breeze docs with different pytest example as explained as mentioned in the example is removed from the test_core.py", "Update BREEZE.rst with different test example (#36234) Updating the Breeze.rst file with a different test example as the function mentioned in the example is removed from the test_core.py", "Update BREEZE.rst with different example (#36234) Updating the breeze code is not necessary as it uses some different pytest example as the function mentioned in the example is removed from the test_core.py", "Update BREEZE.rst with pytest test example (#36234) Updating the breeze docs with different pytest example as the function mentioned in this script is removed from the test_core.py", "Update d the docs with different test example (#36234) . Fixed the breeze docs with different pytest example as the function mentioned in the example is removed from the test_core.py"], "original_ll": -5.026402473449707, "sampled_ll": -5.140718460083008, "all_perturbed_sampled_ll": [-5.158693313598633, -5.129602909088135, -5.0411906242370605, -5.120418548583984, -4.110641956329346, -5.391119480133057, -4.593173503875732, -5.215285778045654, -5.017303943634033, -4.722959995269775], "all_perturbed_original_ll": [-4.958158016204834, -4.5100860595703125, -4.70819616317749, -4.738880157470703, -4.952540397644043, -4.6844611167907715, -4.036793231964111, -4.784114360809326, -5.113297939300537, -5.292448043823242], "perturbed_sampled_ll": -4.950039005279541, "perturbed_original_ll": -4.777897548675537, "perturbed_sampled_ll_std": 0.35581670825067874, "perturbed_original_ll_std": 0.32807893141684313}, {"original": "Fix wrong deprecation warning for `S3ToSnowflakeOperator` (#26047)", "sampled": "Fix wrong deprecation warning for `S3ToSnowflakeOperator` (#26047)By", "perturbed_sampled": ["Fix wrong deprecation warning for `S3ToSnowflakeOperator` (#26047)By", "Fix wrong deprecation warning for `S3ToSnowflakeOperator` (#26047)By", "Fix wrong deprecation warning for `S3ToSnowflakeOperator` (#26047)By", "Fix wrong deprecation warning for `S3ToSnowflakeOperator` (#26047)By", "Fix wrong deprecation warning for `S3ToSnowflakeOperator` (#26047)By", "Fix wrong deprecation warning for `S3ToSnowflakeOperator` (#26047)By", "Fix wrong deprecation warning for `S3ToSnowflakeOperator` (#26047)By", "Fix wrong deprecation warning for `S3ToSnowflakeOperator` (#26047)By", "Fix wrong deprecation warning for `S3ToSnowflakeOperator` (#26047)By", "Fix wrong deprecation warning for `S3ToSnowflakeOperator` (#26047)By"], "perturbed_original": ["Fix wrong deprecation warning for `S3ToSnowflakeOperator` (#26047)", "Fix wrong deprecation warning for `S3ToSnowflakeOperator` (#26047)", "Fix wrong deprecation warning for `S3ToSnowflakeOperator` (#26047)", "Fix wrong deprecation warning for `S3ToSnowflakeOperator` (#26047)", "Fix wrong deprecation warning for `S3ToSnowflakeOperator` (#26047)", "Fix wrong deprecation warning for `S3ToSnowflakeOperator` (#26047)", "Fix wrong deprecation warning for `S3ToSnowflakeOperator` (#26047)", "Fix wrong deprecation warning for `S3ToSnowflakeOperator` (#26047)", "Fix wrong deprecation warning for `S3ToSnowflakeOperator` (#26047)", "Fix wrong deprecation warning for `S3ToSnowflakeOperator` (#26047)"], "original_ll": -5.12251091003418, "sampled_ll": -5.677745342254639, "all_perturbed_sampled_ll": [-5.677745342254639, -5.677745342254639, -5.677745342254639, -5.677745342254639, -5.677745342254639, -5.677745342254639, -5.677745342254639, -5.677745342254639, -5.677745342254639, -5.677745342254639], "all_perturbed_original_ll": [-5.12251091003418, -5.12251091003418, -5.12251091003418, -5.12251091003418, -5.12251091003418, -5.12251091003418, -5.12251091003418, -5.12251091003418, -5.12251091003418, -5.12251091003418], "perturbed_sampled_ll": -5.677745342254639, "perturbed_original_ll": -5.12251091003418, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Add --only-my-changes flag to breeze static-checks command (#31269) When you have a workflow, when you rebase several of your commits, on top of main, there is often a need to re-run pre-commits for all the commits that have been changed by me in the branch (this for example handles case when pre-commits changed in the main branch, but the rebase did not result in conflict (this does not run pre-commit automatically even if you have it installed in your repository). It's also a good \"sanity\" check to run before you push your branch.", "sampled": "Add --only-my-changes flag to breeze static-checks command (#31269) When you have a workflow, when you rebase several of your static checks, the check is automatically run only if its result matches the change in all the dynamic changes. It does a lot better for static checks that do only just one or two commits. (#313320) Allow use of commit id even if no change happened in other branch (#352890)\n\nbug fixes, performance improvements\n\nFeatures\n\nBug fixes, performance improvements, and performance improvements with new versioning feature (thanks to @TrentJ), code generator improvements in package.json and project.json (#315640)", "perturbed_sampled": ["Add --only-my-changes flag to breeze static-checks command (#31269) When you have a workflow, when you rebase all your static checks, the check is automatically applied even if its result matches the change in all the dynamic checks. That does a lot better for static checks that do only just one or two commits. (#313320) Allow use of commit id even if no id is present in other commit identifiers Bug fixes, performance improvements\n\nFeatures\n\nBug fixes, performance improvements, and performance improvements with new versioning feature (thanks to @TrentJ), code comparisons in package.json and project.json (#315640)", "Add --only-my-changes flag to breeze static-checks command (#31269) If you have a workflow, when you rebase several of your static s. A static check is automatically run only if its result matches the change that corresponded to the dynamic changes. It does a lot better for static checks that do only just one to two commits. (#313320) Allow use of dynamic status check even if no change happened in other commits Bug fixes, performance improvements\n\nFeatures\n\nBug fixes, performance improvements, and performance improvements with new versioning feature (thanks to @TrentJ), code generator improvements in package.json and project.json (#315640)", "Add --only-my-changes flag to breeze static-checks command (#31269) When you have a workflow, where you need to rebase several of your static checks, the check is automatically run only if its result matches the change in all the dynamic changes. It does a lot better for static checks that do only just one or two commits. (#313320) Allow branch to be set with commit name: branchname, even if no change happened in other branch (#352890)\n\nbug fixes, performance improvements\n\nFeatures\n\nBug fixes, improvements, and performance improvements with new versioning feature (thanks to bug generator improvements ) Includes refactoring of import-prop and project.json (#315640)", "Add --only-my-changes flag to breeze static-checks command (#31269) When you have a workflow, when you rebase several of your static checks, the check is automatically revoked if its result matches the change in the first commit. It does a lot better for static checks when you choose to do only just one or two commits. (#313320) Allow use of commit id even if no change was made to other branch (#352890)\n\nbug fixes, performance improvements\n\nFeatures\n\nBug fixes, performance improvements, and improvements with new versioning feature (thanks to @TrentJ), code generator improvements in package.json and project.json (#315640)", "Add --only-my-changes flag to breeze static-checks command (#31269) When you have a workflow, when running several of your static checks, it is possible to do one only if its own changes have the change in all the dynamic changes. It does a lot better for static checks that do only just one or two commits. (#313320) Allow use of commit id even if no change happened in other branch (#352890)\n\nbug fixes, performance improvements, improvements, and performance improvements, and performance improvements with new versioning feature (thanks to @TrentJ), code generator , new and improved package.json and project.json (#315640)", ". Added \"save\" flag to breeze static-checks command If you have a workflow, when running several of your static checks, the check is automatically run only if its result matches the change in all the dynamic changes. It does a lot better for static checks that do only just one or two commits. (#313320) Allow use of commit id even if change happened in other branch (#352890)\n\nbug fixes, performance improvements\n\nFeatures\n\nBug fixes, bug fixes and performance improvements with new versioning feature (thanks to Andrew Agarwal). Change code generator improvements in package.json and project.json (#315640)", "Add --only-my-changes flag to create-check command (#31269) If you have a dynamic change to do after you rebase several of your static checks, the check is automatically run only if its result matches the change in all the dynamic changes. It does a lot of nice things for small static checks that do only just one or two commits. Removed use of commit id even if no change happened in other branch (#352890)\n\nbug fixes, performance improvements\n\nFeatures\n\nBug fixes, performance improvements, and performance improvements with new branch tty (thanks to @TrentJ), code generator improvements in package.json and project.json (#315640)", "Add --only-my-changes flag to breeze static-checks command (#31269) When you have a workflow, when you rebase several of your static checks, the check is automatically run , and its result matches the change in all the dynamic changes. It does a lot better for static checks to do only just one or a few commits. This is probably a bug. Make use of commit id even if no change happened in other branch (#352890)\n\nbug fixes, performance improvements\n\nFeatures\n\nBug fixes, performance improvements, and branching with new versioning feature (thanks to @TrentJ), code generator improvements in package.json and project.json (#315640)", "Add --only-my-changes flag to breeze static-checks command (#31269) When you have a workflow, when you rebase several of your static checks, the check is automatically run only if its result is a change in your dynamic changes. It does a lot better for static s, allowing you to do only just one or two static checks (#313320) Allow branch to be used as commit id even if it happened in other branch (#352890)\n\nbug fixes, performance improvements\n\nFeatures\n\nBug fixes, performance improvements, and performance improvements with new versioning feature (thanks to @TrentJ), code generator improvements in package.json and project.json (#315640)", "Add --only-my-changes flag to breeze static-checks command (#31269) When you have a workflow, when you rebase several of the static checks, the check is automatically run only if its result matches the change in all the dynamic changes. It does a lot better for static checks with high impact on only just one or two commits. (#313320) Using branch number instead of commit id even if no change happened in other branch . Bug fixes, performance improvements\n\nFeatures\n\nBug fixes, performance improvements Features Bug fixes, performance improvements with new versioning feature (thanks to @TrentJ), code generator improvements in package.json . (#315640)"], "perturbed_original": ["Add --only-my-changes flag to breeze static-checks command (#31269) When you have a workflow, where you rebase several of your commits, on top of main, there is often a need to re-run pre-commits for all the commits that have been changed by me in the branch (this for every change in the same branch) in the case anything changed in the main branch, but the rebase did not result in conflict (this does not run pre-commit automatically even if you have it installed in your workspace). It's a good \"sanity\" check to run before you rebase the main branch.", "Add --only-my-changes flag to breeze static-checks system. When you have a workflow, when you rebase several of your commits, on top of main, there is often a need to re-run pre-commits for all the commits that were changed by me in the branch . The following example handles case when pre-commits changed in the main branch, but the rebase did not result in conflict (this does not run pre-commit automatically even if you have it set to run in your repository). It's also a better approach to check to be sure your pre-commit changes before you push your branch.", "Add 're-run pre-commit' option to breeze static-checks command (#31269) When you have a workflow, when you rebase several of your branches on the main, there is often a need to re-run pre-commits for all the commits that have been changed by me in the branch (this for example handles those pre-commits changed in the main branch, but the rebase did not result in conflict (this does not run pre-commit automatically even if you have its installed in your repository). It's also useful you have a \"sanity\" check to run before you push your branch.", "Add --only-my-changes flag to breeze static-checks command (#31269) When doing a workflow, when you use several of your branches as a branch on top of main, there is often a need to re-run pre-commits for all the commits that was changed by me in the branch (this for example handles case when pre-commits changed in the main branch, but the rebase did not result in conflict (this will run pre-commit automatically even if you have it installed in your repository). It's also a good \"sanity\" check to run before you push your branch.", "Add --only-my-changes flag to breeze doc (#31269) When you use the main workflow, when you rebase several of your commits, on top of main, there is often a need to re-run pre-commits for all the commits that have been changed by me in the branch. This flag for example handles case when pre-commits changed something on the main branch, but the rebase did not result in conflict (this does not run pre-commit automatically , but you should run it if you have it installed in your repository). It's also a good \"sanity\" check to run before you start the primary branch.", "-line flag to breeze static-checks command . If you have a workflow, when you want to push every branch of your commits, on top of main, there is often a need to re-run pre-commits for all the commits that would have changed on the commit or in the branch (this for example handles case when pre-commits changed in the main branch, but the rebase did not result in conflict (this does not run pre-commit automatically even if you have it installed in your repository). It's also a good \"sanity\" check to run before you push your branch.", "Add --only-my-changes flag . static-checks command (#31269) When you have a workflow, when you rebase several of your commits, on top of main, there is often a need to re-run pre-commits for all the commits that have been changed by me in the main branch. This for example handles case when pre-commits changed in the main branch, but the rebase did not result in conflict (this does not run in your default repository, even if you have it installed in your repository). It's also a good \"sanity\" check to run before you push your branch.", "Add --only-my-changes flag to breeze static-checks command (#31269) When you have a workflow, and you often can rebase several of your own branches on top of main, there is often a need to re-run pre-commits for all the commits that have been changed by me - in the main branch (#32815). This example handles case when pre-commits changed in the main branch, but the rebase did not result in conflict (this does not run pre-commit automatically unless you have it installed on your repository). It's also a good \"sanity\" check to run before you push your branch.", "Add --only-my-changes flag to breeze static-checks command (#31269) When you have a workflow, when you rebase some of your commits, on top of main, there is often the need to re-run pre-commits for all the commits have been changed by me in the branch (this for is a case when pre-commits changed by me in the main branch, but the rebase did not change them anyway) because there was in conflict (this does not run pre-commit automatically even if you have it installed in your repository). It's also a good \"sanity\" check to run before you push your branch.", "Add --only-my-changes flag to breeze . (#31269) When you have a workflow, when you rebase several of your commits, on top of main, there is a need to re-run pre-commits for all the commits that have been changed by me in the branch . This example handles case when pre-commits were performed before rebase of the main branch, but the rebase did not result in conflict (this does not run pre-commit automatically even if you have it installed in you repository). It's also a good thing to run before you push your branch."], "original_ll": -3.6772780418395996, "sampled_ll": -3.414069175720215, "all_perturbed_sampled_ll": [-3.6904966831207275, -3.7186532020568848, -3.5773868560791016, -3.478484630584717, -3.725389242172241, -3.587414264678955, -3.6026997566223145, -3.6886322498321533, -3.5042381286621094, -3.695128917694092], "all_perturbed_original_ll": [-3.5513315200805664, -3.5720431804656982, -3.6419010162353516, -3.834000587463379, -3.512958288192749, -3.5577425956726074, -3.519406318664551, -3.778759479522705, -3.7156519889831543, -3.56712007522583], "perturbed_sampled_ll": -3.6268523931503296, "perturbed_original_ll": -3.6250915050506594, "perturbed_sampled_ll_std": 0.0850286629809854, "perturbed_original_ll_std": 0.10753373951834803}, {"original": "Google provider: Remove `bigquery_conn_id`, `google_cloud_storage_conn_id` (#23326) * `bigquery_conn_id` is removed. Please use `gcp_conn_id`. affected classes: `BigQueryCheckOperator` `BigQueryCreateEmptyDatasetOperator` `BigQueryDeleteDatasetOperator` `BigQueryDeleteTableOperator` `BigQueryExecuteQueryOperator` `BigQueryGetDataOperator` `BigQueryHook` `BigQueryIntervalCheckOperator` `BigQueryTableExistenceSensor` `BigQueryTablePartitionExistenceSensor` `BigQueryToBigQueryOperator` `BigQueryToGCSOperator` `BigQueryUpdateTableSchemaOperator` `BigQueryUpsertTableOperator` `BigQueryValueCheckOperator` `GCSToBigQueryOperator` * `google_cloud_storage_conn_id` is removed. Please use `gcp_conn_id`. affected classes: `ADLSToGCSOperator` `BaseSQLToGCSOperator` `CassandraToGCSOperator` `GCSBucketCreateAclEntryOperator` `GCSCreateBucketOperator` `GCSDeleteObjectsOperator` `GCSHook` `GCSListObjectsOperator` `GCSObjectCreateAclEntryOperator` `GCSToBigQueryOperator` `GCSToGCSOperator` `GCSToLocalFilesystemOperator` `LocalFilesystemToGCSOperator`", "sampled": "Google provider: Remove `bigquery_conn_id`, `google_cloud_storage_conn_id` (#23326) * `bigquery_conn`: add query arguments as arguments to get_clustering_info (#23231) * `google_cloud_storage_conn`: create bucket based on specified user ID (#23220) * `google_cloud_storage_conn`: use `bigquery_conn_id` value when creating new bucket (#23231) * `bigquery_conn_id`: add `bigquery_conn_id` values as defaults (#23208) * `google_cloud_storage_conn`: add `bigquery_conn_id` values to `clustering_info` (#23230) *", "perturbed_sampled": ["Google provider: Remove `bigquery_conn_id`, `google_cloud_storage_conn_id` (#23326) * `bigquery_conn`: add query arguments as arguments to get_clustering_info (#23231) * `google_cloud_storage_conn`: create bucket based on specified user ID (#23220) * `google_cloud_storage_conn`: use `bigquery_conn_id` when creating new bucket (#23231) * `bigquery_conn_id`: add `bigquery_conn_id` values as arguments to get_clustering_info (#23234) * `google_cloud_storage_conn`: add `bigquery_conn_id` values as arguments to fetch_files (#23230) *", "Google provider: Remove `bigquery_conn_id`, `google_cloud_storage_conn_id` (#23326) * `bigquery_conn`: add query arguments as arguments to get_clustering_info (#23231) * <unk>bigquery_conn<unk>: create bucket based on specified user ID (#23220) * use `bigquery_conn_id` value when creating new bucket (#23231) * set `bigquery_conn_id` values as defaults (#23208) * `google_cloud_storage_conn`: add `bigquery_conn_id` values to `clustering_info` (#23230) *", "Google provider: Remove `bigquery_conn_id`, `google_cloud_storage_conn_id` (#23326) * `bigquery_conn`: add clustering ID values as arguments to get_clustering_info (#23231) * `google_cloud_storage_conn`: create bucket based on specified user ID (#23220) * `google_cloud_storage_conn`: use `bigquery_conn_id` value when creating new bucket (#23231) * `bigquery_conn_id`: add `bigquery_conn_id` values as arguments (#23230) * `google_cloud_storage_conn`: add `bigquery_conn_id` values as arguments (#23230) *", "Google provider: Remove `bigquery_conn_id`, `google_cloud_storage_conn_id` (#23326) * Google provider: add query arguments as arguments to queries (#23231) * `google_cloud_storage_conn`: create bucket based on specified user ID (#23220) * `google_cloud_storage_conn`: use `bigquery_conn_id` value when creating new bucket (#23231) * `bigquery_conn_id`: add `bigquery_conn_id` values as defaults (#23208) * Google provider: add `bigquery_conn_id` values to `clustering_info` (#23230) *", "Google provider: Remove `bigquery_conn_id`, `google_cloud_storage_conn_id` (#23326) * `bigquery_conn`: Use arguments as arguments to configure bucket (#23349) * `google_cloud_storage_conn`: create bucket based on specified user ID (#23220) * `google_cloud_storage_conn`: use `bigquery_conn_id` value when creating new bucket (#23231) * `bigquery_conn_id`: enable values as defaults (#23208) * `google_cloud_storage_conn`: add `bigquery_conn_id` values to `clustering_info` (#23230) *", "Google provider: Remove `bigquery_conn_id`, `google_cloud_storage_conn_id` (#23326) * Accept query arguments as arguments to get_clustering_info (#23231) * Create bucket based on specified user (#23278) * `google_cloud_storage_conn`: use `bigquery_conn_id` value when creating new bucket (#23231) * `bigquery_conn_id`: add `bigquery_conn_id` values as defaults (#23208) * `google_cloud_storage_conn`: add `bigquery_conn_id` values to `clustering_info` (#23230) *", "Google provider: Remove `bigquery_conn_id`, `google_cloud_storage_conn_id` (#23326) * `bigquery_conn`: Add arguments as arguments to get_clustering_info (#23211) * `google_cloud_storage_conn`: create bucket based on specified user ID (#23220) * <unk>bigquery_conn<unk>: not use `bigquery_conn_id` value when creating new bucket (#23231) * `bigquery_conn_id`: add `bigquery_conn_id` values as defaults (#23208) * `google_cloud_storage_conn`: add `bigquery_conn_id` values to `clustering_info` (#23230) *", "Google provider: Remove `bigquery_conn_id`, `google_cloud_storage_conn_id` (#23326) * Google provider: add query arguments as arguments to get_clustering_info (#23231) * `google_cloud_storage_conn`: assign buckets based on specified user ID (#23220) * `google_cloud_storage_conn`: use `bigquery_conn_id` value when creating new bucket s * `bigquery_conn_id`: add `bigquery_conn_id` values as defaults (#23208) * `google_cloud_storage_conn`: add `bigquery_conn_id` values to `clustering_info` (#23230) *", "Google provider: Remove `bigquery_conn_id`, `google_cloud_storage_conn_id` (#23326) * <unk>bigquery_conn<unk>: query arguments as arguments to get_clustering_info (#23231) * `google_cloud_storage_conn`: create bucket based on user ID (#23220) * remove `bigquery_conn_id` value when creating new bucket (#23231) * `bigquery_conn_id`: add `bigquery_conn_id` values as defaults (#23208) * `google_cloud_storage_conn`: add `bigquery_conn_id` values to `clustering_info` (#23230) *", "Google provider: add `google_cloud_storage_conn_id` (#23326) * `bigquery_conn`: add query arguments as arguments to get_clustering_info (#23231) * Create new bucket based on specified user ID (#23220) * `google_cloud_storage_conn`: use `bigquery_conn_id` value when creating new bucket (#23231) * `bigquery_conn_id`: add `bigquery_conn_id` values as defaults (#23208) * `google_cloud_storage_conn`: add schema parameters to `clustering_info` (#23230) *"], "perturbed_original": ["Google provider: Remove `bigquery_conn_id`, as needed. * <unk>bigquery_conn_id<unk> is removed. Please use `gcp_conn_id`. affected classes: `BigQueryCheckOperator` `BigQueryCreateEmptyDatasetOperator` `BigQueryDeleteDatasetOperator` `BigQueryDeleteTableOperator` <unk>BigQueryGeneralOperator<unk> `BigQueryHook` `BigQueryIntervalCheckOperator` `BigQueryTableExistenceSensor` `BigQueryTablePartitionExistenceSensor` `BigQueryToBigQueryOperator` `BigQueryToGCSOperator` `BigQueryUpdateTableSchemaOperator` `BigQueryUpsertTableOperator` `BigQueryValueCheckOperator` `GCSToBigQueryOperator` * `google_cloud_storage_conn_id` is removed. Please use `gcp_conn_id`. affected classes: `ADLSToGCSOperator` `BaseSQLToGCSOperator` `CassandraToGCSOperator` `GCSBucketCreateAclEntryOperator` `GCSCreateBucketOperator` `GCSDeleteObjectsOperator` `GCSHook` `GCSListObjectsOperator` `GCSObjectCreateAclEntryOperator` `GCSToBigQueryOperator` `GCSToGCSOperator` `GCSToLocalFilesystemOperator` `LocalFilesystemToGCSOperator`", "Google provider: Remove `bigquery_conn_id`, `google_cloud_storage_conn_id` (#23326) * `bigquery_conn_id` is removed. Please use `gcp_conn_id`. affected classes: `BigQueryCheckOperator` `BigQueryCreateEmptyDatasetOperator` `BigQueryDeleteDatasetOperator` `BigQueryDeleteTableOperator` `BigQueryExecuteQueryOperator` `BigQueryGetDataOperator` `BigQueryHook` `BigQueryIntervalCheckOperator` `BigQueryTableExistenceSensor` `BigQueryTablePartitionExistenceSensor` `BigQueryToBigQueryOperator` `BigQueryToGCSOperator` <unk>BigQueryValueInfoOperator<unk> `BigQueryValueCheckOperator` `GCSToBigQueryOperator` * <unk>bigquery_conn_id<unk> is removed. Please use `gcp_conn_id`. affected classes: `ADLSToGCSOperator` `BaseSQLToGCSOperator` `CassandraToGCSOperator` <unk>GCSCheckOperator<unk> `GCSDeleteObjectsOperator` `GCSHook` `GCSListObjectsOperator` `GCSObjectCreateAclEntryOperator` `GCSToBigQueryOperator` `GCSToGCSOperator` `GCSToLocalFilesystemOperator` `LocalFilesystemToGCSOperator`", "Google provider: Remove `bigquery_conn_id`, `google_cloud_storage_conn_id` (#23326) * `bigquery_conn_id` is removed. Please use `gcp_conn_id`. affected classes: `BigQueryCheckOperator` `BigQueryCreateEmptyDatasetOperator` `BigQueryDeleteDatasetOperator` / `BigQueryGetDataOperator` `BigQueryHook` `BigQueryIntervalCheckOperator` `BigQueryTableExistenceSensor` `BigQueryTablePartitionExistenceSensor` `BigQueryToBigQueryOperator` `BigQueryToGCSOperator` `BigQueryUpdateTableSchemaOperator` `BigQueryUpsertTableOperator` `BigQueryValueCheckOperator` `GCSToBigQueryOperator` * <unk>bigquery_conn_id<unk> is removed. Please use `gcp_conn_id`. affected classes: `ADLSToGCSOperator` `BaseSQLToGCSOperator` `CassandraToGCSOperator` `GCSBucketCreateAclEntryOperator` / `GCSHook` `GCSListObjectsOperator` `GCSObjectCreateAclEntryOperator` `GCSToBigQueryOperator` `GCSToGCSOperator` `GCSToLocalFilesystemOperator` `LocalFilesystemToGCSOperator`", "Google provider: Remove `bigquery_conn_id`, `google_cloud_storage_conn_id` (#23326) * `bigquery_conn_id` is removed. Please use `gcp_conn_id`. affected classes: <unk>BigQueryCreateTableOperator<unk> `BigQueryCheckOperator` `BigQueryCreateEmptyDatasetOperator` `BigQueryDeleteDatasetOperator` `BigQueryDeleteTableOperator` `BigQueryExecuteQueryOperator` `BigQueryGetDataOperator` `BigQueryHook` `BigQueryIntervalCheckOperator` `BigQueryTableExistenceSensor` `BigQueryTablePartitionExistenceSensor` `BigQueryToBigQueryOperator` `BigQueryToGCSOperator` `BigQueryUpdateTableSchemaOperator` `BigQueryUpsertTableOperator` <unk>BigQuery * `google_cloud_storage_conn_id` is removed. Please use `gcp_conn_id`. affected classes: `ADLSToGCSOperator` `BaseSQLToGCSOperator` `CassandraToGCSOperator` `GCSBucketCreateAclEntryOperator` `GCSCreateBucketOperator` `GCSDeleteObjectsOperator` <unk>GCSOpenObjectsOperator<unk> `GCSObjectCreateAclEntryOperator` `GCSToBigQueryOperator` `GCSToGCSOperator` `GCSToLocalFilesystemOperator` `LocalFilesystemToGCSOperator`", "Google provider: Remove `bigquery_conn_id`, `google_cloud_storage_conn_id` (#23326) * `bigquery_conn_id` is removed. Instead use `gcp_conn_id`. affected classes: `BigQueryCheckOperator` `BigQueryCreateEmptyDatasetOperator` `BigQueryDeleteDatasetOperator` `BigQueryDeleteTableOperator` `BigQueryExecuteQueryOperator` `BigQueryGetDataOperator` `BigQueryHook` `BigQueryIntervalCheckOperator` `BigQueryTableExistenceSensor` `BigQueryTablePartitionExistenceSensor` `BigQueryToBigQueryOperator` <unk>BigQueryUploadDataOperator<unk> `BigQueryUpsertTableOperator` `BigQueryValueCheckOperator` `GCSToBigQueryOperator` * `google_cloud_storage_conn_id` is removed. Instead use `gcp_conn_id`. affected classes: `ADLSToGCSOperator` `BaseSQLToGCSOperator` `CassandraToGCSOperator` `GCSBucketCreateAclEntryOperator` `GCSCreateBucketOperator` `GCSDeleteObjectsOperator` `GCSHook` `GCSListObjectsOperator` `GCSObjectCreateAclEntryOperator` `GCSToBigQueryOperator` `GCSToGCSOperator` `GCSToLocalFilesystemOperator` `LocalFilesystemToGCSOperator`", "Google provider: Remove `bigquery_conn_id`, `google_cloud_storage_conn_id` (#23326) * <unk>bigquery_conn_id<unk> is removed. Please use `gcp_conn_id`. affected classes: `BigQueryCheckOperator` `BigQueryCreateEmptyDatasetOperator` <unk>BigQueryDataCreateTimer<unk> `BigQueryExecuteQueryOperator` `BigQueryGetDataOperator` `BigQueryHook` `BigQueryIntervalCheckOperator` `BigQueryTableExistenceSensor` `BigQueryTablePartitionExistenceSensor` `BigQueryToBigQueryOperator` `BigQueryToGCSOperator` `BigQueryUpdateTableSchemaOperator` `BigQueryUpsertTableOperator` `BigQueryValueCheckOperator` `GCSToBigQueryOperator` * `google_cloud_storage_conn_id` is removed. Please use `gcp_conn_id`. affected classes: `ADLSToGCSOperator` `BaseSQLToGCSOperator` `CassandraToGCSOperator` `GCSBucketCreateAclEntryOperator` `GCSCreateBucketOperator` `GCSDeleteObjectsOperator` `GCSHook` `GCSListObjectsOperator` `GCSObjectCreateAclEntryOperator` `GCSToBigQueryOperator` <unk>DataSourceToGCSOperator<unk> `LocalFilesystemToGCSOperator`", "Google provider: Remove `bigquery_conn_id`, `google_cloud_storage_conn_id` (#23326) * `bigquery_conn_id` is removed. Please use `gcp_conn_id`. affected classes: `BigQueryCheckOperator` <unk>BigQueryCheckTableOperator<unk> `BigQueryDeleteTableOperator` `BigQueryExecuteQueryOperator` `BigQueryGetDataOperator` `BigQueryHook` `BigQueryIntervalCheckOperator` <unk>BigQueryObserver<unk> `BigQueryToBigQueryOperator` `BigQueryToGCSOperator` `BigQueryUpdateTableSchemaOperator` `BigQueryUpsertTableOperator` `BigQueryValueCheckOperator` * `google_cloud_storage_conn_id` is removed. Please use `gcp_conn_id`. affected classes: `ADLSToGCSOperator` `BaseSQLToGCSOperator` `CassandraToGCSOperator` `GCSBucketCreateAclEntryOperator` `GCSCreateBucketOperator` `GCSDeleteObjectsOperator` `GCSHook` `GCSListObjectsOperator` `GCSObjectCreateAclEntryOperator` `GCSToBigQueryOperator` `GCSToGCSOperator` `GCSToLocalFilesystemOperator` `LocalFilesystemToGCSOperator`", "Google provider: Remove `bigquery_conn_id`, `google_cloud_storage_conn_id` (#23326) * `bigquery_conn_id` is removed. Please use `gcp_conn_id`. affected classes: `BigQueryCheckOperator` `BigQueryCreateEmptyDatasetOperator` `BigQueryDeleteDatasetOperator` `BigQueryDeleteTableOperator` `BigQueryExecuteQueryOperator` `BigQueryGetDataOperator` `BigQueryHook` `BigQueryIntervalCheckOperator` `BigQueryTableExistenceSensor` `BigQueryTablePartitionExistenceSensor` `BigQueryToBigQueryOperator` `BigQueryToGCSOperator` `BigQueryUpdateTableSchemaOperator` `BigQueryUpsertTableOperator` `BigQueryValueCheckOperator` `GCSToBigQueryOperator` * `google_cloud_storage_conn_id` is removed. Please use <unk>gcp_conn_id<unk>. affected classes: `ADLSToGCSOperator` `BaseSQLToGCSOperator` `CassandraToGCSOperator` `GCSBucketCreateAclEntryOperator` `GCSCreateBucketOperator` `GCSDeleteObjectsOperator` `GCSHook` `GCSListObjectsOperator` <unk>GCSHookGateway<unk> `GCSToGCSOperator` `GCSToLocalFilesystemOperator` `LocalFilesystemToGCSOperator`", "Google provider: Remove `bigquery_conn_id`, `google_cloud_storage_conn_id` (#23326) * `bigquery_conn_id` is removed. Please use <unk>gcp_conn_id<unk>. affected classes: <unk>BigQueryCallback<unk> `BigQueryDeleteDatasetOperator` `BigQueryDeleteTableOperator` `BigQueryExecuteQueryOperator` `BigQueryGetDataOperator` `BigQueryHook` `BigQueryIntervalCheckOperator` `BigQueryTableExistenceSensor` `BigQueryTablePartitionExistenceSensor` <unk>BigQueryTablePartition<unk> `BigQueryUpdateTableSchemaOperator` `BigQueryUpsertTableOperator` `BigQueryValueCheckOperator` `GCSToBigQueryOperator` * `google_cloud_storage_conn_id` is removed. Please use `gcp_conn_id`. affected classes: `ADLSToGCSOperator` `BaseSQLToGCSOperator` `CassandraToGCSOperator` `GCSBucketCreateAclEntryOperator` `GCSCreateBucketOperator` `GCSDeleteObjectsOperator` `GCSHook` `GCSListObjectsOperator` `GCSObjectCreateAclEntryOperator` `GCSToBigQueryOperator` `GCSToGCSOperator` `GCSToLocalFilesystemOperator` `LocalFilesystemToGCSOperator`", "Google provider: Remove `bigquery_conn_id`, removed. * `bigquery_conn_id` is removed. Please use `gcp_conn_id`. affected classes: `BigQueryCheckOperator` `BigQueryCreateEmptyDatasetOperator` `BigQueryDeleteDatasetOperator` `BigQueryDeleteTableOperator` `BigQueryExecuteQueryOperator` `BigQueryGetDataOperator` `BigQueryHook` `BigQueryIntervalCheckOperator` `BigQueryTableExistenceSensor` `BigQueryTablePartitionExistenceSensor` `BigQueryToBigQueryOperator` `BigQueryToGCSOperator` `BigQueryUpdateTableSchemaOperator` `BigQueryUpsertTableOperator` `BigQueryValueCheckOperator` `GCSToBigQueryOperator` * `google_cloud_storage_conn_id` is removed. Please use `gcp_conn_id`. affected classes: `ADLSToGCSOperator` `BaseSQLToGCSOperator` `CassandraToGCSOperator` `GCSBucketCreateAclEntryOperator` `GCSCreateBucketOperator` <unk>GCSCreateBucketOperator<unk> `GCSListObjectsOperator` `GCSObjectCreateAclEntryOperator` `GCSToBigQueryOperator` `GCSToGCSOperator` `GCSToLocalFilesystemOperator` `LocalFilesystemToGCSOperator`"], "original_ll": -1.9139013290405273, "sampled_ll": -1.8263578414916992, "all_perturbed_sampled_ll": [-1.7285678386688232, -2.4547290802001953, -1.8358503580093384, -2.114023447036743, -2.1177914142608643, -2.1785340309143066, -2.1889734268188477, -2.0919289588928223, -2.3009305000305176, -2.3023316860198975], "all_perturbed_original_ll": [-2.0976083278656006, -2.101365327835083, -2.150334119796753, -2.0999321937561035, -2.0782406330108643, -2.221374034881592, -2.050492525100708, -2.105553388595581, -2.1704797744750977, -2.0517263412475586], "perturbed_sampled_ll": -2.1313660740852356, "perturbed_original_ll": -2.1127106666564943, "perturbed_sampled_ll_std": 0.20486695024670762, "perturbed_original_ll_std": 0.05090206605923013}, {"original": "Update README_RELEASE_PROVIDER_PACKAGES.md (#33304)", "sampled": "Update README_RELEASE_PROVIDER_PACKAGES.md (#33304)So", "perturbed_sampled": ["Update README_RELEASE_PROVIDER_PACKAGES.md (#33304)So", "Update README_RELEASE_PROVIDER_PACKAGES.md (#33304)So", "Update README_RELEASE_PROVIDER_PACKAGES.md (#33304)So", "Update README_RELEASE_PROVIDER_PACKAGES.md (#33304)So", "Update README_RELEASE_PROVIDER_PACKAGES.md (#33304)So", "Update README_RELEASE_PROVIDER_PACKAGES.md (#33304)So", "Update README_RELEASE_PROVIDER_PACKAGES.md (#33304)So", "Update README_RELEASE_PROVIDER_PACKAGES.md (#33304)So", "Update README_RELEASE_PROVIDER_PACKAGES.md (#33304)So", "Update README_RELEASE_PROVIDER_PACKAGES.md (#33304)So"], "perturbed_original": ["Update README_RELEASE_PROVIDER_PACKAGES.md (#33304)", "Update README_RELEASE_PROVIDER_PACKAGES.md (#33304)", "Update README_RELEASE_PROVIDER_PACKAGES.md (#33304)", "Update README_RELEASE_PROVIDER_PACKAGES.md (#33304)", "Update README_RELEASE_PROVIDER_PACKAGES.md (#33304)", "Update README_RELEASE_PROVIDER_PACKAGES.md (#33304)", "Update README_RELEASE_PROVIDER_PACKAGES.md (#33304)", "Update README_RELEASE_PROVIDER_PACKAGES.md (#33304)", "Update README_RELEASE_PROVIDER_PACKAGES.md (#33304)", "Update README_RELEASE_PROVIDER_PACKAGES.md (#33304)"], "original_ll": -3.9321835041046143, "sampled_ll": -4.618158340454102, "all_perturbed_sampled_ll": [-4.618158340454102, -4.618158340454102, -4.618158340454102, -4.618158340454102, -4.618158340454102, -4.618158340454102, -4.618158340454102, -4.618158340454102, -4.618158340454102, -4.618158340454102], "all_perturbed_original_ll": [-3.9321835041046143, -3.9321835041046143, -3.9321835041046143, -3.9321835041046143, -3.9321835041046143, -3.9321835041046143, -3.9321835041046143, -3.9321835041046143, -3.9321835041046143, -3.9321835041046143], "perturbed_sampled_ll": -4.618158340454102, "perturbed_original_ll": -3.9321835041046143, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Update doc for DAG file processing (#23209) We can now run the ``DagFileProcessorProcess`` in a separate process and it's not fully documented Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "sampled": "Update doc for DAG file processing (#23209) We can now run the ``DagFileProcessorProcess`` in a separate process and it will no longer be interrupted by processes", "perturbed_sampled": ["Update doc for DAG file processing (#23209) We can now run the ``DagFileProcessorProcess`` in a separate process and it will no longer be included in two different processes", "Update doc for DAG file processing (#23209) We can now run the ``DagFileProcessorProcess`` in a separate process and it will no longer be interrupted by processes", "Update doc for DAG File Processor (#23209) We can now run the ``DagFileProcessorProcess`` in a separate process and it will no longer be interrupted by processes", "Update doc for DAG file processing (#23209) We can now run the DAG file processing as a separate process and it will no longer be interrupted by processes", "Update doc for DAG file processing (#23209) We can now run the ``DagFileProcessorProcess`` in a separate process and therefore the processing will no longer be interrupted by processes", "Update doc for DAG file processing (#23209) We can now run the ``DagFileProcessorProcess`` in a separate process and it will no longer be involved in the processes", "Update doc for DAG file processing (#23209) We can now run the ``DagFileProcessorProcess`` in a separate process and it will no longer be used by processes", "Update doc for DAG file processing (#23209) We can now run the ``DagFileProcessorProcess`` in a separate process and it will not be interrupted by processes", "Update - DAG file processing (#23209) We can now run the ``DagFileProcessorProcess`` in a separate process and it will no longer be interrupted by processes", "Update doc for DAG file processor process. We can now run the ``DagFileProcessorProcess`` in a separate process and it will no longer be interrupted by processes"], "perturbed_original": ["Update doc for DAG file processor We can now run the ``DagFileProcessorProcess`` in a separate process and it's not fully documented Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Update doc for DAG file processing (#23209) We can now run the file processing as a separate process and it's not fully documented Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Update doc for DAG file processing (#23209) We can see it has the ``DagFileProcessorProcess`` in a separate process and it's not fully documented Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Update doc for DAG file processing (#23209) We can now run the DAG file processing as a separate process and it's not fully documented Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Process for DAG file processing (#23209) We can now run the ``DagFileProcessorProcess`` in a separate process and it's not fully documented Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Update doc for DAG file processor We can now run the ``DagFileProcessorProcess`` in a separate process and it's not fully documented Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Update doc for DAG file processing (#23209) We can now run the ``DagFileProcessorProcess`` in a separate process and it's not fully documented . Author: Uranus Chung <uranusjr@gmail.com>", "Update doc for DAG file processing (#23209) We can 't work on DAG files in separate processes because we run the ``DagFileProcessorProcess`` in a separate process and it's not fully documented Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Update on DAG file processing (#23209) We can now run the ``DagFileProcessorProcess`` in a separate process and it's not fully documented Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Update doc for DAG file processing (#23209) We can now run the ``DagFileProcessorProcess`` in a separate process although still not fully documented Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>"], "original_ll": -4.272830486297607, "sampled_ll": -4.0761189460754395, "all_perturbed_sampled_ll": [-4.182235240936279, -4.0761189460754395, -4.269235610961914, -3.764920949935913, -4.131216526031494, -4.145753383636475, -4.123994827270508, -4.102634906768799, -3.8750884532928467, -3.854250192642212], "all_perturbed_original_ll": [-4.321900367736816, -4.306169033050537, -4.587682247161865, -4.06422233581543, -4.100318908691406, -4.321900367736816, -4.220504283905029, -4.110846996307373, -4.168604850769043, -4.4334187507629395], "perturbed_sampled_ll": -4.052544903755188, "perturbed_original_ll": -4.263556814193725, "perturbed_sampled_ll_std": 0.1550356247904114, "perturbed_original_ll_std": 0.1559181348439864}, {"original": "Change Architecture and OperatingSystem classies into Enums (#28627) Since they are objects already, there is a very little overhead into making them Enums and it has the nice property of being able to add type hinting for the returned values.", "sampled": "Change Architecture and OperatingSystem classies into Enums (#28627) Since they are objects already, there is a very little overhead into making them Enums (#28674) Prevent the user from getting information about current language #28678 Create new function to handle the", "perturbed_sampled": ["Change Architecture and OperatingSystem classies into Enums (#28627) Since they are objects already, there is a very little overhead into making them Enums and thus saving the user from being confused about which one, #28678 Create new function to handle the", "Change Architecture and OperatingSystem classies into Enums , since they are objects already, there is a very little overhead into making them new classes. Prevent the user from getting information about current language . Create a new function to handle the", "Language and OperatingSystem classies into Enums (#28627) Since all of the classes can be converted into objects already, there is a very little overhead into making the change (#28674) Prevent the user from getting information about current language #28678 Create new function to handle the", "Change Architecture and OperatingSystem classies into Enums (#28627) Since they are objects already, there is a very small learning curve into making Enumers (#28674) Prevent the user from getting information about current language #28678 Create new class that would safely handle the", "Change Architecture and turn this class into Enums (#28627) Since they are objects already, there is a very short path into making an object. (#28674) Prevent the user from getting information about current language #28678 Create new function to handle the", "Change Architecture and OperatingSystem classies into Enums (#28627) Since they are enums already, there is a very little overhead into making them Enums (#28674) Prevent the user from getting notified about changes (#28075) #28678 Create new function to handle the", "Change Architecture and OperatingSystem classies into objects. Since they are objects already, there is a very little overhead into the model. Add Enums (#28674) Prevent the user from getting information about them. #28678 Create new function to handle the", "Change Architecture and OperatingSystem classies into Enums (#28627) Since most architecture classes are objects already, there is a very little overhead into making them Enums (#28674) Prevent the user from asking about current language #28678 Create new function to read the", "Change Architecture and OperatingSystem classies into Enums (#28627) Since they are objects , there is a very little overhead in adding them into code and making them Enums (#28674) Prevent the user from getting information about current language #28678 Create new class to handle the", "Change Architecture and turn all Enums into Enums (#28627) Since they are objects already, I feel we need to put a very little overhead into making them Enums (#28674) Prevent the user from getting information about current language from new function to handle the"], "perturbed_original": ["Change d our OperatingSystem classies into Enums . As they are already Classies there is a very little overhead into making them Enums and it has the nice property of being able to add type hinting for the returned values.", "Change Architecture and OperatingSystem classies into Enums : Since they are objects already, there is a minimal overhead into making them Enums and it has the nice property of being able to add type hinting for the returned values.", "Change Architecture and OperatingSystem classies into Enums! Since they are objects already, there is a very little overhead into using Enums and it has the nice property of being able to add type hinting to the returned values.", "Change Architecture and OperatingSystem classies into Enums (#28627) Since they are only classes already, there is a very little overhead into making them Enums and it has the nice benefits of being able to use type hinting for the returned values.", "Change Architecture and OperatingSystem classies into Enums (#28627) Since they are objects already, there is a very little overhead into making them Enums and it 's also nice to have the flexibility in being able to add type hinting for the returned values.", "Types and make them into Enums (#28627) Since they are objects already, there is a very little overhead into making them Enums and it has the nice property of being able to also add type hinting for the returned values.", "Change Architecture and OperatingSystem classies into Enums (#28627) Since they are objects , there is a very little overhead into making some classes and it has the nice property of being able to add type hinting for the values.", "Change Architecture and OperatingSystem classies into Enums (#28627) Since they are classes there is a very little overhead into making them enums and it has the nice benefits of being able to add type hinting for the returned values.", "Change Architecture and OperatingSystem classies into Enums (#28627) Since they are objects there is a very little overhead in making them Enums and it has the nice property of being able to have a class hinting for the returned values.", "Change d the OperatingSystem classies into Enums (#28627) Since they are objects already, there is a very little overhead into making them Enums and not losing the nice property of being able to add type hinting for the returned values."], "original_ll": -4.313924789428711, "sampled_ll": -4.496889591217041, "all_perturbed_sampled_ll": [-4.763833522796631, -4.802054405212402, -4.543711185455322, -4.917389392852783, -4.421830654144287, -4.307785987854004, -4.610102653503418, -4.569483757019043, -4.373091697692871, -4.29172945022583], "all_perturbed_original_ll": [-4.461549282073975, -4.304324150085449, -4.200261116027832, -4.342690467834473, -4.360535144805908, -3.785548210144043, -4.665530681610107, -4.41217041015625, -4.25869607925415, -4.565677642822266], "perturbed_sampled_ll": -4.560101270675659, "perturbed_original_ll": -4.3356983184814455, "perturbed_sampled_ll_std": 0.20502134915261716, "perturbed_original_ll_std": 0.22626403649911023}, {"original": "Make Google Dataform operators templated_fields more consistent (#34187)", "sampled": "Make Google Dataform operators templated_fields more consistent (#34187)A", "perturbed_sampled": ["Make Google Dataform operators templated_fields more consistent (#34187)A", "Make Google Dataform operators templated_fields more consistent (#34187)A", "Make Google Dataform operators templated_fields more consistent (#34187)A", "Make Google Dataform operators templated_fields more consistent (#34187)A", "Make Google Dataform operators templated_fields more consistent (#34187)A", "Make Google Dataform operators templated_fields more consistent (#34187)A", "Make Google Dataform operators templated_fields more consistent (#34187)A", "Make Google Dataform operators templated_fields more consistent (#34187)A", "Make Google Dataform operators templated_fields more consistent (#34187)A", "Make Google Dataform operators templated_fields more consistent (#34187)A"], "perturbed_original": ["Make Google Dataform operators templated_fields more consistent (#34187)", "Make Google Dataform operators templated_fields more consistent (#34187)", "Make Google Dataform operators templated_fields more consistent (#34187)", "Make Google Dataform operators templated_fields more consistent (#34187)", "Make Google Dataform operators templated_fields more consistent (#34187)", "Make Google Dataform operators templated_fields more consistent (#34187)", "Make Google Dataform operators templated_fields more consistent (#34187)", "Make Google Dataform operators templated_fields more consistent (#34187)", "Make Google Dataform operators templated_fields more consistent (#34187)", "Make Google Dataform operators templated_fields more consistent (#34187)"], "original_ll": -6.525368690490723, "sampled_ll": -6.9474101066589355, "all_perturbed_sampled_ll": [-6.9474101066589355, -6.9474101066589355, -6.9474101066589355, -6.9474101066589355, -6.9474101066589355, -6.9474101066589355, -6.9474101066589355, -6.9474101066589355, -6.9474101066589355, -6.9474101066589355], "all_perturbed_original_ll": [-6.525368690490723, -6.525368690490723, -6.525368690490723, -6.525368690490723, -6.525368690490723, -6.525368690490723, -6.525368690490723, -6.525368690490723, -6.525368690490723, -6.525368690490723], "perturbed_sampled_ll": -6.9474101066589355, "perturbed_original_ll": -6.525368690490723, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Helm chart 1.6.0 is released; bump chart version to 1.7.0-dev (#23840)", "sampled": "Helm chart 1.6.0 is released; bump chart version to 1.7.0-dev (#23840)Image", "perturbed_sampled": ["Helm chart 1.6.0 is released; bump chart version to 1.7.0-dev (#23840)Image", "Helm chart 1.6.0 is released; bump chart version to 1.7.0-dev (#23840)Image", "Helm chart 1.6.0 is released; bump chart version to 1.7.0-dev (#23840)Image", "Helm chart 1.6.0 is released; bump chart version to 1.7.0-dev (#23840)Image", "Helm chart 1.6.0 is released; bump chart version to 1.7.0-dev (#23840)Image", "Helm chart 1.6.0 is released; bump chart version to 1.7.0-dev (#23840)Image", "Helm chart 1.6.0 is released; bump chart version to 1.7.0-dev (#23840)Image", "Helm chart 1.6.0 is released; bump chart version to 1.7.0-dev (#23840)Image", "Helm chart 1.6.0 is released; bump chart version to 1.7.0-dev (#23840)Image", "Helm chart 1.6.0 is released; bump chart version to 1.7.0-dev (#23840)Image"], "perturbed_original": ["Helm chart 1.6.0 is released; bump chart version to 1.7.0-dev (#23840)", "Helm chart 1.6.0 is released; bump chart version to 1.7.0-dev (#23840)", "Helm chart 1.6.0 is released; bump chart version to 1.7.0-dev (#23840)", "Helm chart 1.6.0 is released; bump chart version to 1.7.0-dev (#23840)", "Helm chart 1.6.0 is released; bump chart version to 1.7.0-dev (#23840)", "Helm chart 1.6.0 is released; bump chart version to 1.7.0-dev (#23840)", "Helm chart 1.6.0 is released; bump chart version to 1.7.0-dev (#23840)", "Helm chart 1.6.0 is released; bump chart version to 1.7.0-dev (#23840)", "Helm chart 1.6.0 is released; bump chart version to 1.7.0-dev (#23840)", "Helm chart 1.6.0 is released; bump chart version to 1.7.0-dev (#23840)"], "original_ll": -4.208068370819092, "sampled_ll": -4.651737689971924, "all_perturbed_sampled_ll": [-4.651737689971924, -4.651737689971924, -4.651737689971924, -4.651737689971924, -4.651737689971924, -4.651737689971924, -4.651737689971924, -4.651737689971924, -4.651737689971924, -4.651737689971924], "all_perturbed_original_ll": [-4.208068370819092, -4.208068370819092, -4.208068370819092, -4.208068370819092, -4.208068370819092, -4.208068370819092, -4.208068370819092, -4.208068370819092, -4.208068370819092, -4.208068370819092], "perturbed_sampled_ll": -4.651737689971924, "perturbed_original_ll": -4.208068370819092, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "INTHEWILD, add shopify (#25701) Since we've been using it for years and is core to our data org.", "sampled": "INTHEWILD, add shopify (#25701) Since we've been using it for years and is core to our data org.TheBigData.com,", "perturbed_sampled": ["INTHEWILD, add shopify (#25701) : Weve been using it for years and is core to our data org.TheBigData.com,", "INTHEWILD, add shopify (#25701) Since we've been using it for a business is core to our data org.TheBigData.com,", "INTHEWILD, Inc. (#25701) Since we've been using it for years and is core to our data org.TheBigData.com,", "INTHEWILD, INC. (#25701) Since we've been using it for years and is core to our data org.TheBigData.com,", ". shopify (#25701) Since we've been using it for years and is core to our data org.TheBigData.com,", "INTHEWILD, add shopify (#25701) Since we've been using INTHEWILD data for years and is core to our data org.TheBigData.com,", "INTHEWILD, add shopify (#25701) Since we've been using it for years and is core to our data org.TheBigData.com,", "INTHEWILD, add shopify (#25701) Since we've been using it for years, and it is core to our data org.TheBigData.com,", "INTHEWILD, add shopify (#25701) , weve been using it for years and is core to our data org.TheBigData.com,", "INTHEWILD, add shopify . we've been using it for years and is core to our data org.TheBigData.com,"], "perturbed_original": ["INTHEWILD, add shopify (#25701) Since we've been using it for years and is the largest platform for our data org.", "INTHEWILD, add shopify (#25701) Since we've been using Shopify for years and is core to our data org.", "INTHEWILD, add shopify (#25701) \u2014 we\u2019ve been using it for years and is core to our data org.", "INTHEWILD, add shopify (#25701) Since we have been using it for years and is core to our data org.", "INTHEWILD, add our own support. Since we've been using it for years and is core to our data org.", "Intuit? shopify (#25701) Since we've been using it for years and is core to our data org.", "INTHEWILD, add shopify (#25701) Since we've been using it for years and is part of our data org.", "INTHEWILD, add shopify (#25701) Since we've been using shopify for 8 years and is core to our data org.", "INTHEWILD, add shopify (#25701) Since we've used it for years and is core to our data org.", "INTHEWILD, add shopify (#25701) Since we've been using it for years , shopify is core to our data org."], "original_ll": -5.322024345397949, "sampled_ll": -5.121696949005127, "all_perturbed_sampled_ll": [-5.296511173248291, -5.378279685974121, -4.655663967132568, -4.636359691619873, -5.143677711486816, -5.012013912200928, -5.121696949005127, -4.738448619842529, -5.174490928649902, -4.818570137023926], "all_perturbed_original_ll": [-5.342254161834717, -5.064741611480713, -5.504375457763672, -5.354342937469482, -4.914851188659668, -5.150190830230713, -5.253200531005859, -5.114767551422119, -5.616940498352051, -5.10304594039917], "perturbed_sampled_ll": -4.997571277618408, "perturbed_original_ll": -5.241871070861817, "perturbed_sampled_ll_std": 0.2547798573772819, "perturbed_original_ll_std": 0.20361495714693142}, {"original": "Enable string normalization in python formatting - providers (#27205)", "sampled": "Enable string normalization in python formatting - providers (#27205)With", "perturbed_sampled": ["Enable string normalization in python formatting - providers (#27205)With", "Enable string normalization in python formatting - providers (#27205)With", "Enable string normalization in python formatting - providers (#27205)With", "Enable string normalization in python formatting - providers (#27205)With", "Enable string normalization in python formatting - providers (#27205)With", "Enable string normalization in python formatting - providers (#27205)With", "Enable string normalization in python formatting - providers (#27205)With", "Enable string normalization in python formatting - providers (#27205)With", "Enable string normalization in python formatting - providers (#27205)With", "Enable string normalization in python formatting - providers (#27205)With"], "perturbed_original": ["Enable string normalization in python formatting - providers (#27205)", "Enable string normalization in python formatting - providers (#27205)", "Enable string normalization in python formatting - providers (#27205)", "Enable string normalization in python formatting - providers (#27205)", "Enable string normalization in python formatting - providers (#27205)", "Enable string normalization in python formatting - providers (#27205)", "Enable string normalization in python formatting - providers (#27205)", "Enable string normalization in python formatting - providers (#27205)", "Enable string normalization in python formatting - providers (#27205)", "Enable string normalization in python formatting - providers (#27205)"], "original_ll": -6.687281131744385, "sampled_ll": -7.368417739868164, "all_perturbed_sampled_ll": [-7.368417739868164, -7.368417739868164, -7.368417739868164, -7.368417739868164, -7.368417739868164, -7.368417739868164, -7.368417739868164, -7.368417739868164, -7.368417739868164, -7.368417739868164], "all_perturbed_original_ll": [-6.687281131744385, -6.687281131744385, -6.687281131744385, -6.687281131744385, -6.687281131744385, -6.687281131744385, -6.687281131744385, -6.687281131744385, -6.687281131744385, -6.687281131744385], "perturbed_sampled_ll": -7.368417739868164, "perturbed_original_ll": -6.687281131744385, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Only load distribution of a name once (#25296)", "sampled": "Only load distribution of a name once (#25296)Include", "perturbed_sampled": ["Only load distribution of a name once (#25296)Include", "Only load distribution of a name once (#25296)Include", "Only load distribution of a name once (#25296)Include", "Only load distribution of a name once (#25296)Include", "Only load distribution of a name once (#25296)Include", "Only load distribution of a name once (#25296)Include", "Only load distribution of a name once (#25296)Include", "Only load distribution of a name once (#25296)Include", "Only load distribution of a name once (#25296)Include", "Only load distribution of a name once (#25296)Include"], "perturbed_original": ["Only load distribution of a name once (#25296)", "Only load distribution of a name once (#25296)", "Only load distribution of a name once (#25296)", "Only load distribution of a name once (#25296)", "Only load distribution of a name once (#25296)", "Only load distribution of a name once (#25296)", "Only load distribution of a name once (#25296)", "Only load distribution of a name once (#25296)", "Only load distribution of a name once (#25296)", "Only load distribution of a name once (#25296)"], "original_ll": -6.3500189781188965, "sampled_ll": -6.713711261749268, "all_perturbed_sampled_ll": [-6.713711261749268, -6.713711261749268, -6.713711261749268, -6.713711261749268, -6.713711261749268, -6.713711261749268, -6.713711261749268, -6.713711261749268, -6.713711261749268, -6.713711261749268], "all_perturbed_original_ll": [-6.3500189781188965, -6.3500189781188965, -6.3500189781188965, -6.3500189781188965, -6.3500189781188965, -6.3500189781188965, -6.3500189781188965, -6.3500189781188965, -6.3500189781188965, -6.3500189781188965], "perturbed_sampled_ll": -6.713711261749268, "perturbed_original_ll": -6.3500189781188965, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Add support for TaskGroup in ExternalTaskSensor (#24902)", "sampled": "Add support for TaskGroup in ExternalTaskSensor (#24902)As", "perturbed_sampled": ["Add support for TaskGroup in ExternalTaskSensor (#24902)As", "Add support for TaskGroup in ExternalTaskSensor (#24902)As", "Add support for TaskGroup in ExternalTaskSensor (#24902)As", "Add support for TaskGroup in ExternalTaskSensor (#24902)As", "Add support for TaskGroup in ExternalTaskSensor (#24902)As", "Add support for TaskGroup in ExternalTaskSensor (#24902)As", "Add support for TaskGroup in ExternalTaskSensor (#24902)As", "Add support for TaskGroup in ExternalTaskSensor (#24902)As", "Add support for TaskGroup in ExternalTaskSensor (#24902)As", "Add support for TaskGroup in ExternalTaskSensor (#24902)As"], "perturbed_original": ["Add support for TaskGroup in ExternalTaskSensor (#24902)", "Add support for TaskGroup in ExternalTaskSensor (#24902)", "Add support for TaskGroup in ExternalTaskSensor (#24902)", "Add support for TaskGroup in ExternalTaskSensor (#24902)", "Add support for TaskGroup in ExternalTaskSensor (#24902)", "Add support for TaskGroup in ExternalTaskSensor (#24902)", "Add support for TaskGroup in ExternalTaskSensor (#24902)", "Add support for TaskGroup in ExternalTaskSensor (#24902)", "Add support for TaskGroup in ExternalTaskSensor (#24902)", "Add support for TaskGroup in ExternalTaskSensor (#24902)"], "original_ll": -6.41204309463501, "sampled_ll": -7.075325965881348, "all_perturbed_sampled_ll": [-7.075325965881348, -7.075325965881348, -7.075325965881348, -7.075325965881348, -7.075325965881348, -7.075325965881348, -7.075325965881348, -7.075325965881348, -7.075325965881348, -7.075325965881348], "all_perturbed_original_ll": [-6.41204309463501, -6.41204309463501, -6.41204309463501, -6.41204309463501, -6.41204309463501, -6.41204309463501, -6.41204309463501, -6.41204309463501, -6.41204309463501, -6.41204309463501], "perturbed_sampled_ll": -7.075325965881348, "perturbed_original_ll": -6.41204309463501, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Add test for datasets reserving 'airflow' scheme (#25914)", "sampled": "Add test for datasets reserving 'airflow' scheme (#25914)In", "perturbed_sampled": ["Add test for datasets reserving 'airflow' scheme (#25914)In", "Add test for datasets reserving 'airflow' scheme (#25914)In", "Add test for datasets reserving 'airflow' scheme (#25914)In", "Add test for datasets reserving 'airflow' scheme (#25914)In", "Add test for datasets reserving 'airflow' scheme (#25914)In", "Add test for datasets reserving 'airflow' scheme (#25914)In", "Add test for datasets reserving 'airflow' scheme (#25914)In", "Add test for datasets reserving 'airflow' scheme (#25914)In", "Add test for datasets reserving 'airflow' scheme (#25914)In", "Add test for datasets reserving 'airflow' scheme (#25914)In"], "perturbed_original": ["Add test for datasets reserving 'airflow' scheme (#25914)", "Add test for datasets reserving 'airflow' scheme (#25914)", "Add test for datasets reserving 'airflow' scheme (#25914)", "Add test for datasets reserving 'airflow' scheme (#25914)", "Add test for datasets reserving 'airflow' scheme (#25914)", "Add test for datasets reserving 'airflow' scheme (#25914)", "Add test for datasets reserving 'airflow' scheme (#25914)", "Add test for datasets reserving 'airflow' scheme (#25914)", "Add test for datasets reserving 'airflow' scheme (#25914)", "Add test for datasets reserving 'airflow' scheme (#25914)"], "original_ll": -6.212742328643799, "sampled_ll": -6.718313217163086, "all_perturbed_sampled_ll": [-6.718313217163086, -6.718313217163086, -6.718313217163086, -6.718313217163086, -6.718313217163086, -6.718313217163086, -6.718313217163086, -6.718313217163086, -6.718313217163086, -6.718313217163086], "all_perturbed_original_ll": [-6.212742328643799, -6.212742328643799, -6.212742328643799, -6.212742328643799, -6.212742328643799, -6.212742328643799, -6.212742328643799, -6.212742328643799, -6.212742328643799, -6.212742328643799], "perturbed_sampled_ll": -6.718313217163086, "perturbed_original_ll": -6.212742328643799, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Add missing changelog in 2.6.0 (#31011) * Add missing changelog in 2.6.0 * Update RELEASE_NOTES.rst Co-authored-by: Pankaj Koti <pankajkoti699@gmail.com> * fixup! Add missing changelog in 2.6.0 --------- Co-authored-by: Pankaj Koti <pankajkoti699@gmail.com>", "sampled": "Add missing changelog in 2.6.0 (#31011) * Add missing changelog in 2.6.0 * Update RELEASE.jar to 6.0.14.2 * Upgraded BoolInt 8 to the latest version * New version, fixed BoolInt8 bug", "perturbed_sampled": ["Add missing changelog in 2.6.0 * Add missing changelog in 2.6.0 * Update RELEASE.jar to 6.0.14.2 * Upgraded BoolInt 8 to the latest version * New version, fixed BoolInt8 bug", "Add missing changelog in 2.6.0 (#31011) * Add missing changelog in 2.6.0 * Update RELEASE.jar to 6.0.14.2 * Upgraded BoolInt 8 to the latest version from 2.5.0 version, fixed BoolInt8 bug", "Add missing changelog in 2.6.0 (#31011) * Add missing changelog in 2.6.0 * Update RELEASE.jar to 6.0.14.2 * Upgraded BoolInt 8 to the latest version * New version, solved bug", "Add missing changelog in 1.2.0 * Add missing changelog in 2.6.0 * Update RELEASE.jar to 6.0.14.2 * Upgraded BoolInt 8 to the latest version * New version, fix bug", "* Add missing changelog in 2.6.0 (#31011) * Add missing changelog in 2.6.0 * Update RELEASE.jar to 6.0.14.2 * Upgraded BoolInt 8 to the latest version * Closed / fixed BoolInt8 bug", "Add missing changelog in 2.6.0 (#31011) * Add missing changelog in 2.6.0 * Updated Bool8 to 6.0.14.2 * Upgraded BoolInt 8 to the latest release * New version, fixed BoolInt8 bug", "Add missing changelog in 2.6.0 (#31011) * Add missing changelog in 2.6.0 * Update RELEASE.jar to 6.0.14.2 * Upgraded documentation to the latest version * New version, fixed BoolInt8 bug", "Add missing changelog in 2.6.0 * Add missing changelog in 2.6.0 * Update RELEASE.jar to 6.0.14.2 * Upgraded BoolInt 8 to latest version * New version, fixed BoolInt8 bug", "Add new DB in 2.6.0 (#31011) * Add new SMB in 2.6.0 * Update RELEASE.jar to 6.0.14.2 * Upgraded BoolInt 8 to the latest version * New version, fixed BoolInt8 bug", "Add missing changelog in 2.6.0 (#31011) * Add missing changelog in 2.6.0 * Update RELEASE.jar to 6.0.14.2 * Upgraded BoolInt 8 to the latest version. * New version, fixed BoolInt8 bug"], "perturbed_original": ["Add missing changelog in 2.6.0 * fixup! Add missing changelog in 2.6.0 * Update RELEASE_NOTES.rst Co-authored-by: Pankaj Koti <pankajkoti699@gmail.com> * fixup! Add missing changelog in 2.6.0 --------- Co-authored-by: Pankaj Koti <pankajkoti699@gmail.com>", "Add missing changelog in 2.6.0 (#31011) * Add missing changelog in 2.6.0 (#31011) * RELEASE_NOTES.rst Co-authored-by: Pankaj Koti <pankajkoti699@gmail.com> * fixup! Add missing changelog in 2.6.0 (#31011) Co-authored-by: Pankaj Koti <pankajkoti699@gmail.com>", "Add missing changelog in 2.6.0 (#31011) * Add missing changelog in 2.6.0 * Added Co-authored-by: Pankaj Koti <pankajkoti699@gmail.com> * fixup! Add missing changelog in 2.6.0 * Co-authored-by: Pankaj Koti <pankajkoti699@gmail.com>", "Add missing changelog in 2.6.0 (#31011) * Add missing changelog in 2.6.0 * Update RELEASE_NOTES.rst Co-authored-by: Pankaj Koti <pankajkoti699@gmail.com> * fixup! Add missing changelog in 2.6.0 --------- ----- --- Pankaj Koti <pankajkoti699@gmail.com>", "Add missing changelog in 2.6.0 (#31011) * Add missing changelog in 2.6.0 * Update RELEASE_NOTES.rst Co-authored-by: Pankaj Koti Good fixup! Add missing changelog in 2.6.0 --------- Co-authored-by: Pankaj Koti <pankajkoti699@gmail.com>", "Add missing changelog in 2.6.0 (#31011) * Add missing changelog in 2.6.0 (#31013) * Update RELEASE_NOTES.rst Co-authored-by: Pankaj Koti <pankajkoti699@gmail.com> * fixup! Add missing changelog in 2.6.0 --------- Co-authored-by: Pankaj Koti <pankajkoti699@gmail.com>", "Add missing changelog in 2.6.0 (#31011) * Add missing changelog in 2.6.0 * Update RELEASE_NOTES.rst Co-authored-by: Pankaj Koti <pankajkoti699@gmail.com> * fixup! Add missing changelog in 2.6.0 --------- Co-authored-by: Pankaj Koti <pankajkoti699@gmail.com>", "Add missing changelog in 2.6.0 (#31011) * Add missing changelog in 2.6.0 * Update RELEASE_NOTES.rst Co-authored-by: Pankaj Koti Excellent fixup! * Add missing changelog in 2.6.0 --------- Co-authored-by: Pankaj Koti <pankajkoti699@gmail.com>", "Add missing changelog in 2.6.0 (#31011) * Add missing changelog in 2.6.0 * Update RELEASE_NOTES.rst Co-authored-by: Pankaj Koti <pankajkoti699@gmail.com> * fixup! Add missing changelog in 2.6.0 --------- Co-authored-by: Pankaj Koti <pankajkoti699@gmail.com>", "Add missing changelog in 2.6.0 (#31011) * fixup! Add missing changelog in 2.6.0 * Update RELEASE_NOTES.rst Co-authored-by: Pankaj Koti <pankajkoti699@gmail.com> * fixup! Add missing changelog in 2.6.0 Co-authored-by: Pankaj Koti <pankajkoti699@gmail.com>"], "original_ll": -2.1828808784484863, "sampled_ll": -3.0183310508728027, "all_perturbed_sampled_ll": [-2.8406803607940674, -2.9881458282470703, -3.157658338546753, -3.020111083984375, -3.203619956970215, -3.0333828926086426, -3.1700687408447266, -2.8969264030456543, -3.4140408039093018, -2.993778944015503], "all_perturbed_original_ll": [-2.0355379581451416, -1.9358959197998047, -2.0105018615722656, -2.40073823928833, -2.5939409732818604, -2.157362937927246, -2.1828808784484863, -2.5387043952941895, -2.1828808784484863, -2.0191118717193604], "perturbed_sampled_ll": -3.071841335296631, "perturbed_original_ll": -2.205755591392517, "perturbed_sampled_ll_std": 0.15898542005526461, "perturbed_original_ll_std": 0.218565222697748}, {"original": "Fix dynamodb test (#31316)", "sampled": "Fix dynamodb test (#31316)This", "perturbed_sampled": ["Fix dynamodb test (#31316)This", "Fix dynamodb test (#31316)This", "Fix dynamodb test (#31316)This", "Fix dynamodb test (#31316)This", "Fix dynamodb test (#31316)This", "Fix dynamodb test (#31316)This", "Fix dynamodb test (#31316)This", "Fix dynamodb test (#31316)This", "Fix dynamodb test (#31316)This", "Fix dynamodb test (#31316)This"], "perturbed_original": ["Fix dynamodb test (#31316)", "Fix dynamodb test (#31316)", "Fix dynamodb test (#31316)", "Fix dynamodb test (#31316)", "Fix dynamodb test (#31316)", "Fix dynamodb test (#31316)", "Fix dynamodb test (#31316)", "Fix dynamodb test (#31316)", "Fix dynamodb test (#31316)", "Fix dynamodb test (#31316)"], "original_ll": -6.724749565124512, "sampled_ll": -7.469329833984375, "all_perturbed_sampled_ll": [-7.469329833984375, -7.469329833984375, -7.469329833984375, -7.469329833984375, -7.469329833984375, -7.469329833984375, -7.469329833984375, -7.469329833984375, -7.469329833984375, -7.469329833984375], "all_perturbed_original_ll": [-6.724749565124512, -6.724749565124512, -6.724749565124512, -6.724749565124512, -6.724749565124512, -6.724749565124512, -6.724749565124512, -6.724749565124512, -6.724749565124512, -6.724749565124512], "perturbed_sampled_ll": -7.469329833984375, "perturbed_original_ll": -6.724749565124512, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Update admonitions in Python operator doc to reflect sentiment (#36340) Within the Python operator how-to guide, there are doc admonitions that don't necessarily reflect the sentiment of the call-out. For example, there are several places where there is a recommendation to use the TaskFlow version of an operator but the admonition is a warning; this is more of a tip when authoring DAGs. This PR hopes to match the sentiment of the call-out with an \"appropriate\" admonition in the doc for better context and visbility when reading the doc.", "sampled": "Update admonitions in Python operator doc to reflect sentiment (#36340) Within the Python operator how-to guide, there are doc admonitions that don't really reflect the opinion expressed. This might seem like more code, I think it's a minor misstep. But I've personally experienced that when I change a line, all the code that doesn't adhere to our code of thinking will simply sit there when you try and read it by hand. I tried to be more clear; for reference, this is a simple error: >>> from decimal import", "perturbed_sampled": ["Edit in Python operator doc to reflect our code (#36340) Within the Python operator how-to guide, there are doc admonitions that don't really reflect the opinion expressed. This might seem like more of a challenge and one might think it's a minor misstep. But I've personally experienced that when I change a line, all the code that doesn't adhere to our code of thinking will simply sit there when you try and compile the package by hand. I would like to be more clear; for reference, this is a simple text from decimal import", "Update admonitions in Python operator doc to reflect newer information. (#36340) Within the Python operator how-to guide, there are doc admonitions that don't necessarily appear to reflect the opinion expressed. This might seem like more code, I think it's a minor misstep. But I've personally experienced that when it comes to breaking a line, any code that doesn't adhere to our code of thinking will simply sit there when you try and read it by hand. I just want to be more clear; for reference, this is a simple function from decimal import", "Added comments in Python operator doc to reflect sentiment (#36340) Within the Python operator how-to guide, there are doc admonitions that don't really reflect the opinion expressed. While it might seem like more code, I think it's a minor misstep. I have personally experienced that when I change a line, all the code that doesn't adhere to our code of thinking will simply sit there when you try and read it by hand. I tried to be more open to this concept. For reference, this is a comment. >>> from decimal import", "Update admonitions in Python operator to reflect sentiment (#36340) Within the Python operator how-to guide, there are doc admonitions that don't really reflect the opinion expressed. This might seem like more of an error, and at first, I think it's a minor misstep. But I've personally experienced that when developers try and change a line, all the code that would adhere to our code of thinking will still be there when you try and read it by hand. I tried to be more clear; for reference, this is a simple error: >>> from decimal import", "Update admonitions in Python operator doc to reflect sentiment (#36340) Within the Python operator how-to guide, there are admonitions that may be re-written to reflect the opinion expressed. This might seem like more code, I think it's just one more common misstep. But I've personally experienced that when I change a command, the code that doesn't adhere to our way of thinking will simply sit there when you try and read it by hand. I tried to be more clear; for reference, this is a simple error: >>> from decimal import", "Update admonitions in Python operator guides to reflect sentiment (#36340) Within the Python operator how-to guide, there are doc admonitions that don't really reflect the opinion expressed. This might seem like a trivial issue, and I think it's an easily avoided misstep. But I've personally experienced that when I change a line, all the code that doesn't adhere to our way of thinking will simply sit there , and we'll have to try and read it by hand. I tried to be more clear; for reference, here's a simple error: >>> from decimal import", "Update admonitions in Python operator doc to reflect sentiment (#36340) Within the Python operator how-to guide, there are doc admonitions that don't fit the opinion that these might seem like more code, I think , as a minor misstep. But I've personally experienced that when I change a line, all the code that doesn't adhere to this way of thinking will simply sit there when you try and read it by hand. I tried to make the doc more clear; for reference, this is a simple error: >>> from decimal import", "Fix comments in Python operator doc to reflect sentiment (#36340) Within the Python operator how-to guide, there are doc admonitions that don't really reflect the opinion expressed. This might seem like more code, I think it's a minor misstep. But I've personally experienced that when I comment on a line, all the code that doesn't adhere to our code of thinking will simply sit there until you try and read it by hand. I tried to be more clear; for example, here is a line that makes the following comment. >>> from decimal import", "Update admonitions in Python operator doc s to reflect sentiment (#36340) In the Python operator docs, there are doc admonitions that don't really reflect the opinion expressed. This might seem like more code, I think it's a minor misstep. But I've personally experienced that when I change a test method, the code that doesn't adhere to our code of thinking will simply sit there when you try and read it by hand. I think that it would be better to make this change publicly. Just for reference, this is a simple error: >>> from decimal import", "Update admonitions in Python operator doc to reflect sentiment (#36340) Within the Python operator how-to there are doc admonitions that don't really reflect the opinion expressed. This might seem a minor error, and for our code, I think it's a minor misstep. But I have experienced something similar when I change all the doc comments and all the code that doesn't adhere to our design thinking will simply sit there when you try and read it by hand. I tried to be more clear; for reference, this is a simple error: >>> from decimal import"], "perturbed_original": ["Update admonitions in operator doc to reflect sentiment (#36340) Within the Python operator how-to guide, there are doc admonitions that may no longer reflect the sentiment of the operators as they call-out. For example, there are several places where there is a recommendation to use the operator instead of an operator but there is a warning; this is more of a tip when authoring DAGs. This tries to match the sentiment of the call-out with an \"appropriate\" admonition in the doc for better context and visbility when reading the doc.", "Update admonitions in Python operator doc to reflect sentiment . In the Python operator how-to guide, there are doc admonitions that do not necessarily reflect the sentiment of the call-out. For example, there are several places where there is a recommendation to use the Python 2.1 version of an operator but the admonition is a warning; this is more of a tip when authoring DAGs. This PR hopes to match the sentiment of the call-out with the more \"appropriate\" admonition in the doc for better context and clarity when reading the doc.", "Update admonitions in Python operator doc to reflect sentiment (#36340) Within the Python operator how-to guide, there are doc admonitions that don't necessarily reflect the sentiment of the call-out. For example, there are descriptions where an admonition is a recommendation to use the TaskFlow version of an operator , while a doc admonition is a warning; this is more of a tip when authoring DAGs. This PR hopes to match the sentiment of the call-out with an \"appropriate\" admonition in the doc for better context and visbility when reviewing the operation doc.", "Update admonitions in Python operator doc to reflect sentiment (#36340) Within the Python operator how-to guide, there are doc admonitions that don't necessarily reflect the sentiment of the call-out. For example, there are several examples where there is a call-out to use the call-out of an operator but the admonition is a warning; this is more of an issue when authoring DAGs. This PR hopes to match the sentiment of the call-out with an \"appropriate\" admonition in the doc for better context and visbility in the doc.", "Update admonitions in Python operator doc to reflect sentiment (#36340) Within the Python operator how-to guide, there are doc admonitions for each call-out that do not necessarily reflect the sentiment of the call-out. For example, in several places where there is a recommendation to use the TaskFlow version of an operator, the admonition is a warning; for several other calls-outs, it would be more of a tip when authoring DAGs. This change is designed to match the sentiment of the call-out with an \"appropriate\" admonition in the doc for ease of use and visbility when reading the doc.", "Update admonitions in Python operators. This PR is related to Admonition (#36340) Within the Python operator how-to doc, there are doc admonitions that don't necessarily reflect the sentiment of the call-out. For example, there are several places where there is a recommendation to use the corresponding version of an operator but the admonition is a warning; this is more of a tip when authoring DAGs. This PR hopes to match the sentiment of the call-out with an \"appropriate\" admonition in the doc for better context and visbility when reading the doc.", "Update tips in Python operator doc to reflect sentiment (#36340) Within the Python how-to guide, there are doc admonitions that don't necessarily reflect the sentiment of the call-out. For example, there are several places where there is a recommendation to use the TaskFlow as an operator but the admonition is a warning; this is more of a tip when authoring DAGs. This PR hopes to match the sentiment of the call-out with an \"appropriate\" warning in the doc for clarification and visbility when reading the doc.", "Update admonitions in Python operator how-to guide to reflect sentiment (#36340) Within the Python operator how-to guide, there are doc s that don't necessarily reflect the sentiment of the call-out. For example, there are several places where there is a recommendation to use the TaskFlow version of an operator but the admonition is a warning; this is more of a hassle when authoring DAGs. This PR hopes to match the sentiment of a call-out with an \"appropriate\" admonition in the doc for better context and visbility when reading the doc.", "Update admonitions in Python operator doc to reflect sentiment of call-outs. In the Python operator how-to guide, there are doc admonitions that don't necessarily reflect the sentiment of the call-out. For example, there are several places where there is a recommendation to use the TaskFlow version of an operator but the admonition is a warning; this is more of a tip when authoring DAGs. This PR proposes to match the sentiment of the call-out with an admonition in the doc for better readability and visbility when reading the doc.", "Update admonitions in Python operator how-to guide to better reflect sentiment (#36340) Within the Python operator how-to guide, there are doc admonitions that don't necessarily reflect the sentiment of usage. For example, there are several places where there is a recommendation to use the TaskFlow version of an operator , but the doc admonition is a warning; this is more of a call-out when authoring DAGs. This PR hopes to match the sentiment of the call-out with an \"appropriate\" admonition in the doc to provide better context and visbility when reading the doc."], "original_ll": -3.8208069801330566, "sampled_ll": -3.767641067504883, "all_perturbed_sampled_ll": [-3.8742122650146484, -3.941322088241577, -3.6972897052764893, -3.7845382690429688, -3.782207727432251, -3.652972459793091, -3.9911444187164307, -3.6028988361358643, -3.6153454780578613, -3.8637874126434326], "all_perturbed_original_ll": [-3.868311882019043, -3.6223413944244385, -3.872370958328247, -3.538994789123535, -3.640277862548828, -3.7725436687469482, -3.9451165199279785, -3.8137097358703613, -3.5391969680786133, -3.753147602081299], "perturbed_sampled_ll": -3.7805718660354612, "perturbed_original_ll": -3.736601138114929, "perturbed_sampled_ll_std": 0.129606398533168, "perturbed_original_ll_std": 0.13679230730287484}, {"original": "DatabricksSubmitRunOperator to support taskflow (#29840) * move validation to execute + change type hints * revert type changes * update tests * move json normalisation in SubmitRunDeferrable too --------- Co-authored-by: Hernan Resnizky <hernanresnizky@NEX-0003.local> Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "sampled": "DatabricksSubmitRunOperator to support taskflow (#29840) * move validation to execute + change type hints * revert type changes * update code to get the output from getRunCommandLine() * update types when required * update some of types", "perturbed_sampled": ["DatabricksSubmitRunOperator to support taskflow (#29840) * move code to execute + change type hints * revert type changes * change code to get the output from getRunCommandLine() * update types when required * update some of types", "DatabricksSubmitRunOperator .aspx taskflow (#29840) * move validation to execute + change type hints * revert type changes * update code to get the output from getRunCommandLine() * change validation when required * update some of types", "DatabricksSubmitRunOperator to make validation to execute (#29840) * move validation to execute + change type hints * revert type changes * update code to get the output from getRunCommandLine() * update validation code if required * update some of types", "DatabricksSubmitRunOperator to support taskflow (#29840) * move validation to execute + change type hints for type changes * update code to get the output from getRunCommandLine() * update code to support error handling when required * update some of types", "DatabricksSubmitRunOperator to support taskflow (#29840) * move validation to execute + change type hints * revert type changes * update code to get the output from getRunCommandLine() * update types when reversing * update existing types", "DatabricksSubmitRunOperator to support taskflow (#29840) * move validation to execute + change to run() * revert type changes * update code to get the output from getRunCommandLine() * update types when required * fix some inconsistent use of types", "DatabricksSubmitRunOperator to run (#29840) * move validation to execute + change type hints * revert invalid validation errors * update code to get the output from getRunCommandLine() * update types when required * update some of types", "DatabricksSubmitRunOperator to support taskflow (#29840) * move validation * add + = hints * revert type changes * update code to get the output from getRunCommandLine() * update types when required * update some of types", "DatabricksSubmitRunOperator : * update validation taskflow (#29840) * move validation to execute + change type hints * revert type changes * update code to get the output from the validation * update types when required * update some of types", "* update class to support taskflow (#29840) * update caller to execute + change type hints * revert type changes * update code to get the output from getRunCommandLine() * update types when required * update some of types"], "perturbed_original": ["DatabricksSubmitRunOperator to support taskflow (#29840) * move validation to execute + change type in Exception * revert type changes * update tests * move json normalisation in SubmitRunDeferrable too --------- Co-authored-by: Hernan Resnizky <hernanresnizky@NEX-0003.local> Co-authored-by: Uranus J. <uranusjr@gmail.com>", "DatabricksSubmitRunOperator to support taskflow (#29840) * move validation to execute + change type hints * push tests to run * make changes * update tests * add validation normalisation in SubmitRunDeferrable too --------- Co-authored-by: Hernan Resnizky <hernanresnizky@NEX-0003.local> Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "DatabricksSubmitRunOperator to support taskflow (#29840) * move data validation to execute + change test * revert type changes * update tests * move json normalisation in SubmitRunDeferrable too --------- Co-authored-by: Hernan Resnizky <hernanresnizky@NEX-0003.local> Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "DatabricksSubmitRunOperator to support taskflow (#29840) * move validation to execute + change type hints * revert type changes * update validation hints * move json normalisation in SubmitRunDeferrable too --------- Co-authored-by: Hernan Resnizky <unk>hr@gmail.com> , Tzu-ping Chung <uranusjr@gmail.com>", "DatabricksSubmitRunOperator to support taskflow (#29840) * move validation to execute + change type hints * revert type changes * update tests * move them in SubmitRunDeferrable too --------- Co-authored-by: Hernan Resnizky <hernanresnizky@NEX-0003.local> Co-authored-by: Uranus Jirgavicius <uranusjr@gmail.com>", "DatabricksSubmitRunOperator to support taskflow (#29840) * move validation to execute + change type hints * revert type changes * add validation * add data normalisation in SubmitRunDeferrable too --------- Co-authored-by: Hernan Resnizky <hernanresnizky@NEX-0003.local> Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "DatabricksSubmitRunOperator to support taskflow (#29840) * add new code to execute taskflow * add type hints * revert type changes * update tests * move json normalisation in SubmitRunDeferrable too --------- Co-authored-by: Hernan Resnizky <hernanresnizky@NEX-0003.local> Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "DatabricksSubmitRunOperator to support taskflow (#29840) * move validation to execute + change type hints * revert type changes * update tests * move json validation to execute * make SubmitRunDeferrable too --------- Co-authored-by: Hernan Resnizky <hernanresnizky@NEX-0003.local> Yang Sung Chung <uranusjr@gmail.com>", "DatabricksSubmitRunOperator to support taskflow (#29840) * move validation to execute * update type hints * revert type changes * update tests * move json normalisation in SubmitRunDeferrable to * deprecate validation Co-authored-by: Hernan Resnizky <hernanresnizky@NEX-0003.local> Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "DatabricksSubmitRunOperator to support taskflow (#29840) * move validation to execute + change type hints * revert databricks:json normalisation * update tests * move json normalisation in SubmitRunDeferrable * update debugs * Co-authored-by: Hernan Resnizky <hernanresnizky@NEX-0003.local> Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>"], "original_ll": -4.703723430633545, "sampled_ll": -5.272892475128174, "all_perturbed_sampled_ll": [-5.126677989959717, -5.460596084594727, -5.03965950012207, -4.9266133308410645, -5.434012413024902, -5.009617805480957, -4.950918674468994, -5.3767313957214355, -5.236480712890625, -4.901230335235596], "all_perturbed_original_ll": [-4.6012959480285645, -4.591943740844727, -4.656152725219727, -5.2497358322143555, -4.479759216308594, -4.653957366943359, -4.5053181648254395, -4.946413040161133, -4.505001544952393, -4.457998752593994], "perturbed_sampled_ll": -5.146253824234009, "perturbed_original_ll": -4.664757633209229, "perturbed_sampled_ll_std": 0.20487218125960371, "perturbed_original_ll_std": 0.236424575913614}, {"original": "Add an option to use a direct DB connection in KEDA when pgbouncer is enabled (#32608) * Add an option to use a direct DB connection in KEDA when pgbouncer is enabled Signed-off-by: Hussein Awala <hussein@awala.fr> * Fix helm doc --------- Signed-off-by: Hussein Awala <hussein@awala.fr>", "sampled": "Add an option to use a direct DB connection in KEDA when pgbouncer is enabled (#32608) * Add an option to use a direct DB connection in KEDA when pgbouncer is enabled (#32608) * Add an option to use a direct DB connection in KEDA", "perturbed_sampled": ["Add an option to use a direct DB connection in KEDA when pgbouncer is enabled (#30973) * Add an option to use a direct DB connection in KEDA when pgbouncer is enabled (#32608) * Add an option to use a direct DB connection in KEDA", "Add an option to open a direct DB connection in KEDA when pgbouncer is enabled (#32608) * Add an option to open a direct DB connection in KEDA when pgbouncer is enabled (#32608) * Add an option to open a direct DB connection in KEDA", "Add an option to use a direct DB connection in KEDA when pgbouncer is enabled (#32608) * Add an option to use a direct DB connection in KEDA when pgbouncer is enabled (#32608) * Add an option to use a direct DB connection in KEDA", "Add an option to use a direct DB connection in KEDA when pgbouncer is enabled (#32608) * Add an option to use a direct DB connection in KEDA when pgblog is enabled (#32608) * Add an option to use a direct DB connection in KEDA", "Add an option to use a direct DB connection in KEDA when pgbouncer is enabled (#32608) * Add an option to use a direct DB connection in KEDA when pgbouncer is enabled (#32608) * Add an option to use a direct DB connection in KEDA", "Add an option to use a direct DB connection in KEDA when pgbouncer is enabled * Add an option to use a direct DB connection in KEDA when pgbouncer is enabled (#32608) * Add an option to use a direct DB connection in KEDA", "Add an option to use a direct DB connection in KEDA when pgbouncer is enabled (#32608) * Add an option to use a direct DB connection in KEDA when pgbouncer is enabled (#32618) Add an option to use a direct DB connection in KEDA", "Add an option to use a direct DB connection in KEDA when pgbouncer is enabled (#32608) * Add an option to use a direct DB connection in KEDA when pgbouncer is enabled (#32608) * Add an option to use a direct DB connection in KEDA", "Add an option to use a direct DB connection in KEDA when pgbouncer is enabled (#32608) * Add an option to use a direct DB connection in KEDA when pgbouncer is enabled (#32608) * Add an option to use a direct DB connection in KEDA", "Add an option to use a direct DB connection in KEDA when pgbouncer is enabled (#32608) * Add an option to use a direct DB connection in KEDA when pgbouncer is enabled (#32608) * Add an option to use a direct DB connection in KEDA"], "perturbed_original": ["Add an option to use a direct DB connection in KEDA when pgbouncer is enabled (#32608) * Add an option to use a direct DB connection in KEDA when pgbouncer is enabled Signed-off-by: Hussein Awala * Fix helm doc --------- Signed-off-by: Hussein Awala <hussein@awala.fr>", "Add an option to use a direct DB connection in KEDA when pgbouncer is enabled * Add an option to use a direct DB connection in KEDA when pgbouncer is enabled Signed-off-by: Hussein Awala <hussein@awala.fr> * Fix helm message Signed-off-by: Hussein Awala <hussein@awala.fr>", "Add an option to use a direct DB connection in KEDA when pgbouncer is enabled (#32608) * Add an option to use a direct DB connection in KEDA when pgbouncer is enabled Signed-off-by: Hussein Awala <hussein@awala.fr> * Fix helm doc --------- Signed-off-by: Hussein Awala <hussein@awala.fr>", "Add an option to use a direct DB connection in KEDA when pgbouncer is enabled * Add an option to use a direct DB connection in KEDA when pgbouncer is enabled Signed-off-by: Hussein Awala ******* Fix helm doc --------- Signed-off-by: Hussein Awala <hussein@awala.fr>", "Add an option to use a direct DB connection in KEDA when pgbouncer is enabled (#32608) * Add an option to use a direct DB connection in KEDA when pgbouncer is enabled. - Hussein Awala * Fix helm doc --------- Signed-off-by: Hussein Awala <hussein@awala.fr>", "Add an option to use a direct DB connection in KEDA when pgbouncer is enabled (#32608) * Add an option to use a direct DB connection in KEDA when pgbouncer is enabled Signed-off-by: Hussein Awala <hussein@awala.fr> * Fix helm doc --------- Signed-off-by: Hussein Awala <hussein@awala.fr>", "Add an option to use a direct DB connection in KEDA when pgbouncer is enabled (#32608) * Add an option to use a direct DB connection in KEDA when pgbouncer is enabled Signed-off-by: Hussein Awala <hussein@awala.fr> * Fix helm doc --------- Hussein Awala <hussein@awala.fr>", "Add an option to use a direct DB connection in KEDA when pgbouncer is enabled (#32608) * Add an option to use a direct DB connection in KEDA when pgbouncer is enabled Signed-off-by: Hussein Awala <hussein@awala.fr> * Fix helm errors (#25303) Signed-off-by: Hussein Awala <hussein@awala.fr>", "Add an option to use a direct DB connection in KEDA when pgbouncer is enabled (#32608) * Add an option to use a direct DB connection in KEDA when pgbouncer is enabled Signed-off-by: Hussein Awala <hussein@awala.fr> * Added option for opening doc --------- Signed-off-by: Hussein Awala <hussein@awala.fr>", "Add an option to use a direct DB connection in KEDA when pgbouncer is enabled (#32608) Add an option to use a direct DB connection in KEDA when pgbouncer is enabled Signed-off-by: Hussein Awala <hussein@awala.fr> * Fix helm doc --------- Signed-off-by: Hussein Awala <hussein@awala.fr>"], "original_ll": -2.8224174976348877, "sampled_ll": -2.1747548580169678, "all_perturbed_sampled_ll": [-2.3776488304138184, -2.1559746265411377, -2.1747548580169678, -2.545166015625, -2.1747548580169678, -2.3478987216949463, -2.4514567852020264, -2.1747548580169678, -2.1747548580169678, -2.1747548580169678], "all_perturbed_original_ll": [-3.191723585128784, -2.643859386444092, -2.8224174976348877, -3.150286912918091, -3.4037349224090576, -2.8224174976348877, -3.112067222595215, -2.663706064224243, -2.8057403564453125, -2.8440442085266113], "perturbed_sampled_ll": -2.2751919269561767, "perturbed_original_ll": -2.945999765396118, "perturbed_sampled_ll_std": 0.13579020313559145, "perturbed_original_ll_std": 0.23891518202770573}, {"original": "Fixes the Kafka provider's max message limit error (#32926) (#33321) * Fixes kafka provider failing reading messages Fixes the issue(#32926) where kafka provider returns an error when max messages is not set since it keeps reading and messages left goes into negative. Makes sure that the kafka provider works when max messages isn't passed into the operator", "sampled": "Fixes the Kafka provider's max message limit error (#32926) (#33321) * Fixes kafka provider failing reading messages Fixes the issue where an error occurred in running the Kafka container. * Fixes an issue when reading a non-sequential message containing numbers and a binary string (#32543)\n\n(#32543) * Fixes an issue when reading a non-sequential message containing numbers and", "perturbed_sampled": ["Fixes the Kafka provider's max -bytes-per-hour error (#32926) (#33321) * Fixes kafka 1.2 log reading from the file from the issue where an error occurred in running the Kafka provider. * Fixes an issue when reading a non-sequential message containing numbers and a binary string (#32543)\n\n(#32543) * Fixes an issue when reading a non-sequential message containing numbers and", "Fixes the Kafka provider's max _t error in the message. * Fixes kafka provider failing reading messages Fixes the issue where an error occurred in running the Kafka container. * Fixes an issue when reading a non-sequential message containing numbers and a binary string (#32543)\n\n(#32543) * Fixes an issue when reading a non-sequential message containing numbers and", "Fixes the Kafka container message limit error (#32926) (#33321) * Fixes the Kafka messaging provider failing reading messages Fixes the issue where an error occurred in running the Kafka container. * Fixes an issue when reading a non-sequential message containing numbers and a message (#32543)\n\n(#32543) * Fixes an issue when reading a non-sequential message containing numbers and", "Fixes the Kafka max message limit error (#32926) (#33321) * Fixes kafka provider failing when testing an API (#33321) * Fixes the issue where an error occurred in running the code (#33322) * Fixes an issue when reading a non-sequential message containing numbers and a binary string (#32543)\n\n(#32543) * Fixes an issue when reading a non-sequential message containing numbers and", "Fixes the Kafka provider's max user size error (#32926) (#33321) * Fixes kafka provider failing reading messages Fixes a problem where an error occurred in running the kafka container. * Fixes an issue when reading a non-sequential message containing numbers and a binary string (#32543)\n\n(#32543) * Fixes an issue when reading a non-sequential message containing numbers and", "Fixes the Kafka provider failing reading the same message multiple times for different clients (#32926) (#33321) * Fixes kafka provider failing reading messages Fixes the issue where an error occurred in running the Kafka container. * Fixes an issue when reading a non-sequential message containing numbers and a message object. (#32543)\n\n(#32543) * Fixes an issue when reading a non-sequential message containing numbers and", "Fixes the Kafka provider's max message limit error (#32926) (#33321) * Fixes kafka provider failing reading messages Fixes an issue where an error occurred when trying to query the Kafka container. * Fixes an issue when receiving a non-sequential message containing numbers and a binary string (#32543)\n\n(#32543) * Fixes an issue when receiving a non-sequential message containing numbers and", "Fixes the Kafka provider's max message limit error (#33321) * Fixes kafka provider not deleting messages Fixes the issue where an error occurred in running the Kafka container. * Fixes an issue when reading a non-sequential message containing numbers and a binary string (#32543)\n\n(#32543) * Fixes an issue when reading a non-sequential message containing numbers and", "Fixes the Kafka provider's max message limit error (#32926) (#33321) * Fixes kafka provider failing reading messages Fixes the issue where an error occurred in running the Kafka container. * Fixes an issue when reading a non-sequential message containing numbers and a binary value * Fixes an issue when reading a non-sequential message containing numbers and", "Fixes the Kafka provider's max message limit error (#32926) (#33321) * Fixes kafka provider failing reading messages * Fixes an issue where an error occurred in running the Kafka container. * Fixes an issue when reading a non-sequential message containing numbers and a binary string (#32543)\n\n(#32543) * Fixes an issue when reading a non-sequential message containing numbers and"], "perturbed_original": ["Fixes the Kafka provider's max message limit error (#32926) (#33321) * Fixes kafka provider failing reading maximum messages. Fixes the issue(#32926) where kafka provider returns an error when max message limit is not set since it keeps reading and messages left goes into negative. Makes sure that the kafka provider works . and the same max number of messages isn't passed into the operator", "Fixes the issue where kafka provider fails reading messages set without max message set (#32926) (#33321) * Fixes kafka provider failing reading messages Fixes the issue(#32926) where kafka provider returns an error when max messages is not set but keeps reading and messages left goes into negative. Makes sure that the kafka provider works when max messages is inserted into the operator", "Fixes kafka provider's max message limit error (#32926) (#33321) * Fixes kafka provider failing reading messages left issue(#32926) where kafka provider returns an error when max messages is not set since it is negative and messages left goes into negative. Makes sure that the kafka provider works when max messages is passed into the operator", "Fixes the Kafka provider's negative read limit error (#32926) (#33321) * Fixes kafka provider failing reading data for the user. Fixes the issue(#32926) where kafka provider returns an error when max messages is not set since provider failed reading and messages left are negative. Makes sure that the kafka provider works when max messages isn't passed into the operator", "Fixes the Kafka provider's max message limit error (#32926) (#33321) : kafka provider failing reading messages Fixes the issue(#32926) where the kafka provider returns an error when max messages is not set since it keeps reading and messages left are negative. Makes sure that the kafka provider works when max messages is set into the operator", "Fixes the kafka message provider max message limit error (#32926) (#33321) * Fixes kafka provider failing reading max messages Fixed the issue(#32926) where kafka provider returns an error when max messages is not set since it goes into 0 and messages left goes into negative. Makes sure that the kafka provider setting of max messages isn't passed into the operator", "Fixes kafka provider's max message limit error (#32926) (#33321) * Fixes kafka provider failing reading messages Fixes the issue(#32926) where kafka provider starts showing error when max messages limit is not set since it keeps reading and messages left to open are always negative. Makes sure that the kafka provider works when max messages isn't passed into the operator", "Message left 0 : Kafka provider's max message limit error . * Fixes kafka provider failing reading messages Fixes the issue(#32926) where kafka provider returns an error when max message limit is not set since it keeps reading and messages left goes into negative. Makes sure that the kafka provider 's limit of max messages isn't passed into the operator", "Fixes the Kafka provider's max message limit error (#32926) (#33321) * Fixes kafka provider failing reading messages Fixes the issue(#32926) where kafka provider returns an error when the current number of messages is not set since it keeps changing messages left goes into negative. Makes sure that the kafka provider works so that the number of messages isn't passed into the operator", "Fixes kafka provider's message limit error (#32926) (#33321) * Fixes kafka provider failing reading messages Fixes the issue(#32926) where kafka provider get an error when max messages is not set correctly, though provider keeps reading and messages left goes into negative. Makes sure that the kafka provider works when max messages isn't passed into the operator"], "original_ll": -4.160024166107178, "sampled_ll": -3.0432183742523193, "all_perturbed_sampled_ll": [-3.03713321685791, -3.1891822814941406, -3.0945792198181152, -2.852057456970215, -3.051454782485962, -2.9128050804138184, -2.976489543914795, -3.0165021419525146, -3.348278760910034, -2.9339680671691895], "all_perturbed_original_ll": [-4.1068267822265625, -4.064295291900635, -3.8387410640716553, -4.028738975524902, -4.065287113189697, -3.9370474815368652, -4.045141696929932, -4.428364276885986, -4.060994625091553, -4.148464679718018], "perturbed_sampled_ll": -3.0412450551986696, "perturbed_original_ll": -4.072390198707581, "perturbed_sampled_ll_std": 0.13701219392182953, "perturbed_original_ll_std": 0.14473909943767724}, {"original": "Fix MyPy issues in AWS Sensors (#20717)", "sampled": "Fix MyPy issues in AWS Sensors (#20717)On", "perturbed_sampled": ["Fix MyPy issues in AWS Sensors (#20717)On", "Fix MyPy issues in AWS Sensors (#20717)On", "Fix MyPy issues in AWS Sensors (#20717)On", "Fix MyPy issues in AWS Sensors (#20717)On", "Fix MyPy issues in AWS Sensors (#20717)On", "Fix MyPy issues in AWS Sensors (#20717)On", "Fix MyPy issues in AWS Sensors (#20717)On", "Fix MyPy issues in AWS Sensors (#20717)On", "Fix MyPy issues in AWS Sensors (#20717)On", "Fix MyPy issues in AWS Sensors (#20717)On"], "perturbed_original": ["Fix MyPy issues in AWS Sensors (#20717)", "Fix MyPy issues in AWS Sensors (#20717)", "Fix MyPy issues in AWS Sensors (#20717)", "Fix MyPy issues in AWS Sensors (#20717)", "Fix MyPy issues in AWS Sensors (#20717)", "Fix MyPy issues in AWS Sensors (#20717)", "Fix MyPy issues in AWS Sensors (#20717)", "Fix MyPy issues in AWS Sensors (#20717)", "Fix MyPy issues in AWS Sensors (#20717)", "Fix MyPy issues in AWS Sensors (#20717)"], "original_ll": -6.661556720733643, "sampled_ll": -7.2715301513671875, "all_perturbed_sampled_ll": [-7.2715301513671875, -7.2715301513671875, -7.2715301513671875, -7.2715301513671875, -7.2715301513671875, -7.2715301513671875, -7.2715301513671875, -7.2715301513671875, -7.2715301513671875, -7.2715301513671875], "all_perturbed_original_ll": [-6.661556720733643, -6.661556720733643, -6.661556720733643, -6.661556720733643, -6.661556720733643, -6.661556720733643, -6.661556720733643, -6.661556720733643, -6.661556720733643, -6.661556720733643], "perturbed_sampled_ll": -7.2715301513671875, "perturbed_original_ll": -6.661556720733643, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Strip markup from app_name if instance_name_has_markup = True (#28894) Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "sampled": "Strip markup from app_name if instance_name_has_markup = True (#28894) Co-authored-by: Tadeusz B\u0142aszkiewicz <tadeuszb@suse.de>", "perturbed_sampled": ["Strip markup from app_name if instance_name_has_markup = True (#28894) Co-authored-by: Tadeusz B\u0142aszkiewicz <tadeuszb@suse.de>", "Strip markup from app_name if instance_name_has_markup = True (#28894) Co-authored-by: Tadeusz B\u0142aszkiewicz <tadeuszb@suse.de>", "Strip markup from app_name if instance_name_has_markup = True (#28894) Co-authored-by: Tadeusz B\u0142aszkiewicz <tadeuszb@suse.de>", "Strip markup from app_name if instance_name_has_markup = True (#28894) Co-authored-by: Tadeusz B\u0142aszkiewicz <tadeuszb@suse.de>", "Strip markup from app_name if instance_name_has_markup = True (#28894) Co-authored-by: Tadeusz B\u0142aszkiewicz <tadeuszb@suse.de>", "Strip markup from app_name if instance_name_has_markup = True (#28894) Co-authored-by: Tadeusz B\u0142aszkiewicz <tadeuszb@suse.de>", "Strip markup from app_name if instance_name_has_markup = True (#28894) Co-authored-by: Tadeusz B\u0142aszkiewicz <tadeuszb@suse.de>", "Strip markup from app_name if instance_name_has_markup = True (#28894) Co-authored-by: Tadeusz B\u0142aszkiewicz <tadeuszb@suse.de>", "Strip markup from app_name if instance_name_has_markup = True (#28894) Co-authored-by: Tadeusz B\u0142aszkiewicz <tadeuszb@suse.de>", "Strip markup from app_name if instance_name_has_markup = True (#28894) Co-authored-by: Tadeusz B\u0142aszkiewicz <tadeuszb@suse.de>"], "perturbed_original": ["Strip markup from app_name if instance_name_has_markup = True (#28894) Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Strip markup from app_name if instance_name_has_markup = True (#28894) Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Strip markup from app_name if instance_name_has_markup = True (#28894) Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Strip markup from app_name if instance_name_has_markup = True (#28894) Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Strip markup from app_name if instance_name_has_markup = True (#28894) Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Strip markup from app_name if instance_name_has_markup = True (#28894) Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Strip markup from app_name if instance_name_has_markup = True (#28894) Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Strip markup from app_name if instance_name_has_markup = True (#28894) Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Strip markup from app_name if instance_name_has_markup = True (#28894) Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "Strip markup from app_name if instance_name_has_markup = True (#28894) Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>"], "original_ll": -4.129654407501221, "sampled_ll": -3.197568893432617, "all_perturbed_sampled_ll": [-3.197568893432617, -3.197568893432617, -3.197568893432617, -3.197568893432617, -3.197568893432617, -3.197568893432617, -3.197568893432617, -3.197568893432617, -3.197568893432617, -3.197568893432617], "all_perturbed_original_ll": [-4.129654407501221, -4.129654407501221, -4.129654407501221, -4.129654407501221, -4.129654407501221, -4.129654407501221, -4.129654407501221, -4.129654407501221, -4.129654407501221, -4.129654407501221], "perturbed_sampled_ll": -3.197568893432617, "perturbed_original_ll": -4.129654407501221, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Allow depending to a @task_group as a whole (#20671)", "sampled": "Allow depending to a @task_group as a whole (#20671)For", "perturbed_sampled": ["Allow depending to a @task_group as a whole (#20671)For", "Allow depending to a @task_group as a whole (#20671)For", "Allow depending to a @task_group as a whole (#20671)For", "Allow depending to a @task_group as a whole (#20671)For", "Allow depending to a @task_group as a whole (#20671)For", "Allow depending to a @task_group as a whole (#20671)For", "Allow depending to a @task_group as a whole (#20671)For", "Allow depending to a @task_group as a whole (#20671)For", "Allow depending to a @task_group as a whole (#20671)For", "Allow depending to a @task_group as a whole (#20671)For"], "perturbed_original": ["Allow depending to a @task_group as a whole (#20671)", "Allow depending to a @task_group as a whole (#20671)", "Allow depending to a @task_group as a whole (#20671)", "Allow depending to a @task_group as a whole (#20671)", "Allow depending to a @task_group as a whole (#20671)", "Allow depending to a @task_group as a whole (#20671)", "Allow depending to a @task_group as a whole (#20671)", "Allow depending to a @task_group as a whole (#20671)", "Allow depending to a @task_group as a whole (#20671)", "Allow depending to a @task_group as a whole (#20671)"], "original_ll": -5.895024299621582, "sampled_ll": -6.541508197784424, "all_perturbed_sampled_ll": [-6.541508197784424, -6.541508197784424, -6.541508197784424, -6.541508197784424, -6.541508197784424, -6.541508197784424, -6.541508197784424, -6.541508197784424, -6.541508197784424, -6.541508197784424], "all_perturbed_original_ll": [-5.895024299621582, -5.895024299621582, -5.895024299621582, -5.895024299621582, -5.895024299621582, -5.895024299621582, -5.895024299621582, -5.895024299621582, -5.895024299621582, -5.895024299621582], "perturbed_sampled_ll": -6.541508197784424, "perturbed_original_ll": -5.895024299621582, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Simplify FAB table resetting (#27869) We can simplify how we reset FAB tables now that everything is an \"Airflow\" table.", "sampled": "Simplify FAB table resetting (#27869) We can simplify how we reset FAB tables now that everything is an \"Airflow\" filter.", "perturbed_sampled": ["Simplify FAB table resetting (#27869) We can simplify how we reset FAB tables. Remember that everything is an \"Airflow\" filter.", "Simplify FAB table resetting (#27869) We can simplify how we reset FAB tables now . There is an \"Airflow\" filter.", "Re: FAB table resetting (#27869) We can simplify how we reset FAB tables now that everything is an \"Airflow\" filter.", "Simplify FAB table reset (#27869) We can simplify how we reset FAB tables now that everything is an \"Airflow\" filter.", "Simplify FAB table resetting (#27869) We can simplify how we reset FAB tables now that there is an \"Airflow\" filter.", "Simplify FAB table resetting (#27869) We can simplify how we reset FB tables, now that everything is an \"Airflow\" filter.", "Simplify FAB table resetting (#27869) We can simplify how to reset FAB tables now that everything is an \"Airflow\" filter.", "Simplify FAB table resetting (#27869) We can simplify how we reset FAB tables now that there is an \"Airflow\" filter.", "Fix table resetting (#27869) We can simplify how we reset FAB tables now that everything is an \"Airflow\" filter.", "Simplify FAB table resetting (#27869) We can simplify how we reset FAB tables by knowing that everything is an \"Airflow\" filter."], "perturbed_original": ["Simplify FAB table setting. We can simplify how we reset FAB tables now that everything is an \"Airflow\" table.", "Simplify FAB tables reset (#27869) We can simplify how we reset FAB tables now that everything is an \"Airflow\" table.", "Simplify FAB table resetting : We can simplify how we reset FAB tables now that everything is an \"Airflow\" table.", "Simplify FAB table resetting (#27869) We can simplify how we reset tables now that everything is an \"Airflow\" table.", "Simplify FAB table resetting (#27869) We can simplify how we reset FAB tables now we know it is an \"Airflow\" table.", "Simplify FAB table resetting (#27869) We can simplify how we create, reset and delete FAB tables now that everything is an \"Airflow\" table.", "Simplify FAB table resetting (#27869) - simplify how we reset FAB tables now that everything is an \"Airflow\" table.", "Simplify FAB table resetting (#27869) This feature would simplify how we reset FAB tables now that everything is an \"Airflow\" table.", "Simplify FAB table resets. We can simplify how we reset FAB tables now that everything is an \"Airflow\" table.", "Simplify FAB table resetting (#27869) We can simplify how we reset FAB tables now that everything we do has an \"Airflow\" table."], "original_ll": -4.250558376312256, "sampled_ll": -4.376213550567627, "all_perturbed_sampled_ll": [-4.416392803192139, -4.494898796081543, -4.743845462799072, -4.470341682434082, -4.11221981048584, -4.782675266265869, -4.46562385559082, -4.11221981048584, -5.281067371368408, -4.430722713470459], "all_perturbed_original_ll": [-4.183084964752197, -4.500428676605225, -4.09268856048584, -4.632996559143066, -4.17288875579834, -4.109957695007324, -4.3629961013793945, -4.258563995361328, -4.05104398727417, -4.261054992675781], "perturbed_sampled_ll": -4.531000757217408, "perturbed_original_ll": -4.262570428848266, "perturbed_sampled_ll_std": 0.32472226578338326, "perturbed_original_ll_std": 0.17752475897404124}, {"original": "`GoogleDriveToGCSOperator`: Remove `destination_bucket` and `destination_object`", "sampled": "`GoogleDriveToGCSOperator`: Remove `destination_bucket` and `destination_object`This", "perturbed_sampled": ["`GoogleDriveToGCSOperator`: Remove `destination_bucket` and `destination_object`This", "`GoogleDriveToGCSOperator`: Remove `destination_bucket` and `destination_object`This", "`GoogleDriveToGCSOperator`: Remove `destination_bucket` and `destination_object`This", "`GoogleDriveToGCSOperator`: Remove `destination_bucket` and `destination_object`This", "`GoogleDriveToGCSOperator`: Remove `destination_bucket` and `destination_object`This", "`GoogleDriveToGCSOperator`: Remove `destination_bucket` and `destination_object`This", "`GoogleDriveToGCSOperator`: Remove `destination_bucket` and `destination_object`This", "`GoogleDriveToGCSOperator`: Remove `destination_bucket` and `destination_object`This", "`GoogleDriveToGCSOperator`: Remove `destination_bucket` and `destination_object`This", "`GoogleDriveToGCSOperator`: Remove `destination_bucket` and `destination_object`This"], "perturbed_original": ["`GoogleDriveToGCSOperator`: Remove `destination_bucket` and `destination_object`", "`GoogleDriveToGCSOperator`: Remove `destination_bucket` and `destination_object`", "`GoogleDriveToGCSOperator`: Remove `destination_bucket` and `destination_object`", "`GoogleDriveToGCSOperator`: Remove `destination_bucket` and `destination_object`", "`GoogleDriveToGCSOperator`: Remove `destination_bucket` and `destination_object`", "`GoogleDriveToGCSOperator`: Remove `destination_bucket` and `destination_object`", "`GoogleDriveToGCSOperator`: Remove `destination_bucket` and `destination_object`", "`GoogleDriveToGCSOperator`: Remove `destination_bucket` and `destination_object`", "`GoogleDriveToGCSOperator`: Remove `destination_bucket` and `destination_object`", "`GoogleDriveToGCSOperator`: Remove `destination_bucket` and `destination_object`"], "original_ll": -4.321408271789551, "sampled_ll": -4.629648685455322, "all_perturbed_sampled_ll": [-4.629648685455322, -4.629648685455322, -4.629648685455322, -4.629648685455322, -4.629648685455322, -4.629648685455322, -4.629648685455322, -4.629648685455322, -4.629648685455322, -4.629648685455322], "all_perturbed_original_ll": [-4.321408271789551, -4.321408271789551, -4.321408271789551, -4.321408271789551, -4.321408271789551, -4.321408271789551, -4.321408271789551, -4.321408271789551, -4.321408271789551, -4.321408271789551], "perturbed_sampled_ll": -4.629648685455322, "perturbed_original_ll": -4.321408271789551, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Fix await_container_completion condition (#23883)", "sampled": "Fix await_container_completion condition (#23883)The", "perturbed_sampled": ["Fix await_container_completion condition (#23883)The", "Fix await_container_completion condition (#23883)The", "Fix await_container_completion condition (#23883)The", "Fix await_container_completion condition (#23883)The", "Fix await_container_completion condition (#23883)The", "Fix await_container_completion condition (#23883)The", "Fix await_container_completion condition (#23883)The", "Fix await_container_completion condition (#23883)The", "Fix await_container_completion condition (#23883)The", "Fix await_container_completion condition (#23883)The"], "perturbed_original": ["Fix await_container_completion condition (#23883)", "Fix await_container_completion condition (#23883)", "Fix await_container_completion condition (#23883)", "Fix await_container_completion condition (#23883)", "Fix await_container_completion condition (#23883)", "Fix await_container_completion condition (#23883)", "Fix await_container_completion condition (#23883)", "Fix await_container_completion condition (#23883)", "Fix await_container_completion condition (#23883)", "Fix await_container_completion condition (#23883)"], "original_ll": -6.02053689956665, "sampled_ll": -6.738839626312256, "all_perturbed_sampled_ll": [-6.738839626312256, -6.738839626312256, -6.738839626312256, -6.738839626312256, -6.738839626312256, -6.738839626312256, -6.738839626312256, -6.738839626312256, -6.738839626312256, -6.738839626312256], "all_perturbed_original_ll": [-6.02053689956665, -6.02053689956665, -6.02053689956665, -6.02053689956665, -6.02053689956665, -6.02053689956665, -6.02053689956665, -6.02053689956665, -6.02053689956665, -6.02053689956665], "perturbed_sampled_ll": -6.738839626312256, "perturbed_original_ll": -6.02053689956665, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Fix the docstrings (#22497) I think PubSubHook is using gRPC but not REST.", "sampled": "Fix the docstrings (#22497) I think PubSubHook is using gRPC but not REST.In", "perturbed_sampled": ["Fix the docstrings (#22497) I think PubSubHook is using gRPC but not REST.In", "Fix the docstrings (#22497) I think PubSubHook is using gRPC but not REST.In", "Fix the docstrings (#22497) I think PubSubHook is using gRPC but not REST.In", "Fix the docstrings (#22497) I think PubSubHook is using gRPC but not REST.In", "Fix the docstrings (#22497) I think PubSubHook is using gRPC but not REST.In", "Fix the docstrings (#22497) I think PubSubHook is using gRPC but not REST.In", "Fix the docstrings (#22497) I think PubSubHook is using gRPC but not REST.In", "Fix the docstrings (#22497) I think PubSubHook is using gRPC but not REST.In", "Fix the docstrings (#22497) I think PubSubHook is using gRPC but not REST.In", "Fix the docstrings (#22497) I think PubSubHook is using gRPC but not REST.In"], "perturbed_original": ["Fix the docstrings (#22497) I think PubSubHook is using gRPC but not REST.", "Fix the docstrings (#22497) I think PubSubHook is using gRPC but not REST.", "Fix the docstrings (#22497) I think PubSubHook is using gRPC but not REST.", "Fix the docstrings (#22497) I think PubSubHook is using gRPC but not REST.", "Fix the docstrings (#22497) I think PubSubHook is using gRPC but not REST.", "Fix the docstrings (#22497) I think PubSubHook is using gRPC but not REST.", "Fix the docstrings (#22497) I think PubSubHook is using gRPC but not REST.", "Fix the docstrings (#22497) I think PubSubHook is using gRPC but not REST.", "Fix the docstrings (#22497) I think PubSubHook is using gRPC but not REST.", "Fix the docstrings (#22497) I think PubSubHook is using gRPC but not REST."], "original_ll": -4.900029182434082, "sampled_ll": -5.176907539367676, "all_perturbed_sampled_ll": [-5.176907539367676, -5.176907539367676, -5.176907539367676, -5.176907539367676, -5.176907539367676, -5.176907539367676, -5.176907539367676, -5.176907539367676, -5.176907539367676, -5.176907539367676], "all_perturbed_original_ll": [-4.900029182434082, -4.900029182434082, -4.900029182434082, -4.900029182434082, -4.900029182434082, -4.900029182434082, -4.900029182434082, -4.900029182434082, -4.900029182434082, -4.900029182434082], "perturbed_sampled_ll": -5.176907539367676, "perturbed_original_ll": -4.900029182434082, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Fix typo in retag_images.py (#23280)", "sampled": "Fix typo in retag_images.py (#23280)If", "perturbed_sampled": ["Fix typo in retag_images.py (#23280)If", "Fix typo in retag_images.py (#23280)If", "Fix typo in retag_images.py (#23280)If", "Fix typo in retag_images.py (#23280)If", "Fix typo in retag_images.py (#23280)If", "Fix typo in retag_images.py (#23280)If", "Fix typo in retag_images.py (#23280)If", "Fix typo in retag_images.py (#23280)If", "Fix typo in retag_images.py (#23280)If", "Fix typo in retag_images.py (#23280)If"], "perturbed_original": ["Fix typo in retag_images.py (#23280)", "Fix typo in retag_images.py (#23280)", "Fix typo in retag_images.py (#23280)", "Fix typo in retag_images.py (#23280)", "Fix typo in retag_images.py (#23280)", "Fix typo in retag_images.py (#23280)", "Fix typo in retag_images.py (#23280)", "Fix typo in retag_images.py (#23280)", "Fix typo in retag_images.py (#23280)", "Fix typo in retag_images.py (#23280)"], "original_ll": -5.770430088043213, "sampled_ll": -6.566345691680908, "all_perturbed_sampled_ll": [-6.566345691680908, -6.566345691680908, -6.566345691680908, -6.566345691680908, -6.566345691680908, -6.566345691680908, -6.566345691680908, -6.566345691680908, -6.566345691680908, -6.566345691680908], "all_perturbed_original_ll": [-5.770430088043213, -5.770430088043213, -5.770430088043213, -5.770430088043213, -5.770430088043213, -5.770430088043213, -5.770430088043213, -5.770430088043213, -5.770430088043213, -5.770430088043213], "perturbed_sampled_ll": -6.566345691680908, "perturbed_original_ll": -5.770430088043213, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Note that yarn dev needs webserver in debug mode (#24119) * Note that yarn dev needs webserver -d * Update CONTRIBUTING.rst Co-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com> * Use -D * Revert \"Use -D\" This reverts commit 94d63adcf36aac13f5d94c2d4cd651907d833794. Co-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com>", "sampled": "Note that yarn dev needs webserver in debug mode (#24119) * Note that yarn dev needs webserver -d * Update CONTRIBUTING.md for all of the new stuff. * Updated the README of yarn dev to read as much as it", "perturbed_sampled": ["Note that yarn dev is now running in debug mode . * Note that yarn dev needs webserver -d * * Get updates for all of the new stuff. * Updated the README of yarn dev to read as much as it", "Note that yarn updates a webserver in some cases (#24119) * Note that yarn updates a webserver -d * Update CONTRIBUTING.md for all of the new stuff. * Updated the README of yarn dev to read as much as it", "Note that yarn dev needs webserver in order to work. patch (#24119) * Note that yarn dev needs webserver -d * Updated CONTRIBUTING.md for all of the new stuff. * Updated the README of yarn dev to read as though we are using it", "Note that yarn dev uses webserver in debug mode (#24119) * Note that yarn dev needs webserver -d * Update CONTRIBUTING.md for all of the new tests * Updated the yarn deps for yarn dev to read as much as it", "Note that yarn dev needs webserver in debug mode (#24119) * Note that yarn dev needs webserver -d * Update CONTRIBUTING.md with the most of the new stuff. * Updated the README of yarn dev to read as much as it", "Note that yarn dev needs webserver in debug mode (#24119) * Note that yarn dev needs webserver in debug mode, * Update d yarn dev to read all of the new stuff. * Updated the new yarn dev to read as much as it", "Note that yarn dev needs webserver in debug mode (#24119) * Note that yarn dev needs webserver -d * Update CONTRIBUTING.md for all the new syntax * Updated the README of yarn dev to read as much as it", "Note that yarn dev needs webserver in debug mode * Note that yarn dev needs webserver -d * Update CONTRIBUTING.md for all of the new stuff. * Download the README of yarn dev to read as much as it", "Note that yarn dev runs in debug mode (#24119) * Note that yarn dev needs webserver -d * Update CONTRIBUTING.md for all of the new docs * Updated the README of yarn dev to read more about yarn dev as it", "Note that yarn dev needs webserver in debug mode (#24119) * Note that yarn dev needs webserver -d * Update CONTRIBUTING.md for all of the new stuff. * Updated the README of yarn dev to reflect this as much as it"], "perturbed_original": ["Note that yarn dev needs webserver in -d (#24119) * Note that yarn dev needs webserver -d * Update CONTRIBUTING.rst Co-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com> * Note that yarn dev needs webserver -D * Revert : This reverts commit 94d63adcf36aac13f5d94c2d4cd651907d833794. Co-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com>", "Note that yarn dev is in debug mode (#24119) * Note that yarn dev needs webserver -d * Update CONTRIBUTING.rst Co-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com> * Use -D * Run \"warn -D\" This reverts commit 94d63adcf36aac13f5d94c2d4cd651907d833794. Co-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com>", "-d * Note yarn dev needs webserver -d * Init mode (#24119) * Note yarn dev needs webserver -d * Update CONTRIBUTING.rst Co-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com> * Use -D * Revert \"Use -D\" This reverts commit 94d63adcf36aac13f5d94c2d4cd651907d833794. Co-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com>", "that yarn dev needs webserver in debug mode (#24119) * Note that yarn dev needs webserver -d * Update CONTRIBUTING.rst Co-authored-by: Jed Cunningham <unk>66968678> Update * Use -D * Revert \"Use -D\" This reverts \"Use -D\" Co-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com>", "Note that yarn dev needs webserver in vocation (#24119) * Note that yarn dev needs webserver -d * . Co-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com> * Use -D * Revert \"Use -D\" reverts commit 94d63adcf36aac13f5d94c2d4cd651907d833794. Co-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com>", "Note that user needs webserver in debug mode (#24119) * Note that user needs webserver -d * Update CONTRIBUTING.rst Co-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com> * Use -D * Revert \"Use -D\" section in commit 94d63adcf36aac13f5d94c2d4cd651907d833794. Co-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com>", "* yarn dev can now execute in debug mode on the webserver -d * Note that yarn dev needs webserver -d * Update CONTRIBUTING.rst Co-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com> * Use -D * Revert \"Use -D\" This reverts commit 94d63adcf36aac13f5d94c2d4cd651907d833794. Co-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com>", "Note that yarn , needs webserver in debug mode (#24119) * Note that yarn, needs webserver -d * Update CONTRIBUTING.rst Co-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com> * Use -D Revert \"Use -D\" This reverts commit 94d63adcf36aac13f5d94c2d4cd651907d833794. Co-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com>", "Note that yarn dev needs webserver in debug mode (#24119) * Note that yarn dev needs webserver -d * Update CONTRIBUTING.rst * Authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com> * Use -D * Revert \"Use -D\" This reverts commit 94d63adcf36aac13f5d94c2d4cd651907d833794. Co-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com>", "Note that yarn dev needs webserver in debug mode (#24119) * Note that yarn dev needs webserver -d * Revert CONTRIBUTING.rst ** to Jed Cunningham <66968678+jedcunningham@users.noreply.github.com> * Use -D * Revert \"Use -D\" This reverts commit s written in Jed Cunningham <66968678+jedcunningham@users.noreply.github.com>"], "original_ll": -3.186520576477051, "sampled_ll": -3.4528253078460693, "all_perturbed_sampled_ll": [-3.95646595954895, -3.497659921646118, -3.6018667221069336, -3.9056246280670166, -3.530721426010132, -4.108538627624512, -3.6545724868774414, -3.5591907501220703, -3.5733511447906494, -3.51363468170166], "all_perturbed_original_ll": [-3.0519824028015137, -3.387789011001587, -3.2432944774627686, -3.95355486869812, -3.3405680656433105, -3.2111573219299316, -3.21391224861145, -3.2375659942626953, -3.2492477893829346, -3.4096665382385254], "perturbed_sampled_ll": -3.6901626348495484, "perturbed_original_ll": -3.329873871803284, "perturbed_sampled_ll_std": 0.20636911109602885, "perturbed_original_ll_std": 0.2293676244357036}, {"original": "Fix Google cloud tests which are incompatible with `aiohttp==3.8.6` (#34822)", "sampled": "Fix Google cloud tests which are incompatible with `aiohttp==3.8.6` (#34822)As", "perturbed_sampled": ["Fix Google cloud tests which are incompatible with `aiohttp==3.8.6` (#34822)As", "Fix Google cloud tests which are incompatible with `aiohttp==3.8.6` (#34822)As", "Fix Google cloud tests which are incompatible with `aiohttp==3.8.6` (#34822)As", "Fix Google cloud tests which are incompatible with `aiohttp==3.8.6` (#34822)As", "Fix Google cloud tests which are incompatible with `aiohttp==3.8.6` (#34822)As", "Fix Google cloud tests which are incompatible with `aiohttp==3.8.6` (#34822)As", "Fix Google cloud tests which are incompatible with `aiohttp==3.8.6` (#34822)As", "Fix Google cloud tests which are incompatible with `aiohttp==3.8.6` (#34822)As", "Fix Google cloud tests which are incompatible with `aiohttp==3.8.6` (#34822)As", "Fix Google cloud tests which are incompatible with `aiohttp==3.8.6` (#34822)As"], "perturbed_original": ["Fix Google cloud tests which are incompatible with `aiohttp==3.8.6` (#34822)", "Fix Google cloud tests which are incompatible with `aiohttp==3.8.6` (#34822)", "Fix Google cloud tests which are incompatible with `aiohttp==3.8.6` (#34822)", "Fix Google cloud tests which are incompatible with `aiohttp==3.8.6` (#34822)", "Fix Google cloud tests which are incompatible with `aiohttp==3.8.6` (#34822)", "Fix Google cloud tests which are incompatible with `aiohttp==3.8.6` (#34822)", "Fix Google cloud tests which are incompatible with `aiohttp==3.8.6` (#34822)", "Fix Google cloud tests which are incompatible with `aiohttp==3.8.6` (#34822)", "Fix Google cloud tests which are incompatible with `aiohttp==3.8.6` (#34822)", "Fix Google cloud tests which are incompatible with `aiohttp==3.8.6` (#34822)"], "original_ll": -5.575248718261719, "sampled_ll": -6.004149913787842, "all_perturbed_sampled_ll": [-6.004149913787842, -6.004149913787842, -6.004149913787842, -6.004149913787842, -6.004149913787842, -6.004149913787842, -6.004149913787842, -6.004149913787842, -6.004149913787842, -6.004149913787842], "all_perturbed_original_ll": [-5.575248718261719, -5.575248718261719, -5.575248718261719, -5.575248718261719, -5.575248718261719, -5.575248718261719, -5.575248718261719, -5.575248718261719, -5.575248718261719, -5.575248718261719], "perturbed_sampled_ll": -6.004149913787842, "perturbed_original_ll": -5.575248718261719, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "recipes documentation: update airflow version (#23148) Not sure if there's a way to generate the version automatically, seems like there's something like that [here](https://github.com/apache/airflow/blob/main/docs/docker-stack/docker-examples/extending/add-providers/Dockerfile#L18) that finally generates the latest version [here](https://airflow.apache.org/docs/docker-stack/build.html#example-of-upgrading-airflow-provider-packages).", "sampled": "recipes documentation: update airflow version (#23148) Not sure if there's a way to generate the version automatically, seems like there's something like this built into the repo. If true, I can", "perturbed_sampled": ["recipes documentation: update airflow version , not sure if there's a way to generate the version automatically, seems like there's something like this built into the repo. If true, I can", "This is a reference to update airflow version (#23148) Not sure if there's a way to generate the version automatically, seems like there's something like this built into the repo. Anything else that I can", "recipes for use in airflow version (#23148) Not sure if there's a way to generate the version automatically, seems like there's something like this built into the repo. However, I can", "recipes documentation: update the recipes version (#23148) Not sure if there's a way to generate the version automatically, seems like there's something like this built into the recipe itself. It is true, I can", "recipes documentation: update airflow version (#23148) Not sure if there's a way to generate the version automatically, seems like there should be something like this built into my configuration. If true, I can", "recipes documentation: update airflow version (#23148) Not sure if there's a way to generate the version automatically, seems like something that should be built into the repo. If true, I can", "recipes documentation: update airflow version (#23148) Not sure yet, is there a way to generate the version automatically, seems like there's something like this built into the repo. If there is, I can", "recipes documentation: update airflow version (#23148) Not sure if there's a way to generate the version automatically, seems that there should be something like this built into the plugin. not true, I can", "recipes documentation: update airflow version (#23148) Not sure if there's a way to generate the version automatically, seems like there's something like this built into our repo. If true, I can", "recipes documentation: update airflow version (#23148) Not sure if there's an option to generate the version automatically, seems like there's something like this built into the repo. If not, I can"], "perturbed_original": ["recipes documentation: update airflow version at least weekly? Not sure if there's some script in there to generate the version automatically, seems like there's something like that [here](https://github.com/apache/airflow/blob/main/docs/docker-stack/docker-examples/extending/add-providers/Dockerfile#L18) that finally generates the latest version [here](https://airflow.apache.org/docs/docker-stack/build.html#example-of-upgrading-airflow-provider-packages).", "recipes documentation: update airflow version (#23148) Not sure if there's a way to generate the documentation. Edit: seems like there's something like that [here](https://github.com/apache/airflow/blob/main/docs/docker-stack/docker-examples/extending/add-providers/Dockerfile#L18) that finally updated it to the latest version [here](https://airflow.apache.org/docs/docker-stack/build.html#example-of-upgrading-airflow-provider-packages).", "recipes documentation: update airflow version (#23148) Not sure if there's a way to update airflow version automatically, seems like there's something like ./airflow-version-upgrade that finally generates the latest version [here](https://airflow.apache.org/docs/docker-stack/build.html#example-of-upgrading-airflow-provider-packages).", "recipes documentation: update airflow provider packages file. Not sure if there's a way to generate the version automatically, seems like there's something like that [here](https://github.com/apache/airflow/blob/main/docs/docker-stack/docker-examples/extending/add-providers/Dockerfile#L18) that generates the latest version [here](https://airflow.apache.org/docs/docker-stack/build.html#example-of-upgrading-airflow-provider-packages).", "recipes documentation: update airflow version (#23148) Not sure if there's a way to generate the version automatically, seems like there's something like that [here](https://github.com/apache/airflow/blob/main/docs/docker-stack/docker-examples/extending/add-providers/Dockerfile#L18) that could be used to fetch the version [here](https://airflow.apache.org/docs/docker-stack/build.html#example-of-upgrading-airflow-provider-packages).", "update airflow package (#62473) update airflow version (#23148) Not sure if there's a way to generate the new version automatically, seems like there's something like that [here](https://github.com/apache/airflow/blob/main/docs/docker-stack/docker-examples/extending/add-providers/Dockerfile#L18) that finally generates the latest version [here](https://airflow.apache.org/docs/docker-stack/build.html#example-of-upgrading-airflow-provider-packages).", "recipes documentation: update airflow version (#23148) ? Not sure if there's a way or process to update the version automatically, seems like there's something like that [here](https://github.com/apache/airflow/blob/main/docs/docker-stack/docker-examples/extending/add-providers/Dockerfile#L18) that finally generates the latest version [here](https://airflow.apache.org/docs/docker-stack/build.html#example-of-upgrading-airflow-provider-packages).", "recipes documentation: update , improve, and remove outdated text. (#23148) Not sure if there's a way to generate the version automatically, but there's something like that [here](https://github.com/apache/airflow/blob/main/docs/docker-stack/docker-examples/extending/add-providers/Dockerfile#L18) that finally generates the latest version [here](https://airflow.apache.org/docs/docker-stack/build.html#example-of-upgrading-airflow-provider-packages).", "Provider to update airflow version (#23148) Not sure if there's a way to generate the version automatically, seems like there's a script for that [here](https://github.com/apache/airflow/blob/main/docs/docker-stack/docker-examples/extending/add-providers/Dockerfile#L18) that finally generates the latest version [here](https://airflow.apache.org/docs/docker-stack/build.html#example-of-upgrading-airflow-provider-packages).", "recipes documentation: update . (#23148) Not sure if there's a way to generate the version automatically, but by default there's something like that [here](https://github.com/apache/airflow/blob/main/docs/docker-stack/docker-examples/extending/add-providers/Dockerfile#L18) that finally generates the latest version [here](https://airflow.apache.org/docs/docker-stack/build.html#example-of-upgrading-airflow-provider-packages)."], "original_ll": -2.9720265865325928, "sampled_ll": -4.0603766441345215, "all_perturbed_sampled_ll": [-3.9843993186950684, -3.8962674140930176, -3.8809916973114014, -3.8176944255828857, -4.112372875213623, -4.0831828117370605, -4.008014678955078, -4.267411231994629, -4.180855751037598, -4.019738674163818], "all_perturbed_original_ll": [-2.9788284301757812, -2.9846556186676025, -3.360553741455078, -2.8456602096557617, -2.8979523181915283, -3.000269651412964, -3.06939959526062, -2.9954729080200195, -2.9191038608551025, -3.0109574794769287], "perturbed_sampled_ll": -4.025092887878418, "perturbed_original_ll": -3.006285381317139, "perturbed_sampled_ll_std": 0.13278707100344178, "perturbed_original_ll_std": 0.13267375351913988}, {"original": "Use actual classes instead of dictionary (#20922)", "sampled": "Use actual classes instead of dictionary (#20922)We", "perturbed_sampled": ["Use actual classes instead of dictionary (#20922)We", "Use actual classes instead of dictionary (#20922)We", "Use actual classes instead of dictionary (#20922)We", "Use actual classes instead of dictionary (#20922)We", "Use actual classes instead of dictionary (#20922)We", "Use actual classes instead of dictionary (#20922)We", "Use actual classes instead of dictionary (#20922)We", "Use actual classes instead of dictionary (#20922)We", "Use actual classes instead of dictionary (#20922)We", "Use actual classes instead of dictionary (#20922)We"], "perturbed_original": ["Use actual classes instead of dictionary (#20922)", "Use actual classes instead of dictionary (#20922)", "Use actual classes instead of dictionary (#20922)", "Use actual classes instead of dictionary (#20922)", "Use actual classes instead of dictionary (#20922)", "Use actual classes instead of dictionary (#20922)", "Use actual classes instead of dictionary (#20922)", "Use actual classes instead of dictionary (#20922)", "Use actual classes instead of dictionary (#20922)", "Use actual classes instead of dictionary (#20922)"], "original_ll": -5.865798473358154, "sampled_ll": -6.7075629234313965, "all_perturbed_sampled_ll": [-6.7075629234313965, -6.7075629234313965, -6.7075629234313965, -6.7075629234313965, -6.7075629234313965, -6.7075629234313965, -6.7075629234313965, -6.7075629234313965, -6.7075629234313965, -6.7075629234313965], "all_perturbed_original_ll": [-5.865798473358154, -5.865798473358154, -5.865798473358154, -5.865798473358154, -5.865798473358154, -5.865798473358154, -5.865798473358154, -5.865798473358154, -5.865798473358154, -5.865798473358154], "perturbed_sampled_ll": -6.7075629234313965, "perturbed_original_ll": -5.865798473358154, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Update PR template (#24851)", "sampled": "Update PR template (#24851)(https://gist.github.com/juliannoh/4cb25ae5d3ba494314e69fbece9cc1dd)\n\nBug", "perturbed_sampled": ["Update PR template (#24851)(https://gist.github.com/juliannoh/4cb25ae5d3ba494314e69fbece9cc1dd)\n\nBug", "Update PR template (#24851)(https://gist.github.com/juliannoh/4cb25ae5d3ba494314e69fbece9cc1dd)\n\nBug", "Update PR template (#24851)(https://gist.github.com/juliannoh/4cb25ae5d3ba494314e69fbece9cc1dd)\n\nBug", "Update PR template (#24851)(https://gist.github.com/juliannoh/4cb25ae5d3ba494314e69fbece9cc1dd)\n\nBug", "Update PR template (#24851)(https://gist.github.com/juliannoh/4cb25ae5d3ba494314e69fbece9cc1dd)\n\nBug", "Update PR template (#24851)(https://gist.github.com/juliannoh/4cb25ae5d3ba494314e69fbece9cc1dd)\n\nBug", "Update PR template (#24851)(https://gist.github.com/juliannoh/4cb25ae5d3ba494314e69fbece9cc1dd)\n\nBug", "Update PR template (#24851)(https://gist.github.com/juliannoh/4cb25ae5d3ba494314e69fbece9cc1dd)\n\nBug", "Update PR template (#24851)(https://gist.github.com/juliannoh/4cb25ae5d3ba494314e69fbece9cc1dd)\n\nBug", "Update PR template (#24851)(https://gist.github.com/juliannoh/4cb25ae5d3ba494314e69fbece9cc1dd)\n\nBug"], "perturbed_original": ["Update PR template (#24851)", "Update PR template (#24851)", "Update PR template (#24851)", "Update PR template (#24851)", "Update PR template (#24851)", "Update PR template (#24851)", "Update PR template (#24851)", "Update PR template (#24851)", "Update PR template (#24851)", "Update PR template (#24851)"], "original_ll": -7.192155361175537, "sampled_ll": -3.9306752681732178, "all_perturbed_sampled_ll": [-3.9306752681732178, -3.9306752681732178, -3.9306752681732178, -3.9306752681732178, -3.9306752681732178, -3.9306752681732178, -3.9306752681732178, -3.9306752681732178, -3.9306752681732178, -3.9306752681732178], "all_perturbed_original_ll": [-7.192155361175537, -7.192155361175537, -7.192155361175537, -7.192155361175537, -7.192155361175537, -7.192155361175537, -7.192155361175537, -7.192155361175537, -7.192155361175537, -7.192155361175537], "perturbed_sampled_ll": -3.9306752681732178, "perturbed_original_ll": -7.192155361175537, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Parse 'docker context ls --format=json' correctly (#34711)", "sampled": "Parse 'docker context ls --format=json' correctly (#34711)Docker", "perturbed_sampled": ["Parse 'docker context ls --format=json' correctly (#34711)Docker", "Parse 'docker context ls --format=json' correctly (#34711)Docker", "Parse 'docker context ls --format=json' correctly (#34711)Docker", "Parse 'docker context ls --format=json' correctly (#34711)Docker", "Parse 'docker context ls --format=json' correctly (#34711)Docker", "Parse 'docker context ls --format=json' correctly (#34711)Docker", "Parse 'docker context ls --format=json' correctly (#34711)Docker", "Parse 'docker context ls --format=json' correctly (#34711)Docker", "Parse 'docker context ls --format=json' correctly (#34711)Docker", "Parse 'docker context ls --format=json' correctly (#34711)Docker"], "perturbed_original": ["Parse 'docker context ls --format=json' correctly (#34711)", "Parse 'docker context ls --format=json' correctly (#34711)", "Parse 'docker context ls --format=json' correctly (#34711)", "Parse 'docker context ls --format=json' correctly (#34711)", "Parse 'docker context ls --format=json' correctly (#34711)", "Parse 'docker context ls --format=json' correctly (#34711)", "Parse 'docker context ls --format=json' correctly (#34711)", "Parse 'docker context ls --format=json' correctly (#34711)", "Parse 'docker context ls --format=json' correctly (#34711)", "Parse 'docker context ls --format=json' correctly (#34711)"], "original_ll": -5.4085469245910645, "sampled_ll": -5.530730247497559, "all_perturbed_sampled_ll": [-5.530730247497559, -5.530730247497559, -5.530730247497559, -5.530730247497559, -5.530730247497559, -5.530730247497559, -5.530730247497559, -5.530730247497559, -5.530730247497559, -5.530730247497559], "all_perturbed_original_ll": [-5.4085469245910645, -5.4085469245910645, -5.4085469245910645, -5.4085469245910645, -5.4085469245910645, -5.4085469245910645, -5.4085469245910645, -5.4085469245910645, -5.4085469245910645, -5.4085469245910645], "perturbed_sampled_ll": -5.530730247497559, "perturbed_original_ll": -5.4085469245910645, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Refactor Slack API Hook and add Connection (#25852)", "sampled": "Refactor Slack API Hook and add Connection (#25852)The", "perturbed_sampled": ["Refactor Slack API Hook and add Connection (#25852)The", "Refactor Slack API Hook and add Connection (#25852)The", "Refactor Slack API Hook and add Connection (#25852)The", "Refactor Slack API Hook and add Connection (#25852)The", "Refactor Slack API Hook and add Connection (#25852)The", "Refactor Slack API Hook and add Connection (#25852)The", "Refactor Slack API Hook and add Connection (#25852)The", "Refactor Slack API Hook and add Connection (#25852)The", "Refactor Slack API Hook and add Connection (#25852)The", "Refactor Slack API Hook and add Connection (#25852)The"], "perturbed_original": ["Refactor Slack API Hook and add Connection (#25852)", "Refactor Slack API Hook and add Connection (#25852)", "Refactor Slack API Hook and add Connection (#25852)", "Refactor Slack API Hook and add Connection (#25852)", "Refactor Slack API Hook and add Connection (#25852)", "Refactor Slack API Hook and add Connection (#25852)", "Refactor Slack API Hook and add Connection (#25852)", "Refactor Slack API Hook and add Connection (#25852)", "Refactor Slack API Hook and add Connection (#25852)", "Refactor Slack API Hook and add Connection (#25852)"], "original_ll": -6.63955545425415, "sampled_ll": -7.0551323890686035, "all_perturbed_sampled_ll": [-7.0551323890686035, -7.0551323890686035, -7.0551323890686035, -7.0551323890686035, -7.0551323890686035, -7.0551323890686035, -7.0551323890686035, -7.0551323890686035, -7.0551323890686035, -7.0551323890686035], "all_perturbed_original_ll": [-6.63955545425415, -6.63955545425415, -6.63955545425415, -6.63955545425415, -6.63955545425415, -6.63955545425415, -6.63955545425415, -6.63955545425415, -6.63955545425415, -6.63955545425415], "perturbed_sampled_ll": -7.0551323890686035, "perturbed_original_ll": -6.63955545425415, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Discard semicolon stripping in SQL hook (#25855)", "sampled": "Discard semicolon stripping in SQL hook (#25855)This", "perturbed_sampled": ["Discard semicolon stripping in SQL hook (#25855)This", "Discard semicolon stripping in SQL hook (#25855)This", "Discard semicolon stripping in SQL hook (#25855)This", "Discard semicolon stripping in SQL hook (#25855)This", "Discard semicolon stripping in SQL hook (#25855)This", "Discard semicolon stripping in SQL hook (#25855)This", "Discard semicolon stripping in SQL hook (#25855)This", "Discard semicolon stripping in SQL hook (#25855)This", "Discard semicolon stripping in SQL hook (#25855)This", "Discard semicolon stripping in SQL hook (#25855)This"], "perturbed_original": ["Discard semicolon stripping in SQL hook (#25855)", "Discard semicolon stripping in SQL hook (#25855)", "Discard semicolon stripping in SQL hook (#25855)", "Discard semicolon stripping in SQL hook (#25855)", "Discard semicolon stripping in SQL hook (#25855)", "Discard semicolon stripping in SQL hook (#25855)", "Discard semicolon stripping in SQL hook (#25855)", "Discard semicolon stripping in SQL hook (#25855)", "Discard semicolon stripping in SQL hook (#25855)", "Discard semicolon stripping in SQL hook (#25855)"], "original_ll": -6.4136061668396, "sampled_ll": -6.97808837890625, "all_perturbed_sampled_ll": [-6.97808837890625, -6.97808837890625, -6.97808837890625, -6.97808837890625, -6.97808837890625, -6.97808837890625, -6.97808837890625, -6.97808837890625, -6.97808837890625, -6.97808837890625], "all_perturbed_original_ll": [-6.4136061668396, -6.4136061668396, -6.4136061668396, -6.4136061668396, -6.4136061668396, -6.4136061668396, -6.4136061668396, -6.4136061668396, -6.4136061668396, -6.4136061668396], "perturbed_sampled_ll": -6.97808837890625, "perturbed_original_ll": -6.4136061668396, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Refactor: Simplify code in www (#33270)", "sampled": "Refactor: Simplify code in www (#33270)Inlining", "perturbed_sampled": ["Refactor: Simplify code in www (#33270)Inlining", "Refactor: Simplify code in www (#33270)Inlining", "Refactor: Simplify code in www (#33270)Inlining", "Refactor: Simplify code in www (#33270)Inlining", "Refactor: Simplify code in www (#33270)Inlining", "Refactor: Simplify code in www (#33270)Inlining", "Refactor: Simplify code in www (#33270)Inlining", "Refactor: Simplify code in www (#33270)Inlining", "Refactor: Simplify code in www (#33270)Inlining", "Refactor: Simplify code in www (#33270)Inlining"], "perturbed_original": ["Refactor: Simplify code in www (#33270)", "Refactor: Simplify code in www (#33270)", "Refactor: Simplify code in www (#33270)", "Refactor: Simplify code in www (#33270)", "Refactor: Simplify code in www (#33270)", "Refactor: Simplify code in www (#33270)", "Refactor: Simplify code in www (#33270)", "Refactor: Simplify code in www (#33270)", "Refactor: Simplify code in www (#33270)", "Refactor: Simplify code in www (#33270)"], "original_ll": -5.701931953430176, "sampled_ll": -6.323432922363281, "all_perturbed_sampled_ll": [-6.323432922363281, -6.323432922363281, -6.323432922363281, -6.323432922363281, -6.323432922363281, -6.323432922363281, -6.323432922363281, -6.323432922363281, -6.323432922363281, -6.323432922363281], "all_perturbed_original_ll": [-5.701931953430176, -5.701931953430176, -5.701931953430176, -5.701931953430176, -5.701931953430176, -5.701931953430176, -5.701931953430176, -5.701931953430176, -5.701931953430176, -5.701931953430176], "perturbed_sampled_ll": -6.323432922363281, "perturbed_original_ll": -5.701931953430176, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Remove framer-motion from custom tooltip (#24449) * remove framer-motion from custom tooltip * remove framer-motion type declaration file", "sampled": "Remove framer-motion from custom tooltip (#24449) * remove framer-motion from custom tooltip * remove framer-motion type declaration file", "perturbed_sampled": ["Remove framer-motion from custom tooltip (#24449) * remove framer-motion from custom tooltip (#34797) * remove framer-motion type declaration file", "Remove framer-motion from custom tooltip (#24449) * remove framer-motion from custom tooltip * remove framer-motion type declaration file", "Remove framer-motion from custom tooltip (#24449) * remove framer-motion from custom tooltip * remove framer-motion type declaration file", "Remove framer-motion from custom tooltip (#24449) * remove framer-motion from custom tooltip * remove framer-motion type declaration file", "Remove framer-motion from custom tooltip (#24449) * remove framer-motion from custom tooltip (#26091) * modify framer-motion type declaration file", "Remove framer-motion from custom tooltip (#24449) * remove framer-motion from custom tooltip * remove framer-motion type declaration file", "Remove framer-motion from custom tooltip (#24449) * remove framer-motion from custom tooltip * Update type declaration file", "Remove framer-motion from custom tooltip (#24449) * remove framer-motion from custom tooltip * remove framer-motion type declaration file", "* remove framer-motion from custom tooltip (#24449) * remove framer-motion from custom tooltip * remove framer-motion type declaration file", "Remove framer-motion from custom tooltip (#24449) * remove framer-motion from custom tooltip (#25663) * remove framer-motion type declaration file"], "perturbed_original": ["Remove framer-motion from custom tooltip (#24449) * remove framer-motion from custom tooltip * modify type declaration file", "Remove framer-motion from custom tooltip (#24449) * remove framer-motion from custom tooltip * remove framer-motion type declaration file", "Remove framer-motion from custom tooltip (#24449) * remove framer-motion from custom tooltip * remove framer-motion type declaration file", "Remove framer-motion from custom tooltip * remove framer-motion from default tooltip * remove framer-motion from custom tooltip * remove framer-motion type declaration file", "Remove framer-motion from custom tooltip (#24449) * Remove framer-motion from custom tooltip * remove framer-motion type declaration file", "Remove framer-motion from custom tooltip (#24449) * remove framer-motion from custom tooltip * remove framer-motion from log file", "Remove framer-motion from custom tooltip (#24449) * remove framer-motion from custom tooltip * remove framer-motion type declaration file", "Remove framer-motion from custom tooltip (#24449) * remove framer-motion from custom tooltip * remove framer-motion type declaration file", "Remove framer-motion from custom Tooltip * remove framer-motion from custom tooltip * remove framer-motion type declaration file", "Remove framer-motion from custom tooltip * remove framer-motion from custom tooltip * remove framer-motion type declaration file"], "original_ll": -4.460954666137695, "sampled_ll": -4.460954666137695, "all_perturbed_sampled_ll": [-4.293995380401611, -4.460954666137695, -4.460954666137695, -4.460954666137695, -4.310985565185547, -4.460954666137695, -5.1412672996521, -4.460954666137695, -4.385249614715576, -4.210085391998291], "all_perturbed_original_ll": [-5.179415225982666, -4.460954666137695, -4.460954666137695, -3.5364298820495605, -4.576930522918701, -4.019497394561768, -4.460954666137695, -4.460954666137695, -4.4801411628723145, -4.381015300750732], "perturbed_sampled_ll": -4.46463565826416, "perturbed_original_ll": -4.401724815368652, "perturbed_sampled_ll_std": 0.2411892543503772, "perturbed_original_ll_std": 0.3938201678435855}, {"original": "clear specific dag run TI (#23516)", "sampled": "clear specific dag run TI (#23516)This", "perturbed_sampled": ["clear specific dag run TI (#23516)This", "clear specific dag run TI (#23516)This", "clear specific dag run TI (#23516)This", "clear specific dag run TI (#23516)This", "clear specific dag run TI (#23516)This", "clear specific dag run TI (#23516)This", "clear specific dag run TI (#23516)This", "clear specific dag run TI (#23516)This", "clear specific dag run TI (#23516)This", "clear specific dag run TI (#23516)This"], "perturbed_original": ["clear specific dag run TI (#23516)", "clear specific dag run TI (#23516)", "clear specific dag run TI (#23516)", "clear specific dag run TI (#23516)", "clear specific dag run TI (#23516)", "clear specific dag run TI (#23516)", "clear specific dag run TI (#23516)", "clear specific dag run TI (#23516)", "clear specific dag run TI (#23516)", "clear specific dag run TI (#23516)"], "original_ll": -9.835419654846191, "sampled_ll": -10.06265926361084, "all_perturbed_sampled_ll": [-10.06265926361084, -10.06265926361084, -10.06265926361084, -10.06265926361084, -10.06265926361084, -10.06265926361084, -10.06265926361084, -10.06265926361084, -10.06265926361084, -10.06265926361084], "all_perturbed_original_ll": [-9.835419654846191, -9.835419654846191, -9.835419654846191, -9.835419654846191, -9.835419654846191, -9.835419654846191, -9.835419654846191, -9.835419654846191, -9.835419654846191, -9.835419654846191], "perturbed_sampled_ll": -10.06265926361084, "perturbed_original_ll": -9.835419654846191, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Summarize skipped tests after tests are run (#30520) When Pytest run tests it provides a summary of the tests. We are running a lot of the tests so we are really interested only in cases that are \"interesting\". So far we were not showing \"skipped\" tests in the summary, because there were cases where a lot of tests were skipped (mostly when integration tests were run - we collected tests from \"tests\" folder and run only those tests that were not skipped by @integration mark. This however changed in #28170 as we moved all integration tests to \"integration\" subfolder and now instead of large number of skipped tests we run them selectively for each integration. This should help in verifying that the skipped tests were skipped for a good reason", "sampled": "Summarize skipped tests after tests are run (#30520) When Pytest run tests it provides a summary of the tests. We are running a few more of them to ensure they are run before testing begins. TestCase will now also run and show the skipped test results.\n\nPytest now uses _PyTestCase__ in the name of all tests in the class loader. All tests and modules loaded from the module will be given an index based on their class name.\n\nImplemented a 'PYTHON_SELF' environment variable in test.py to enable an auto-complete for __doc__ and __def__. This includes the classes that are imported from the pytest-framework itself, not those defined by the loader. See the tests/ folder for examples.\n\nPydata modules are now properly serialized (the last 2 bytes have now been written).\n\nSome of _PyObjectTest_Initialize(_PyObject*) initialization", "perturbed_sampled": ["Summarize skipped tests after tests are run: When Pytest run tests it provides a summary of the tests. We are able to skip a few more of them to ensure they are run before testing begins. TestCase will also run and show the skipped test results.\n\nPytest now uses _PyTestCase__ in the name of tests and in the class name itself. All tests and modules loaded from the module builder are given an index based on the class base and not the class name.\n\nImplemented a 'PYTHON_SELF' environment variable in test.py to enable an auto-complete for __doc__ and __def__. This includes modules and tests that are imported from the pytest-framework itself, and not the modules defined by the loader. See the tests/ folder for examples.\n\nPydata modules are now properly serialized (the last 2 bytes have now been written).\n\nSome of _PyObjectTest_Initialize(_PyObject*) initialization", "skipped tests after tests are run (#30520) When Pytest run tests it shows a short summary of the tests. We 've added a few more of them to ensure they are run before testing begins. TestCase will now also run and show the skipped tests. Pytest now uses _PyTestCase__ in the name of all tests in the class loader. All tests and modules loaded from the module will be added at the index based on their class name.\n\nImplemented a 'PYTHON_SELF' environment variable in test.py to enable an auto-complete for __doc__ and __def__. This includes the classes that are imported from the pytest-framework itself, but are not defined by the loader. See the PyTest folder for examples.\n\nPydata files are now properly serialized (the last 2 pages have now been written).\n\nSome of _PyObjectTest_Initialize(_PyObject*) initialization", "Summarize results after tests run (#30520) are not run tests but run a copy of the tests. We are running a few tests to summarize the tests results (we have removed them to ensure they are run before testing is done); the tests will now also run and show the summary results.\n\nPytest now uses _PyTestCase__ in the name of all tests in the class loader. All tests and modules loaded from the module will be given an index based on their class name.\n\nImplemented a 'PYTHON_SELF' environment variable in test.py to enable an auto-complete for __doc__ and __def__. This includes the classes that are imported from the pytest-framework itself, not those defined by the loader. See the tests/ folder for examples.\n\nPydata modules are now properly serialized (the first 2 bytes have now been written).\n\nSome of _PyObjectTest_Initialize(_PyObject*) initialization", "Summarize skipped tests when tests are run. When Pytest run tests it provides a summary of the tests. We are running a few more of them to ensure they are run before testing begins. TestCase will now also be an environment variable to show the skipped test results.\n\nPytest now uses _PyTestCase__ in the name space of tests in the class loader. All tests and modules loaded from the module will be given an index based on their class name.\n\nImplemented an environment variable in test.py to enable an auto-complete for classes with classes __def__. This includes the classes that are imported from the pytest-framework itself, not just classes imported by the loader. See the tests/ folder for examples.\n\nPydata modules are now properly handled in the modules_.py file. The last 2 bytes have now been removed. Implementing of _PyObjectTest_Initialize(_PyObject*) initialization", "Summarize skipped tests after tests run by test case (#30520) When an application skips tests it provides a summary of the tests. We are running a few more of them to ensure that all the skipping tests have been run before testing begins. TestCase will now also run and show the skipped test results.\n\nPytest now uses _PyTestCase__ in the name of all tests in the loader. All tests and modules loaded from the module will be sorted by index based on their class name. Use the 'PYTHON_SELF' environment variable in test.py to enable an auto-complete for __doc__ and __def__. This includes the classes that are imported from the pytest-framework itself, not those defined by the loader. See the tests/ folder . All the modules are now properly loaded again (the last ones have now been written).\n\nSome of _PyObjectTest_Initialize(_PyObject*) initialization", "Summarize skipped tests after tests are run (#30520) When Pytest run tests it now shows a summary of the tests it skipped. After some tests are skipped it will pick a few more of them to ensure they are run before testing begins. TestCase will now also run and show the test results.\n\nPytest now uses a class file to determine the name of all tests in the class loader. All tests and modules loaded from the module will be given an index based on their class name.\n\nImplemented a 'PYTHON_SELF' environment variable in test.py to enable an auto-complete for __doc__ and __def__. This includes the classes that are imported from the pytest-framework itself, not those defined by the loader. See the tests/ folder for examples.\n\nPydata modules are now properly serialized (the last 2 bytes have now been set as bytes). Fixed the behavior of _PyObjectTest_Initialize(_PyObject*) initialization", "Summarize skipped tests after tests are run. When Pytest run tests it provides a summary of the tests. We are running a few more of them so they are run before testing begins. TestCase will now also run and provide a summary of skipped test results.\n\nPytest now uses _PyTestCase__ as the class name of all tests in the class loader. All tests and modules loaded from the module will be given an index based on their class name.\n\nImplemented a 'PYTHON_SELF' environment variable in test.py to enable auto-insertions for __doc__ and __def__. This includes the tests that are imported from the pytest-framework itself, not the package pytested.jar, or by themselves. See also the test.py folder for examples.\n\nPydata modules are now properly serialized (the last 2 bytes have now been written).\n\nSome of _PyObjectTest_Initialize(_PyObject*) initialization", "Summarize skipped tests after tests run. (#30520) When Pytest run tests it provides a summary of skipped tests. We are running a few more of them to ensure they are skipped before testing begins. TestCase will now also run one of the skipped tests and list the skipped test results.\n\nPytest now uses _PyTestCase__ in the name of all tests in the class loader. All tests and modules defined in the loader will be given an index based on their class name.\n\nImplemented a 'PYTHON_SELF' environment variable in test.py to enable an auto-complete for __doc__ and __def__. This includes the classes that are imported from the pytest-framework -modules package and those defined in the loader. See the tests/ folder for examples.\n\nPydata modules are now properly serialized (the first 4 bytes have now been written).\n\nSome of _PyObjectTest_Initialize(_PyObject*) initialization", "Summarize skipped tests after tests are run (#30520) When Pytest runs a test, it reports a summary of the tests. We are running a few more of them to ensure they are run before the actual test begins. TestCase will now also run and show the skipped test results.\n\nPytest now uses _PyTestCase__ in the name of all tests in the class loader. All tests and modules in the module will always be given an index based on their class name.\n\nImplemented a 'PYTHON_SELF' environment variable in test.py to enable an auto-complete for __doc__ and __def__. This includes the classes that are actually defined from test.py itself, not those defined by the loader. See the tests/ folder for more details. Tests are now properly serialized (the last 2 bytes have now been written).\n\nSome of _PyObjectTest_Initialize(_PyObject*) initialization", "Summarize skipped tests after tests run (#30520) When Pytest run tests it provides a summary of the tests. When running tests, Pytest skips one or more of them to ensure that all the tests are run before testing begins. TestCase will now also run a command to show a summary of the skipped test results.\n\nPytest now uses _PyTestCase__ in the name of all tests in the class loader. All tests and modules loaded from the module will be given an index based on their class name.\n\nImplemented a 'PYTHON_SELF' environment variable in test.py to enable an auto-complete for modules named __def__. Now tests will run the classes that are imported from the pytest-framework itself, not those defined in the modules loader. Check tests/ folder for examples.\n\nPydata modules are now properly serialized (the last 2 bytes have now been written).\n\nSome of _PyObjectTest_Initialize(_PyObject*) initialization"], "perturbed_original": ["Summarize skipped tests after tests are run (#30520) - When we run tests it provides a summary of the tests. We are running a lot of integration tests so we are really interested only in cases that were skipped by @integration mark. So far we were not showing \"skipped\" tests in the summary incase there were cases where a lot of tests were skipped (mostly when integration tests were run - so we skipped tests from \"tests\" folder and show only those tests that were not skipped by @integration mark. This however changed in #28170 as we moved all integration tests to \"integration\" subfolder and now instead of showing the number of skipped tests we display those selectively for each integration. This should help in verifying that the skipped tests were skipped for a good reason", "Summarize skipped tests as they are run . This is really important to us as it helps us to understand why the skipped tests were skipped in Pytest as it provides a summary of the skips. We are running a lot of the tests so we are really interested only in cases that are \"interesting\". So far we were not showing \"skipped\" tests in Pytest because there were many cases when quite a lot of tests were skipped (mostly when integration tests were run - we collected tests from \"tests\" folder and run only those tests that were skipped by @integration mark. This got changed in #28170 as we moved all integration tests to \"integration\" subfolder and now instead of large number of skipped tests we run them selectively for each integration. This should help in verifying that the skipped tests are run for a good reason", "Summarize skipped tests when they are run (#30520) When Pytest run our tool automatically provides a summary of the tests. We are running a lot of the tests so we are really interested only in cases that are \"interesting\". So far we were not showing \"skipped\" tests in the summary, because there are integrations where a lot of tests were skipped (mostly tests marked with @integration). To verify that only those \"skiped\" tests were run - we collected tests from \"tests\" folder and run only those tests that are not skipped by @integration mark. This changed in #28170 as we moved all integration tests to \"integration\" folder so now instead of large number of skipped tests we run them selectively for each integration. This should help in verifying that some of tests were skipped for a good reason", "Summarize skipped tests after tests are run (#30520) When Pytest run tests it provides a summary of the tests. We are running a lot of the tests so we really interested only in cases that we consider as \"interesting\". So far we were not showing \"skipped\" tests in the summary, because there were cases where a lot of tests were skipped (mostly when multiple tests were run - we collected tests from \"tests\" folder and run only those tests which were not skipped by other developers). This however changed again, as we moved all tests to \"integration\" subfolder and now instead of showing number of skipped tests we run them selectively for each integration. This should help in verifying that skipped tests were skipped for a good reason", "Summarize test results after tests are run (#30520) When Pytest run , Pytest build provides a summary of the results of the tests. We are running summary of the tests in the test pipeline so we are really interested only in cases that are \"interesting\". So far we were not showing \"skipped\" tests in the summary, because there were cases where a lot of tests were skipped (mostly when integration tests were run - we collected tests from \"tests\" folder and ran only those tests that were not skipped by @integration mark. This however changed in #28170 as we moved all integration tests to \"integration\" subfolder and now instead of large number of skipped tests we run them selectively for each integration. This should help in verifying that the skipped tests were skipped for a good reason", "Summarize skipped tests after tests are run . When Pytest run tests it provides a summary of the tests. We are running a lot of the tests so we are really interested only in cases that are \"interesting\". In the past we were showing \"skipped\" tests in the summary, only because there were cases where a lot of tests were skipped and we couldn't show the missing tests (mostly when integration tests were run - we collected tests from \"tests\" folder and run only those tests that were not skipped ), thus increasing the failure mark. This was changed in #28170 . We have moved all integration tests to \"integration\" folder so now instead of large number of skipped tests we run them selectively for each integration. This should help in verifying that the skipped tests were skipped for a good reason", "a summary of tests after tests are run? When Pytest is run it provides a summary of the tests. We are running a lot of the tests so we are really interested only in cases that are \"interesting\". So far we are not showing \"skipped\" tests in the summary, because in the cases where a big number of tests were skipped (mostly when integration tests were run - we collected tests from \"tests\" folder) we run only those tests that were not skipped by @integration mark. This however changed in July when we moved all integration tests to \"integration\" subfolder and now instead of large number of skipped tests we run them selectively for each integration. This might help a bit in verifying that the skipped tests were skipped for a good reason", "Summarize skipped tests after tests are run (#30520) When Pytest run tests it provides a summary of the tests. We are running a lot of the tests so we are really interested only in cases that are \"interesting\". So far we have been showing \"skipped\" tests in the summary, because there were already a lot of tests included in it (mostly when integration tests occurred) - we used to simply pick all tests from \"tests\" folder and run only those tests that were not skipped by @integration mark. This however changed in #28170 as we moved the integration tests to \"integration\" subfolder and now instead of large number of skipped tests we run them selectively for each integration. This is very helpful in verifying that the skipped tests are being skipped for a good reason", "Summarize skipped tests after tests are run ? When we have Pytest run tests it provides a summary of the tests. We are running a lot of the tests so we are really interested only in cases that are \"interesting\". So far we are not showing \"skipped\" tests in the summary, because there were cases where we ran large number of tests for a single integration (mostly when integration tests were run - we collected all the tests into \"tests\" folder and run only those that were not skipped by @integration mark. This however changed in #28170 as we moved integration tests to \"integration\" folder, and now instead of large number of skipped tests we run them selectively for each integration. This should help in verifying that the skipped tests were skipped for a real reason", "Summarize skipped tests when integration tests are run (#30520) When Pytest run it provides a summary of the tests. We are running a lot of the tests so the summary is really interested only in cases that are \"interesting\". So far we were showing \"skipped\" tests in summary because there were cases where a lot of tests were skipped (mostly when integration tests were run - we collected tests from integration folder and run only those tests that were not skipped by @integration mark. This however changed in new release - we moved all integration tests to \"integration\" subfolder and instead of large number of skipped tests we run them selectively for each integration. This should help in verifying that the skipped tests were skipped for a good reason"], "original_ll": -3.3140265941619873, "sampled_ll": -2.9703595638275146, "all_perturbed_sampled_ll": [-3.0134358406066895, -3.134972095489502, -3.0342750549316406, -3.1601972579956055, -3.2207252979278564, -2.9998552799224854, -3.0808615684509277, -2.992964506149292, -2.949659824371338, -3.010205030441284], "all_perturbed_original_ll": [-3.1870083808898926, -3.1460330486297607, -3.4075024127960205, -3.3431894779205322, -3.357583522796631, -3.3529410362243652, -3.2421762943267822, -3.4001357555389404, -3.353895664215088, -3.4484710693359375], "perturbed_sampled_ll": -3.059715175628662, "perturbed_original_ll": -3.323893666267395, "perturbed_sampled_ll_std": 0.08217235099097193, "perturbed_original_ll_std": 0.0941401731072692}, {"original": "Clean bigquery operator tests (#30550)", "sampled": "Clean bigquery operator tests (#30550)Fingerprint", "perturbed_sampled": ["Clean bigquery operator tests (#30550)Fingerprint", "Clean bigquery operator tests (#30550)Fingerprint", "Clean bigquery operator tests (#30550)Fingerprint", "Clean bigquery operator tests (#30550)Fingerprint", "Clean bigquery operator tests (#30550)Fingerprint", "Clean bigquery operator tests (#30550)Fingerprint", "Clean bigquery operator tests (#30550)Fingerprint", "Clean bigquery operator tests (#30550)Fingerprint", "Clean bigquery operator tests (#30550)Fingerprint", "Clean bigquery operator tests (#30550)Fingerprint"], "perturbed_original": ["Clean bigquery operator tests (#30550)", "Clean bigquery operator tests (#30550)", "Clean bigquery operator tests (#30550)", "Clean bigquery operator tests (#30550)", "Clean bigquery operator tests (#30550)", "Clean bigquery operator tests (#30550)", "Clean bigquery operator tests (#30550)", "Clean bigquery operator tests (#30550)", "Clean bigquery operator tests (#30550)", "Clean bigquery operator tests (#30550)"], "original_ll": -8.665815353393555, "sampled_ll": -8.105795860290527, "all_perturbed_sampled_ll": [-8.105795860290527, -8.105795860290527, -8.105795860290527, -8.105795860290527, -8.105795860290527, -8.105795860290527, -8.105795860290527, -8.105795860290527, -8.105795860290527, -8.105795860290527], "all_perturbed_original_ll": [-8.665815353393555, -8.665815353393555, -8.665815353393555, -8.665815353393555, -8.665815353393555, -8.665815353393555, -8.665815353393555, -8.665815353393555, -8.665815353393555, -8.665815353393555], "perturbed_sampled_ll": -8.105795860290527, "perturbed_original_ll": -8.665815353393555, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Add task state hover highlighting to new graph (#30100) * Add task state hover highlighting to new graph * add tests * remove unneeded eslint-disable", "sampled": "Add task state hover highlighting to new graph (#30100) * Add task state hover highlighting to new graph * add tests * remove unneeded eslint", "perturbed_sampled": ["Add task state hover highlighting to new graph (#30100) * Add task state hover highlighting to new graph * add tests * remove unneeded eslint", "Add task state hover highlighting to new graph (#30100) * Add task state hover highlighting to new graph * add tests * remove unneeded eslint", "Add task state hover highlighting to new graph (#30100) * Add task state hover highlighting to new graph (#30010) * add tests * remove unneeded eslint", "Add task state hover highlighting to new graph (#30100) * Add task state hover highlighting to new graph * add eslint * remove unneeded eslint", "Add task state hover highlighting to new graph (#30100) * Add task state hover highlighting to new graph * add tests * remove unneeded eslint", "Add task state hover highlighting to new graph (#30100) * Add task state hover highlighting to new graph * add tests * remove unneeded eslint", "Add task state hover highlighting to new graph * Add task state hover highlighting to new graph * add tests * remove unneeded eslint", "Add task state hover highlighting to new graph (#30100) * Add task state hover highlighting to new graph * add nested graphs * remove unneeded eslint", "Add task state hover highlighting to new graph (#30100) * Add task state hover highlighting to new graph (#30100) * add tests * remove unneeded eslint", "(#30100) * Add task state hover highlighting to new graph (#30100) * Add task state hover highlighting to new graph * add tests * remove unneeded eslint"], "perturbed_original": ["Add task state hover highlighting to new graph (#30100) * Add task state hover highlighting to new graph * add tests * remove unneeded eslint-disable", "Add task state hover highlighting to new graph (#30100) * Add task state hover highlighting to new graph * add tests * remove unneeded eslint-disable", "Add task state hover highlighting to new graph (#30100) * Add task state hover highlighting to new graph * add tests * remove unneeded eslint-disable", "Add task state hover highlighting to new graph (#30100) * add task state hover highlighting to new graph * add tests * remove unneeded eslint-disable", "Add task state hover highlighting to new graph (#30100) * Add task state hover highlighting to new graph (#30100) * add tests * remove unneeded eslint-disable", "Add task state hover highlighting to new graph (#30100) * Add task state hover highlighting to new graph * add tests * remove unneeded eslint-disable", "Add task state hover highlighting to new graph (#30100) * Add task state hover highlighting to new graph * add tests * disable eslint-disable", "Add task state hover highlighting to new graph (#30100) * Add task state hover highlighting to new graph * add tests * remove unneeded eslint-disable", "Add task state hover highlighting to new graph (#30100) * add task state hover highlighting to new graph * add tests * remove unneeded eslint-disable", "Add task state hover highlighting to new graph (#30100) * Add task state hover highlighting to new graph * add * remove unneeded eslint-disable"], "original_ll": -4.261870384216309, "sampled_ll": -4.356767177581787, "all_perturbed_sampled_ll": [-4.356767177581787, -4.356767177581787, -4.012054920196533, -4.175470352172852, -4.356767177581787, -4.356767177581787, -4.221195697784424, -4.4067063331604, -3.7943084239959717, -3.788156747817993], "all_perturbed_original_ll": [-4.261870384216309, -4.261870384216309, -4.261870384216309, -4.233882904052734, -3.7303242683410645, -4.261870384216309, -4.482824325561523, -4.261870384216309, -4.233882904052734, -4.45719051361084], "perturbed_sampled_ll": -4.182496118545532, "perturbed_original_ll": -4.244745683670044, "perturbed_sampled_ll_std": 0.2255088190813487, "perturbed_original_ll_std": 0.19187128884972865}, {"original": "Do not log the hook connection details even at DEBUG level (#22627)", "sampled": "Do not log the hook connection details even at DEBUG level (#22627)This", "perturbed_sampled": ["Do not log the hook connection details even at DEBUG level (#22627)This", "Do not log the hook connection details even at DEBUG level (#22627)This", "Do not log the hook connection details even at DEBUG level (#22627)This", "Do not log the hook connection details even at DEBUG level (#22627)This", "Do not log the hook connection details even at DEBUG level (#22627)This", "Do not log the hook connection details even at DEBUG level (#22627)This", "Do not log the hook connection details even at DEBUG level (#22627)This", "Do not log the hook connection details even at DEBUG level (#22627)This", "Do not log the hook connection details even at DEBUG level (#22627)This", "Do not log the hook connection details even at DEBUG level (#22627)This"], "perturbed_original": ["Do not log the hook connection details even at DEBUG level (#22627)", "Do not log the hook connection details even at DEBUG level (#22627)", "Do not log the hook connection details even at DEBUG level (#22627)", "Do not log the hook connection details even at DEBUG level (#22627)", "Do not log the hook connection details even at DEBUG level (#22627)", "Do not log the hook connection details even at DEBUG level (#22627)", "Do not log the hook connection details even at DEBUG level (#22627)", "Do not log the hook connection details even at DEBUG level (#22627)", "Do not log the hook connection details even at DEBUG level (#22627)", "Do not log the hook connection details even at DEBUG level (#22627)"], "original_ll": -5.812219142913818, "sampled_ll": -6.241601467132568, "all_perturbed_sampled_ll": [-6.241601467132568, -6.241601467132568, -6.241601467132568, -6.241601467132568, -6.241601467132568, -6.241601467132568, -6.241601467132568, -6.241601467132568, -6.241601467132568, -6.241601467132568], "all_perturbed_original_ll": [-5.812219142913818, -5.812219142913818, -5.812219142913818, -5.812219142913818, -5.812219142913818, -5.812219142913818, -5.812219142913818, -5.812219142913818, -5.812219142913818, -5.812219142913818], "perturbed_sampled_ll": -6.241601467132568, "perturbed_original_ll": -5.812219142913818, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "[INTHEWILD] Update EBANX company users (#21220)", "sampled": "[INTHEWILD] Update EBANX company users (#21220)One", "perturbed_sampled": ["[INTHEWILD] Update EBANX company users (#21220)One", "[INTHEWILD] Update EBANX company users (#21220)One", "[INTHEWILD] Update EBANX company users (#21220)One", "[INTHEWILD] Update EBANX company users (#21220)One", "[INTHEWILD] Update EBANX company users (#21220)One", "[INTHEWILD] Update EBANX company users (#21220)One", "[INTHEWILD] Update EBANX company users (#21220)One", "[INTHEWILD] Update EBANX company users (#21220)One", "[INTHEWILD] Update EBANX company users (#21220)One", "[INTHEWILD] Update EBANX company users (#21220)One"], "perturbed_original": ["[INTHEWILD] Update EBANX company users (#21220)", "[INTHEWILD] Update EBANX company users (#21220)", "[INTHEWILD] Update EBANX company users (#21220)", "[INTHEWILD] Update EBANX company users (#21220)", "[INTHEWILD] Update EBANX company users (#21220)", "[INTHEWILD] Update EBANX company users (#21220)", "[INTHEWILD] Update EBANX company users (#21220)", "[INTHEWILD] Update EBANX company users (#21220)", "[INTHEWILD] Update EBANX company users (#21220)", "[INTHEWILD] Update EBANX company users (#21220)"], "original_ll": -6.949875354766846, "sampled_ll": -7.313741207122803, "all_perturbed_sampled_ll": [-7.313741207122803, -7.313741207122803, -7.313741207122803, -7.313741207122803, -7.313741207122803, -7.313741207122803, -7.313741207122803, -7.313741207122803, -7.313741207122803, -7.313741207122803], "all_perturbed_original_ll": [-6.949875354766846, -6.949875354766846, -6.949875354766846, -6.949875354766846, -6.949875354766846, -6.949875354766846, -6.949875354766846, -6.949875354766846, -6.949875354766846, -6.949875354766846], "perturbed_sampled_ll": -7.313741207122803, "perturbed_original_ll": -6.949875354766846, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Prepare 2nd wave of providers in December (#36373)", "sampled": "Prepare 2nd wave of providers in December (#36373)The", "perturbed_sampled": ["Prepare 2nd wave of providers in December (#36373)The", "Prepare 2nd wave of providers in December (#36373)The", "Prepare 2nd wave of providers in December (#36373)The", "Prepare 2nd wave of providers in December (#36373)The", "Prepare 2nd wave of providers in December (#36373)The", "Prepare 2nd wave of providers in December (#36373)The", "Prepare 2nd wave of providers in December (#36373)The", "Prepare 2nd wave of providers in December (#36373)The", "Prepare 2nd wave of providers in December (#36373)The", "Prepare 2nd wave of providers in December (#36373)The"], "perturbed_original": ["Prepare 2nd wave of providers in December (#36373)", "Prepare 2nd wave of providers in December (#36373)", "Prepare 2nd wave of providers in December (#36373)", "Prepare 2nd wave of providers in December (#36373)", "Prepare 2nd wave of providers in December (#36373)", "Prepare 2nd wave of providers in December (#36373)", "Prepare 2nd wave of providers in December (#36373)", "Prepare 2nd wave of providers in December (#36373)", "Prepare 2nd wave of providers in December (#36373)", "Prepare 2nd wave of providers in December (#36373)"], "original_ll": -6.215186595916748, "sampled_ll": -6.4961137771606445, "all_perturbed_sampled_ll": [-6.4961137771606445, -6.4961137771606445, -6.4961137771606445, -6.4961137771606445, -6.4961137771606445, -6.4961137771606445, -6.4961137771606445, -6.4961137771606445, -6.4961137771606445, -6.4961137771606445], "all_perturbed_original_ll": [-6.215186595916748, -6.215186595916748, -6.215186595916748, -6.215186595916748, -6.215186595916748, -6.215186595916748, -6.215186595916748, -6.215186595916748, -6.215186595916748, -6.215186595916748], "perturbed_sampled_ll": -6.4961137771606445, "perturbed_original_ll": -6.215186595916748, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Add disable retry flag on backfill (#23829)", "sampled": "Add disable retry flag on backfill (#23829)I", "perturbed_sampled": ["Add disable retry flag on backfill (#23829)I", "Add disable retry flag on backfill (#23829)I", "Add disable retry flag on backfill (#23829)I", "Add disable retry flag on backfill (#23829)I", "Add disable retry flag on backfill (#23829)I", "Add disable retry flag on backfill (#23829)I", "Add disable retry flag on backfill (#23829)I", "Add disable retry flag on backfill (#23829)I", "Add disable retry flag on backfill (#23829)I", "Add disable retry flag on backfill (#23829)I"], "perturbed_original": ["Add disable retry flag on backfill (#23829)", "Add disable retry flag on backfill (#23829)", "Add disable retry flag on backfill (#23829)", "Add disable retry flag on backfill (#23829)", "Add disable retry flag on backfill (#23829)", "Add disable retry flag on backfill (#23829)", "Add disable retry flag on backfill (#23829)", "Add disable retry flag on backfill (#23829)", "Add disable retry flag on backfill (#23829)", "Add disable retry flag on backfill (#23829)"], "original_ll": -5.797621250152588, "sampled_ll": -6.621650218963623, "all_perturbed_sampled_ll": [-6.621650218963623, -6.621650218963623, -6.621650218963623, -6.621650218963623, -6.621650218963623, -6.621650218963623, -6.621650218963623, -6.621650218963623, -6.621650218963623, -6.621650218963623], "all_perturbed_original_ll": [-5.797621250152588, -5.797621250152588, -5.797621250152588, -5.797621250152588, -5.797621250152588, -5.797621250152588, -5.797621250152588, -5.797621250152588, -5.797621250152588, -5.797621250152588], "perturbed_sampled_ll": -6.621650218963623, "perturbed_original_ll": -5.797621250152588, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Update core example DAGs to use `@task.branch` decorator (#25242) * Update core example DAGs to use `@task.branch` decorator * fixup! Update core example DAGs to use `@task.branch` decorator fixup! fixup! Update core example DAGs to use `@task.branch` decorator * fixup! fixup! Update core example DAGs to use `@task.branch` decorator * Update `override` return type anno + use DAG context manager * Update dedent for dataset docs * Use `__future__.annotations` where applicable * fixup!", "sampled": "Update core example DAGs to use `@task.branch` decorator (#25242) * Update core example DAGs to use `@task.branch |@module.grub`, (via #25645) * Add new example decorators for `@module.grub`, `@task.branch`, `@task.task` * Add new example decorators for `@task.branch |@module.grub`, @task.task * Introduce new `@task.grub` decorator (#25238) * Introduce new `@task.grub` decorator (#25529) * Adding '@task.branch |@module.grub` decorator (#25268) * Adding '@task.grub` decorator (#26712) * Adding example decorators for `@task.grub` and `@module.grub` (#25235) * Added @task.", "perturbed_sampled": ["Update core example DAGs to use `@task.branch` decorator (#25242) * Update core example DAGs to use `@task.branch <unk> decorator (#25624, #25645) * Add new example decorators for `@module.grub`, `@task.branch`, `@task.task` * Add new example decorators for `@task.branch |@module.grub`, @task.task * Introduce new `@task.grub` decorator (#25238) * Introduce new `@task.grub` decorator (#25529) * Adding '@task.branch |@module.grub` decorator (#25268) * Adding @task.branch<unk> decorators (#26712) * Added example decorators for `@task.grub` and `@module.grub` * Added @task.", "Update core example DAGs to use `@task.branch` decorator (#25242) * Update core example DAGs to use `@task.branch <unk> ( #25645) * Add new example decorators for `@module.grub`, `@task.branch`, `@task.task` * Add new example decorators for `@task.branch |@module.grub`, @task.task * Introduce new `@task.grub` decorator (#25238) * Introduce new `@task.grub` decorator * Adding '@task.branch |@module.grub` decorator (#25268) * Adding '@task.grub` decorator (#26712) * Adding new example decorators for `@task.grub` and `@module.grub` (#25235) * Added @task.", "Update core example DAGs to use `@task.branch` decorator (#25242) * Update core example DAGs to use `@task.branch <unk> decorator (#25637, #25645) * Add new example decorators for `@module.grub`, `@task.branch`, `@task.task` * Add new example decorators for `@task.branch |@module.grub`, @task.task * Introduce new `@task.grub` decorator (#25238) * Introduce new `@task.grub` decorator (#25529) * Adding '@task.branch |@module.grub` decorator (#25268) * Adding '@task.grub` decorator (#26712) * Add new example decorators for *@task.branch<unk> * Added `@module.grub` (#25235) * Added @task.", "Update core example DAGs to use `@task.branch` (via #25648) * Update core example DAGs to use `@task.branch |@module.grub`, (via #25645) * Add new examples for `@module.grub`, `@task.branch`, `@task.task` * Add new examples for `@task.branch |@module.grub`, @task.task * Introduce new `@task.grub` decorator (#25238) * Introduce new `@task.grub` decorator (#25529) * Introduce new |@module.grub` decorator (#25268) * Adding '@task.grub` decorator (#26712) * Adding example decorators for `@task.grub` and `@module.grub` (#25235) * Added @task.", "Update core example DAGs to use `@task.branch` decorator (#25242) * Update core example DAGs to use `@task.branch |@module.grub`, (via #25645) * Add new example decorators for `@module.grub`, `@task.branch`, `@task.task` * Add new example decorators for `@task.branch <unk> and <unk>@task.task<unk> * Introduce new `@task.grub` decorator (#25238) * Introduce new `@task.grub` decorator (#25529) * Adding '@task.branch |@module.grub` decorator (#25268) * Introducing new decorator (#26712) * Adding sample decorators for `@task.grub` and `@module.grub` (#25235) * Added @task.", "Update core example DAGs to use `@task.branch` decorator (#25242) * Update core example DAGs to use `@task.branch |@module.grub`, (via #25645) * Add new example decorators for `@module.grub`, `@task.branch`, `@task.task` * Add new example decorators for `@task.branch |@module.grub`, (via #25645) * Introduce new `@task.grub` decorator (#25238) * Introduce new `@task.grub` decorator (#25529) * Adding '@task.branch |@module.grub` decorator (#25769) * Adding '@task.grub` decorator (#26712) * Adding example decorators for `@task.grub` and `@module.grub` * Added @task.", "Update core example DAGs to use `@task.branch` decorator (via #26249) * Update core example DAGs to use `@task.branch |@module.grub`, (via #25645) * Add new example decorators for `@module.grub`, `@task.branch`, `@task.task` * Add new example decorators for `@task.branch |@module.grub`, @task.task * Introduce new `@task.grub` decorator (#25525) * Introduce new `@task.grub` decorator (#25529) * Adding '@task.branch |@module.grub` decorator (#25268) * Adding '@task.grub` decorator (#26712) * Adding example decorators for `@task.grub` and `@module.grub` (#25235) and @task.", "Update core example DAGs (via @task) * Introduce new `@task.branch` decorator (#25242) * Update core example DAGs to use `@task.branch |@module.grub`, (via @task.branch) * Add new decorators for `@module.grub`, `@task.branch`, `@task.task` * Add new decorators for `@task.branch |@module.grub`, @task.task * Introduce new `@task.grub` decorator (#25238) * Introduce new `@task.grub` decorator (#25529) * Adding '@task.branch |@module.grub` decorator (#25268) * Adding '@task.grub` decorator (#26712) * Adding example decorators for `@task.grub` and `@module.grub` (#25235) * Added @task.", "Update core example DAGs to use `@task.branch` decorator (#25242) * Update core example DAGs to use `@task.branch |@module.grub`, (via #25645) * Add new example decorators for `@module.grub`, `@task.branch`, `@task.task` * Add new example decorators for `@task.branch |@module.grub`, @task.task <unk> * Introduce new <unk>task.branch<unk> decorator (#25238) * Introduce new `@task.grub` decorator (#25529) * Adding @task.module decorator (#25268) * Adding '@task.grub` decorator (#26712) * Added example decorators for `@task.grub` and `@module.grub` (#25235) * Added @task.", "Update core example DAGs to use `@task.branch` decorator (#25242) * Update core example DAGs to use @task.task decorator (via #25645) * Add new example decorators for `@module.grub`, `@task.branch`, `@task.task` * Add example decorators for `@task.branch |@module.grub`, @task.task * Introduce new @task.branch decorator (#25238) * Introduce new `@task.grub` decorator (#25529) * Adding '@task.branch |@module.grub` decorator (#25268) * Adding '@task.grub` decorator (#26712) * Adding example decorators for `@task.grub` and <unk>task.grid<unk> * Added @task."], "perturbed_original": ["Update core example DAGs to use `@task.branch` decorator (#25242) * Update core example DAGs to use `@task.branch` decorator * fixup! Update core example DAGs to use `@task.branch` decorator fixup! fixup! Update core example DAGs to use `@task.branch` decorator * fixup! * Update core example DAGs to use <unk>@task.branch<unk> decorator * Update `override` return type anno + use DAG context manager * Update dedent for dataset docs * Use `__future__.annotations` where applicable * fixup!", "Update core example DAGs to use `@task.branch` decorator (#25242) * Update core example DAGs to use `@task.branch` decorator * fixup! Update core example DAGs to use `@task.branch` decorator fixup! fixup! Update core example DAGs to use `@task.branch` decorator * fixup! fixup! Update core example DAGs to use * fixup! fixup! fixup! fixup! fixup! * Update `override` return type anno + use DAG * * Update dedent for dataset docs in `__future__.annotations` where applicable * fixup!", "Update core example DAGs to use <unk>@task.branch<unk> decorator (#25242) * Update core example DAGs to use `@task.branch` decorator * fixup! Update core example DAGs to use `@task.branch` decorator (#25242) * Update core example DAGs to use `@task.branch` decorator * fixup! Update core example DAGs to use `@task.branch` decorator * Update `override` return type anno + use DAG context manager * Update dedent for all use cases * Use `__future__.annotations` where applicable * fixup!", "Update core example DAGs to use `@task.branch` decorator (#25242) Update core example DAGs to use `@task.branch` decorator * fixup! Update core example DAGs to use `@task.branch` decorator * fixup! Update core example DAGs to use branch decorator * fixup! fixup! Update core example DAGs to use branch decorator * Update `override` return type anno + use DAG context manager * Update dedent for dataset docs * Use context manager when applicable * fixup!", "Update core example DAGs to use `@task.branch` decorator (#25242) * Update core example DAGs to use `@task.branch` decorator * fixup! Update core example DAGs to use `@task.branch` decorator fixup! fixup! Update core example DAGs to use `@task.branch` decorator * fixup! fixup! Update core example DAGs to use `@task.branch` decorator * Update `override` return type + use DAG context manager * Update dedent for instance * Use `__future__.annotations` where applicable * fixup!", "Update core example DAGs to use `@task.branch` decorator (#25242) * Update core example DAGs to use `@task.branch` decorator (#25242) * fixup! fixup! Update core example DAGs to use `@task.branch` decorator fixup! fixup! Update core example DAGs to use `@task.branch` decorator * fixup! fixup! Update core example DAGs to use `@task.branch` decorator * `override` return type anno + use DAG context manager * Use dedent for dataset docs * Use `__future__.annotations` where applicable * fixup!", "Update core example DAGs to use `@task.branch` decorator (#25242) * Update core example DAGs to use `@task.branch` decorator * fixup! Update core example DAGs to use `@task.branch` decorator fixup! fixup! Update core example DAGs to use `@task.branch` decorator * fixup! fixup! Update core example DAGs to use `@task.branch` decorator * Fix `override` return type anno + use DAG context manager * Update dedent info in DAG wget docs * Use `__future__.annotations` where applicable * fixup!", "Update core example DAGs to use `@task.branch` decorator (#25242) * Update core example DAGs to use `@task.branch` decorator * fixup! Update core example DAGs to use `@task.branch` decorator fixup! fixup! Update core example DAGs to use `@task.branch` decorator * fixup! fixup! Update core example DAGs to use `@task.branch` decorator * Update `override` in <unk>/anno<unk> anno + use DAG context manager * Update dedent for dataset docs to include `__future__.annotations` where applicable * fixup!", "Update core example DAGs to use `@task.branch` decorator fixup! fixup! Update core example DAGs to use `@task.branch` decorator * fixup! Update core example DAGs to use `@task.branch` decorator fixup! fixup! Update core example DAGs to use `@task.branch` decorator * fixup! fixup! Update core instance return types to use `@task.branch` decorator * Update `override` return type anno + use anno manager * Update dedent ation docs * Use `__future__.annotations` where applicable * fixup!", "Update core example DAGs to use decorator (#25242) * Update core example DAGs to use `@task.branch` decorator * fixup! Update core example DAGs to use <unk>@task.branch<unk> decorator fixup! fixup! Update core example DAGs to use `@task.branch` decorator * fixup! Update core example DAGs to use `@task.branch` decorator * Update `override` return type * Allow DAGs to use DAG context manager * Update dedent for dataset docs for `__future__.annotations` where applicable * fixup!"], "original_ll": -2.481809377670288, "sampled_ll": -1.6737364530563354, "all_perturbed_sampled_ll": [-1.8883711099624634, -1.8245344161987305, -1.8901889324188232, -1.80316162109375, -2.020714521408081, -1.6479464769363403, -1.7151473760604858, -1.7075148820877075, -2.015364170074463, -2.1444239616394043], "all_perturbed_original_ll": [-2.714632272720337, -2.450350046157837, -2.629619598388672, -2.7603166103363037, -2.3765132427215576, -2.3768913745880127, -2.4693989753723145, -2.652804136276245, -2.492733955383301, -2.8291101455688477], "perturbed_sampled_ll": -1.8657367467880248, "perturbed_original_ll": -2.5752370357513428, "perturbed_sampled_ll_std": 0.15031316010737492, "perturbed_original_ll_std": 0.15477354935280405}, {"original": "Add Mapped task instance endpoint (#21965) Add an API endpoint that supplies details of a mapped task instance.", "sampled": "Add Mapped task instance endpoint (#21965) Add an API endpoint that supplies details of a mapped task instance.Rendering", "perturbed_sampled": ["Add Mapped task instance endpoint (#21965) Add an endpoint, mapping, that supplies details of a mapped task instance.Rendering", "Mapped task instance endpoint (#21965) Add an API endpoint that supplies details of a mapped task instance.Rendering", "Add Mapped task instance endpoint (#21965) Add an additional endpoint that supplies details of a mapped task instance.Rendering", "Add Mapped task instance endpoint : Adds an API endpoint that supplies details of a mapped task instance.Rendering", "Add Mapped task instance endpoint (#21965) Add an API endpoint that supplies details of a mapped task instance.Rendering", "Add Mapped task instance endpoint (#21965) Add an API endpoint that supplies details of a mapped task instance.Rendering", "Add Mapped task instance endpoint (#21965) Add an API endpoint to gather details of a mapped task instance.Rendering", "Add Mapped task instance endpoint (#21965) Add an API endpoint that retrieves data that supplies details of a mapped task instance.Rendering", "Add Mapped task instance endpoint (#21965) Add an API endpoint that supplies details of a mapped task instance.Rendering", "Add Mapped task instance endpoint (#21965) - The mapped task instances API endpoint that supplies details of a mapped task instance.Rendering"], "perturbed_original": ["Add Mapped task API endpoint (#21965) Add an API endpoint that supplies details of a mapped task instance.", "Add Mapped task instance endpoint (#21965) Add a mapping task instance endpoint that supplies details of a mapped task instance.", "Add Mapped task API endpoint (#21965) Add an API endpoint that supplies details of a mapped task instance.", "Add Mapped task instance endpoint (#21965) Add an API endpoint that returns the details of a mapped task instance.", "Add Mapped task instance endpoint (#21965) Add a task-instance-mapping endpoint that supplies details of a mapped task instance.", "Add Mapped task instance endpoint (#21965) Add an endpoint that supplies details of a mapped task instance.", "Add Mapped Task endpoint (#21965) Add an API endpoint that supplies details of a mapped task instance.", "Add Mapped task instance endpoint (#21965) Add an API endpoint that supplies details on an associated mapped task instance.", "Add Mapped task API Endpoint. (#21965) Add an API endpoint that supplies details of a mapped task instance.", "Add detail API task instance endpoint (#21965) Add an API endpoint that supplies details of a mapped task instance."], "original_ll": -5.092185974121094, "sampled_ll": -5.07865571975708, "all_perturbed_sampled_ll": [-5.227739334106445, -4.904036045074463, -5.181512832641602, -5.039444446563721, -5.07865571975708, -5.07865571975708, -4.956569671630859, -4.83844518661499, -5.07865571975708, -5.141742706298828], "all_perturbed_original_ll": [-4.995148181915283, -4.7698493003845215, -4.995148181915283, -4.574028015136719, -4.615164756774902, -5.250542640686035, -5.131711483001709, -5.263879299163818, -4.878321170806885, -5.320450305938721], "perturbed_sampled_ll": -5.052545738220215, "perturbed_original_ll": -4.979424333572387, "perturbed_sampled_ll_std": 0.11601888827340398, "perturbed_original_ll_std": 0.2540824847902123}, {"original": "add managed identity support to AsyncDefaultAzureCredential (#35394) * feat(providers/microsoft): add AsyncDefaultAzureCredential support and make args keyword args for get_default_azure_credential * refactor(providers/microsoft): split get_default_azure_credential into 2 functions", "sampled": "add managed identity support to AsyncDefaultAzureCredential (#35394) * feat(providers/microsoft): add AsyncDefaultAzureCredential to Microsoft Azure Azure Core Services * feat(providers/microsoft): add Azure AD Connect endpoint to Azure", "perturbed_sampled": ["add managed identity support to AsyncDefaultAzureCredential (#35394) * feat(providers/microsoft): add AsyncDefaultAzureCredential to Microsoft Azure Azure Core Services * feat(providers/microsoft): add Azure AD Connect or for Microsoft Azure", "add managed identity support to AsyncDefaultAzureCredential (#35394) * feat(providers/microsoft): add AsyncDefaultAzureCredential to Microsoft Azure Azure AD Connect Endpoint * feat(providers/microsoft): add Azure AD Connect endpoint to Azure", "add managed identity support to Microsoft Azure Core Services * feat(providers/microsoft): add AsyncDefaultAzureCredential to Microsoft Azure Azure Core Services * feat(providers/microsoft): add Azure AD Connect endpoint to Azure", "add managed identity support to AsyncDefaultAzureCredential (#35394) * feat(providers/microsoft): add Azure AD Connect endpoint to Microsoft Azure Azure Core Services * feat(providers/microsoft): add Azure AD Connect endpoint to Azure", "add managed identity support to AsyncDefaultAzureCredential (#35394) * feat(providers/microsoft): add AsyncDefaultAzureCredential to Microsoft Azure Azure Core Services Featured Providers * feat(server/microsoft): add Azure AD Connect endpoint to Azure", "add managed identity support to AsyncDefaultAzureCredential (#35394) * feat(providers/microsoft): add AsyncDefaultAzureCredential to Microsoft Azure Azure Core (#35372) * feat(providers/microsoft): add Azure AD Connect endpoint to Azure", "add managed identity support to AsyncDefaultAzureCredential (#35394) * feat(providers/microsoft): add AsyncDefaultAzureCredential to Microsoft Azure Azure Core DB (#37273) * feat(providers/microsoft): add Azure AD Connect endpoint to Azure", "add managed identity support to AsyncDefaultAzureCredential (#35394) * feat(providers/microsoft): add AsyncDefaultAzureCredential user api to Azure Azure Core Services * feat(providers/microsoft): add Azure AD Connect endpoint to Azure", "add managed identity support to AsyncDefaultAzureCredential (#35394) * feat(providers/microsoft): add AsyncDefaultAzureCredential to Microsoft Azure AD Connect Services * feat(providers/microsoft): add Azure AD Connect endpoint to Azure", "add managed identity support to Microsoft Azure * feat(providers/microsoft): add AsyncDefaultAzureCredential to Microsoft Azure Azure Core Services * feat(providers/microsoft): add Azure AD Connect endpoint to Azure"], "perturbed_original": ["add managed identity support to AsyncDefaultAzureCredential (#35394) * feat(providers/microsoft): add AsyncDefaultAzureCredential * feat(providers/microsoft): make args keyword args for get_default_azure_credential * refactor(providers/microsoft): split get_default_azure_credential into 2 functions", "add <unk>azurecredential> support to AsyncDefaultAzureCredential (#35394) * feat(providers/microsoft): add AsyncDefaultAzureCredential support and make args keyword args for get_default_azure_credential * refactor(providers/microsoft): split get_default_azure_credential into 2 functions", "add managed identity support to AsyncDefaultAzureCredential (#35394) * feat(providers/microsoft): add AsyncDefaultAzureCredential support and make args keyword optional in the get_default_azure_credential * refactor(providers/microsoft): split get_default_azure_credential into 2 functions", "add managed identity support to AsyncDefaultAzureCredential (#35394) * feat(providers/microsoft): add AsyncDefaultAzureCredential support and make it args for get_default_azure_credential * refactor(providers/microsoft): split get_default_azure_credential into 2 functions", "add managed identity support to AsyncDefaultAzureCredential (#35394) * feat(providers/microsoft): add args and make args keyword args for get_default_azure_credential * refactor(providers/microsoft): split get_default_azure_credential into 2 functions", "add managed identity support to AsyncDefaultAzureCredential (#35394) * feat(providers/microsoft): add args and make args keyword args for get_default_azure_credential * refactor(providers/microsoft): split get_default_azure_credential into 2 functions", "add managed identity support to AsyncDefaultAzureCredential (#35394) * feat(providers/microsoft): add AsyncDefaultAzureCredential support and make args keyword optional to get_default_azure_credential * refactor(providers/microsoft): split get_default_azure_credential into 2 functions", "add managed identity support to AsyncDefaultAzureCredential (#35394) * feat(providers/microsoft): add AsyncDefaultAzureCredential support and make args required for get_default_azure_credential * refactor(providers/microsoft): split get_default_azure_credential into 2 functions", "add managed identity support to AsyncDefaultAzureCredential (#35394) * feat(providers/microsoft): add AsyncDefaultAzureCredential support and make args keyword args for get_default_azure_credential * refactor(providers/microsoft): merge get_default_azure_credential into 2 functions", "add readonly/writeonly support to AsyncDefaultAzureCredential (#35394) * feat(providers/microsoft): add AsyncDefaultAzureCredential support and make args keyword args for get_default_azure_credential * refactor(providers/microsoft): split get_default_azure_credential into 2 functions"], "original_ll": -3.2712881565093994, "sampled_ll": -3.6133854389190674, "all_perturbed_sampled_ll": [-3.7684226036071777, -3.4502575397491455, -3.7545156478881836, -3.8516464233398438, -3.974782705307007, -3.518885612487793, -3.588679552078247, -3.822132110595703, -3.528637647628784, -3.9842042922973633], "all_perturbed_original_ll": [-3.00692081451416, -3.232048749923706, -3.271697759628296, -3.245938777923584, -3.5934014320373535, -3.5934014320373535, -3.293043613433838, -3.269911766052246, -3.3720695972442627, -3.1317272186279297], "perturbed_sampled_ll": -3.724216413497925, "perturbed_original_ll": -3.301016116142273, "perturbed_sampled_ll_std": 0.18245842883248975, "perturbed_original_ll_std": 0.17345268477346112}, {"original": "Add arg --yes to `db export-archived` command. (#29485) This was omitted in the command but I think it's necessary so one can choose to override the questions", "sampled": "Add arg --yes to `db export-archived` command. (#29485) This was omitted in the command but I think it's necessary now. (#58391)\n\nThe `sqlite3_dump' command has been moved to", "perturbed_sampled": ["Add arg --yes to `db export-archived` command. (#29485) This was omitted in the command but I think it's necessary . `sqlite3_dump' has been moved to", "Add arg --yes to `db export-archived` command. (#29485) This was omitted in the command but I see it's necessary now. (#58391)\n\nThe `sqlite3_dump' command was moved to", "Add flag to `db export-archived` command. (#29485) This was omitted in the initial README, but I think it's necessary now. (#58391)\n\nThe `sqlite3_dump' command has been moved to", "Add arg --yes to `db export-archived` command. The parameter was omitted in the command but I think it's necessary now. (#58391)\n\nThe `sqlite3_dump' command has been added to", "Add arg --yes to `db export-archived` command. arg --yes was omitted in the command but I think it's necessary now. (#58391)\n\nThe `sqlite3_dump' command has been moved to", "Add arg --yes to `db export-archived` command. (#29485) This was omitted in the command but I think it's necessary now. (#58391)\n\nThe `sqlite3_dump' command was moved from the db command files to this command. moved to", "Use --yes to `db _ph.dll'. (#29485) This was omitted in the command but I think it's necessary now. (#58391)\n\nThe `sqlite3_dump' command has been moved to", "Add arg --yes to `db export-archived` command. (#29485) This was omitted in the command but I think it's important. (#58391)\n\nThe `sqlite3_dump' command has a value-arg parameter in addition to", "Add arg 3 to `db export-archived` command. (#29485) This was omitted in the command but I think it's necessary now. (#58391)\n\nThe bug has been moved to", "Add arg --yes to `db export-archived` command. (#29485) I omitted it from the archive command but I think it's necessary now. (#58391)\n\nThe `sqlite3_dump' command has been moved to"], "perturbed_original": ["Add arg --yes to `db export-archived` command. (#29485) This was an optional parameter on the command but I think it's necessary so one can explicitly override the questions", "(#29485) Add --yes to `db export-archived` command. (#29485) This was omitted in the command but I think it's necessary so you can choose to override the questions", "Add arg --yes to `db export-archived` command. (#29485) This was omitted in the command but I believe it's necessary so one can choose to archive questions", "Add arg --yes to `db export-archived` command. (#29485) This option might be omitted in the command but I think it is necessary so one can choose to override the questions", "Add arg --yes to `db export-archived` command. (#29485) This is optional in the command but I think it's necessary so one more option at the end to override the questions", "Add arg --yes to `db export-archived` command. (#29485) This was omitted in the original export command but I think it's necessary so one can have the option to override the questions", "by putting --yes to `db export-archived` command. (#29485) This was omitted in the command but I think it's important so that one can choose to override the questions", "Add arg to `db export-archived` command. This was omitted in the command but I think it's necessary so one can choose to override the questions", "Add arg --yes -choose -- export-archived` ?>. This was omitted in the command but I think it's necessary so one can choose to override the questions", "Add arg --yes to `db export-archived` command. (#29485) This was omitted in the issue, but I think it's necessary so one has an option to override the questions"], "original_ll": -5.080813407897949, "sampled_ll": -3.913706064224243, "all_perturbed_sampled_ll": [-4.547524452209473, -4.136662006378174, -3.4921844005584717, -3.9385082721710205, -3.8479039669036865, -4.131428241729736, -4.190849781036377, -4.158858299255371, -4.189835071563721, -3.957261085510254], "all_perturbed_original_ll": [-5.090106964111328, -4.488260269165039, -5.184458255767822, -4.947141647338867, -4.907718181610107, -4.854642391204834, -5.115461826324463, -4.722128391265869, -5.289767265319824, -4.842160224914551], "perturbed_sampled_ll": -4.059101557731628, "perturbed_original_ll": -4.9441845417022705, "perturbed_sampled_ll_std": 0.26174752291057213, "perturbed_original_ll_std": 0.22466181522059356}, {"original": "System test for EMR Serverless (#25559) * System test for EMR Serverless following the template in #24643 (AIP-47) * Remove example_emr_serverless.py from example_dags", "sampled": "System test for EMR Serverless (#25559) * System test for EMR Serverless following the template in #24643 (AIP-1.20) * Improved support for configuring", "perturbed_sampled": ["System test for EMR Serverless * System test for EMR Serverless following the template in #24643 (AIP-1.20) * Improved support for configuring", "System test for EMR Serverless (#25559) * System test for EMR Serverless following the template in #24643 (AIP-1.20) * Improved support for configuring", "System test for EMR Serverless (#25559) * System test for EMR Serverless following the template in #24643 (AIP-1.20) * Improved support for configuring", "System test for EMR Serverless * System test for EMR Serverless following the template in #24643 (AIP-1.20) * Improved support for configuring", "System test for EMR Serverless (#25559) * System test for EMR Serverless following the template in #24643 (AIP-1.20) * Improved support for configuring", "System test for EMR Serverless * System test for EMR Serverless following the template in #24643 (AIP-1.20) * Improved support for configuring", "System test for EMR Serverless * System test for EMR Serverless following the template in #24643 (AIP-1.20) * Improved support for configuring", "System test for EMR Serverless following the template in #24644 * System test for EMR Serverless following the template in #24643 (AIP-1.20) * Improved support for configuring", "System test for EMR Serverless (#25559) * System test for EMR Serverless following the template in #24643 (AIP-1.20) * Improved support for configuring", "System test for EMR Serverless (#25559) * System test for EMR Serverless following the template in #24643 (AIP-1.20) * Improved support for configuring"], "perturbed_original": ["System test for EMR Serverless (#25559) * System test for EMR Serverless following the template in #24643 (AIP-47) * Remove test from test in example_dags", "System test for EMR Serverless (#25559) * System test for EMR Serverless which use the template in #24643 (AIP-47) * Remove example_emr_serverless.py from example_dags", "System test for EMR Serverless (#25559) * System test for EMR Serverless replacing the template in #24643 (AIP-47) * Remove example_emr_serverless.py from example_dags", "System test for EMR Serverless : System test for EMR Serverless following the template in #24643 (AIP-47) * Remove example_emr_serverless.py from example_dags", "System test for EMR Serverless (#25559) * System test for EMR Serverless following the template in GitHub * Remove example_emr_serverless.py from example_dags", "System test for EMR Serverless (#25559) * System test for EMR Serverless following the template in the example code * Remove example_emr_serverless.py from example_dags", "System test for EMR Serverless (#25559) * System test for EMR Serverless following changes made in #24643 (AIP-47) * Remove example_emr_serverless.py from example_dags", "System test for EMR Serverless (#25559) * System test EMR Serverless following the template in #24643 (AIP-47) * Remove example_emr_serverless.py from example_dags", "System test for EMR Serverless (#25559) * Write a test for EMR Serverless following the template in #24643 (AIP-47) * Remove example_emr_serverless.py from example_dags", "System test for EMR Serverless (#25559) * System test for EMR Serverless : Updates template in #24643 (AIP-47) * Remove example_emr_serverless.py from example_dags"], "original_ll": -4.086208820343018, "sampled_ll": -4.034708023071289, "all_perturbed_sampled_ll": [-4.247795581817627, -4.034708023071289, -4.034708023071289, -4.247795581817627, -4.034708023071289, -4.247795581817627, -4.247795581817627, -3.654620885848999, -4.034708023071289, -4.034708023071289], "all_perturbed_original_ll": [-4.6447272300720215, -4.275152206420898, -4.282803535461426, -4.353025436401367, -4.240021705627441, -4.122666358947754, -3.9995276927948, -4.406093120574951, -4.104325771331787, -4.3848090171813965], "perturbed_sampled_ll": -4.081934332847595, "perturbed_original_ll": -4.281315207481384, "perturbed_sampled_ll_std": 0.17429521488005792, "perturbed_original_ll_std": 0.17353253972031663}, {"original": "Patch MockExecutor in tests instead of \"prod\" code (#29028) Patch the MockExecutor into the executor list within test code rather than core/prod code.", "sampled": "Patch MockExecutor in tests instead of \"prod\" code (#29028) Patch the MockExecutor into the executor list within test code with an Executor that", "perturbed_sampled": ["Patch MockExecutor in tests instead of \"prod\" code (#29028) Patch the MockExecutor into the executor list within tests with an Executor that", "Patch MockExecutor in tests instead of \"prod\" code (#29028) Patch the MockExecutor into the executor . Replace the test code with an Executor that", "Patch MockExecutor in tests instead of \"prod\" code (#29028) Patch the MockExecutor into the executor list within test code with the patch that", "Patch MockExecutor in tests instead of \"prod\" code (#29028) Patch the MockExecutor into the executor list within test /prod code - This should patch an Executor that", "Patch MockExecutor in tests instead of \"prod\" code (#29028) - Add patch with MockExecutor into the executor list within test code with an Executor that", "Patch MockExecutor in tests and \"prod\" code (#29028) Patch the MockExecutor into the executor list within test code with an Executor that", "Patch MockExecutor in tests instead of \"prod\" code (#29028) Patch the MockExecutor into the executor list within tests with an Executor that", "Patch MockExecutor into test instead of \"prod\" code (#29028) Patch the MockExecutor into the executor list within test code with an Executor that", "Patch MockExecutor in tests instead of \"prod\" code (#29028) Patch the MockExecutor into the executor list within test code patch a Mock Executor that", "Patch MockExecutor in test code instead of \"prod\" code (#29028) Patch the MockExecutor into the executor list within test code with an Executor that"], "perturbed_original": ["Patch MockExecutor in tests instead of \"prod\" code (#29028) Patch to add mockexecutor into the executor list within test code rather than core/prod code.", "Patch MockExecutor in tests instead of \"prod\" code (#29028) Patch the MockExecutor into the executor list within test code rather than core/prod code.", "Patch MockExecutor in tests instead of \"prod\" code . patch the MockExecutor into the executor list within test code rather than core/prod code.", "Patch MockExecutor in tests instead of \"prod\" code (#29028) - Patch MockExecutor into the executor list within test code rather than core/prod code.", "Patch MockExecutor in tests instead of \"prod\" code (#29028) Patch the MockExecutor into the executor for test code rather than core/prod code.", "code in tests instead of \"prod\" code (#29028) Patch the MockExecutor into the executor list within test code rather than core/prod code.", "Patch MockExecutor in tests instead of \"prod\" code. Patch the MockExecutor into the executor list within test code rather than core/prod code.", "Patch MockExecutor in tests instead of core/prod code (#29028) Patch the MockExecutor into the executor list within test code rather than core/prod code.", "Patch MockExecutor in tests instead of code. (#29028) Patch the MockExecutor into the executor list within test code rather than core/prod code.", "Patch MockExecutor in tests instead of \"prod\" code (#29028) Patch the MockExecutor into the executor list within test code instead of core/prod code."], "original_ll": -4.507083892822266, "sampled_ll": -4.65079402923584, "all_perturbed_sampled_ll": [-4.677382946014404, -4.42144775390625, -4.860382556915283, -4.7527852058410645, -4.838015556335449, -4.626068115234375, -4.677382946014404, -4.868742942810059, -4.838523864746094, -4.476927757263184], "all_perturbed_original_ll": [-4.660252094268799, -4.507083892822266, -4.551076412200928, -4.577490329742432, -4.346301078796387, -4.795334339141846, -4.351628303527832, -4.068971157073975, -4.542428493499756, -4.441916465759277], "perturbed_sampled_ll": -4.703765964508056, "perturbed_original_ll": -4.484248256683349, "perturbed_sampled_ll_std": 0.15130099748681866, "perturbed_original_ll_std": 0.18859557793889586}, {"original": "Refactor unneeded 'continue' jumps around the repo (#33849)", "sampled": "Refactor unneeded 'continue' jumps around the repo (#33849)Description", "perturbed_sampled": ["Refactor unneeded 'continue' jumps around the repo (#33849)Description", "Refactor unneeded 'continue' jumps around the repo (#33849)Description", "Refactor unneeded 'continue' jumps around the repo (#33849)Description", "Refactor unneeded 'continue' jumps around the repo (#33849)Description", "Refactor unneeded 'continue' jumps around the repo (#33849)Description", "Refactor unneeded 'continue' jumps around the repo (#33849)Description", "Refactor unneeded 'continue' jumps around the repo (#33849)Description", "Refactor unneeded 'continue' jumps around the repo (#33849)Description", "Refactor unneeded 'continue' jumps around the repo (#33849)Description", "Refactor unneeded 'continue' jumps around the repo (#33849)Description"], "perturbed_original": ["Refactor unneeded 'continue' jumps around the repo (#33849)", "Refactor unneeded 'continue' jumps around the repo (#33849)", "Refactor unneeded 'continue' jumps around the repo (#33849)", "Refactor unneeded 'continue' jumps around the repo (#33849)", "Refactor unneeded 'continue' jumps around the repo (#33849)", "Refactor unneeded 'continue' jumps around the repo (#33849)", "Refactor unneeded 'continue' jumps around the repo (#33849)", "Refactor unneeded 'continue' jumps around the repo (#33849)", "Refactor unneeded 'continue' jumps around the repo (#33849)", "Refactor unneeded 'continue' jumps around the repo (#33849)"], "original_ll": -6.126823425292969, "sampled_ll": -6.742197513580322, "all_perturbed_sampled_ll": [-6.742197513580322, -6.742197513580322, -6.742197513580322, -6.742197513580322, -6.742197513580322, -6.742197513580322, -6.742197513580322, -6.742197513580322, -6.742197513580322, -6.742197513580322], "all_perturbed_original_ll": [-6.126823425292969, -6.126823425292969, -6.126823425292969, -6.126823425292969, -6.126823425292969, -6.126823425292969, -6.126823425292969, -6.126823425292969, -6.126823425292969, -6.126823425292969], "perturbed_sampled_ll": -6.742197513580322, "perturbed_original_ll": -6.126823425292969, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "TriggerDagRunOperator.operator_extra_links is attr (#24676) There's absolutely no reason this needs to be a property. And it cannot be since we need to access this at the class level.", "sampled": "TriggerDagRunOperator.operator_extra_links is attr (#24676) There's absolutely no reason this needs to be a property. [2ef5c2a2ce5c0] 2018-05-14 Todd C. Miller <Todd.Miller@courtesan.com> * Makefile.in: Fix compiler warnings that were generated", "perturbed_sampled": ["TriggerDagRunOperator.operator_extra_links is attr (#24676) and there is no reason this needs to be a header. Changed 2018-05-14 Todd C. Miller <Todd.Miller@courtesan.com> * Makefile.in: Fix compiler warnings that were generated", "TriggerDagRunOperator.operator_extra_links is attr (#24676) There's absolutely no reason this needs to be a property. [2ef5c2a2ce5c0] 2018-05-14 Todd Miller <Todd.Miller@courtesan.com> * Makefile.in: Fix compiler warnings that were generated", "TriggerDagRunOperator.operator_extra_links is 0 There's absolutely no reason this needs to be a property. [2ef5c2a2ce5c0] Todd C. Miller <Todd.Miller@courtesan.com> * Makefile.in: Fix compiler warnings that were generated", "TriggerDagRunOperator.operator_extra_links is attr (#24676) There's absolutely no reason this needs to be a property. [2ef5c2a2ce5c0] 2018-05-14 Todd C. Miller <Todd.Miller@courtesan.com> * There are additional compiler warnings that were generated", "TriggerDagRunOperator.operator_extra_links is attr (#24676) There's absolutely no reason this needs to be a property. [2ef5c2a2ce5c0] 2018-05-14 Todd Miller <Todd.Miller@courtesan.com> * Makefile.in: Fix compiler warnings during build when wrong values have been generated", "TriggerDagRunOperator.operator_extra_links is attr (#24676) There's no reason this needs to be a property. [2ef5c2a2ce5c0] 2018-05-14 Todd C. Miller <Todd.Miller@courtesan.com> * Deleted the compiler warnings that were generated", "TriggerDagRunOperator.operator_extra_links is attr (#24676) There's absolutely no reason this needs to be a property. [2ef5c2a2ce5c0] 2018-05-14 Todd C. Miller <Todd.Miller@courtesan.com> * The following compiler tests were generated", "TriggerDagRunOperator.operator_extra_links is attr (#24676) ; no reason this needs to be a property. [2ef5c2a2ce5c0] 2018-05-14 Todd Miller <Todd.Miller@courtesan.com> * Makefile.in: Fix compiler warnings that were generated", "TriggerDagRunOperator.operator_extra_links is a good solution. There's absolutely no reason this needs to be changed. [2ef5c2a2ce5c0] 2018-05-14 Todd C. Miller <Todd.Miller@courtesan.com> * Makefile.in: Fix compiler warnings that were generated", "TriggerDagRunOperator.operator_extra_links is n't the right property. There's absolutely no reason this needs to be a property. [2ef5c2a2ce5c0] Todd C. Miller <Todd.Miller@courtesan.com> * Makefile.in: Fix compiler warnings that were generated"], "perturbed_original": ["TriggerDagRunOperator.operator_extra_links is attr (#24676) There's absolutely no reason this needs to be attr. And it shouldn't be since we need to access this at the class level.", "#24678) attr (#24676) There's absolutely no reason this needs to be a property. And it cannot be since we need to do this at the class level.", "TriggerDagRunOperator.operator_extra_links is attr (#24676) There's absolutely no exception here. This needs to be a property. And it cannot be an instance - you need to access this at the class level.", "TriggerDagRunOperator.operator_extra_links . (#24676) There's absolutely no reason this needs to be a dependency and it cannot be since we need to access this at the class level.", "TriggerDagRunOperator.operator_extra_links is attr (#24676) There's absolutely no reason this needs to be a property. And it does not make it easier, since it's easy to access this at the class level.", "TriggerDagRunOperator.operator_extra_links is attr (#24676) There's absolutely no need to pass data, this needs to be a property. And it cannot be a property, we need to access this at the class level.", "TriggerDagRunOperator.operator_extra_links is attr (#24676) There's absolutely no reason this needs to be a property. This cannot be since we need to access it at the class level.", "TriggerDagRunOperator.operator_extra_links is attr (#24676) There's absolutely no reason this needs to be a property. It cannot be since we need to make it at the class level.", "TriggerDagRunOperator.operator_extra_links is attr (#24676) There's absolutely no way this needs to be a property. And it cannot be since we have to access this at the class level.", "TriggerDagRunOperator.operator_extra_links is attr (#24676) but there's no reason this needs to be a property. And it cannot happen when we need to access this at the class level."], "original_ll": -4.340348243713379, "sampled_ll": -2.930861234664917, "all_perturbed_sampled_ll": [-3.208503246307373, -3.2837328910827637, -3.1698503494262695, -3.266201972961426, -3.4722821712493896, -3.241133213043213, -3.3440613746643066, -3.3696484565734863, -2.778491973876953, -3.2554941177368164], "all_perturbed_original_ll": [-4.178948402404785, -3.6319046020507812, -4.42943000793457, -4.496405601501465, -4.168984413146973, -4.269111633300781, -4.4357781410217285, -4.326226234436035, -4.394763469696045, -4.423584938049316], "perturbed_sampled_ll": -3.2389399766922, "perturbed_original_ll": -4.275513744354248, "perturbed_sampled_ll_std": 0.17416210860163173, "perturbed_original_ll_std": 0.23913019809094965}, {"original": "Remove code duplication in the test suite test_views_acl.py (#20887)", "sampled": "Remove code duplication in the test suite test_views_acl.py (#20887)The", "perturbed_sampled": ["Remove code duplication in the test suite test_views_acl.py (#20887)The", "Remove code duplication in the test suite test_views_acl.py (#20887)The", "Remove code duplication in the test suite test_views_acl.py (#20887)The", "Remove code duplication in the test suite test_views_acl.py (#20887)The", "Remove code duplication in the test suite test_views_acl.py (#20887)The", "Remove code duplication in the test suite test_views_acl.py (#20887)The", "Remove code duplication in the test suite test_views_acl.py (#20887)The", "Remove code duplication in the test suite test_views_acl.py (#20887)The", "Remove code duplication in the test suite test_views_acl.py (#20887)The", "Remove code duplication in the test suite test_views_acl.py (#20887)The"], "perturbed_original": ["Remove code duplication in the test suite test_views_acl.py (#20887)", "Remove code duplication in the test suite test_views_acl.py (#20887)", "Remove code duplication in the test suite test_views_acl.py (#20887)", "Remove code duplication in the test suite test_views_acl.py (#20887)", "Remove code duplication in the test suite test_views_acl.py (#20887)", "Remove code duplication in the test suite test_views_acl.py (#20887)", "Remove code duplication in the test suite test_views_acl.py (#20887)", "Remove code duplication in the test suite test_views_acl.py (#20887)", "Remove code duplication in the test suite test_views_acl.py (#20887)", "Remove code duplication in the test suite test_views_acl.py (#20887)"], "original_ll": -4.794921398162842, "sampled_ll": -5.237403869628906, "all_perturbed_sampled_ll": [-5.237403869628906, -5.237403869628906, -5.237403869628906, -5.237403869628906, -5.237403869628906, -5.237403869628906, -5.237403869628906, -5.237403869628906, -5.237403869628906, -5.237403869628906], "all_perturbed_original_ll": [-4.794921398162842, -4.794921398162842, -4.794921398162842, -4.794921398162842, -4.794921398162842, -4.794921398162842, -4.794921398162842, -4.794921398162842, -4.794921398162842, -4.794921398162842], "perturbed_sampled_ll": -5.237403869628906, "perturbed_original_ll": -4.794921398162842, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Mask secrets in stdout for 'airflow tasks test' (#24362) A stdout redirector is implemented to mask all values to stdout and redact any secrets in it with the secrets masker. This redirector is applied to the 'airflow.task' logger. Co-authored-by: Alex Kennedy <alex.kennedy@astronomer.io>", "sampled": "Mask secrets in stdout for 'airflow tasks test' (#24362) A stdout redirector is implemented to mask all values to stdout in these tests. (#23992) Initial support for \"Airflow tasks test\" when using 'sprint task' and test_task (#24162)\n\nFixed \"airflow_task.\"py error message when testing", "perturbed_sampled": ["Mask secrets in stdout for 'airflow tasks test' (#24362) A stdout file will probably need to be implemented to mask all values to avoid any data leaks to these tests. (#23992) Initial support for \"Airflow tasks test\" when using 'sprint task' and avoid \"airflow_task.\"py error message when testing", "Mask secrets in stdout for 'airflow tasks test'. (#24362) A stdout redirector is implemented to mask all values to stdout in these tests. (#23992) Initial version of \"Airflow tasks test\" when using 'sprint task' . (#24162)\n\nFixed \"airflow_task.\"py error message when testing", "Mask secrets in stdout for 'airflow tasks test' (#24362) A stdout redirector is implemented to mask input to stdout in these tests. (#23992) Initial ized \"Airflow tasks test\" when using 'sprint task' and test_task (#24162)\n\nFixed \"airflow_task.\"py error , when testing", "Mask secrets in tests using 'airflow tasks test' (#24362) A stdout redirector is implemented to mask all values to stdout in these tests. This should greatly increase the support for \"airflow tasks test\" when using 'sprint task' and test_task (#24162)\n\nFixed \"airflow_task.\"py error message when testing", "Mask secrets in mock tasks for 'airflow tasks test' (#24362) A stdout redirector is implemented to mask all values to stdout in these tests. (#23992) Initial support for \"airflow tasks test\" for tasks such as 'sprint task' and test_task (#24162)\n\nFixed \"airflow_task.\"py error message when testing", "Mask secrets in stdout for 'sprint task test' . A stdout redirector is implemented to mask all secrets in stdout in these tests. (#23992) Initial support for \"Airflow tasks test\" when using 'sprint task' and test_task (#24162)\n\nFixed \"airflow_task.\"py error message when testing", "Mask secrets in stdout for 'airflow tasks test'. A stdout redirector is implemented to write all values to stdout in these tests. (#23992) Initial support for \"Airflow tasks test\" when using 'sprint task' and test_task . Require no additional error message when testing", "Mask secrets in stdout for 'airflow tasks test' (#24362) A stdout masking plugin has been implemented to mask all values to stdout in these tests. (#23992) Initial support for \"Airflow tasks test\" using 'sprint task' and test_task (#24162)\n\nFixed \"airflow_task.\"py to use correct error structure when testing", "Mask secrets in new tests using 'airflow tasks test' (#24362) A stdout redirector is implemented to route all values to stdout in these tests. (#23992) Initial support for \"airflow tasks test\" when using 'sprint task' and test_task (#24162)\n\nFixed \"airflow_task.\"py error message when testing", "Mask secrets in stdout when testing 'Airflow tasks test' (#24362) A stdout redirector is implemented to mask all values to stdout in these tests. Add support for \"Airflow tasks test\" when testing 'airflow tasks task' and test_task (#24162)\n\nFixed \"airflow_task.\"py error message when testing"], "perturbed_original": ["Mask secrets in stdout for 'airflow .task' (#24362) A stdout redirector is implemented to mask all secrets found in stdout and mask any hidden secrets in it with the secrets masker. This redirector is applied to the 'airflow.task' logger. Co-authored-by: Alex Kennedy <alex.kennedy@astronomer.io>", "Mask secrets in stdout for 'airflow tasks test' (#24362) A stdout redirector is implemented to redirect all values to stdout and redact any secrets in stdout by the secrets masker. This redirector is applied to an 'airflow.task' logger. Co-authored-by: Alex Kennedy <alex.kennedy@astronomer.io>", "Mask secrets in stdout in tasks test' (#24362) A redirector is implemented to display all values to stdout and redact any secrets in it with the secrets masker. This redirector is applied to the 'airflow.task' logger. Co-authored-by: Alex Kennedy <alex.kennedy@astronomer.io>", "Mask secrets in stdout for 'airflow tasks test' (#24362) A stdout masker is implemented to mask all values to stdout . Mask any secrets in it with the secrets masker. This is applied to the 'airflow.task' logger. Co-authored-by: Alex Kennedy <alex.kennedy@astronomer.io>", "Mask secrets in logs in 'airflow tasks test' (#24362) A stdout redirector is implemented to mask all values to stdout and redact any secrets written with a masker. This redirector is applied to the 'airflow.task' logger. Co-authored-by: Alex Kennedy <alex.kennedy@astronomer.io>", "Mask ing stdout for 'airflow tasks test' (#24362) A stdout redirector is implemented to mask all values sent in stdout and redact any secrets in it with the code below. This redirector is applied to the 'airflow.task' logger. Co-authored-by: Alex Kennedy <alex.kennedy@astronomer.io>", "Mask secrets in stdout for tasks test' (#24362) A stdout redirector is implemented to mask all values in it and redact any secrets in it with the secrets masker. This redirector is applied to the 'airflow.task' test case. By Alex Kennedy <alex.kennedy@astronomer.io>", "Mask secrets in stdout for 'airflow tasks test' (#24362) A stdout redirector used to mask all values to stdout and redact any secrets written with the secrets masker. This redirector is applied to the flow tasks test script. Co-authored-by: Alex Kennedy <alex.kennedy@astronomer.io>", "Mask secrets in stdout for 'airflow tasks test' (#24362) : a redirector is implemented to mask all values to stdout and to hide or edit the secrets in it with the secrets masker. This redirector is applied to the 'airflow.task' logger. It\u2019s written in R and is maintained by Alex Kennedy <alex.kennedy@astronomer.io>", "Mask secrets in stdout for 'airflow .task' Logger: (#24362) A stdout redirector is implemented to mask all values in stdout and redact any secrets in it with the secrets masker. This redirector is used only in the 'airflow.task' logger. Co-authored-by: Alex Kennedy <alex.kennedy@astronomer.io>"], "original_ll": -4.032771110534668, "sampled_ll": -4.027977466583252, "all_perturbed_sampled_ll": [-4.42337703704834, -4.0629448890686035, -4.411551475524902, -4.225921630859375, -4.0268731117248535, -4.30107307434082, -4.501154899597168, -4.033581733703613, -4.079652309417725, -4.037619590759277], "all_perturbed_original_ll": [-3.7694859504699707, -4.04139518737793, -4.165749549865723, -4.267463684082031, -4.169676303863525, -4.092154502868652, -4.2990241050720215, -4.240370273590088, -4.375673294067383, -3.8079710006713867], "perturbed_sampled_ll": -4.210374975204468, "perturbed_original_ll": -4.122896385192871, "perturbed_sampled_ll_std": 0.17676535955719372, "perturbed_original_ll_std": 0.19112983911668616}, {"original": "Add default_deferrable config (#31712)", "sampled": "Add default_deferrable config (#31712)To", "perturbed_sampled": ["Add default_deferrable config (#31712)To", "Add default_deferrable config (#31712)To", "Add default_deferrable config (#31712)To", "Add default_deferrable config (#31712)To", "Add default_deferrable config (#31712)To", "Add default_deferrable config (#31712)To", "Add default_deferrable config (#31712)To", "Add default_deferrable config (#31712)To", "Add default_deferrable config (#31712)To", "Add default_deferrable config (#31712)To"], "perturbed_original": ["Add default_deferrable config (#31712)", "Add default_deferrable config (#31712)", "Add default_deferrable config (#31712)", "Add default_deferrable config (#31712)", "Add default_deferrable config (#31712)", "Add default_deferrable config (#31712)", "Add default_deferrable config (#31712)", "Add default_deferrable config (#31712)", "Add default_deferrable config (#31712)", "Add default_deferrable config (#31712)"], "original_ll": -6.324667930603027, "sampled_ll": -7.101391792297363, "all_perturbed_sampled_ll": [-7.101391792297363, -7.101391792297363, -7.101391792297363, -7.101391792297363, -7.101391792297363, -7.101391792297363, -7.101391792297363, -7.101391792297363, -7.101391792297363, -7.101391792297363], "all_perturbed_original_ll": [-6.324667930603027, -6.324667930603027, -6.324667930603027, -6.324667930603027, -6.324667930603027, -6.324667930603027, -6.324667930603027, -6.324667930603027, -6.324667930603027, -6.324667930603027], "perturbed_sampled_ll": -7.101391792297363, "perturbed_original_ll": -6.324667930603027, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Fix changelog spelling (#22926)", "sampled": "Fix changelog spelling (#22926)I", "perturbed_sampled": ["Fix changelog spelling (#22926)I", "Fix changelog spelling (#22926)I", "Fix changelog spelling (#22926)I", "Fix changelog spelling (#22926)I", "Fix changelog spelling (#22926)I", "Fix changelog spelling (#22926)I", "Fix changelog spelling (#22926)I", "Fix changelog spelling (#22926)I", "Fix changelog spelling (#22926)I", "Fix changelog spelling (#22926)I"], "perturbed_original": ["Fix changelog spelling (#22926)", "Fix changelog spelling (#22926)", "Fix changelog spelling (#22926)", "Fix changelog spelling (#22926)", "Fix changelog spelling (#22926)", "Fix changelog spelling (#22926)", "Fix changelog spelling (#22926)", "Fix changelog spelling (#22926)", "Fix changelog spelling (#22926)", "Fix changelog spelling (#22926)"], "original_ll": -6.1523118019104, "sampled_ll": -7.116081237792969, "all_perturbed_sampled_ll": [-7.116081237792969, -7.116081237792969, -7.116081237792969, -7.116081237792969, -7.116081237792969, -7.116081237792969, -7.116081237792969, -7.116081237792969, -7.116081237792969, -7.116081237792969], "all_perturbed_original_ll": [-6.1523118019104, -6.1523118019104, -6.1523118019104, -6.1523118019104, -6.1523118019104, -6.1523118019104, -6.1523118019104, -6.1523118019104, -6.1523118019104, -6.1523118019104], "perturbed_sampled_ll": -7.116081237792969, "perturbed_original_ll": -6.1523118019104, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "SagemakerProcessingOperator stopped honoring `existing_jobs_found` (#27456)", "sampled": "SagemakerProcessingOperator stopped honoring `existing_jobs_found` (#27456)The", "perturbed_sampled": ["SagemakerProcessingOperator stopped honoring `existing_jobs_found` (#27456)The", "SagemakerProcessingOperator stopped honoring `existing_jobs_found` (#27456)The", "SagemakerProcessingOperator stopped honoring `existing_jobs_found` (#27456)The", "SagemakerProcessingOperator stopped honoring `existing_jobs_found` (#27456)The", "SagemakerProcessingOperator stopped honoring `existing_jobs_found` (#27456)The", "SagemakerProcessingOperator stopped honoring `existing_jobs_found` (#27456)The", "SagemakerProcessingOperator stopped honoring `existing_jobs_found` (#27456)The", "SagemakerProcessingOperator stopped honoring `existing_jobs_found` (#27456)The", "SagemakerProcessingOperator stopped honoring `existing_jobs_found` (#27456)The", "SagemakerProcessingOperator stopped honoring `existing_jobs_found` (#27456)The"], "perturbed_original": ["SagemakerProcessingOperator stopped honoring `existing_jobs_found` (#27456)", "SagemakerProcessingOperator stopped honoring `existing_jobs_found` (#27456)", "SagemakerProcessingOperator stopped honoring `existing_jobs_found` (#27456)", "SagemakerProcessingOperator stopped honoring `existing_jobs_found` (#27456)", "SagemakerProcessingOperator stopped honoring `existing_jobs_found` (#27456)", "SagemakerProcessingOperator stopped honoring `existing_jobs_found` (#27456)", "SagemakerProcessingOperator stopped honoring `existing_jobs_found` (#27456)", "SagemakerProcessingOperator stopped honoring `existing_jobs_found` (#27456)", "SagemakerProcessingOperator stopped honoring `existing_jobs_found` (#27456)", "SagemakerProcessingOperator stopped honoring `existing_jobs_found` (#27456)"], "original_ll": -6.362898349761963, "sampled_ll": -6.683621883392334, "all_perturbed_sampled_ll": [-6.683621883392334, -6.683621883392334, -6.683621883392334, -6.683621883392334, -6.683621883392334, -6.683621883392334, -6.683621883392334, -6.683621883392334, -6.683621883392334, -6.683621883392334], "all_perturbed_original_ll": [-6.362898349761963, -6.362898349761963, -6.362898349761963, -6.362898349761963, -6.362898349761963, -6.362898349761963, -6.362898349761963, -6.362898349761963, -6.362898349761963, -6.362898349761963], "perturbed_sampled_ll": -6.683621883392334, "perturbed_original_ll": -6.362898349761963, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Update .readthedocs.yml (#23903) String instead of Int see https://docs.readthedocs.io/en/stable/config-file/v2.html", "sampled": "Update .readthedocs.yml (#23903) String instead of Int see https://docs.readthedocs.io/en/latest/scripting/.\n\n.", "perturbed_sampled": ["Update .readthedocs.yml (#23903) String instead of Int see https://docs.readthedocs.io/en/latest/scripting/.\n\n.", "Update .readthedocs.yml (#23903) String instead of Int see https://docs.readthedocs.io/en/latest/scripting/.\n\n.", "Update .readthedocs.yml (#23903) String instead of Int see https://docs.readthedocs.io/en/latest/scripting/.\n\n.", "Update .readthedocs.yml (#23903) String instead of Int see https://docs.readthedocs.io/en/latest/scripting/.\n\n.", "Update .readthedocs.yml (#23903) String instead of Int see https://docs.readthedocs.io/en/latest/scripting/.\n\n.", "Update .readthedocs.yml (#23903) String instead of Int see https://docs.readthedocs.io/en/latest/scripting/.\n\n.", "Update .readthedocs.yml (#23903) String instead of Int see https://docs.readthedocs.io/en/latest/scripting/.\n\n.", "Update .readthedocs.yml (#23903) String instead of Int see https://docs.readthedocs.io/en/latest/scripting/.\n\n.", "Update .readthedocs.yml (#23903) String instead of Int see https://docs.readthedocs.io/en/latest/scripting/.\n\n.", "Update .readthedocs.yml (#23903) String instead of Int see https://docs.readthedocs.io/en/latest/scripting/.\n\n."], "perturbed_original": ["Update .readthedocs.yml (#23903) String instead of Int see https://docs.readthedocs.io/en/stable/config-file/v2.html", "Update .readthedocs.yml (#23903) String instead of Int see https://docs.readthedocs.io/en/stable/config-file/v2.html", "Update .readthedocs.yml (#23903) String instead of Int see https://docs.readthedocs.io/en/stable/config-file/v2.html", "Update .readthedocs.yml (#23903) String instead of Int see https://docs.readthedocs.io/en/stable/config-file/v2.html", "Update .readthedocs.yml (#23903) String instead of Int see https://docs.readthedocs.io/en/stable/config-file/v2.html", "Update .readthedocs.yml (#23903) String instead of Int see https://docs.readthedocs.io/en/stable/config-file/v2.html", "Update .readthedocs.yml (#23903) String instead of Int see https://docs.readthedocs.io/en/stable/config-file/v2.html", "Update .readthedocs.yml (#23903) String instead of Int see https://docs.readthedocs.io/en/stable/config-file/v2.html", "Update .readthedocs.yml (#23903) String instead of Int see https://docs.readthedocs.io/en/stable/config-file/v2.html", "Update .readthedocs.yml (#23903) String instead of Int see https://docs.readthedocs.io/en/stable/config-file/v2.html"], "original_ll": -3.598766565322876, "sampled_ll": -3.0668301582336426, "all_perturbed_sampled_ll": [-3.0668301582336426, -3.0668301582336426, -3.0668301582336426, -3.0668301582336426, -3.0668301582336426, -3.0668301582336426, -3.0668301582336426, -3.0668301582336426, -3.0668301582336426, -3.0668301582336426], "all_perturbed_original_ll": [-3.598766565322876, -3.598766565322876, -3.598766565322876, -3.598766565322876, -3.598766565322876, -3.598766565322876, -3.598766565322876, -3.598766565322876, -3.598766565322876, -3.598766565322876], "perturbed_sampled_ll": -3.0668301582336426, "perturbed_original_ll": -3.598766565322876, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Added Snowflake provider to the Docker image (#29171)", "sampled": "Added Snowflake provider to the Docker image (#29171)I've", "perturbed_sampled": ["Added Snowflake provider to the Docker image (#29171)I've", "Added Snowflake provider to the Docker image (#29171)I've", "Added Snowflake provider to the Docker image (#29171)I've", "Added Snowflake provider to the Docker image (#29171)I've", "Added Snowflake provider to the Docker image (#29171)I've", "Added Snowflake provider to the Docker image (#29171)I've", "Added Snowflake provider to the Docker image (#29171)I've", "Added Snowflake provider to the Docker image (#29171)I've", "Added Snowflake provider to the Docker image (#29171)I've", "Added Snowflake provider to the Docker image (#29171)I've"], "perturbed_original": ["Added Snowflake provider to the Docker image (#29171)", "Added Snowflake provider to the Docker image (#29171)", "Added Snowflake provider to the Docker image (#29171)", "Added Snowflake provider to the Docker image (#29171)", "Added Snowflake provider to the Docker image (#29171)", "Added Snowflake provider to the Docker image (#29171)", "Added Snowflake provider to the Docker image (#29171)", "Added Snowflake provider to the Docker image (#29171)", "Added Snowflake provider to the Docker image (#29171)", "Added Snowflake provider to the Docker image (#29171)"], "original_ll": -5.546460151672363, "sampled_ll": -6.0155792236328125, "all_perturbed_sampled_ll": [-6.0155792236328125, -6.0155792236328125, -6.0155792236328125, -6.0155792236328125, -6.0155792236328125, -6.0155792236328125, -6.0155792236328125, -6.0155792236328125, -6.0155792236328125, -6.0155792236328125], "all_perturbed_original_ll": [-5.546460151672363, -5.546460151672363, -5.546460151672363, -5.546460151672363, -5.546460151672363, -5.546460151672363, -5.546460151672363, -5.546460151672363, -5.546460151672363, -5.546460151672363], "perturbed_sampled_ll": -6.0155792236328125, "perturbed_original_ll": -5.546460151672363, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "More strong typed state conversion (#32521)", "sampled": "More strong typed state conversion (#32521)Image", "perturbed_sampled": ["More strong typed state conversion (#32521)Image", "More strong typed state conversion (#32521)Image", "More strong typed state conversion (#32521)Image", "More strong typed state conversion (#32521)Image", "More strong typed state conversion (#32521)Image", "More strong typed state conversion (#32521)Image", "More strong typed state conversion (#32521)Image", "More strong typed state conversion (#32521)Image", "More strong typed state conversion (#32521)Image", "More strong typed state conversion (#32521)Image"], "perturbed_original": ["More strong typed state conversion (#32521)", "More strong typed state conversion (#32521)", "More strong typed state conversion (#32521)", "More strong typed state conversion (#32521)", "More strong typed state conversion (#32521)", "More strong typed state conversion (#32521)", "More strong typed state conversion (#32521)", "More strong typed state conversion (#32521)", "More strong typed state conversion (#32521)", "More strong typed state conversion (#32521)"], "original_ll": -8.130390167236328, "sampled_ll": -9.1141939163208, "all_perturbed_sampled_ll": [-9.1141939163208, -9.1141939163208, -9.1141939163208, -9.1141939163208, -9.1141939163208, -9.1141939163208, -9.1141939163208, -9.1141939163208, -9.1141939163208, -9.1141939163208], "all_perturbed_original_ll": [-8.130390167236328, -8.130390167236328, -8.130390167236328, -8.130390167236328, -8.130390167236328, -8.130390167236328, -8.130390167236328, -8.130390167236328, -8.130390167236328, -8.130390167236328], "perturbed_sampled_ll": -9.1141939163208, "perturbed_original_ll": -8.130390167236328, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Fix type of upgrade_to_newer_dependencies parameter (#22597)", "sampled": "Fix type of upgrade_to_newer_dependencies parameter (#22597)I've", "perturbed_sampled": ["Fix type of upgrade_to_newer_dependencies parameter (#22597)I've", "Fix type of upgrade_to_newer_dependencies parameter (#22597)I've", "Fix type of upgrade_to_newer_dependencies parameter (#22597)I've", "Fix type of upgrade_to_newer_dependencies parameter (#22597)I've", "Fix type of upgrade_to_newer_dependencies parameter (#22597)I've", "Fix type of upgrade_to_newer_dependencies parameter (#22597)I've", "Fix type of upgrade_to_newer_dependencies parameter (#22597)I've", "Fix type of upgrade_to_newer_dependencies parameter (#22597)I've", "Fix type of upgrade_to_newer_dependencies parameter (#22597)I've", "Fix type of upgrade_to_newer_dependencies parameter (#22597)I've"], "perturbed_original": ["Fix type of upgrade_to_newer_dependencies parameter (#22597)", "Fix type of upgrade_to_newer_dependencies parameter (#22597)", "Fix type of upgrade_to_newer_dependencies parameter (#22597)", "Fix type of upgrade_to_newer_dependencies parameter (#22597)", "Fix type of upgrade_to_newer_dependencies parameter (#22597)", "Fix type of upgrade_to_newer_dependencies parameter (#22597)", "Fix type of upgrade_to_newer_dependencies parameter (#22597)", "Fix type of upgrade_to_newer_dependencies parameter (#22597)", "Fix type of upgrade_to_newer_dependencies parameter (#22597)", "Fix type of upgrade_to_newer_dependencies parameter (#22597)"], "original_ll": -5.121776103973389, "sampled_ll": -5.598250389099121, "all_perturbed_sampled_ll": [-5.598250389099121, -5.598250389099121, -5.598250389099121, -5.598250389099121, -5.598250389099121, -5.598250389099121, -5.598250389099121, -5.598250389099121, -5.598250389099121, -5.598250389099121], "all_perturbed_original_ll": [-5.121776103973389, -5.121776103973389, -5.121776103973389, -5.121776103973389, -5.121776103973389, -5.121776103973389, -5.121776103973389, -5.121776103973389, -5.121776103973389, -5.121776103973389], "perturbed_sampled_ll": -5.598250389099121, "perturbed_original_ll": -5.121776103973389, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Enable multiple query execution in RedshiftDataOperator (#25619) Enable RedshiftDataOperator to execute a batch of SQL using batch_execute_statement boto3 API.", "sampled": "Enable multiple query execution in RedshiftDataOperator (#25619) Enable RedshiftDataOperator to execute a batch of SQL using batch_execute_with_transparent (#26019) enable", "perturbed_sampled": ["Enable multiple query execution in RedshiftDataOperator . Use RedshiftDataOperator to execute a batch of SQL using batch_execute_with_transparent (#26019) enable", "Enable multiple query execution in RedshiftDataOperator (#25619) Enable RedshiftDataOperator to execute multiple queries using a transparent syntax of SQL using batch_execute_with_transparent (#26019) enable", "Enable multiple query execution in RedshiftDataOperator (#25619) Enable RedshiftDataOperator to execute a batch of queries with batch_execute_with_transparent (#26019) enable", "Enable multiple query execution in RedshiftDataOperator (#25619) Enable RedshiftDataOperator to execute a single SQL using batch_execute_with_transparent (#26019) enable", "Enable multiple query execution on the same row using the RedshiftDataOperator (#25619) Enable RedshiftDataOperator to execute a batch of SQL using batch_execute_with_transparent (#26019) enable", "Enable multiple query execution in Redshift. Enable RedshiftDataOperator to execute a batch of SQL using batch_execute_with_transparent (#26019) enable", "Enable multiple query execution in RedshiftDataOperator (#25619) enable the ability to execute a batch of SQL using batch_execute_with_transparent (#26019) enable", "Enable multiple query execution in RedshiftDataOperator (#25619) Enable RedshiftDataOperator to execute a batch of queries with the new setting batch_execute_with_transparent (#26019) enable", "Enable multiple query execution in RedshiftDataOperator (#25619) Enable RedshiftDataOperator to execute multiple executions of SQL using batch_execute_with_transparent (#26019) enable", "Enable multiple query execution in RedshiftDataOperator (#25619) Enable RedshiftDataOperator to execute a batch of SQL using batch_execute_with_transparent (#26019) enable"], "perturbed_original": ["Enable multiple query execution in RedshiftDataOperator (#25619) Enable RedshiftDataOperator to execute a batch of SQL queries via boto3 API.", "Enable multiple query execution in RedshiftDataOperator (#25619) Enable RedshiftDataOperator to execute a multi-query/statement SQL using batch_execute_statement boto3 API.", "Enable multiple query execution in RedshiftDataOperator . The RedshiftDataOperator to execute a batch of SQL using batch_execute_statement boto3 API.", "Enable multiple query execution in RedshiftDataOperator (#25619) Enable RedshiftDataOperator to execute a batch of SQL using the API.", "Enable multiple query execution in RedshiftDataOperator (#25619) Enable RedshiftDataOperator to execute multiple statements of SQL using batch_execute_statement boto3 API.", "Configure batch storage query execution in RedshiftDataOperator (#25619) Enable RedshiftDataOperator to execute a batch of SQL using batch_execute_statement boto3 API.", "Enable multiple query execution in RedshiftDataOperator . Allow RedshiftDataOperator to execute a batch of SQL using batch_execute_statement boto3 API.", "Enable multiple query execution in RedshiftDataOperator ! Use RedshiftDataOperator to execute a batch of SQL using batch_execute_statement boto3 API.", "Enable multiple SQL statements in RedshiftDataOperator (#25619) Enable RedshiftDataOperator to execute a batch of SQL using batch_execute_statement boto3 API.", "Enable multiple query execution in RedshiftDataOperator (#25619) Enable RedshiftDataOperator to execute a batch of SQL using batch_execute_statement boto3 API."], "original_ll": -4.729500770568848, "sampled_ll": -4.102941989898682, "all_perturbed_sampled_ll": [-4.2266435623168945, -4.153327941894531, -4.038767337799072, -4.290972709655762, -3.7777585983276367, -4.5844340324401855, -4.31797456741333, -4.0128655433654785, -4.233086109161377, -4.102941989898682], "all_perturbed_original_ll": [-4.6182098388671875, -4.79291296005249, -4.61622953414917, -4.41841459274292, -4.82050895690918, -4.748973846435547, -4.507749557495117, -4.592822551727295, -4.665100574493408, -4.729500770568848], "perturbed_sampled_ll": -4.173877239227295, "perturbed_original_ll": -4.651042318344116, "perturbed_sampled_ll_std": 0.20392786894496653, "perturbed_original_ll_std": 0.12046496791935314}, {"original": "Fix RTIF test against the apply-expand (#22121)", "sampled": "Fix RTIF test against the apply-expand (#22121)About", "perturbed_sampled": ["Fix RTIF test against the apply-expand (#22121)About", "Fix RTIF test against the apply-expand (#22121)About", "Fix RTIF test against the apply-expand (#22121)About", "Fix RTIF test against the apply-expand (#22121)About", "Fix RTIF test against the apply-expand (#22121)About", "Fix RTIF test against the apply-expand (#22121)About", "Fix RTIF test against the apply-expand (#22121)About", "Fix RTIF test against the apply-expand (#22121)About", "Fix RTIF test against the apply-expand (#22121)About", "Fix RTIF test against the apply-expand (#22121)About"], "perturbed_original": ["Fix RTIF test against the apply-expand (#22121)", "Fix RTIF test against the apply-expand (#22121)", "Fix RTIF test against the apply-expand (#22121)", "Fix RTIF test against the apply-expand (#22121)", "Fix RTIF test against the apply-expand (#22121)", "Fix RTIF test against the apply-expand (#22121)", "Fix RTIF test against the apply-expand (#22121)", "Fix RTIF test against the apply-expand (#22121)", "Fix RTIF test against the apply-expand (#22121)", "Fix RTIF test against the apply-expand (#22121)"], "original_ll": -6.275001049041748, "sampled_ll": -7.149346828460693, "all_perturbed_sampled_ll": [-7.149346828460693, -7.149346828460693, -7.149346828460693, -7.149346828460693, -7.149346828460693, -7.149346828460693, -7.149346828460693, -7.149346828460693, -7.149346828460693, -7.149346828460693], "all_perturbed_original_ll": [-6.275001049041748, -6.275001049041748, -6.275001049041748, -6.275001049041748, -6.275001049041748, -6.275001049041748, -6.275001049041748, -6.275001049041748, -6.275001049041748, -6.275001049041748], "perturbed_sampled_ll": -7.149346828460693, "perturbed_original_ll": -6.275001049041748, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Update build.rst for docker compose and helm chart (#27677)", "sampled": "Update build.rst for docker compose and helm chart (#27677)A", "perturbed_sampled": ["Update build.rst for docker compose and helm chart (#27677)A", "Update build.rst for docker compose and helm chart (#27677)A", "Update build.rst for docker compose and helm chart (#27677)A", "Update build.rst for docker compose and helm chart (#27677)A", "Update build.rst for docker compose and helm chart (#27677)A", "Update build.rst for docker compose and helm chart (#27677)A", "Update build.rst for docker compose and helm chart (#27677)A", "Update build.rst for docker compose and helm chart (#27677)A", "Update build.rst for docker compose and helm chart (#27677)A", "Update build.rst for docker compose and helm chart (#27677)A"], "perturbed_original": ["Update build.rst for docker compose and helm chart (#27677)", "Update build.rst for docker compose and helm chart (#27677)", "Update build.rst for docker compose and helm chart (#27677)", "Update build.rst for docker compose and helm chart (#27677)", "Update build.rst for docker compose and helm chart (#27677)", "Update build.rst for docker compose and helm chart (#27677)", "Update build.rst for docker compose and helm chart (#27677)", "Update build.rst for docker compose and helm chart (#27677)", "Update build.rst for docker compose and helm chart (#27677)", "Update build.rst for docker compose and helm chart (#27677)"], "original_ll": -6.340100288391113, "sampled_ll": -6.854395389556885, "all_perturbed_sampled_ll": [-6.854395389556885, -6.854395389556885, -6.854395389556885, -6.854395389556885, -6.854395389556885, -6.854395389556885, -6.854395389556885, -6.854395389556885, -6.854395389556885, -6.854395389556885], "all_perturbed_original_ll": [-6.340100288391113, -6.340100288391113, -6.340100288391113, -6.340100288391113, -6.340100288391113, -6.340100288391113, -6.340100288391113, -6.340100288391113, -6.340100288391113, -6.340100288391113], "perturbed_sampled_ll": -6.854395389556885, "perturbed_original_ll": -6.340100288391113, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Update ``README_RELEASE_PROVIDER_PACKAGES.md`` (#28939)", "sampled": "Update ``README_RELEASE_PROVIDER_PACKAGES.md`` (#28939)FULL_SOURCE", "perturbed_sampled": ["Update ``README_RELEASE_PROVIDER_PACKAGES.md`` (#28939)FULL_SOURCE", "Update ``README_RELEASE_PROVIDER_PACKAGES.md`` (#28939)FULL_SOURCE", "Update ``README_RELEASE_PROVIDER_PACKAGES.md`` (#28939)FULL_SOURCE", "Update ``README_RELEASE_PROVIDER_PACKAGES.md`` (#28939)FULL_SOURCE", "Update ``README_RELEASE_PROVIDER_PACKAGES.md`` (#28939)FULL_SOURCE", "Update ``README_RELEASE_PROVIDER_PACKAGES.md`` (#28939)FULL_SOURCE", "Update ``README_RELEASE_PROVIDER_PACKAGES.md`` (#28939)FULL_SOURCE", "Update ``README_RELEASE_PROVIDER_PACKAGES.md`` (#28939)FULL_SOURCE", "Update ``README_RELEASE_PROVIDER_PACKAGES.md`` (#28939)FULL_SOURCE", "Update ``README_RELEASE_PROVIDER_PACKAGES.md`` (#28939)FULL_SOURCE"], "perturbed_original": ["Update ``README_RELEASE_PROVIDER_PACKAGES.md`` (#28939)", "Update ``README_RELEASE_PROVIDER_PACKAGES.md`` (#28939)", "Update ``README_RELEASE_PROVIDER_PACKAGES.md`` (#28939)", "Update ``README_RELEASE_PROVIDER_PACKAGES.md`` (#28939)", "Update ``README_RELEASE_PROVIDER_PACKAGES.md`` (#28939)", "Update ``README_RELEASE_PROVIDER_PACKAGES.md`` (#28939)", "Update ``README_RELEASE_PROVIDER_PACKAGES.md`` (#28939)", "Update ``README_RELEASE_PROVIDER_PACKAGES.md`` (#28939)", "Update ``README_RELEASE_PROVIDER_PACKAGES.md`` (#28939)", "Update ``README_RELEASE_PROVIDER_PACKAGES.md`` (#28939)"], "original_ll": -4.0301008224487305, "sampled_ll": -4.357109546661377, "all_perturbed_sampled_ll": [-4.357109546661377, -4.357109546661377, -4.357109546661377, -4.357109546661377, -4.357109546661377, -4.357109546661377, -4.357109546661377, -4.357109546661377, -4.357109546661377, -4.357109546661377], "all_perturbed_original_ll": [-4.0301008224487305, -4.0301008224487305, -4.0301008224487305, -4.0301008224487305, -4.0301008224487305, -4.0301008224487305, -4.0301008224487305, -4.0301008224487305, -4.0301008224487305, -4.0301008224487305], "perturbed_sampled_ll": -4.357109546661377, "perturbed_original_ll": -4.0301008224487305, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Remove is_setup flag from TaskInstance (#32997) I don't feel this column is that needed. It is only used in one place and only for minor performance gain, it seems. This may eventually be useful, but it may be a good idea to delay committing to adding a column. Migrating the TaskInstance table is pretty expensive...", "sampled": "Remove is_setup flag from TaskInstance (#32997) I don't feel this column is that needed. It is only used in one place and I have nothing to do with anything in that table unless I need it\n\n\u2022 Cleanup of empty tables (#32439) A column here or there is not usually going to be a bug that", "perturbed_sampled": ["Remove d from TaskInstance (#32997) I don't feel this column is needed. It is only in one place and I have nothing to do with anything in that table unless I need it\n\n\u2022 Cleanup of empty tables (#32439) One or two empty columns here or there is not usually going to be a bug that", "\u2022 Remove the \"Move to\" flag from TaskInstance (#32997) I don't feel this column is that needed. It is only used once, no other place and I am not going to do with anything with this table unless I need it\n\n\u2022 Cleanup of empty tables (#32439) A column here or there is not usually going to be a bug that", "Remove is_setup flag from TaskInstance (#32997) I don't feel like that is very necessary. It is only used in a single table and I have nothing to do with anything in that table unless I need it\n\n\u2022 Cleanup of empty tables (#32439) A column here or there is not usually going to be a bug that", "Remove is_setup flag from table (#32997) I don't feel this column is that needed. It is only in one place and I have nothing to do with it. I can't make a clean up for that table unless I need it\n\n\u2022 Cleanup of empty tables (#32439) A column here or there is not usually going to be needed other than that", "Remove is_setup flag from TaskInstance (#32997) I don't feel this column is that needed. It is only used in one place and does not have to do with anything in the program unless I need it\n\n\u2022 Cleanup of empty tables (#32439) A clean-up or there is not usually going to be a bug that", "Remove column from TaskInstance (#32997) I don't feel this column is that needed. Since it's only used in one place I have nothing to do with anything in that table unless I need it\n\n\u2022 Cleanup of empty tables (#32439) A column here or there is not usually necessary. It could be a bug that", "Remove is_setup flag from TaskInstance (#32997) I don't feel this column is important here. It is only used in one place and I have nothing to do with anything in that table unless I need it\n\n\u2022 Cleanup of empty tables (#32439) This seems irrelevant here or there is not going to be a bug that", "Remove table from TaskInstance (#32997) I don't feel this column is that needed. It is only in one place and I have nothing to do with anything in that table unless I want to. Cleanup of empty tables (#32439) A column here or there is not even useful, I'm going to be a bug that", "Remove is_setup flag from TaskInstance (#32997) I don't think this column is that needed. It is only used in one place and I have nothing to do with anything in that table unless I need it\n\n\u2022 Cleanup of src (#32439) one here or there is not usually going to be a bug that", "Remove is_setup flag from TaskInstance (#32997) I don't feel this column is that needed. It is only used in the table and I have nothing to do with anything in that table unless I have to edit it\n\n\u2022 Cleanup of empty tables (#32439) A table doesn't need this column or there is not usually going to be anything in that"], "perturbed_original": ["the Task flag from TaskInstance (#32997) I don't feel this column is that needed. It is only used when there are jobs in place and only for data gain, it seems. This may eventually be useful, but it may be a good idea to delay that part over while adding a column. Migrating the TaskInstance table is pretty expensive...", "Remove is_setup flag from task name! I don't feel this column is that needed. It is only that one . This should be added only for minor performance gain, it seems. This may eventually be useful, but it may be a good idea to delay that before adding a column. Migrating the TaskInstance table is pretty expensive...", "Remove is_setup flag from TaskInstance column. I don't feel this column is needed. It 's only used in one place and only for minor performance gain, it seems. This may eventually be removed, but it may be a good idea to delay committing to adding a column. Migrating the TaskInstance table is pretty expensive...", "Remove is_setup flag in TaskInstance (#32997) I don't feel like this is that needed. It is only used in a tiny tiny fraction of tasks, and only for minor performance gain, it seems. This may eventually be useful, but might be a good idea to delay committing to adding a column. Migrating the TaskInstance table is pretty expensive...", "Remove is_setup flag from a T-Instance. I don't think this column is that needed. It is only used on a few occasions, it is unlikely to go out of place and only for minor performance issues it seems. This may eventually be useful, but it may be a good idea to delay committing to adding a column. Migrating the TaskInstance table is pretty expensive...", "Remove is_setup flag from TaskInstance (#32997) I don't feel this column is that needed. It 's only used in one place and only for minor performance gain, it seems. It may eventually be useful, but it might be a good idea to eliminate it, as opposed to adding a column. Migrating the TaskInstance table is pretty expensive...", "Remove is_setup flag in task instance (#32997) I don't think this column is that needed. It is only used in one place and only for minor performance gain, it seems. This may eventually be useful, but it may be a useful reason to delay committing to adding this column as well. Migrating the TaskInstance table is pretty expensive...", "Remove is_setup flag in it (#32997) I don't really think this column is that needed. It is only used in one place and only for performance/stability gain, it seems. This may eventually be useful, but it might be a good idea to delay committing to adding a column. Migrating the TaskInstance table is pretty expensive...", "Remove is_setup from TaskInstance (#32997) I don't think the column is that needed. It is only used in one place and only for minor performance gain, which is still very little. This may eventually be useful, but it may be a good idea to delay committing to adding a column. Migrating the TaskInstance column could get pretty expensive...", "Remove is_setup flag from TaskInstance s. I don't feel this flag is all that needed. It is only used in one place and only for minor performance gain, it seems. This may eventually be useful, but it may be a good idea to delay committing to adding it. Migrating the source to an archived project is pretty expensive..."], "original_ll": -4.034191608428955, "sampled_ll": -3.734849452972412, "all_perturbed_sampled_ll": [-3.633464813232422, -3.8148257732391357, -3.6069626808166504, -3.6634809970855713, -4.054595947265625, -3.613032102584839, -3.875983715057373, -3.725228786468506, -4.03235387802124, -3.6626391410827637], "all_perturbed_original_ll": [-4.254068374633789, -4.131556510925293, -3.8114943504333496, -4.039051532745361, -3.9066944122314453, -3.8714356422424316, -4.153058052062988, -4.100711345672607, -3.905855894088745, -3.824230194091797], "perturbed_sampled_ll": -3.7682567834854126, "perturbed_original_ll": -3.9998156309127806, "perturbed_sampled_ll_std": 0.16055372289049688, "perturbed_original_ll_std": 0.14747180183153255}, {"original": "Bring back the decision buttons on DAG trigger (#33394) When show_trigger_form_if_no_params is set to True, the decision buttons to trigger with or without config should be shown just like we had it in 2.6.3", "sampled": "Bring back the decision buttons on DAG trigger (#33394) When show_trigger_form_if_no_params is set to True, we can't display the actual form when a non-parametric form is present (#33404)\n\nis set to When show_trigger_form_if_no_params is set", "perturbed_sampled": ["Bring back the decision form for a DAG trigger (#33394) When show_trigger_form_if_no_params is set to True, we can't display the actual form when a trigger form is present (#33404)\n\nis set to When show_trigger_form_if_no_params is set", "Bring back the decision buttons on DAG trigger (#33394) When show_trigger_form_if_no_params is set to True, we can't display the actual form when no form is present (#33404)\n\nis set to When view_trigger_form_is set", "3) On click, we hide the decision buttons on the form (#33394) When show_trigger_form_if_no_params is set to True, we can't display the actual form when a non-parametric form is present (#33404)\n\nis set to When show_trigger_form_if_no_params is set", "Bring back the decision buttons on DAG trigger (#33394) When show_trigger_form_if_no_params is set to True, only display the actual form when a non-parametric form is present (#33404)\n\nis set to When show_trigger_form if is not set", "Bring back the decision buttons on DAG trigger (#33394) When show_trigger_form_if_no_params is set to True, when display the trigger form when a non-parametric form is present (#33404)\n\nis set to When show_trigger_form_if_no_params is set", "Bring back the decision buttons on DAG trigger (#33394) When show_trigger_form_if_no_params is set to True, we can't display the trigger when a non-parametric form is given. When show_trigger_form is set to When show_trigger_form_if_no_params is set", "Bring back the decision buttons on DAG trigger (#33394) When show_trigger_form_if_no_params is set to True, we can't display the actual form if no non-parametric form is present (#33404)\n\nis set to When show_trigger_form_if_no_params is set", "Bring back the decision buttons on DAG trigger (#33394) is set to When is set to True, we can't make these buttons redundant. Show the actual form when a non-parametric form is present (#33404)\n\nis set to When show_trigger_form_if_no_params is set", "Bring back the decision buttons on trigger forms (#33394) When show_trigger_form_if_no_params is set to True, we can't display the actual form when a trigger form is present (#33404)\n\nis set to When show_trigger_form_if_no_params is set", "Bring back the function displayed on DAG trigger (#33394) When show_trigger_form_if_no_params is set to True, we can't display the actual form when a non-parametric form is present (#33404)\n\nis set to True) is set"], "perturbed_original": ["Bring back the decision buttons on DAG trigger forms without config. When show_trigger_form_if_no_params is set to True, the decision buttons to trigger form without config should be shown just like we had it in 2.6.3", "Bring back the decision buttons on DAG trigger (#33394) When show_trigger_form_if_no_params switch is set to True, the decision buttons to trigger with or without parameters should be shown just like we had it in 2.6.3", "Bring back the decision buttons on DAG Trigger form (default form). When show_trigger_form_if_no_params is set to True, the decision buttons to trigger with or without config should be shown just like we had it in 2.6.3", "Bring back the decision buttons to trigger (#33394) When show_trigger_form_if_no_params is set to True, the decision buttons to trigger with or without config should be shown just like we had it in 2.6.3", "Bring back the decision buttons on DAG trigger page? If you set show_trigger_form_if_no_params set to True, the decision buttons to trigger with or without config should be shown just like we had it in 2.6.3", "Bring back the decision buttons on DAG trigger. When show_trigger_form_if_no_params is set to True, the decision buttons to trigger with or without config should be shown just like we do in 2.6.3", "Bring back the decision buttons in case of no config in DAG trigger (#33394) When show_trigger_form_if_no_params is set to True, the decision buttons to use with or without config should be shown just like we had it in 2.6.3", "Bring back the decision buttons on DAG trigger (#33394) When show_trigger_form_if_no_params is set to True, the buttons to trigger with or without config should be shown just like a DAG trigger, like we have it in 2.6.3", "Bring back the decision buttons on DAG trigger (#33394) When show_trigger_form_if_no_params is set to True, the decision buttons to trigger with or without config should be shown : as we had in 2.6.3", "Bring back decision buttons on DAG trigger (#33394) When this is set to True, the decision buttons to trigger with or without config should be shown just like we had it in 2.6.3"], "original_ll": -4.3012919425964355, "sampled_ll": -2.894345760345459, "all_perturbed_sampled_ll": [-2.7940595149993896, -3.626873254776001, -2.7779605388641357, -3.379873752593994, -2.9063806533813477, -3.0730507373809814, -2.8976566791534424, -4.1661906242370605, -2.7207744121551514, -3.61710262298584], "all_perturbed_original_ll": [-4.118988513946533, -4.23458194732666, -4.17885160446167, -4.115155220031738, -4.35284948348999, -4.195451736450195, -4.241403579711914, -4.132984161376953, -4.509975433349609, -4.370570659637451], "perturbed_sampled_ll": -3.195992279052734, "perturbed_original_ll": -4.245081233978271, "perturbed_sampled_ll_std": 0.45696998944362666, "perturbed_original_ll_std": 0.12241308600733275}, {"original": "Use object instead of array in config.yml for config template (#28417) This makes it easier to navigate the document in IDE.", "sampled": "Use object instead of array in config.yml for config template (#28417) This makes it easier to navigate the document in IDE.We", "perturbed_sampled": ["Use object instead of array in config.yml for config template (#28417) This makes it easier to handle the configuration document in IDE.We", "String instead of array in config.yml for config template (#28417) This makes it easier to navigate the document in IDE.We", "Use float instead of array in config.yml for config template (#28417) This makes it easier to navigate the document in IDE.We", "Use object instead of array in config.yml for config template (#28417) This makes it easier to navigate the config template in the IDE.We", "Please use a list instead of array in config.yml for config template (#28417) This makes it easier to navigate the document in IDE.We", "Use object instead of array in config.yml for config template (#28417) makes it easier to navigate the document in IDE.We", "Use object instead of array in config.yml for config template (#28417) This makes it easier to navigate the iFixit code in IDE.We", "Use object instead of array in config.yml for config template (#28417) This makes it easier to navigate the config.yml template in the IDE.We", "Use object instead of array in config.yml for config template (#28417) This makes it easier to edit the document in IDE.We", "Use object instead of array in config.yml for config template (#28417) This makes it easier for the user to view the document in IDE.We"], "perturbed_original": ["Text instead of array in config.yml for config template (#28417) This makes it easier to navigate the document in IDE.", "Use object instead of array in config.yml for config template (#28417) This makes it easier to navigate through in IDE.", "Use object instead of script or class config.yml for config template (#28417) This makes it easier to navigate the document in IDE.", "Use file instead of array in config.yml for config template (#28417) This makes it easier to navigate the document in IDE.", "Use object instead of array in config.yml for config template (#28417) This makes it easier to navigate the document in IDE.", "Use object instead of array in config.yml for config template (#28417) This makes it easier to navigate the config template in the default IDE.", "Use object instead of array s for config template (#28417) This makes it easier to navigate the document in IDE.", "Use this kind of array in config.yml for config template (#28417) This makes it easier to navigate the document in IDE.", "Use object instead array in config.yml for config template (#28417) This makes it easier to navigate the document in IDE.", "Use list instead of array in config.yml for config template (#28417) This makes it easier to navigate the document in IDE."], "original_ll": -4.06813907623291, "sampled_ll": -4.318530082702637, "all_perturbed_sampled_ll": [-4.414760589599609, -4.671831130981445, -4.7101826667785645, -3.84958815574646, -4.360228538513184, -4.466434955596924, -4.445647239685059, -3.656643867492676, -4.2585930824279785, -4.103806972503662], "all_perturbed_original_ll": [-4.4538373947143555, -4.129565238952637, -4.39729118347168, -4.195637226104736, -4.06813907623291, -3.7121782302856445, -4.7695417404174805, -4.255284786224365, -4.497491359710693, -4.317789554595947], "perturbed_sampled_ll": -4.293771719932556, "perturbed_original_ll": -4.279675579071045, "perturbed_sampled_ll_std": 0.32075156391751125, "perturbed_original_ll_std": 0.27018927005931526}, {"original": "Add map_index to XCom model and interface (#22112) * Add map_index to XCom primary key This is not actually stored correctly yet. We still need to fix the XCom interface. * Add map_index to XCom interface This adds an additional (optional) map_index argument to XCom's get/set/clear interface so mapped task instances can push to the correct entries, and have them pulled correctly by a downstream. To make the XCom interface easier to use for common scenarios, a convenience method get_value is added to take a TaskInstanceKey that automatically performs argument unpacking and call get_one underneath. This is not done as a get_one overload to simplify the implementation and typing.", "sampled": "Add map_index to XCom model and interface (#22112) * Add map_index to XCom primary key This is not actually stored correctly in the model, but it's there. The code works fine except when you're loading a lot of models. This should also be fixed in the next release (#22116) * Remove map_index from XCom primary key in _XCom_LoadedXML_Init (#22124) * Fix XCom model's default flag to 0. When you enable XCom \"default\" mode in game config files and load-the-game it will use default XCom model's default flags which is 0. That will cause problem when you load/load maps, because if XCom models has default flags but XCom's primary_index has", "perturbed_sampled": ["Add map_index to XCom model and interface (#22112) * Add map_index to XCom model and interface This is not actually used in the model, but it's there. The default is 0. Which should be fine except when you're loading a lot of models. This should also be fixed in the next release (#22116) * Remove map_index from XCom primary key in _XCom_LoadedXML_Init .xml (#22113) * Fix XCom model's default flag to 0. When you enable XCom \"default\" flags in game config files and load-the-game it use default XCom model flags which is 0. This will cause problem when you load/load maps, because if XCom models has default flags but XCom's primary_index has", "Add map_index to XCom model and interface (#22112) * Add map_index to XCom primary key and interface * Map_index is not actually stored in the model, but it's there. The code works fine except when you're loading a lot of models. This should also be fixed in XCom 2.3.2 release (#22116) * Remove map_index from XCom primary key and interface (#22124) * Fix XCom model's default flag to 0. When you enable XCom \"default\" flag in game config files and the game will use default XCom model's default flags which is 0. That will cause problems when you 're loading models because if XCom models has default flags but XCom's primary_index has", "Add map_index to XCom data interface (#22112) * Add map_index to XCom primary key This is not actually stored correctly in the model, but it's there. The code should probably load the file correctly except when you're loading a lot of models. This should also be fixed in the next release (#22116) * Remove map_index from XCom primary key in _XCom_LoadedXML_Init (#22124) * Fix XCom model's default flag to 0. When you enable XCom \"default\" mode in game mode and load XCom model, the system will use default XCom model's flag that is set to -1, which is 0. That will cause problem when you load/load maps, because XCom models has default flags but XCom's primary_index has", "Add map_index to XCom model and interface (#22112) * Add map_index to XCom primary key This is not stored correctly in the model, but it's there. The code works fine except when you're loading a lot of models. This should be fixed in the next release (#22116) * Remove map_index from XCom primary key in _XCom_LoadedXML_Init () Fix XCom model's default flag to 0. When you use \"default\" mode in game config files and load-the-game it will use XCom model's default flags which is 0, since it has not been set in game config files. That will cause problem when creating maps, because if XCom models has default flags but XCom's primary_index has", "Add map_index to XCom model and loading (#22213) * Add map_index to XCom primary key This is not actually stored to the model, though it needs to be there. The code works fine except when you're loading a lot of models. This should also be fixed in the next release (#22116) * Remove map_index from XCom primary key in _XCom_LoadedXML_Init (#22124) * Fix XCom model's default flag to 0. If you enable XCom \"default\" mode in game config files and load-the-game you will use default XCom model's default flags which is 0. That will cause problem when you load/load maps, because if XCom models has default flags but XCom's primary_index has", "Add map_index to XCom model and interface (#22112) * Add map_index to XCom primary key This is not actually stored correctly in XCom's model, but it's there. The map should be fine except when you're loading map. That side of things should also be fixed in our next mainline release (#22118) * Remove map_index from XCom 's primary key in _XCom_LoadedXML_Init (#22124) * Fix XCom model's default flag to 0. When you enable XCom \"default\" mode in game config files and load-the-game it will use default XCom model's default flags which is 0. That will cause problem when you load/load maps, because if XCom models has default flag to 0, that means XCom's primary_index has", "Add map_index to XCom primary key and interface (#22112) * Add map_index to XCom primary key This is not specified correctly in the model, but it's there. The code works fine except when loading a lot of models. This should also be fixed in the next release (#22116) * Remove map_index from XCom primary key in _XCom_LoadedXML_Init (#22124) * Fix XCom model's default flag to 0. When you set \"default\" mode in game config files and load-the-game it will use default XCom model's default flags which is 0. That 's not a problem, but it causes problem when you load/load maps, even if XCom models has default flags and map primary_index has", "Add map_index to XCom model and interface * Add map_index to XCom primary key This is not actually stored correctly in the model, but it's there. The code works , but it can be a pain when you're loading a lot of models. This should also be fixed in the next release (#22116) * Remove map_index from XCom primary key in _XCom_LoadedXML_Init (#22124) * Fix XCom default flag to 0. When you enable XCom \"default\" mode in game config section and load-the-game it will use default XCom model's default flags which is 0. That will cause problem when you try to load XCom models at once because if XCom models have zero default flags but XCom's primary_index has", "Add map_index to XCom model and interface (#22112) * Add map_index to XCom primary key This is not stored correctly in the map_index, but it's there. The initial map will work just fine except when you're loading a lot of models. This should be fixed in the next release (#22116) * Remove map_index from XCom primary key in _XCom_LoadedXML_Init (#22124) * Fix XCom model's default flags setting to 0. When you enable XCom \"default\" mode in your config files and load-the-game it will use default XCom model's default flags which are 0. That will cause problem when you load/load maps, because if the XCom model has default flags but XCom's primary_index has", "Add map_index to model primary key and interface (#22112) * Add map_index to XCom primary key . The map_index has not been added correctly in the model, but it's there. The code works fine except when I have a lot of models. This should also be fixed in the next release (#22116) * Remove map_index from XCom primary key in _XCom_LoadedXML_Init (#22124) * Fix XCom model's default flag to 0. When you enable XCom \"default\" flag in game config files , it will use default XCom model's default flags for model instead of all other flags. That's weird. Only default flag is 0. That will cause problem when you load/load maps, because if XCom models has default flags but XCom's primary_index has"], "perturbed_original": ["Add map_index to XCom model and interface (#22112) * Add map_index to XCom primary model This is not actually stored correctly yet. We still need to fix the XCom interface. * Add mapping to XCom interface This adds an input map_index argument to XCom's get/set/clear interface so mapped task instances can push to the correct entries, and have them pulled correctly by a downstream. To make the XCom interface easier to use for common scenarios, a convenience method get_value was added to take a TaskInstanceKey that automatically performs argument unpacking and call able generation. This is not done for the get_one overload to simplify the implementation and typing.", "Add map_index to XCom model and interface (#22112) * Add map_index to XCom model and interface This is not actually stored locally. We still need to fix the XCom interface. * Add map_index to XCom interface This adds a (optional) map_index argument to the get/set/clear interface so mapped task instances can push to their associated API entries, and have them pulled correctly by a downstream. To make the XCom interface easier to use for common scenarios, a convenience method get_value is added to take a TaskInstanceKey that performs the mapping and call this out if the value mapped is NULL. This is not done as a get_one overload to simplify the implementation and typing.", "Add map_index to XCom model and interface (#22112) * Add map_index to XCom primary key This is not stored correctly yet. We still need to fix the XCom interface. * Add map_index to XCom interface This adds an additional (optional) map_index argument to XCom's get/set/clear interface so mapped _index entries can push to new keyspace entries, and have them loaded correctly by a downstream. To make the XCom interface easier to use for developers, a new interface get_value is added to take a TaskInstanceKey that automatically performs argument unpacking and call get_one underneath. This is not done as a get_one overload to simplify memory usage and typing.", "Add map_index to XCom model and interface (#22112) * Add map_index to XCom model and interface This is not actually stored correctly yet. We need to fix the XCom interface. * Add map_index to XCom interface This adds an additional (optional) map_index argument to XCom's get/set/clear interface so mapped queries can push to the correct entries, and stale entries can be pulled correctly by a downstream. To make the XCom interface easier to use for common scenarios, the method get_value is added to take a TaskInstanceKey that automatically performs argument extraction without having to explicitly call get_one . This is not done as a get_one overload to simplify the implementation and typing.", "Add map_index to XCom model and interface (#22112) * Add map_index to XCom primary key This is not actually stored correctly yet. We still need to fix the XCom interface. * Add map_index to XCom primary key The fix adds an additional (optional) map_index argument to the interface so mapped types can push to the correct entries, e.g. from upstream, to have them pulled correctly by a downstream. To make the XCom interface easier to use , particularly in emergency scenarios, a convenience method get_value is added to take a TaskInstanceKey that automatically performs argument unpacking and call get_one underneath. This is provided as a simple overload to simplify the implementation and typing.", "Add map_index to XCom model and interface (#22112) * Add map_index to XCom model key This is in progress, but the map is not stored correctly yet. We still need to fix the XCom interface. * Add map_index to XCom interface This adds an additional (optional) map_index to XCom's get/set/clear interface so mapped models can push to a specific target their mapping entries, and have them moved by a downstream. To make the XCom interface easier to use for common scenarios, a convenience method get_value is added to take a TaskInstanceKey that automatically performs argument manipulation without having to call get_one underneath. This is not done as a get_one overload , but instead in the implementation and typing.", "Add map_index to XCom model and interface (#22112) * Add map_index to XCom primary key This is not actually stored correctly yet. We still need to define mapping in the XCom interface. * Add map_index to XCom interface This adds an additional (optional) map_index argument to XCom's get/set/clear interface so mapped task instances can push to the correct entries, and have them pulled in a downstream. * Make XCom interface easier to use To make the XCom interface easier to use for common scenarios, a convenience method get_value is added to the TaskInstanceKey that automatically performs argument unpacking and call get_one underneath. This is done as a get_one overload to simplify the use and typing.", "Add map_index to XCom model and interface * Add map_index to XCom primary key This is not actually stored correctly , so we still need to fix the XCom interface. * Add map_index to XCom interface This adds a (optional) map_index argument to XCom's get/set/clear interface so mapped xcom objects can push to the correct entries, and have them pulled correctly by a downstream. To make the XCom interface easy to use for common scenarios, a convenience method get_value is implemented above; this will just take a TaskInstanceKey that does no argument unpacking and call get_one underneath. This is not done as a get_one overload , but rather for the convenience of the implementation and typing.", "Add map_index to XCom model and interface (#22112) * Add map_index to XCom primary key This is not actually ready yet. We need to fix the XCom interface. * Add location to map in XCom interface This adds an additional (optional) map_index argument to XCom's get/set/clear methods. Mapped tasks can be pulled together to generate additional instances. mapped task instances can push to another system, update the entries, and use the entries pulled as a downstream. To make the XCom interface easier to use for common scenarios, a convenience method get_value is added to take a TaskInstanceKey that automatically performs argument unpacking and call get_one . This is not done as a get_one overload to simplify the implementation and typing.", "Add map_index to XCom model and interface (#22112) * Add map_index to XCom primary key This is not actually stored correctly yet. We still need to fix the XCom interface. * Add map_index to XCom interface This adds an optional map_index argument to XCom's get/set/clear interface so mapped task instances can push to the map_index property and have them be cleared by XCom. To make the XCom interface easier to use for common scenarios, a convenience method get_value is added to take a TaskInstanceKey (XComKey) and performs argument unpacking in get_one underneath. This is not done as a get_one method, to simplify the implementation and typing."], "original_ll": -3.8165786266326904, "sampled_ll": -2.9365580081939697, "all_perturbed_sampled_ll": [-3.0086381435394287, -2.9053797721862793, -2.9773995876312256, -3.0086307525634766, -3.0204336643218994, -3.0995841026306152, -3.0671465396881104, -3.0638034343719482, -2.962522268295288, -2.9929311275482178], "all_perturbed_original_ll": [-4.040802955627441, -3.7457056045532227, -3.836745023727417, -3.6748948097229004, -3.846774101257324, -3.7484335899353027, -3.6568846702575684, -3.747478723526001, -3.9402947425842285, -3.5625712871551514], "perturbed_sampled_ll": -3.010646939277649, "perturbed_original_ll": -3.7800585508346556, "perturbed_sampled_ll_std": 0.0537102540490517, "perturbed_original_ll_std": 0.13345457580606626}, {"original": "Use `requires_access_custom_view` for user and roles API endpoints (#35207)", "sampled": "Use `requires_access_custom_view` for user and roles API endpoints (#35207)What", "perturbed_sampled": ["Use `requires_access_custom_view` for user and roles API endpoints (#35207)What", "Use `requires_access_custom_view` for user and roles API endpoints (#35207)What", "Use `requires_access_custom_view` for user and roles API endpoints (#35207)What", "Use `requires_access_custom_view` for user and roles API endpoints (#35207)What", "Use `requires_access_custom_view` for user and roles API endpoints (#35207)What", "Use `requires_access_custom_view` for user and roles API endpoints (#35207)What", "Use `requires_access_custom_view` for user and roles API endpoints (#35207)What", "Use `requires_access_custom_view` for user and roles API endpoints (#35207)What", "Use `requires_access_custom_view` for user and roles API endpoints (#35207)What", "Use `requires_access_custom_view` for user and roles API endpoints (#35207)What"], "perturbed_original": ["Use `requires_access_custom_view` for user and roles API endpoints (#35207)", "Use `requires_access_custom_view` for user and roles API endpoints (#35207)", "Use `requires_access_custom_view` for user and roles API endpoints (#35207)", "Use `requires_access_custom_view` for user and roles API endpoints (#35207)", "Use `requires_access_custom_view` for user and roles API endpoints (#35207)", "Use `requires_access_custom_view` for user and roles API endpoints (#35207)", "Use `requires_access_custom_view` for user and roles API endpoints (#35207)", "Use `requires_access_custom_view` for user and roles API endpoints (#35207)", "Use `requires_access_custom_view` for user and roles API endpoints (#35207)", "Use `requires_access_custom_view` for user and roles API endpoints (#35207)"], "original_ll": -5.259988784790039, "sampled_ll": -5.798915386199951, "all_perturbed_sampled_ll": [-5.798915386199951, -5.798915386199951, -5.798915386199951, -5.798915386199951, -5.798915386199951, -5.798915386199951, -5.798915386199951, -5.798915386199951, -5.798915386199951, -5.798915386199951], "all_perturbed_original_ll": [-5.259988784790039, -5.259988784790039, -5.259988784790039, -5.259988784790039, -5.259988784790039, -5.259988784790039, -5.259988784790039, -5.259988784790039, -5.259988784790039, -5.259988784790039], "perturbed_sampled_ll": -5.798915386199951, "perturbed_original_ll": -5.259988784790039, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Updated MongoDB logo (#23746) As per https://www.mongodb.com/brand-resources", "sampled": "Updated MongoDB logo (#23746) As per https://www.mongodb.com/brand-resourcesPaid-Design-for-a-simple-web-database", "perturbed_sampled": ["Updated MongoDB logo (#23746) As per https://www.mongodb.com/brand-resourcesPaid-Design-for-a-simple-web-database", "Updated MongoDB logo (#23746) As per https://www.mongodb.com/brand-resourcesPaid-Design-for-a-simple-web-database", "Updated MongoDB logo (#23746) As per https://www.mongodb.com/brand-resourcesPaid-Design-for-a-simple-web-database", "Updated MongoDB logo (#23746) As per https://www.mongodb.com/brand-resourcesPaid-Design-for-a-simple-web-database", "Updated MongoDB logo (#23746) As per https://www.mongodb.com/brand-resourcesPaid-Design-for-a-simple-web-database", "Updated MongoDB logo (#23746) As per https://www.mongodb.com/brand-resourcesPaid-Design-for-a-simple-web-database", "Updated MongoDB logo (#23746) As per https://www.mongodb.com/brand-resourcesPaid-Design-for-a-simple-web-database", "Updated MongoDB logo (#23746) As per https://www.mongodb.com/brand-resourcesPaid-Design-for-a-simple-web-database", "Updated MongoDB logo (#23746) As per https://www.mongodb.com/brand-resourcesPaid-Design-for-a-simple-web-database", "Updated MongoDB logo (#23746) As per https://www.mongodb.com/brand-resourcesPaid-Design-for-a-simple-web-database"], "perturbed_original": ["Updated MongoDB logo (#23746) As per https://www.mongodb.com/brand-resources", "Updated MongoDB logo (#23746) As per https://www.mongodb.com/brand-resources", "Updated MongoDB logo (#23746) As per https://www.mongodb.com/brand-resources", "Updated MongoDB logo (#23746) As per https://www.mongodb.com/brand-resources", "Updated MongoDB logo (#23746) As per https://www.mongodb.com/brand-resources", "Updated MongoDB logo (#23746) As per https://www.mongodb.com/brand-resources", "Updated MongoDB logo (#23746) As per https://www.mongodb.com/brand-resources", "Updated MongoDB logo (#23746) As per https://www.mongodb.com/brand-resources", "Updated MongoDB logo (#23746) As per https://www.mongodb.com/brand-resources", "Updated MongoDB logo (#23746) As per https://www.mongodb.com/brand-resources"], "original_ll": -4.076098918914795, "sampled_ll": -3.708271026611328, "all_perturbed_sampled_ll": [-3.708271026611328, -3.708271026611328, -3.708271026611328, -3.708271026611328, -3.708271026611328, -3.708271026611328, -3.708271026611328, -3.708271026611328, -3.708271026611328, -3.708271026611328], "all_perturbed_original_ll": [-4.076098918914795, -4.076098918914795, -4.076098918914795, -4.076098918914795, -4.076098918914795, -4.076098918914795, -4.076098918914795, -4.076098918914795, -4.076098918914795, -4.076098918914795], "perturbed_sampled_ll": -3.708271026611328, "perturbed_original_ll": -4.076098918914795, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Add how-to Guide for WinRM operators (#21344)", "sampled": "Add how-to Guide for WinRM operators (#21344)One", "perturbed_sampled": ["Add how-to Guide for WinRM operators (#21344)One", "Add how-to Guide for WinRM operators (#21344)One", "Add how-to Guide for WinRM operators (#21344)One", "Add how-to Guide for WinRM operators (#21344)One", "Add how-to Guide for WinRM operators (#21344)One", "Add how-to Guide for WinRM operators (#21344)One", "Add how-to Guide for WinRM operators (#21344)One", "Add how-to Guide for WinRM operators (#21344)One", "Add how-to Guide for WinRM operators (#21344)One", "Add how-to Guide for WinRM operators (#21344)One"], "perturbed_original": ["Add how-to Guide for WinRM operators (#21344)", "Add how-to Guide for WinRM operators (#21344)", "Add how-to Guide for WinRM operators (#21344)", "Add how-to Guide for WinRM operators (#21344)", "Add how-to Guide for WinRM operators (#21344)", "Add how-to Guide for WinRM operators (#21344)", "Add how-to Guide for WinRM operators (#21344)", "Add how-to Guide for WinRM operators (#21344)", "Add how-to Guide for WinRM operators (#21344)", "Add how-to Guide for WinRM operators (#21344)"], "original_ll": -5.762533664703369, "sampled_ll": -6.503626346588135, "all_perturbed_sampled_ll": [-6.503626346588135, -6.503626346588135, -6.503626346588135, -6.503626346588135, -6.503626346588135, -6.503626346588135, -6.503626346588135, -6.503626346588135, -6.503626346588135, -6.503626346588135], "all_perturbed_original_ll": [-5.762533664703369, -5.762533664703369, -5.762533664703369, -5.762533664703369, -5.762533664703369, -5.762533664703369, -5.762533664703369, -5.762533664703369, -5.762533664703369, -5.762533664703369], "perturbed_sampled_ll": -6.503626346588135, "perturbed_original_ll": -5.762533664703369, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Improved instructions for custom image build with docker compose (#21052) * Create build.rst * Update docs/docker-stack/build.rst Co-authored-by: Jarek Potiuk <jarek@potiuk.com> * fix doc build Co-authored-by: Jarek Potiuk <jarek@potiuk.com> Co-authored-by: eladkal <45845474+eladkal@users.noreply.github.com>", "sampled": "Improved instructions for custom image build with docker compose (#21052) * Create build.rst * Update docs/docker-stack/build.rst * Merge build.rst into docker-io* * Make docker-build script aware of --build --with=\"build.rst\" * Merge", "perturbed_sampled": ["Improved instructions at creating an image for docker compose (#21052) * Create build.rst * Update docs/docker-stack/build.rst * Merge build.rst into docker-io* * Make docker-build script aware of --build --with=\"build.rst\" * Merge", "Improved instructions for custom izing docker build with docker compose (#21052) * Create build.rst * Update docs/docker-stack/build.rst * Merge build.rst into docker-io* * Make docker-build script aware of --with=\"build.rst\" * Merge", "instructions for custom image build in compose (#21052) * Create build.rst * Update docs/docker-stack/build.rst * Merge build.rst into docker-io* * Make docker-build script aware of --build --with=\"build.rst\" * Merge", "Improved instructions for custom image build with docker compose (#21052) * Create build.rst * Update docs/docker-stack/build.rst * Integrate build into docker-io* * Make docker-build a subcommand of --build --with=\"build.rst\" * Merge", "Improved instructions for custom image images that are used with docker compose (#21052) * Create build.rst * Update docs/docker-stack/build.rst * Merge build.rst into docker-io* * Make build script aware of --build --with=\"build.rst\" * Merge", "Improved instructions for custom image build with docker compose (#21052) * Create build.rst * Update docs/docker-stack/build.rst * Merge build.rst into docker-io* * Make docker-io aware of --build -images * Merge", "Improved instructions for custom image build with docker compose (#21052) * Create build.rst * Make build.rst url the first URL * Merge build.rst * Build images * Make docker-build script aware of --build --with=\"build.rst\" * Merge", "Improved instructions for custom image build with docker compose (#21052) * Create build.rst * Update docs/docker-stack/build.rst * Merge build.rst into docker-io* * Make build script aware of git repository * Merge", "Improved instructions for custom image build with docker -io for * Create build.rst * Update docs/docker-stack/build.rst * Merge build.rst into docker-io* * Make docker-build script use --build --with=\"build.rst\" * Merge", "Improved instructions for docker image build with docker compose (#21052) * Create build.rst * Update docs/docker-stack/build.rst * Merge build.rst into docker-io* * Make docker-build script aware of --build _tmp* * Merge"], "perturbed_original": ["Improved instructions for custom image build with docker compose (#21052) * Create build.rst * Update docs/docker-stack/build.rst by Jarek Potiuk <jarek@potiuk.com> * fix doc build Co-authored-by: Jarek Potiuk <jarek@potiuk.com> * Add Eladkal <45845474+eladkal@users.noreply.github.com>", "Improved instructions for image build with docker compose (#21052) * Create build.rst * Update docs/docker-stack/build.rst Co-authored-by: Jarek Potiuk <jarek@potiuk.com> * fix doc s/docker-stack/docker-stack/build.rst Co-authored-by: Jarek Potiuk <jarek@potiuk.com> Co-authored-by: eladkal <45845474+eladkal@users.noreply.github.com>", "Improved instructions for custom image build with docker compose (#21052) * Create build.rst * Add additional docs/docker-stack/build.rst Co-authored-by: Jarek Potiuk * fix doc build Co-authored-by: Jarek Potiuk <jarek@potiuk.com> Co-authored-by: eladkal <45845474+eladkal@users.noreply.github.com>", "Improved instructions on an image build with docker compose (#21052) * Create build.rst * Update docs/docker-stack/build.rst Co-authored-by: Jarek Potiuk <jarek@potiuk.com> Improve instructions on an image build with image doc build Co-authored-by: Jarek Potiuk <jarek@potiuk.com> Co-authored-by: eladkal <45845474+eladkal@users.noreply.github.com>", "Improved instructions for custom image build with docker compose (#21052) * build instructions * fix build Co-authored-by: Jarek Potiuk <jarek@potiuk.com> * fix doc build Co-authored-by: Jarek Potiuk <jarek@potiuk.com> Co-authored-by: eladkal <45845474+eladkal@users.noreply.github.com>", "Improved instructions for custom image build with docker compose (#21052) * Create build.rst * Update docs/docker-stack/build.rst Co-authored-by: Jarek Potiuk <jarek@potiuk.com> * fix the script Co-authored-by: Jarek Potiuk <jarek@potiuk.com> Co-authored-by: eladkal <45845474+eladkal@users.noreply.github.com>", "Improved instructions * Improved the above code and doc image build with docker compose (#21052) * Create build.rst * improve instructions for image builds with docker compose Co-authored-by: Jarek Potiuk <jarek@potiuk.com> * fix doc build Co-authored-by: Jarek Potiuk <jarek@potiuk.com> Co-authored-by: eladkal <45845474+eladkal@users.noreply.github.com>", "Improved documentation about custom image build and script compose (#21052) * Create build.rst * Update docs/docker-stack/build.rst Co-authored-by: Jarek Potiuk <jarek@potiuk.com> * fix doc build Co-authored-by: Jarek Potiuk <jarek@potiuk.com> Co-authored-by: eladkal <45845474+eladkal@users.noreply.github.com>", "Improved instructions for custom image build with docker compose (#21052) * Create build.rst * Update build.rst * Update instructions: Jarek Potiuk Add and fix doc build Co-authored-by: Jarek Potiuk <jarek@potiuk.com> Co-authored-by: eladkal <45845474+eladkal@users.noreply.github.com>", "Improved instructions for custom image build * compose (#21052) * Create build.rst * Update docs/docker-stack/build.rst Co-authored-by: Jarek Potiuk <jarek@potiuk.com> * fix doc build Co-authored-by: Jarek Potiuk * fix synology-doc: eladkal <45845474+eladkal@users.noreply.github.com>"], "original_ll": -2.801920175552368, "sampled_ll": -3.4631426334381104, "all_perturbed_sampled_ll": [-3.5732288360595703, -3.613553047180176, -3.6306722164154053, -3.7084531784057617, -3.5200531482696533, -3.7407703399658203, -3.7530148029327393, -3.6982667446136475, -3.6124210357666016, -3.6738991737365723], "all_perturbed_original_ll": [-3.1332805156707764, -2.6267101764678955, -3.157433271408081, -2.8207473754882812, -2.747479200363159, -2.824274778366089, -2.9697794914245605, -2.9369678497314453, -3.4194889068603516, -3.542325973510742], "perturbed_sampled_ll": -3.652433252334595, "perturbed_original_ll": -3.017848753929138, "perturbed_sampled_ll_std": 0.07141697158698682, "perturbed_original_ll_std": 0.27936728329911464}, {"original": "Return empty dict if Pod JSON encoding fails (#24478) When UI unpickles executor_configs with outdated k8s objects it can run into the same issue as the scheduler does (see https://github.com/apache/airflow/issues/23727). Our JSON encoder therefore needs to suppress encoding errors arising from pod serialization, and fallback to a default value.", "sampled": "Return empty dict if Pod JSON encoding fails (#24478) When UI unpickles executor_configs with outdated k8s objects it can sometimes fail due to poor encoding by JSON encoding services. This issue has been solved by providing a json_encode_config option that will attempt to generate an unpackable config file instead", "perturbed_sampled": ["Return empty dict if Pod JSON encoding fails . The UI unpickles executor_configs with outdated k8s objects , and will sometimes fail due to poor encoding by JSON encoding services. The problem has been solved by providing a json_encode_config option that will attempt to generate an unpackable config file instead", "Return empty dict if Pod JSON encoding service fails. When UI unpickles executor_configs .json from k8s objects it can sometimes fail due to poor encoding by JSON encoding services. This issue has been solved by providing a json_encode_config option that will attempt to generate a Pod config file instead", "Return empty dict if Pod JSON encoding fails (#24478) When UI unpickles executor_configs with outdated k8s objects it can sometimes fail, possibly due to poor encoding by JSON encoding services. This issue has been resolved by providing a json_encode_config option that will attempt to generate an executable JSON from the XML config file instead", "Return empty dict if Pod JSON encoding fails (#24478) When UI JSON is required with outdated k8s objects it can sometimes fail due to poor encoding by JSON encoding services. This issue has been solved by providing a json_encode_config option that will attempt to include an unpackable config file instead", ": Retry dict if Pod JSON encoding fails (#24478) When UI unpickles executor_configs with outdated k8s objects it can sometimes fail due to poor encoding by JSON encoding services. This has been solved by providing a json_encode_config option that will attempt to generate an unpackable config file instead", "Return empty dict if Pod JSON encoding fails (#24478) When UI unpickles executor_configs for k8s objects it can sometimes fail due to poor encoding by JSON encoding services. This issue has been solved by providing a json_encode_config .json class and thus will now generate an unpackable config file instead", "Return empty dict if json encoding fails (#24478) When UI unpickles executor_configs .json for k8s objects it can sometimes fail due to poor encoding by JSON encoding services. This issue has been solved by providing a json_encode_config option which should attempt to generate an unpackable config file instead", "Return empty dict if JSON encoding fails (#24478) When UI unpickles executor_configs with outdated k8s objects it can sometimes fail due to poor encoding by JSON encoding services. This issue has been solved by providing a hook that will attempt to unpack config files into an unpackable config file instead", "Return empty dict if Pod JSON encoding fails (#24478) When UI unpickles executor_configs with outdated k8s , these can have corrupt value vars due to poor encoding by JSON encoding services. This issue has been solved by providing a json_encode_config option , to attempt to generate an unpackable config file instead", "Create JSON dict if Pod JSON encoding fails (#24478) When UI unpickles executor_configs with outdated k8s objects it can sometimes fail due to poor encoding by JSON encoding services. This issue has been solved by providing an option that will attempt to generate an unpackable config file instead"], "perturbed_original": ["Return empty dict if an attempt at encoding fails . If our UI unpickles executor_configs with outdated k8s objects it can run into the same issue as the scheduler does (see https://github.com/apache/airflow/issues/23727). Our JSON encoder therefore needs to suppress encoding tests, uncouple from pod serialization, and fallback to a default value.", "Return empty dict when JSON encoding fails (#24478) When UI unpickles executor_configs with outdated k8s objects it can run into the same issue as the scheduler does with pod serialization. Our JSON encoder therefore needs to suppress encoding errors arising from pod serialization, and fallback to a default value.", "Return empty : Pod JSON encoding fails (#24478) When UI unpickles executor_configs with outdated k8s objects it can run into the same issue as the scheduler does (see #24476) The JSON encoder therefore has to suppress encoding errors arising from pod serialization, and fallback to a default value.", "Return empty dict if Pod JSON encoding fails (#24478) When UI unpickles executor_configs with outdated k8s objects it can run into the same issue as the scheduler does (see https://github.com/apache/airflow/issues/23727). Our JSON encoder works hard to suppress the errors arising from this and fallback to a default value.", "Return empty dict if Pod JSON encoding fails (#24478) . It also unpickles executor_configs with outdated k8s objects and also run into the same issue as the scheduler does (see https://github.com/apache/airflow/issues/23727). Our JSON encoder therefore needs to suppress errors arising from pod serialization, and fallback to a default value.", "Return empty dict if Pod serialization fails (#24478) When UI unpickles executor_configs with outdated k8s objects it can run into the same problem as the scheduler does (see https://github.com/apache/airflow/issues/23727). Our JSON encoder therefore needs to suppress encoding errors arising from pod serialization, and must have a default value.", "Return true if Pod JSON encoding fails (#24478) . Because the container unpickles executor_configs with outdated k8s objects it can run into the same behaviour in Airflow as the scheduler does (see https://github.com/apache/airflow/issues/23727). Our JSON encoder therefore needs to suppress encoding errors arising from pod serialization, and fallback to a default value.", "Return empty dict if Pod serialization fails . Because the UI unpickles executor_configs with outdated k8s objects it can run into the same issue as the scheduler does (see https://github.com/apache/airflow/issues/23727). Our JSON encoder therefore needs to suppress encoding errors arising from pod serialization, setting the encoding to a default value.", "Return empty dict if Pod JSON encoding fails (#24478) When UI unpickles executor_configs and k8s objects it can lead to the same issue as the scheduler does (see https://github.com/apache/airflow/issues/23727). Our JSON encoder therefore needs to suppress encoding errors during pod serialization, and fallback to a default value.", "Return empty dict if Pod JSON encoding fails (#24478) When UI is working with outdated k8s objects it can run into the same issue that the Airflow Pod scheduler does (see https://github.com/apache/airflow/issues/23727). Our JSON encoder therefore needs to suppress encoding errors arising from Pod serialization, and fallback to a default value."], "original_ll": -4.37192440032959, "sampled_ll": -4.159471035003662, "all_perturbed_sampled_ll": [-4.346704959869385, -4.231952667236328, -4.222440242767334, -4.126367568969727, -4.172511100769043, -4.3547515869140625, -3.950772523880005, -4.197568416595459, -4.568612575531006, -4.415555953979492], "all_perturbed_original_ll": [-4.24066162109375, -4.475628852844238, -4.659134864807129, -4.386587619781494, -4.436306476593018, -4.264302730560303, -4.246798038482666, -4.218628883361816, -4.315451145172119, -4.107267379760742], "perturbed_sampled_ll": -4.258723759651184, "perturbed_original_ll": -4.335076761245728, "perturbed_sampled_ll_std": 0.1622181737454021, "perturbed_original_ll_std": 0.15007600445023725}, {"original": "Fix typing of operator attrs for mypy (#21480)", "sampled": "Fix typing of operator attrs for mypy (#21480)The", "perturbed_sampled": ["Fix typing of operator attrs for mypy (#21480)The", "Fix typing of operator attrs for mypy (#21480)The", "Fix typing of operator attrs for mypy (#21480)The", "Fix typing of operator attrs for mypy (#21480)The", "Fix typing of operator attrs for mypy (#21480)The", "Fix typing of operator attrs for mypy (#21480)The", "Fix typing of operator attrs for mypy (#21480)The", "Fix typing of operator attrs for mypy (#21480)The", "Fix typing of operator attrs for mypy (#21480)The", "Fix typing of operator attrs for mypy (#21480)The"], "perturbed_original": ["Fix typing of operator attrs for mypy (#21480)", "Fix typing of operator attrs for mypy (#21480)", "Fix typing of operator attrs for mypy (#21480)", "Fix typing of operator attrs for mypy (#21480)", "Fix typing of operator attrs for mypy (#21480)", "Fix typing of operator attrs for mypy (#21480)", "Fix typing of operator attrs for mypy (#21480)", "Fix typing of operator attrs for mypy (#21480)", "Fix typing of operator attrs for mypy (#21480)", "Fix typing of operator attrs for mypy (#21480)"], "original_ll": -6.607091426849365, "sampled_ll": -7.182701110839844, "all_perturbed_sampled_ll": [-7.182701110839844, -7.182701110839844, -7.182701110839844, -7.182701110839844, -7.182701110839844, -7.182701110839844, -7.182701110839844, -7.182701110839844, -7.182701110839844, -7.182701110839844], "all_perturbed_original_ll": [-6.607091426849365, -6.607091426849365, -6.607091426849365, -6.607091426849365, -6.607091426849365, -6.607091426849365, -6.607091426849365, -6.607091426849365, -6.607091426849365, -6.607091426849365], "perturbed_sampled_ll": -7.182701110839844, "perturbed_original_ll": -6.607091426849365, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Poke once before defer for GCSObjectsWithPrefixExistenceSensor (#30939)", "sampled": "Poke once before defer for GCSObjectsWithPrefixExistenceSensor (#30939)Still", "perturbed_sampled": ["Poke once before defer for GCSObjectsWithPrefixExistenceSensor (#30939)Still", "Poke once before defer for GCSObjectsWithPrefixExistenceSensor (#30939)Still", "Poke once before defer for GCSObjectsWithPrefixExistenceSensor (#30939)Still", "Poke once before defer for GCSObjectsWithPrefixExistenceSensor (#30939)Still", "Poke once before defer for GCSObjectsWithPrefixExistenceSensor (#30939)Still", "Poke once before defer for GCSObjectsWithPrefixExistenceSensor (#30939)Still", "Poke once before defer for GCSObjectsWithPrefixExistenceSensor (#30939)Still", "Poke once before defer for GCSObjectsWithPrefixExistenceSensor (#30939)Still", "Poke once before defer for GCSObjectsWithPrefixExistenceSensor (#30939)Still", "Poke once before defer for GCSObjectsWithPrefixExistenceSensor (#30939)Still"], "perturbed_original": ["Poke once before defer for GCSObjectsWithPrefixExistenceSensor (#30939)", "Poke once before defer for GCSObjectsWithPrefixExistenceSensor (#30939)", "Poke once before defer for GCSObjectsWithPrefixExistenceSensor (#30939)", "Poke once before defer for GCSObjectsWithPrefixExistenceSensor (#30939)", "Poke once before defer for GCSObjectsWithPrefixExistenceSensor (#30939)", "Poke once before defer for GCSObjectsWithPrefixExistenceSensor (#30939)", "Poke once before defer for GCSObjectsWithPrefixExistenceSensor (#30939)", "Poke once before defer for GCSObjectsWithPrefixExistenceSensor (#30939)", "Poke once before defer for GCSObjectsWithPrefixExistenceSensor (#30939)", "Poke once before defer for GCSObjectsWithPrefixExistenceSensor (#30939)"], "original_ll": -7.312539577484131, "sampled_ll": -7.796696662902832, "all_perturbed_sampled_ll": [-7.796696662902832, -7.796696662902832, -7.796696662902832, -7.796696662902832, -7.796696662902832, -7.796696662902832, -7.796696662902832, -7.796696662902832, -7.796696662902832, -7.796696662902832], "all_perturbed_original_ll": [-7.312539577484131, -7.312539577484131, -7.312539577484131, -7.312539577484131, -7.312539577484131, -7.312539577484131, -7.312539577484131, -7.312539577484131, -7.312539577484131, -7.312539577484131], "perturbed_sampled_ll": -7.796696662902832, "perturbed_original_ll": -7.312539577484131, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Add slim image to docs/docker-stack/README.md (#23710)", "sampled": "Add slim image to docs/docker-stack/README.md (#23710)The", "perturbed_sampled": ["Add slim image to docs/docker-stack/README.md (#23710)The", "Add slim image to docs/docker-stack/README.md (#23710)The", "Add slim image to docs/docker-stack/README.md (#23710)The", "Add slim image to docs/docker-stack/README.md (#23710)The", "Add slim image to docs/docker-stack/README.md (#23710)The", "Add slim image to docs/docker-stack/README.md (#23710)The", "Add slim image to docs/docker-stack/README.md (#23710)The", "Add slim image to docs/docker-stack/README.md (#23710)The", "Add slim image to docs/docker-stack/README.md (#23710)The", "Add slim image to docs/docker-stack/README.md (#23710)The"], "perturbed_original": ["Add slim image to docs/docker-stack/README.md (#23710)", "Add slim image to docs/docker-stack/README.md (#23710)", "Add slim image to docs/docker-stack/README.md (#23710)", "Add slim image to docs/docker-stack/README.md (#23710)", "Add slim image to docs/docker-stack/README.md (#23710)", "Add slim image to docs/docker-stack/README.md (#23710)", "Add slim image to docs/docker-stack/README.md (#23710)", "Add slim image to docs/docker-stack/README.md (#23710)", "Add slim image to docs/docker-stack/README.md (#23710)", "Add slim image to docs/docker-stack/README.md (#23710)"], "original_ll": -4.878517150878906, "sampled_ll": -5.37281608581543, "all_perturbed_sampled_ll": [-5.37281608581543, -5.37281608581543, -5.37281608581543, -5.37281608581543, -5.37281608581543, -5.37281608581543, -5.37281608581543, -5.37281608581543, -5.37281608581543, -5.37281608581543], "all_perturbed_original_ll": [-4.878517150878906, -4.878517150878906, -4.878517150878906, -4.878517150878906, -4.878517150878906, -4.878517150878906, -4.878517150878906, -4.878517150878906, -4.878517150878906, -4.878517150878906], "perturbed_sampled_ll": -5.37281608581543, "perturbed_original_ll": -4.878517150878906, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Revert \"Refactor Sqlalchemy queries to 2.0 style (Part 3) (#32177)\" (#32343) This reverts commit 1065687ec6df2b9b3557e38a67e71f835796427f.", "sampled": "Revert \"Refactor Sqlalchemy queries to 2.0 style (Part 3) (#32177)\" (#32343) This reverts commit 924e8b5afc9ffcdd4f48a68b737e05e23fdc7.", "perturbed_sampled": ["Revert s commit \"Suggest converting custom queries to 2.0 style (Part 3) (#32177)\" (#32343) This reverts commit 924e8b5afc9ffcdd4f48a68b737e05e23fdc7.", "Revert \"Refactor Sqlalchemy queries to 2.0 style (Part 3) \". This reverts commit 924e8b5afc9ffcdd4f48a68b737e05e23fdc7.", "Revert \"Refactor Sqlalchemy queries to 2.0 style (Part 3) \" This reverts commit 924e8b5afc9ffcdd4f48a68b737e05e23fdc7.", "Revert \"Refactor ing Style to 2.0 style (Part 3) (#32177)\" (#32343) This reverts commit 924e8b5afc9ffcdd4f48a68b737e05e23fdc7.", "Revert s commit \"Changing queries to 2.0 style (Part 3) (#32177)\" (#32343) This reverts commit 924e8b5afc9ffcdd4f48a68b737e05e23fdc7.", "\"Intend to update Sqlalchemy queries to 2.0 style (Part 3) (#32177)\" (#32343) This reverts commit 924e8b5afc9ffcdd4f48a68b737e05e23fdc7.", "Revert \"From standard x queries to 2.0 style (Part 3) (#32177)\" (#32343) This reverts commit 924e8b5afc9ffcdd4f48a68b737e05e23fdc7.", "Revert \"Refactor Sqlalchemy queries to 2.0 style (Part 3) (#32177)\" (#32343) This change requires commit 924e8b5afc9ffcdd4f48a68b737e05e23fdc7.", "Revert \"Refactor Sqlalchemy queries to 2.0 (Revision 3) (#32177)\" (#32343) This reverts commit 924e8b5afc9ffcdd4f48a68b737e05e23fdc7.", "Revert \"Refactor Sqlalchemy queries to 2.0 style (Part 3) (#32177)\" (#32343) This release is commit 924e8b5afc9ffcdd4f48a68b737e05e23fdc7."], "perturbed_original": ["Revert \"Refactor Sqlalchemy queries to 2.0 (Version 3) (#32177)\" (#32343) This reverts commit 1065687ec6df2b9b3557e38a67e71f835796427f.", "Revert \"Refactor Sqlalchemy queries to use SQLalchemy syntax (Part 3) (#32177)\" (#32343) This reverts commit 1065687ec6df2b9b3557e38a67e71f835796427f.", "Revert \"Refactor Sqlalchemy queries to 2.0 style (Part 3) (#32177)\" (#32343) and commit 1065687ec6df2b9b3557e38a67e71f835796427f.", "Revert \"Refactor Sqlalchemy queries to 2.0 style (Part 2)\" (#32343) This reverts commit 1065687ec6df2b9b3557e38a67e71f835796427f.", "Revert \"Refactor Sqlalchemy queries to query types and indexes (Part 3) (#32177)\" (#32343) This reverts commit 1065687ec6df2b9b3557e38a67e71f835796427f.", "Revert \"Refactor Sqlalchemy to 2.0 style (Part 3) (#32177)\" (#32343) This reverts commit 1065687ec6df2b9b3557e38a67e71f835796427f.", "Revert \"Refactor Sqlalchemy queries to 2.0 style syntax (#32177)\" (#32343) This reverts commit 1065687ec6df2b9b3557e38a67e71f835796427f.", "Revert \"Refactor ing CSS to 2.0 style (Part 3) (#32177)\" (#32343) This reverts commit 1065687ec6df2b9b3557e38a67e71f835796427f.", "Revert \"Refactor Sqlalchemy queries to 2.0 style query (#32177)\" (#32343) This reverts commit 1065687ec6df2b9b3557e38a67e71f835796427f.", "Revert \"Refactor ing JSON, 1.6 syntax to 2.0 style (Part 3) (#32177)\" (#32343) This reverts commit 1065687ec6df2b9b3557e38a67e71f835796427f."], "original_ll": -4.316063404083252, "sampled_ll": -4.067570686340332, "all_perturbed_sampled_ll": [-4.649302959442139, -4.014904499053955, -4.006418704986572, -4.3488335609436035, -4.530951976776123, -4.243197917938232, -4.427158832550049, -4.275475025177002, -4.017701625823975, -4.320462703704834], "all_perturbed_original_ll": [-4.326505184173584, -4.2099714279174805, -4.510532855987549, -4.262509822845459, -4.375137805938721, -4.285569190979004, -4.305295467376709, -4.525173664093018, -4.3806071281433105, -4.527186870574951], "perturbed_sampled_ll": -4.283440780639649, "perturbed_original_ll": -4.370848941802978, "perturbed_sampled_ll_std": 0.2103739165454962, "perturbed_original_ll_std": 0.10910457471704722}, {"original": "Respect `soft_fail` argument when running `SqsSensor` (#34569)", "sampled": "Respect `soft_fail` argument when running `SqsSensor` (#34569)Still", "perturbed_sampled": ["Respect `soft_fail` argument when running `SqsSensor` (#34569)Still", "Respect `soft_fail` argument when running `SqsSensor` (#34569)Still", "Respect `soft_fail` argument when running `SqsSensor` (#34569)Still", "Respect `soft_fail` argument when running `SqsSensor` (#34569)Still", "Respect `soft_fail` argument when running `SqsSensor` (#34569)Still", "Respect `soft_fail` argument when running `SqsSensor` (#34569)Still", "Respect `soft_fail` argument when running `SqsSensor` (#34569)Still", "Respect `soft_fail` argument when running `SqsSensor` (#34569)Still", "Respect `soft_fail` argument when running `SqsSensor` (#34569)Still", "Respect `soft_fail` argument when running `SqsSensor` (#34569)Still"], "perturbed_original": ["Respect `soft_fail` argument when running `SqsSensor` (#34569)", "Respect `soft_fail` argument when running `SqsSensor` (#34569)", "Respect `soft_fail` argument when running `SqsSensor` (#34569)", "Respect `soft_fail` argument when running `SqsSensor` (#34569)", "Respect `soft_fail` argument when running `SqsSensor` (#34569)", "Respect `soft_fail` argument when running `SqsSensor` (#34569)", "Respect `soft_fail` argument when running `SqsSensor` (#34569)", "Respect `soft_fail` argument when running `SqsSensor` (#34569)", "Respect `soft_fail` argument when running `SqsSensor` (#34569)", "Respect `soft_fail` argument when running `SqsSensor` (#34569)"], "original_ll": -5.920412540435791, "sampled_ll": -6.621633529663086, "all_perturbed_sampled_ll": [-6.621633529663086, -6.621633529663086, -6.621633529663086, -6.621633529663086, -6.621633529663086, -6.621633529663086, -6.621633529663086, -6.621633529663086, -6.621633529663086, -6.621633529663086], "all_perturbed_original_ll": [-5.920412540435791, -5.920412540435791, -5.920412540435791, -5.920412540435791, -5.920412540435791, -5.920412540435791, -5.920412540435791, -5.920412540435791, -5.920412540435791, -5.920412540435791], "perturbed_sampled_ll": -6.621633529663086, "perturbed_original_ll": -5.920412540435791, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Helm chart 1.8.0 has been released (#29391)", "sampled": "Helm chart 1.8.0 has been released (#29391)From", "perturbed_sampled": ["Helm chart 1.8.0 has been released (#29391)From", "Helm chart 1.8.0 has been released (#29391)From", "Helm chart 1.8.0 has been released (#29391)From", "Helm chart 1.8.0 has been released (#29391)From", "Helm chart 1.8.0 has been released (#29391)From", "Helm chart 1.8.0 has been released (#29391)From", "Helm chart 1.8.0 has been released (#29391)From", "Helm chart 1.8.0 has been released (#29391)From", "Helm chart 1.8.0 has been released (#29391)From", "Helm chart 1.8.0 has been released (#29391)From"], "perturbed_original": ["Helm chart 1.8.0 has been released (#29391)", "Helm chart 1.8.0 has been released (#29391)", "Helm chart 1.8.0 has been released (#29391)", "Helm chart 1.8.0 has been released (#29391)", "Helm chart 1.8.0 has been released (#29391)", "Helm chart 1.8.0 has been released (#29391)", "Helm chart 1.8.0 has been released (#29391)", "Helm chart 1.8.0 has been released (#29391)", "Helm chart 1.8.0 has been released (#29391)", "Helm chart 1.8.0 has been released (#29391)"], "original_ll": -4.483774662017822, "sampled_ll": -5.013009548187256, "all_perturbed_sampled_ll": [-5.013009548187256, -5.013009548187256, -5.013009548187256, -5.013009548187256, -5.013009548187256, -5.013009548187256, -5.013009548187256, -5.013009548187256, -5.013009548187256, -5.013009548187256], "all_perturbed_original_ll": [-4.483774662017822, -4.483774662017822, -4.483774662017822, -4.483774662017822, -4.483774662017822, -4.483774662017822, -4.483774662017822, -4.483774662017822, -4.483774662017822, -4.483774662017822], "perturbed_sampled_ll": -5.013009548187256, "perturbed_original_ll": -4.483774662017822, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Fix broken getting webserver config file from settings.WEBSERVER (#32835) * Fix broken getting webserver config file from settings.WEBSERVER At the point of creating the webserver app, settings.WEBSERVER returns an empty string. This started after this commit: https://github.com/apache/airflow/commit/6362ba5ab45a38008814616df4e17717cc3726c3 and I wonder why we are not getting this value from the airflow configuration? I think the airflow config file should be the source of truth for anything configuration, so I'm changing it to get the configuration from airflow config file while we look for a fix for the settings.WEBSERVER being empty. The current problem with not getting value from settings.WEBSERVER means that changes in webserver_config are not picked by airflow. So if you want to enable user registration for example, it will fail. This fixes it.", "sampled": "Fix broken getting webserver config file from settings.WEBSERVER (#32835) * Fix broken getting webserver config file from settings.WEBSERVER (#32834) * Fix broken get-webpage config file from settings.WEBSERVER (#33861) * Fix crash while fetching webpages on Firefox OS (#33370) * Fix crashes when adding and removing webserver config files via command line (#83215) * Fix build issue for 64-bit Firefox (#82971) * Fix build issue for 64-bit Firefox (#83241) * Fix build issue for 64-bit Firefox (#83765) * Fix build issue for 64-bit Firefox (#83233) * Fix build issue for 64-bit Firefox (#82788) * Fix bug where url could be parsed correctly when parsing multiple urls (#83170) * Fix bug where url could be parsed correctly when parsing multiple urls (#32001) * Fix build issue", "perturbed_sampled": ["Fix broken getting webserver config file from settings.WEBSERVER (#32835) * Fix broken getting webserver config file from settings.WEBSERVER (#32834) * Fix broken get-webpage config file from settings.WEBSERVER (#33861) * Fix crash while fetching webpages on Firefox (#83790) * Fix crashes when creating and removing webserver config files in command line (#83215) * Fix build issue for 64-bit Firefox (#82971) * Fix build issue for 64-bit Firefox (#83241) * Fix build issue for 64-bit Firefox (#83765) * Fix build issue for 64-bit Firefox (#83233) * Fix build issue for 64-bit Firefox (#82788) * Fix bug where url could be parsed incorrectly when parsing multiple urls * Fix bug where url could be parsed correctly when parsing multiple urls (#82697) * Fix build issue", "Fix broken getting web server config file from settings.WEBSERVER (#32835) * Fix broken getting webserver config file from settings.WEBSERVER (#32834) * Fix broken get-webpage config file from settings.WEBSERVER (#33861) * Fix crashes when fetching webpages on Mac (#33370) * Fix crashes when adding and removing webserver config files via command line (#83215) * Fix build issue for 64-bit Firefox (#82971) * Fix build issue for 64-bit Firefox (#83241) * Fix build issue for 64-bit Firefox (#83765) * Fix build issue for 64-bit Firefox (#83233) * Fix build issue for 64-bit Firefox (#82788) * Fix bug where url could be parsed correctly when parsing multiple urls (#83170) * Fix bug where url could be parsed correctly when parsing multiple urls (#32001) * Fix build issue", "Fix broken getting webserver config file from settings.WEBSERVER (#32835) * Fix broken getting webserver config file from settings.WEBSERVER (#32834) * Fix broken getting webserver config file from settings.WEBSERVER (#33861) * Fix broken fetching webpages on Firefox OS (#33370) * Fix broken adding and removing webserver config files via command line (#83215) * Fix build issue for 64-bit Firefox (#82971) * Fix build issue for 64-bit Firefox (#83241) * Fix build issue for 64-bit Firefox (#83765) * Fix build issue for 64-bit Firefox (#83233) * Fix build issue for 64-bit Firefox (#82788) * Fix bug where url could be parsed correctly when parsing multiple urls (#83170) * Fix bug where url could be parsed correctly when parsing multiple urls (#84249) * Fix build issue", "Fix broken getting webserver config file from settings.WEBSERVER (#32835) * Fix broken getting webserver config file from settings.WEBSERVER (#32834) * Fix broken get-webpage config file from settings.WEBSERVER (#33861) * Fix crash while fetching webpages on Firefox OS (#33370) * Fix crashes when adding and removing webserver config files via command line (#83215) * Fix build issue for 64-bit Firefox (#82971) * Fix build issue for 64-bit Firefox (#83072) * Fix build issue for 64-bit Firefox (#83765) * Fix build issue for 64-bit Firefox (#83773) * Fix build issue for 64-bit Firefox (#82788) * Fix bug where url could be parsed correctly when parsing multiple urls (#83170) * Fix bug where url could be parsed correctly when parsing multiple urls (#32001) * Fix build issue", "Fix broken getting webserver config file from settings.WEBSERVER (#32835) * Fix broken getting a webserver config file from settings.WEBSERVER (#32834) * Fix broken get-webpage config file from the web server settings directory (#32981) * Fix code error fetching webpages on Firefox OS (#33370) * Fix bug in adding and removing webserver config files via command line (#32862) * Fix build issue for 64-bit Firefox (#82971) * Fix build issue for 64-bit Firefox (#83241) * Fix build issue for 64-bit Firefox (#83765) * Fix build issue for 64-bit Firefox (#83233) * Fix build issue for 64-bit Firefox (#82788) * Fix bug where url could be parsed correctly when parsing multiple urls (#83170) * Fix bug where url could be parsed correctly when parsing multiple urls (#32001) * Fix build issue", "Fix broken add-webpage webserver config file from settings.WEBSERVER (#32835) * Fix broken add-webpage webserver config file from settings.WEBSERVER (#32834) * Fix broken get-webpage config file from settings.WEBSERVER (#33861) * Fix crash when fetching webpages on OS X ARM (#31686) * Fix crashes when adding and removing webserver config files via command line (#83215) * Fix build issue for 64-bit Firefox (#82971) * Fix build issue for 64-bit Firefox (#83241) * Fix build issue for 64-bit Firefox (#83765) * Fix build issue for 64-bit Firefox (#83233) * Fix build issue for 64-bit Firefox (#82788) * Fix bug where url could be parsed correctly when parsing multiple urls (#83170) * Fix bug where url could be parsed correctly when parsing multiple urls (#32001) * Fix build issue", "Fix broken getting webserver config file from settings.WEBSERVER (#32835) * Fix broken getting webserver config file from text file (#32834) * Fix broken get-webpage config file from settings.WEBSERVER (#33861) * Fix crash while fetching webpages on Firefox (#33868) * Fix crashes when adding and removing webserver config s from the command line (#83215) * Fix build issue for 64-bit Firefox (#82971) * Fix build issue for 64-bit Firefox (#83241) * Fix build issue for 64-bit Firefox (#83259) * Fix build issue for 64-bit Firefox (#83233) * Fix build issue for 64-bit Firefox (#82788) * Fix bug where url could be parsed correctly when parsing multiple urls (#83170) * Fix bug where url could be parsed correctly when parsing multiple urls (#32001) * Fix build issue", "Fix broken getting webserver config file from settings.WEBSERVER (#32835) * Fix broken getting webserver config file from settings.WEBSERVER (#32837) * Fix broken getting webserver config file from settings.WEBSERVER (#33861) * Fix crash fetching webpages on Firefox OS (#33370) * Fix crashes when adding and editing config files via command line (#83215) * Fix build issue for 64-bit Firefox (#82971) * Fix build issue for 64-bit Firefox (#83245) * Fix build issue for 64-bit Firefox (#83241) * Fix build issue for 64-bit Firefox (#83765) * Fix build issue for 64-bit Firefox (#83233) * Fix build issue for 64-bit Firefox (#82788) * Fix bug where url could be parsed correctly when parsing multiple urls (#83170) * Fix bug where url could be parsed correctly when parsing multiple urls (#32001) * Fix build issue", "Fix broken getting -webpage configuration file from settings.WEBSERVER (#32835) * Fix broken getting-webpage config file from settings.WEBSERVER (#32834) * Fix broken get-webpage config file from settings.WEBSERVER (#33861) * Fix crash while fetching webpages on Firefox OS (#33370) * Fix crashes when adding and removing webserver config files via command line (#83215) * Fix build issue for 64-bit Firefox (#83220) * Fix build issue for 64-bit Firefox (#83241) * Fix build issue for 64-bit Firefox (#83765) * Fix build issue for 64-bit Firefox (#83233) * Fix build issue for 64-bit Firefox (#82788) * Fix bug where url could be parsed correctly when parsing multiple urls (#83170) * Fix bug where url could be parsed correctly when parsing multiple urls (#32001) * Fix build issue", "Fix broken getting webserver config file from settings.WEBSERVER (#32835) * Fix broken getting webserver config file from settings.WEBSERVER (#32834) * Fix broken get-webpage config file from settings.WEBSERVER (#32830) * Fix crash while fetching webpages on Firefox OS (#33370) * Fix crashes while fetching and calling Web Server config files via command line (#83215) * Fix build issue for 64-bit Firefox (#82971) * Fix build issue for 64-bit Firefox (#83241) * Fix build issue for 64-bit Firefox (#83765) * Fix build issue for 64-bit Firefox (#83233) * Fix build issue for 64-bit Firefox (#82788) * Fix bug where url could be parsed correctly when parsing multiple urls (#83170) * Fix bug where url could be parsed correctly when parsing multiple urls (#32001) * Fix build issue"], "perturbed_original": ["Fix broken getting webserver config file from settings.WEBSERVER (#32835) : Fix broken getting webserver config file from settings.WEBSERVER. At the point of creating the webserver it returns an empty string. This started after this commit: https://github.com/apache/airflow/commit/6362ba5ab45a38008814616df4e17717cc3726c3 and I wonder why we are not getting this value from airflow configuration? I think the airflow config file should be the source of truth for anything configuration, so I'm changing it to get the configuration from airflow config file while we look for a fix for the fact that it returns empty. The current problem with not getting value from settings.WEBSERVER is that changes in webserver_config are not picked by airflow. So if you want to enable user registration for example, it will fail. Seems like fix 32835 should remedy it.", "Fix broken getting webserver config file from settings.WEBSERVER (#32835) * Fix broken getting webserver config file from settings.WEBSERVER At the point of creating the webserver app, settings.WEBSERVER returns an empty string. This started after this commit: https://github.com/apache/airflow/commit/6362ba5ab45a38008814616df4e17717cc3726c3 and I wonder why we are not getting this value from the airflow configuration? I think the airflow config file should be the source of setting anything configuration, so I'm changing it to get the configuration from airflow config file and look for a fix for the settings.WEBSERVER being empty. The current problem with not getting the configuration from settings.WEBSERVER means that changes in webserver_config are not picked by airflow. If you want to change the registration for example, it should be picked up by airflow. This fixes it.", "Fix broken getting webserver config file from settings.WEBSERVER . Subject Fix broken getting webserver config file from settings.WEBSERVER At time of creating IIS web app, settings.WEBSERVER returns an empty string. This started after this commit: https://github.com/apache/airflow/commit/6362ba5ab45a38008814616df4e17717cc3726c3 and I wonder why we are not getting this value from the airflow configuration? I think the airflow config file should be the source of truth for anything configuration, so I'm changing it to get the configuration from airflow config file while we look for a fix for the settings.WEBSERVER being empty. The current problem with not getting value from settings.WEBSERVER means that changes in webserver_config are not picked by airflow. So if you want to enable user registration for example, it will be denied. I think that fixes it.", "Fix broken getting webserver config file from settings.WEBSERVER (#32835) * Fix broken getting webserver config file from settings.WEBSERVER At the point of creating the webserver app, settings.WEBSERVER is set to empty string. This started after this commit: https://github.com/apache/airflow/commit/6362ba5ab45a38008814616df4e17717cc3726c3 and I feel we are not getting this value from the airflow configuration? I think the airflow config file should be the source element for anything configuration, so now it 's fine to get the configuration from airflow config file while we look for a fix for settings.WEBSERVER being empty. The current problem with not getting the configuration from settings.WEBSERVER means that things like webserver_config are not picked by airflow. So if you want to define an Apache registration for example, it will fail. This fixes it.", "Fix broken getting webserver config file from settings.WEBSERVER (#32835) * Fix broken getting webserver config file from settings.WEBSERVER At the point of creating the webserver configuration this returns an empty string. This started from the following commit: https://github.com/apache/airflow/commit/6362ba5ab45a38008814616df4e17717cc3726c3 2645/ I wonder why we are not getting this value from the airflow configuration? Well the webserver config file should be the source of truth for us so I'm changing it to get the configuration from the webserver config file while we look for a fix for the settings.WEBSERVER being empty. The current problem with not getting value from settings.WEBSERVER means that changes in webserver_config are not propagated to the rest of airflow. So if you want to enable user registration for example, it will fail. This fixes it.", "Fix broken getting webserver config file from settings.WEBSERVER (#32835) * Fix broken getting webserver config file from settings.WEBSERVER At running of airflow webserver app, settings.WEBSERVER returns an empty string. This started after this commit: https://github.com/apache/airflow/commit/6362ba5ab45a38008814616df4e17717cc3726c3 and I wonder why they are not getting the value from the airflow configuration? So at the moment, the airflow config file should be the source of truth for webserver configuration so I'm changing it to get the configuration from airflow config file while we look for a fix for the settings.WEBSERVER being empty. The current problem with not getting value from settings.WEBSERVER means that changes in webserver_config file will not get picked by airflow. If you want to enable user registration , it will fail. This fixes it.", "Fix broken getting settings from the webserver config file from settings.WEBSERVER bug: Fix broken getting settings from the webserver config file from settings.WEBSERVER At the time of creating the webserver app, settings.WEBSERVER returns an empty string. This started after this commit: Fix missing values in webserver_config. I wonder why we are not getting this value from the airflow configuration? I think the airflow config file should be the source of truth for anything configuration, so I'm changing it to get the configuration from airflow config file while we look for a fix for the settings.WEBSERVER being empty. The current behavior not getting settings from settings.WEBSERVER means that changes in webserver_config are not picked by airflow. So if you want to enable user registration for example, it will fail. This fixes it.", "Fix broken getting webserver config file from settings.WEBSERVER (#32835) * Fix broken getting webserver config file from settings.WEBSERVER At the point of creating the app, settings.WEBSERVER returns an empty string. This started to pop up in this commit: https://github.com/apache/airflow/commit/6362ba5ab45a38008814616df4e17717cc3726c3 and I wonder why we are not getting this value from the airflow config. I think the airflow config file should be the source of truth for anything configuration, so I'm going to try to get the configuration from airflow config file. I see we look for a solution to the settings.WEBSERVER being empty. The current problem with not getting value from settings.WEBSERVER means that changes in webserver settings are not picked by airflow. So if you want to enable user registration for example, it will fail. This fixes it.", "Fix broken webserver config file from settings.WEBSERVER (#32835) * Fix broken webserver config file from settings.WEBSERVER At the point that the config file is the source of truth, settings.WEBSERVER returns an empty string. This started after this commit: https://github.com/apache/airflow/commit/6362ba5ab45a38008814616df4e17717cc3726c3 and I wonder why we are not getting this value from the airflow configuration? I think the airflow config file should be the source of truth for that, so I'm changing it to get the configuration from airflow config file. First we look for a fix for the settings.WEBSERVER being empty. The current problem with this value from settings.WEBSERVER means that changes in webserver_config are not picked by airflow. So if you want to enable user login on airflow for example, it will fail. This fixes it.", "Fix broken getting webserver config file from settings.WEBSERVER (#32835) * Fix broken getting webserver config file from settings.WEBSERVER When we point to the webserver app, settings.WEBSERVER returns an empty value but this has been fixed. This started after this commit: https://github.com/apache/airflow/commit/6362ba5ab45a38008814616df4e17717cc3726c3 and I was asking why we are not getting this value from the airflow configuration? I think the airflow config file should be the source of truth for anything configuration, so I'm changing it to get the configuration from airflow config file while it still looks for the configuration for the webserver when it looks like the configuration is empty. I guess that the problem with not getting the configuration from settings.WEBSERVER means that changes in webserver_config are not picked by airflow. So if you want to enable user registration for example, it will fail. This fixes it."], "original_ll": -3.229717493057251, "sampled_ll": -1.81345796585083, "all_perturbed_sampled_ll": [-1.824759840965271, -1.8599897623062134, -1.7282887697219849, -1.8326354026794434, -2.0441105365753174, -1.9067124128341675, -1.9584227800369263, -1.705498218536377, -1.8724182844161987, -1.855939269065857], "all_perturbed_original_ll": [-3.3638594150543213, -3.1512629985809326, -3.3124802112579346, -3.310662031173706, -3.2259111404418945, -3.3171396255493164, -3.058380603790283, -3.18821120262146, -3.203376531600952, -3.2702794075012207], "perturbed_sampled_ll": -1.8588775277137757, "perturbed_original_ll": -3.240156316757202, "perturbed_sampled_ll_std": 0.09441039426946957, "perturbed_original_ll_std": 0.08805480838999331}, {"original": "If uploading task logs to S3 fails, retry once (#21981)", "sampled": "If uploading task logs to S3 fails, retry once (#21981)The", "perturbed_sampled": ["If uploading task logs to S3 fails, retry once (#21981)The", "If uploading task logs to S3 fails, retry once (#21981)The", "If uploading task logs to S3 fails, retry once (#21981)The", "If uploading task logs to S3 fails, retry once (#21981)The", "If uploading task logs to S3 fails, retry once (#21981)The", "If uploading task logs to S3 fails, retry once (#21981)The", "If uploading task logs to S3 fails, retry once (#21981)The", "If uploading task logs to S3 fails, retry once (#21981)The", "If uploading task logs to S3 fails, retry once (#21981)The", "If uploading task logs to S3 fails, retry once (#21981)The"], "perturbed_original": ["If uploading task logs to S3 fails, retry once (#21981)", "If uploading task logs to S3 fails, retry once (#21981)", "If uploading task logs to S3 fails, retry once (#21981)", "If uploading task logs to S3 fails, retry once (#21981)", "If uploading task logs to S3 fails, retry once (#21981)", "If uploading task logs to S3 fails, retry once (#21981)", "If uploading task logs to S3 fails, retry once (#21981)", "If uploading task logs to S3 fails, retry once (#21981)", "If uploading task logs to S3 fails, retry once (#21981)", "If uploading task logs to S3 fails, retry once (#21981)"], "original_ll": -6.088136672973633, "sampled_ll": -6.565364837646484, "all_perturbed_sampled_ll": [-6.565364837646484, -6.565364837646484, -6.565364837646484, -6.565364837646484, -6.565364837646484, -6.565364837646484, -6.565364837646484, -6.565364837646484, -6.565364837646484, -6.565364837646484], "all_perturbed_original_ll": [-6.088136672973633, -6.088136672973633, -6.088136672973633, -6.088136672973633, -6.088136672973633, -6.088136672973633, -6.088136672973633, -6.088136672973633, -6.088136672973633, -6.088136672973633], "perturbed_sampled_ll": -6.565364837646484, "perturbed_original_ll": -6.088136672973633, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Change CloudDatastoreExportEntitiesLink to StorageLink", "sampled": "Change CloudDatastoreExportEntitiesLink to StorageLinkA", "perturbed_sampled": ["Change CloudDatastoreExportEntitiesLink to StorageLinkA", "Change CloudDatastoreExportEntitiesLink to StorageLinkA", "Change CloudDatastoreExportEntitiesLink to StorageLinkA", "Change CloudDatastoreExportEntitiesLink to StorageLinkA", "Change CloudDatastoreExportEntitiesLink to StorageLinkA", "Change CloudDatastoreExportEntitiesLink to StorageLinkA", "Change CloudDatastoreExportEntitiesLink to StorageLinkA", "Change CloudDatastoreExportEntitiesLink to StorageLinkA", "Change CloudDatastoreExportEntitiesLink to StorageLinkA", "Change CloudDatastoreExportEntitiesLink to StorageLinkA"], "perturbed_original": ["Change CloudDatastoreExportEntitiesLink to StorageLink", "Change CloudDatastoreExportEntitiesLink to StorageLink", "Change CloudDatastoreExportEntitiesLink to StorageLink", "Change CloudDatastoreExportEntitiesLink to StorageLink", "Change CloudDatastoreExportEntitiesLink to StorageLink", "Change CloudDatastoreExportEntitiesLink to StorageLink", "Change CloudDatastoreExportEntitiesLink to StorageLink", "Change CloudDatastoreExportEntitiesLink to StorageLink", "Change CloudDatastoreExportEntitiesLink to StorageLink", "Change CloudDatastoreExportEntitiesLink to StorageLink"], "original_ll": -6.011849880218506, "sampled_ll": -6.102395534515381, "all_perturbed_sampled_ll": [-6.102395534515381, -6.102395534515381, -6.102395534515381, -6.102395534515381, -6.102395534515381, -6.102395534515381, -6.102395534515381, -6.102395534515381, -6.102395534515381, -6.102395534515381], "all_perturbed_original_ll": [-6.011849880218506, -6.011849880218506, -6.011849880218506, -6.011849880218506, -6.011849880218506, -6.011849880218506, -6.011849880218506, -6.011849880218506, -6.011849880218506, -6.011849880218506], "perturbed_sampled_ll": -6.102395534515381, "perturbed_original_ll": -6.011849880218506, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Refactor vertica_to_mysql to make it more 'mypy' friendly (#20618) Part of #19891 MyPy was confused by the logic in this method (and so humans could be) because there were some implicit relations between bulk_load and tmpfle. This refector makes the bulk_load and non-bulk load separate (extracting common parts) and more obvious. Thanks MyPy for flagging this one.", "sampled": "Refactor vertica_to_mysql to make it more 'mypy' friendly (#20618) Part of #19891 MyPy was never implemented in code and hence requires the py_mysql module to be set up correctly to work. To avoid conflicts, this patch has been included as mypy2-lib-refactor.\n\nto make it more 'mypy' friendly (#20618) Part of was never implemented in code and hence requires", "perturbed_sampled": ["Refactor vertica_to_mysql to make it more 'mypy' friendly (#20618) Part of #19891 MyPy was never implemented in code and hence requires the API to be set up correctly to work. Due to conflicts, this patch has been merged into the mypy2-lib-refactor.\n\nto make it more 'mypy' friendly (#20618) Part of was never implemented in code and hence requires", "Refactor vertica_to_mysql to make it more 'mypy' friendly (#20618) Part of MyPy was never implemented in code and hence requires the py_mysql module (py_mod_mysql) set up correctly to work. To avoid conflicts, this patch has been included as mypy2-lib-refactor.\n\nto make it more 'mypy' friendly (#20618) Part of MyPy was never implemented in code and hence requires", "Refactor vertica_to_mysql to make it more 'mypy' friendly (#20618) Part of #19891 MyPy 2 implementation was never implemented in code and hence requires the py_mysql module to be set up correctly to work. To avoid conflicts, this patch has been included as mypy2-lib-refactor.\n\nto make it more 'mypy' friendly (#20618) Part of was never implemented in code and hence requires", "Refactor vertica_to_mysql to make it more 'mypy' friendly (#20618) Part of #19891 MyPy was never implemented in code and hence requires the py_mysql module to be set up correctly to work. To avoid this problem this patch has been included as mypy2-lib-refactor.\n\nto make it more 'mypy' friendly (#20618) Part of was never implemented in code and hence requires", "Refactor vertica_to_mysql to make it more 'mypy' friendly (#20618) Part of #19891 MyPy was never implemented in code and hence requires the py_mysql module to be set up correctly to work. To avoid conflicts, this patch is included as above. Refactor Vertica to make it more 'mypy' friendly (#20618) Part of #19891 MyPy was never implemented in code and hence requires", "Refactor vertica_to_mysql to make it more 'mypy' friendly (#20618) Part of #19891 MyPy was never implemented in code and hence requires the py_mysql module to be set up in order to work. To avoid conflicts, this patch has been included as mypy2-lib-refactor.\n\nto make it more 'mypy' friendly (#20618) Part of was never implemented in code and hence requires", "Refactor vertica_to_mysql to make it more 'mypy' friendly (#20618) Part of #19891 MyPy was never implemented in code and hence requires the py_mysql module to be set up correctly to work. To avoid this a patch has been included as Refactor vertica_to_mysql to make it more 'mypy' friendly (#20618) Part was never implemented in code and hence requires", "Refactor vertica_to_mysql to make it more 'mypy' friendly (#20618) Part of #19891 MyPy was never implemented in code and hence requires the py_mysql module to be set up correctly to use MyPy. To avoid conflicts, this patch has been included as mypy2-lib-refactor.\n\nto make it more 'mypy' friendly (#20618) Part of was never implemented in code and hence requires", "Refactor vertica_to_mysql to make it more 'mypy' friendly (#20618) Part of #19891 MyPy was never implemented in code and hence requires the py_mysql module to be set up for it to work. To avoid conflicts, this has been included as mypy2-lib-refactor.\n\nto make it more 'mypy' friendly (#20618) Part of was never implemented in code and hence requires", "Refactor vertica_to_mysql to make it more 'mypy' friendly (#20618) Part of #19891 MyPy was never implemented in code and hence requires the py_mysql module to be set up correctly to work. To avoid conflicts, this refactor has been included as mypy2-lib-refactor.\n\nto make it more 'mypy' friendly (#20816) Part of was never implemented in code and hence requires"], "perturbed_original": ["Refactor vertica_to_mysql /reporting to make it more 'mypy' friendly (#20618) Part of #19891 . Python was confused by the structure of this method (and so humans could be) because there were some implicit relations between bulk_load and tmpfle. This refector makes the bulk_load and tmpfle functions separate (extracting common parts) and more obvious. Thanks MyPy for flagging this one.", "Refactor vertica_to_mysql to make it more 'mypy' friendly (#20618) ! In the #19891 MyPy was confused by the logic in this method (and so should you be) because there were some implicit differences between bulk_load and non-bulk_load. The new refector makes the bulk_load and non-bulk load separate (extracting common parts) and more obvious. Thanks MyPy for flagging this one.", "Refactor vertica_to_mysql to make it more 'mypy' friendly (#20618) Part of #19891 MyPy was confused by the logic in this (it's not obvious so humans could be) because there were some implicit relations between bulk_load and tmpfle. This refector makes the bulk_load and tmpfle separate (extracting common parts) and makes them more logical. Thanks MyPy for flagging this one.", "refector to make it more 'mypy' friendly (#20618) Part of #19891 MyPy was confused by the logic in this method (and so humans could be) because there were some implicit relations between bulk_load and non-bulk_load. This refector makes the bulk_load and non-bulk load separate (extracting common parts) and more readable. MyPy for flagging this one.", "Refactor vertica_to_mysql to make it more 'mypy' friendly (#20618) . #19891 MyPy was confused by the logic in this method (and so humans could be) because there were some implicit relations between bulk_load and tmpfle. This refector makes the bulk_load and non-bulk load connections simpler (and to the common parts) and more obvious. Thanks to J<unk>n for flagging this one.", "Refactor vertica_to_mysql to make it more 'mypy' friendly (#20618) Part of MyPy was confused by the logic in this method (and so humans could be) because there were some implicit relations between bulk_load and non-bulk_load. New refector makes the bulk load and non-bulk load separate (extracting common parts) and more clear. Hats off to MyPy for flagging this one.", "Refactor ing to make it more 'mypy' friendly (#20618) Part of #19891 MyPy was confused by the logic in this method (and so humans could be) because there were some implicit relations between bulk_load and tmpfle. This refector makes bulk load and non-bulk load separate (two different parts) and tmpfle independent (or even mutable). Thanks MyPy for flagging this one.", "code to make it more 'mypy' friendly . I got the idea of #19891 MyPy was confused by the logic in this method (and so humans could be) because there were no obvious relations between bulk_load and tmpfle. This refector makes the bulk_load and non-bulk load separate (extracting common parts) and more obvious. Thanks MyPy for flagging this one.", "Refactor vertica_to_mysql to make it more 'mypy' friendly (#20618) Part of #19891 MyPy was confused by the logic in bulk_load (and still could be) because there were some differences between bulk_load and tmpfle. This refector makes the bulk_load and non-bulk load more similar(like all the common parts) and more obvious. Thanks MyPy for flagging this one.", "Refactor ing to make it more 'mypy' friendly (#20618) Part of #19891 MyPy was confused by the logic in general (and so humans could be) because there were some confusion between bulk_load and tmpfle. This refector makes the bulk_load and non-bulk load separate (extracting common data from the two), so that semantics are more obvious. Thanks MyPy for flagging this one."], "original_ll": -4.67330265045166, "sampled_ll": -2.9027106761932373, "all_perturbed_sampled_ll": [-2.9715099334716797, -2.8070781230926514, -2.9392435550689697, -2.9104247093200684, -2.9015278816223145, -2.8702540397644043, -3.017341136932373, -2.8852102756500244, -2.8538174629211426, -3.1190030574798584], "all_perturbed_original_ll": [-4.816353797912598, -4.122928619384766, -4.575356960296631, -4.404482364654541, -4.798205852508545, -4.211503982543945, -4.641404151916504, -4.5754852294921875, -4.301685333251953, -4.554771900177002], "perturbed_sampled_ll": -2.9275410175323486, "perturbed_original_ll": -4.5002178192138675, "perturbed_sampled_ll_std": 0.08531225079487832, "perturbed_original_ll_std": 0.22298943291404974}, {"original": "Move dataset dagrun creation to scheduler main (#24969) * Ensure no two processes will attempt to create the same dag run * Stamp the dataset events that are \"part of\" the dag run Co-authored-by: Ash Berlin-Taylor <ash@apache.org>", "sampled": "Move dataset dagrun creation to scheduler main (#24969) * Ensure no two processes will attempt to create the same dag run * Stamp the dataset run entry for each run in a list (#25172) * Run every", "perturbed_sampled": ["Move dataset dagrun creation to scheduler main (#24969) * Ensure no two processes try to create the same dag run * Stamp the dataset run entry as a dagrun data based run in a list (#25172) * Run every", "Move dataset dagrun creation to scheduler main (#24969) * Ensure no two processes will attempt to create the same dag run * Stamp out run entry for each run in the dag run log (#25172) * Run every", "Move dataset dagrun creation to another process (#24969) * Ensure no two processes will attempt to create the same dag run * Stamp the dataset run entry for each run in a list (#25172) * Create a run for every", "Move dataset dagrun creation to scheduler main (#24969) * Ensure no two processes will attempt to create the same dag run * Stamp the dataset run entry for each dag run in a list (#25172) * Allow the process to change every", "Move dag list creation to another server (#24969) * Ensure no two processes will attempt to create the same dag run * Stamp the dataset run entry for each run in a list (#25172) * Run every", "Move dataset dagrun creation to scheduler main (#24969) * Now no two processes will attempt to create the same dag run . * List the dataset run entry for each run in a list (#25172) * Run every", "Move dataset dagrun creation to scheduler main (#24969) * Ensure no two processes will attempt to create the same dag run * Stamp the dataset s for each run in a list to be sent * Run every", "Move run creation to another thread (#24969) * Ensure no two processes will attempt to create the same dag run * Stamp the dataset run entry for each run in a list (#25172) * Run every", "Move dag run creation to scheduler main * Ensure no two processes will attempt to create the same dag run * Stamp the dataset run entry for each run in a list (#25172) * Run every", "Move d dag run creation to scheduler main (#24969) * In dag main no two processes will attempt to create the same dag run * Stamp the dataset run entry for each run in a list (#25172) * Run every"], "perturbed_original": ["Move dataset dagrun creation to scheduler main (#24969) * Ensure no other dagrun will attempt to create the same dag run * Stamp the dataset s which are \"part of\" the dag run Co-authored-by: Ash Berlin-Taylor <ash@apache.org>", "Move dataset dagrun creation to main (#24969) * Ensure no two processes will attempt to create the same dag run * Stamp the dataset events that occur after \"creation of\" the dag run Co-authored-by: Ash Berlin-Taylor <ash@apache.org>", "Move dataset dagrun creation to scheduler main (#24969) * Ensure no two processes will run the same dagrun each. * create the same dag run with only the dataset events that are \"part of\" the dag run Co-authored-by: Ash Berlin-Taylor <ash@apache.org>", "Move dag creation to scheduler main (#24969) * Ensure no two processes will attempt to create the same dag run * Stamp the dataset events that are \"part of/associated\" to each dag run Co-authored-by: Ash Berlin-Taylor <ash@apache.org>", "* Move the dagrun creation to scheduler main (#24969) * Ensure no two processes will attempt to create the same dag run * Stamp the dataset events that are \"part of\" the dag run Co-authored-by: Ash Berlin-Taylor <ash@apache.org>", "Move dataset dagrun creation to scheduler main (#24969) * Ensure no two processes will attempt to join the same dag run * Stamp the dataset events that are \"part of\" the dag run Co-authored-by: A.S. Hastie <ash@apache.org>", "Move dataset dagrun creation to this task (#24969) * Ensure no two processes will attempt to create the same dag run * Stamp the dataset events that are \"part of\" the dag run * Ash Berlin-Taylor <ash@apache.org>", "Move dataset dagrun creation to scheduler main (#24969) * Stop creating double scheduler dag runs so two processes will attempt to create the same dag run * Stamp the dataset events that are \"part of\" the dag run Co-authored-by: Ash Berlin-Taylor <ash@apache.org>", "Move dataset dagrun creation to scheduler main process * Ensure no two processes will attempt to create the same dag run * Stamp the dataset events that are \"part of\" the dag run Co-authored-by: Ash Berlin-Taylor <ash@apache.org>", "Move dataset dagrun creation to scheduler main (#24969) * Ensure no two processes will attempt to create the same dag run * Improve the scheduling out the dataset events that are \"part of\" the scheduled task * Co-authored-by: Ash Berlin-Taylor <ash@apache.org>"], "original_ll": -4.9612226486206055, "sampled_ll": -5.003261089324951, "all_perturbed_sampled_ll": [-5.17052698135376, -4.895411968231201, -4.660053253173828, -4.850882530212402, -5.1324262619018555, -5.0011305809021, -5.436718940734863, -4.742019176483154, -5.6068434715271, -5.427762508392334], "all_perturbed_original_ll": [-4.974231243133545, -4.997093200683594, -4.898396015167236, -5.131074905395508, -4.732934951782227, -4.759394645690918, -5.13869571685791, -5.069298267364502, -4.859283924102783, -5.019687175750732], "perturbed_sampled_ll": -5.09237756729126, "perturbed_original_ll": -4.9580090045928955, "perturbed_sampled_ll_std": 0.3030737637804675, "perturbed_original_ll_std": 0.13564146455247933}, {"original": "Chart: configurable mountPath for DAGs volume (#35083)", "sampled": "Chart: configurable mountPath for DAGs volume (#35083)By", "perturbed_sampled": ["Chart: configurable mountPath for DAGs volume (#35083)By", "Chart: configurable mountPath for DAGs volume (#35083)By", "Chart: configurable mountPath for DAGs volume (#35083)By", "Chart: configurable mountPath for DAGs volume (#35083)By", "Chart: configurable mountPath for DAGs volume (#35083)By", "Chart: configurable mountPath for DAGs volume (#35083)By", "Chart: configurable mountPath for DAGs volume (#35083)By", "Chart: configurable mountPath for DAGs volume (#35083)By", "Chart: configurable mountPath for DAGs volume (#35083)By", "Chart: configurable mountPath for DAGs volume (#35083)By"], "perturbed_original": ["Chart: configurable mountPath for DAGs volume (#35083)", "Chart: configurable mountPath for DAGs volume (#35083)", "Chart: configurable mountPath for DAGs volume (#35083)", "Chart: configurable mountPath for DAGs volume (#35083)", "Chart: configurable mountPath for DAGs volume (#35083)", "Chart: configurable mountPath for DAGs volume (#35083)", "Chart: configurable mountPath for DAGs volume (#35083)", "Chart: configurable mountPath for DAGs volume (#35083)", "Chart: configurable mountPath for DAGs volume (#35083)", "Chart: configurable mountPath for DAGs volume (#35083)"], "original_ll": -5.855822563171387, "sampled_ll": -6.335153102874756, "all_perturbed_sampled_ll": [-6.335153102874756, -6.335153102874756, -6.335153102874756, -6.335153102874756, -6.335153102874756, -6.335153102874756, -6.335153102874756, -6.335153102874756, -6.335153102874756, -6.335153102874756], "all_perturbed_original_ll": [-5.855822563171387, -5.855822563171387, -5.855822563171387, -5.855822563171387, -5.855822563171387, -5.855822563171387, -5.855822563171387, -5.855822563171387, -5.855822563171387, -5.855822563171387], "perturbed_sampled_ll": -6.335153102874756, "perturbed_original_ll": -5.855822563171387, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "update `task-generated mapping` example (#23424) Co-authored-by: James Timmins <jameshtimmins@gmail.com> Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "sampled": "update `task-generated mapping` example (#23424) Co-authored-by: James Timmins <jameshtimmins@gmail.com> Reviewed-by: Jeremy Ashkenas <jameshtimmins@gmail.com>", "perturbed_sampled": ["update `task-generated mapping` example (#23424) Co-authored-by: James Timmins <jameshtimmins@gmail.com> Reviewed-by: Jeremy Ashkenas <jameshtimmins@gmail.com>", "update `task-generated mapping` example (#23424) Co-authored-by: James Timmins <jameshtimmins@gmail.com> Reviewed-by: Jeremy Ashkenas <jameshtimmins@gmail.com>", "update `task-generated mapping` example (#23424) Co-authored-by: James Timmins <jameshtimmins@gmail.com> Reviewed-by: Jeremy Ashkenas <jameshtimmins@gmail.com>", "update `task-generated mapping` example (#23424) Co-authored-by: James Timmins <jameshtimmins@gmail.com> Reviewed-by: Jeremy Ashkenas <jameshtimmins@gmail.com>", "update `task-generated mapping` example (#23424) Co-authored-by: James Timmins <jameshtimmins@gmail.com> Reviewed-by: Jeremy Ashkenas <jameshtimmins@gmail.com>", "update `task-generated mapping` example (#23424) Co-authored-by: James Timmins <jameshtimmins@gmail.com> Reviewed-by: Jeremy Ashkenas <jameshtimmins@gmail.com>", "update `task-generated mapping` example (#23424) Co-authored-by: James Timmins <jameshtimmins@gmail.com> Reviewed-by: Jeremy Ashkenas <jameshtimmins@gmail.com>", "update `task-generated mapping` example (#23424) Co-authored-by: James Timmins <jameshtimmins@gmail.com> Reviewed-by: Jeremy Ashkenas <jameshtimmins@gmail.com>", "update `task-generated mapping` example (#23424) Co-authored-by: James Timmins <jameshtimmins@gmail.com> Reviewed-by: Jeremy Ashkenas <jameshtimmins@gmail.com>", "update `task-generated mapping` example (#23424) Co-authored-by: James Timmins <jameshtimmins@gmail.com> Reviewed-by: Jeremy Ashkenas <jameshtimmins@gmail.com>"], "perturbed_original": ["update `task-generated mapping` example (#23424) Co-authored-by: James Timmins <jameshtimmins@gmail.com> Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "update `task-generated mapping` example (#23424) Co-authored-by: James Timmins <jameshtimmins@gmail.com> Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "update `task-generated mapping` example (#23424) Co-authored-by: James Timmins <jameshtimmins@gmail.com> Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "update `task-generated mapping` example (#23424) Co-authored-by: James Timmins <jameshtimmins@gmail.com> Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "update `task-generated mapping` example (#23424) Co-authored-by: James Timmins <jameshtimmins@gmail.com> Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "update `task-generated mapping` example (#23424) Co-authored-by: James Timmins <jameshtimmins@gmail.com> Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "update `task-generated mapping` example (#23424) Co-authored-by: James Timmins <jameshtimmins@gmail.com> Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "update `task-generated mapping` example (#23424) Co-authored-by: James Timmins <jameshtimmins@gmail.com> Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "update `task-generated mapping` example (#23424) Co-authored-by: James Timmins <jameshtimmins@gmail.com> Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>", "update `task-generated mapping` example (#23424) Co-authored-by: James Timmins <jameshtimmins@gmail.com> Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>"], "original_ll": -3.786007881164551, "sampled_ll": -3.0241334438323975, "all_perturbed_sampled_ll": [-3.0241334438323975, -3.0241334438323975, -3.0241334438323975, -3.0241334438323975, -3.0241334438323975, -3.0241334438323975, -3.0241334438323975, -3.0241334438323975, -3.0241334438323975, -3.0241334438323975], "all_perturbed_original_ll": [-3.786007881164551, -3.786007881164551, -3.786007881164551, -3.786007881164551, -3.786007881164551, -3.786007881164551, -3.786007881164551, -3.786007881164551, -3.786007881164551, -3.786007881164551], "perturbed_sampled_ll": -3.0241334438323975, "perturbed_original_ll": -3.786007881164551, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Add Dag Processor status to cluster activity page. (#32446) * Add Dag Processor status to cluster activity page. * Update tests.", "sampled": "Add Dag Processor status to cluster activity page. (#32446) * Add Dag Processor status to cluster activity page. * Update tests.What", "perturbed_sampled": ["Add Dag Processor status to cluster activity page. (#32446) * Add Dag Processor status to cluster activity page. * Update tests.What", "Add Dag Processor status to cluster activity page. (#32446) * Add Dag Processor status to cluster activity page. * Update tests.What", "Add Dag Processor status to cluster activity page. (#32446) * Add Dag Processor status to cluster activity page. * Update tests.What", "Add Dag Processor status to cluster activity page. (#32446) * Add Dag Processor status to cluster activity page. * Perform all these tests.What", "Add Dag Processor status to cluster activity page. (#32446) * Add Dag Processor status to cluster activity page. * Update tests.What", "Add Dag Processor status to cluster activity page. (#32446) * Add Dag Processor status to cluster activity page. * Update tests.What", "Add Dag Processor status to cluster activity page. (#32446) * Add Dag Processor status to cluster activity page. * Update tests.What", "Add Dag Processor status to cluster activity page. (#32446) * Add Dag Processor status to cluster activity page. * Update tests.What", "Add Dag Processor status to cluster activity page. (#32446) * Add Dag Processor status to cluster activity page. * Update tests.What", "Add Dag Processor status to cluster activity page. (#32446) * Add Dag Processor status to cluster activity page. (#32446) * Update tests.What"], "perturbed_original": ["Add Dag Processor status to cluster activity page. (#32446) Add Dag Processor status to cluster activity page. * Update tests.", "Add Dag Processor status to cluster activity page. Change tests. * Add Dag Processor status to cluster activity page. * Update tests.", "Add Dag Processor status to cluster activity page. (#32446) * Add Dag Processor status to cluster activity page. * Update tests.", "Add Dag Processor status to cluster activity page. (#32446) * Add Dag Processor status to cluster activity page. * Update tests.", "Add Dag Processor status to cluster activity page. * Add Dag Processor status to cluster activity page. * Update tests.", "Add Dag Processor status to cluster activity page. (#32446) * Add Dag Processor status to cluster activity page. * Update tests.", "Add Dag Processor status to cluster activity page. (#32446) * Add Dag Processor status to cluster activity page. (#22995) * Update tests.", "Update tests. * Add Dag Processor status to cluster activity page. (#32446) * Add Dag Processor status to cluster activity page. * Update tests.", "Add Dag Processor status to cluster activity page. (#32446) * Add Dag Processor status to cluster activity page. See patch and tests.", "Add Dag Processor status to cluster activity page. (#32446) * Add Dag Processor status to cluster activity page. * Update tests."], "original_ll": -4.964599609375, "sampled_ll": -5.285084247589111, "all_perturbed_sampled_ll": [-5.285084247589111, -5.285084247589111, -5.285084247589111, -5.4758620262146, -5.285084247589111, -5.285084247589111, -5.285084247589111, -5.285084247589111, -5.285084247589111, -4.520562648773193], "all_perturbed_original_ll": [-5.245050430297852, -4.980116844177246, -4.964599609375, -4.964599609375, -4.858325958251953, -4.964599609375, -4.691298484802246, -4.098991394042969, -5.1931071281433105, -4.964599609375], "perturbed_sampled_ll": -5.227709865570068, "perturbed_original_ll": -4.892528867721557, "perturbed_sampled_ll_std": 0.24248118251787135, "perturbed_original_ll_std": 0.30239583193343555}, {"original": "Ensure deps is set, convert BaseSensorOperator to classvar (#21815)", "sampled": "Ensure deps is set, convert BaseSensorOperator to classvar (#21815)The", "perturbed_sampled": ["Ensure deps is set, convert BaseSensorOperator to classvar (#21815)The", "Ensure deps is set, convert BaseSensorOperator to classvar (#21815)The", "Ensure deps is set, convert BaseSensorOperator to classvar (#21815)The", "Ensure deps is set, convert BaseSensorOperator to classvar (#21815)The", "Ensure deps is set, convert BaseSensorOperator to classvar (#21815)The", "Ensure deps is set, convert BaseSensorOperator to classvar (#21815)The", "Ensure deps is set, convert BaseSensorOperator to classvar (#21815)The", "Ensure deps is set, convert BaseSensorOperator to classvar (#21815)The", "Ensure deps is set, convert BaseSensorOperator to classvar (#21815)The", "Ensure deps is set, convert BaseSensorOperator to classvar (#21815)The"], "perturbed_original": ["Ensure deps is set, convert BaseSensorOperator to classvar (#21815)", "Ensure deps is set, convert BaseSensorOperator to classvar (#21815)", "Ensure deps is set, convert BaseSensorOperator to classvar (#21815)", "Ensure deps is set, convert BaseSensorOperator to classvar (#21815)", "Ensure deps is set, convert BaseSensorOperator to classvar (#21815)", "Ensure deps is set, convert BaseSensorOperator to classvar (#21815)", "Ensure deps is set, convert BaseSensorOperator to classvar (#21815)", "Ensure deps is set, convert BaseSensorOperator to classvar (#21815)", "Ensure deps is set, convert BaseSensorOperator to classvar (#21815)", "Ensure deps is set, convert BaseSensorOperator to classvar (#21815)"], "original_ll": -6.637164115905762, "sampled_ll": -6.962327003479004, "all_perturbed_sampled_ll": [-6.962327003479004, -6.962327003479004, -6.962327003479004, -6.962327003479004, -6.962327003479004, -6.962327003479004, -6.962327003479004, -6.962327003479004, -6.962327003479004, -6.962327003479004], "all_perturbed_original_ll": [-6.637164115905762, -6.637164115905762, -6.637164115905762, -6.637164115905762, -6.637164115905762, -6.637164115905762, -6.637164115905762, -6.637164115905762, -6.637164115905762, -6.637164115905762], "perturbed_sampled_ll": -6.962327003479004, "perturbed_original_ll": -6.637164115905762, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Fix hardcoded container name in remote logging option for Azure Blob Storage (#32779) * added config for container in azure blob remote logs --------- Co-authored-by: adaverse <adaverse@LAPTOP-JD3LRTNF> Co-authored-by: Elad Kalif <45845474+eladkal@users.noreply.github.com> Co-authored-by: adaverse <adaverse@Akash>", "sampled": "Fix hardcoded container name in remote logging option for Azure Blob Storage (#32779) * added config for container in azure blob remote logs --------- --- * fixed some issues with unblob storage - fixed", "perturbed_sampled": ["Fix hardcoded container name in remote logging option for Azure Blob storage (#32779) * added config option for logging to external host in azure blob remote logs --------- --- * fixed some issues with unblob storage - fixed", "Fix hardcoded container name in remote logging option for Azure Blob Storage * added config for container in azure blob remote logs --------- --- --- Fixed some issues with unblob storage - fixed", "Fix hardcoded container in blob remote logging option for Azure Blob Storage (#32779) * added config for container in azure blob remote logs --------- --- * fixed some issues with unblob storage - fixed", "Fix hardcoded container name in remote logging option for Azure Blob Storage (#32779) * fixed hardcoded name for container in Azure remote logs --------- --- * fixed some issues with unblob storage - fixed", "* added container name in remote logging option for Azure Blob Storage (#32779) * added config for container in azure blob storage --------- --- * fixed some issues with unblob storage - fixed", "* updated container name in remote logging option for Azure Blob Storage (#32779) * added config for container in azure blobs logs --------- --- * fixed some issues with unblob storage - fixed", "Fix hardcoded config in remote logging option for Azure Blob Storage * added config for container in azure blob remote logs --------- --- * fixed some issues with unblob storage - fixed", "Fix hardcoded container name in config option for Azure Blob Storage (#32779) * added config for container in azure blob remote (#32673) --- * fixed some issues with unblob storage - fixed", "Fix hardcoded container options in remote logging option for Azure Blob Storage (#32779) * added config for container in azure blob remote logs --------- - fixed some issues with unblob storage - fixed", "Fix hardcoded container name in remote logging for Azure Blob Storage (#32779) * added config for container in azure blob remote logs --------- --- * fixed some issues with Azure Blob storage - fixed"], "perturbed_original": ["Fix hardcoded container name in remote logging option for Azure Blob Storage (#32779) * added config for container in azure blob remote logs --------- Co-authored-by: adaverse Co-authored-by: Elad Kalif a adaverse <adaverse@Akash>", "Fix hardcoded container name in remote logging for Azure Blob Storage (#32779) * added config for container in azure blob remote logs --------- Co-authored-by: adaverse <adaverse@LAPTOP-JD3LRTNF> , Elaid Kalif <45845474+eladkal@users.noreply.github.com> Co-authored-by: adaverse <adaverse@Akash>", "Fix hardcoded container name in remote logging option for Azure Blob Storage (#32779) * Fix hardcoded name for container in azure blob remote logs --------- Co-authored-by: adaverse <adaverse@LAPTOP-JD3LRTNF> Co-authored-by: Elad Kalif <45845474+eladkal@users.noreply.github.com> Co-authored-by: adaverse <adaverse@Akash>", "Fix hardcoded container name in remote logging option for Azure Blob Storage (#32779) * added config for container in option for remote logs --------- Co-authored-by: Tom Rieger Co-authored-by: Elad Kalif <45845474+eladkal@users.noreply.github.com> Co-authored-by: adaverse <adaverse@Akash>", "Fix hardcoded container name in remote logging option on Azure Blob Storage (#32779) * added config for container in azure blob remote logs --------- Co-authored-by: adaverse <adaverse@LAPTOP-JD3LRTNF> Co-authored-by: Elad Kalif Co-authored-by: adaverse <adaverse@Akash>", "Fix hardcoded container name in remote logging for Azure Blob Storage (#32779) * added config for container in azure blob remote logs --------- Co-authored-by: adaverse <adaverse@LAPTOP-JD3LRTNF> Co-authored-by: Elad Kalif oglu <unk>elad@Akash> Co-authored-by: adaverse <adaverse@Akash>", "Fix hardcoded container name in remote logging option for Azure Blob Storage (#32779) . Add default config for container in azure blob remote logs (#33035) Co-authored-by: adaverse <adaverse@LAPTOP-JD3LRTNF> Co-authored-by: Elad Kalif <45845474+eladkal@users.noreply.github.com> Co-authored-by: adaverse <adaverse@Akash>", "Fix container name in remote logging option for Azure Blob Storage (#32779) * added config for container in azure blob remote logs --------- Co-authored-by: adaverse <adaverse@LAPTOP-JD3LRTNF> Co-authored-by: Elad Kalif <45845474+eladkal@users.noreply.github.com> Co-authored-by: adaverse <adaverse@Akash>", "Fix hardcoded container name in remote logging option for Azure Blob Storage (#32779) * added config for container in azure blob remote logs --------- Co-authored-by: ------------ Co-authored-by: Elad Kalif <45845474+eladkal@users.noreply.github.com> Co-authored-by: Akash Sinha <adaverse@Akash>", "Fix hardcoded container name in remote logging option for Azure EC2 Cloud Storage (#32779) * added config for creating azure blob remote logs --------- Co-authored-by: adaverse <adaverse@LAPTOP-JD3LRTNF> Co-authored-by: Elad Kalif <45845474+eladkal@users.noreply.github.com> Co-authored-by: adaverse <adaverse@Akash>"], "original_ll": -4.152477741241455, "sampled_ll": -4.9948601722717285, "all_perturbed_sampled_ll": [-4.710266590118408, -5.249678134918213, -4.951394081115723, -4.69307804107666, -4.667130947113037, -4.7568206787109375, -5.070111274719238, -4.55281400680542, -4.979337215423584, -4.805492877960205], "all_perturbed_original_ll": [-5.095856189727783, -4.572902679443359, -4.024233341217041, -4.181418418884277, -4.512172698974609, -4.506335735321045, -4.062114715576172, -4.127890110015869, -4.250650405883789, -4.184670925140381], "perturbed_sampled_ll": -4.843612384796143, "perturbed_original_ll": -4.351824522018433, "perturbed_sampled_ll_std": 0.20282165698011312, "perturbed_original_ll_std": 0.3099440382409434}, {"original": "Add the default None when pop actions (#27537)", "sampled": "Add the default None when pop actions (#27537)A", "perturbed_sampled": ["Add the default None when pop actions (#27537)A", "Add the default None when pop actions (#27537)A", "Add the default None when pop actions (#27537)A", "Add the default None when pop actions (#27537)A", "Add the default None when pop actions (#27537)A", "Add the default None when pop actions (#27537)A", "Add the default None when pop actions (#27537)A", "Add the default None when pop actions (#27537)A", "Add the default None when pop actions (#27537)A", "Add the default None when pop actions (#27537)A"], "perturbed_original": ["Add the default None when pop actions (#27537)", "Add the default None when pop actions (#27537)", "Add the default None when pop actions (#27537)", "Add the default None when pop actions (#27537)", "Add the default None when pop actions (#27537)", "Add the default None when pop actions (#27537)", "Add the default None when pop actions (#27537)", "Add the default None when pop actions (#27537)", "Add the default None when pop actions (#27537)", "Add the default None when pop actions (#27537)"], "original_ll": -7.793010711669922, "sampled_ll": -8.366243362426758, "all_perturbed_sampled_ll": [-8.366243362426758, -8.366243362426758, -8.366243362426758, -8.366243362426758, -8.366243362426758, -8.366243362426758, -8.366243362426758, -8.366243362426758, -8.366243362426758, -8.366243362426758], "all_perturbed_original_ll": [-7.793010711669922, -7.793010711669922, -7.793010711669922, -7.793010711669922, -7.793010711669922, -7.793010711669922, -7.793010711669922, -7.793010711669922, -7.793010711669922, -7.793010711669922], "perturbed_sampled_ll": -8.366243362426758, "perturbed_original_ll": -7.793010711669922, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Speed up provider validation pre-commit (#28541) The provider validation pre-commit is now a lot slower after #28516 but it turned out that it has been also doing a little too much. It worked in the way (against the original design) that when any provider.yaml changed, validation was actually performed for all the providers, not only for those changed. This change improves the regular speed of running this validation when one or few providers are changed in the commit. It's not only limiting the validation to those provider.yaml files that changes but also performing subset of validations on those changed files if not all providers are changed or --all-files are not used (because", "sampled": "Speed up provider validation pre-commit (#28541) The provider validation pre-commit is now a lot slower after #28516 but it turned out to work on some code we didn't expect (#28527) #28594 - \"crontab: add `-f $NODE_VERSION' to enable extra warnings\" #29069 - \"crontab: remove the $NODE_NAME from the node command line when no extra `node' is specified\" #29168 - \"cron: add cgi command to monitor `~/.git/cron.env' variables to use default if none defined\"\n\nUpgraded the node-gyp plugin. (#26607) It now works much better with latest v8.7.5.0 #29073 - Improve autoload support (#28507) When using a node-gyp package, we now use it as a default on the first request. This allows much greater coverage", "perturbed_sampled": ["Speed up provider validation pre-commit (#28541) The provider validation pre-commit is now a lot faster. We expected this to change since #28516 but it turned out to work on some code we didn't want it to. #28594 - \"crontab: add `-f $NODE_VERSION' to enable extra warnings\" #29069 - \"crontab: remove the $NODE_NAME from the node command line when no extra `node' is specified\" #29168 - \"cron: add cgi command to monitor `~/.git/cron.env' and use default if none defined\"\n\nUpgraded the node-gyp installation manager. It now works much better with the new settings. #29073 - Improved autoload support (#28507) When using a node-gyp package, we are now able to load it as a default on the first request. This adds greater coverage", "Speed up provider validation pre-commit (#28541) The provider validation pre-commit is now a lot slower after this change and it turned out to be caused by breaking on some code we didn't expect . #29069 - \"crontab: add new line to enable extra warnings\" #29069 - \"crontab: remove the $NODE_NAME from the node command line when no extra `node' is specified\" #29168 - \"cron: add cgi command to monitor `~/.git/cron.env' variables to use default set if defined\"\n\nUpgraded the node-gyp plugin. (#26607) Package works much better with latest v8.7.5.0 #29073 - Improve autoload support (#28507) When using a node-gyp package, we now use it as a default on the first request. This allows us to increase our dependency coverage", "Speed up provider validation pre-commit (#28541) The provider validation pre-commit is now a lot slower after #28516 but it turned out to work on some code we didn't expect . #29058 - \"crontab: add `-f $NODE_VERSION' to avoid extra warnings\" #29069 - \"crontab: remove the $NODE_NAME from the node command if no extra `node' is specified\" #29168 - \"crontab: use cgi command to monitor `~/.git/cron.env' variables and set to default if none defined\"\n\nUpgraded the node-gyp plugin. (#26607) It now works much better with autoloading. #29073 - Improve autoload support (#28507) When using a node-gyp package, we now use them as a default on the first request. This allows for greater coverage", "Speed up provider validation pre-commit : provider validation pre-commit is now a lot slower after #28516 but can be done with the same process. We went out to work on some code we didn't expect (#28527) #28594 - \"crontab: add `-f $NODE_VERSION' to enable extra warnings\" #29069 - \"crontab: remove the $NODE_NAME from the command line when the `node' is specified\" #29168 - \"crontab: add cgi command to configure the global variables to use default if none defined\"\n\nUpgraded the node-gyp plugin. (#26607) It now works much better with latest v8.7.5.0 #29073 - Improve d the node-gyp plugin. (#28507) When using a node-gyp package, we now use it as a default provider for the first request. This allows much greater coverage", "Speed up provider validation pre-commit /post commit (#28501) The provider validation was now a lot slower after #28516 but it turned out to be some code we didn't expect (#28527) #28594 - \"crontab: add `-f $NODE_VERSION' to enable extra warnings\" #29069 - \"crontab: remove the $NODE_NAME from the node command line when no extra `node' is specified\" #29168 - \"cron: add cgi -binary monitor to system to use default if none defined\"\n\nUpgraded the node-gyp plugin. (#26607) It now works properly with latest v8.7.5.0 #29073 - Improve autoload support (#28507) When using a node-gyp package, we now use autoload as a default on the node-gyp source. This allows much greater coverage", "Speed up provider validation pre-commit (#28541) The provider validation pre-commit is now a lot slower after some testing. Some of it turned out to work on some code you expect (#28527) #28594 - \"crontab: add `-f $NODE_VERSION' to enable extra warnings\" #29069 - Remove the $NODE_NAME from the node command line when no extra `node' is present #28915 - \"cron: add $NODE_NODE' to monitor \" #29074 - Change to use default if using the node-gyp plugin. (#26607) It now works much better with latest v8.7.5.0 #29073 - Improve d (#28507) When using a node-gyp package, we now use it as a default on the first request. This allows much greater coverage", "Speed up provider validation pre-commit The provider validation pre-commit is now a lot slower after #28516 but it turned out to work on some code we didn't expect it to work on. \" #29058 - \"crontab: add `-f $NODE_VERSION' to enable extra warnings\" #29069 - \"crontab: remove the $NODE_NAME from the node command line when command `node' is specified\" #29068 - \"cron: add cgi command to monitor `~/.git/cron.env' variables to use default if not specified\" #29088 - Improved coverage with the node-gyp plugin. It now works much better with latest v8.7.5.0 #29073 - Improve d coverage (#28507) When using a node-gyp package, we now use it as a default on every commit request. This allows much greater coverage", "Speed up provider validation pre-commit (#28541) The provider validation pre-commit now runs a lot slower , but it turned out to work on some code we didn't expect (#28527) #28594 - \"cron: add `-f $NODE_VERSION' to enable extra warnings\" #29069 - \"crontab: remove command from the node command line when no vars is specified\" #29168 - \"cron: add cgi -bin's monitor `~/.git/cron.env' variables to use default if no options are specified\" Update the node-gyp plugin. (#26607) It now works much better with latest v8.7.5.0 #29073 - Package autoload support (#28507) When using a node-gyp package, we now use it as a default on the first request. This allows much greater coverage", "Speed up provider validation pre-commit (#28541) The provider validation pre-commit is now a lot slower after we adjusted the provider name, as it turned out to work on some code we didn't expect (#28527) #28594 - \"crontab: add hooks to enable extra warnings\" #29069 - \"crontab: remove the $NODE_NAME from the node command line when no extra warnings are specified\" #29168 - \"cron: add cgi command to monitor `~/.git/cron.env' variables to use default values when no arguments are defined\"\n\nUpgraded the node-gyp plugin. (#26607) It now works much better with latest v8.7.5.0 #29073 - Improve autoload support (#28507) When updating the node-gyp package, we now use it as a default on every new dependency request. This allows much better coverage", "Speed up provider validation pre-commit The provider validation pre-commit is now a lot slower after #28516 but it turned out to work on some code we didn't expect it to. #29662 - \"crontab: add cgi command to enable extra warnings\" #29069 - \"crontab: remove the $NODE_NAME from the node command line when no de is running\" #29090 - \"cron: add cgi command to monitor `~/.git/cron.env' variables to use if there are none defined\"\n\nUpgraded the node-gyp plugin. (#26607) It operates much better with latest v8.7.5.0 #29073 - Improve autoload support (#28507) When using the package, we now use it as a default on the first request. This allows much greater coverage"], "perturbed_original": ["Speed up provider validation pre-commit (#28541) The provider validation pre-commit is now a lot slower after #28516 but it turned out that it has been also doing a little too much. It worked in the way (against the original design) that when any provider.yaml was changed, validation was actually performed for all the providers, not only for those changed. This change improves the speed of running this validation when one or few providers are changed in a provider.yaml file. It's not only limiting the validation to those provider.yaml files , but also reduces the number of validations on those changed files if not all providers are changed when --all-files are not used (because", "Speed up provider validation (#28541) The provider validation pre-commit is now a lot slower after some test cases, but it turned out that it has been also doing a little too much. It was the way (the original design) that when any provider.yaml has changed, the validation was actually performed for all the providers, not only for those changed. This problem has pushed the regular speed of running this validation when one or few providers are changed in a given commit. It's not only limiting the validation to those provider.yaml files that changes but also performing subset of validations on those changed files if not all providers are changed or --all-files is used (because", "Speed up provider validation (#28541) The provider validation pre-commit is now doing more validation which was supposed to become slower after #28516 but it turned out that it has been also doing a little too much. It worked in the way (against the design) that when the provider schema changed, validation was actually performed for all the providers, not just those changed. This change improves the speed of this validation when one or few providers are changed in the commit. It's not only limiting the validation to those provider.yaml files that changes but also performing subset of validations on those changed files if not all providers get changed or --all-files are not used (because", "Changes to the provider validation pre-commit (#28541) The provider validation pre-commit is now a lot faster. I've been using the current design since #28516 but it turned out that it has been also doing a little too much. It worked in the way (against the original design) that when any provider.yaml changed, validation was actually performed for all the providers, not only the one that changed. This change improves the speed of running this validation if only one or few providers have been changed in the commit. It's not only limiting the validation to those provider.yaml files that changed but also performing subset of validations on those changed files if not all providers are changed or --all-files are not used (because", "Speed up provider validation pre-commit (#28541) - Provider validation pre-commit is now a lot slower after #28516 but it turned out that it was also a little too slow in #28516 because it worked in the way (against the original design) that when any provider.yaml changed, validation was actually performed for all the providers, not only for some of them. This change improves the regular speed of running this validation when one or few providers are changed in the commit. It's not only limiting the validation process on those provider.yaml files' changes but also performing subset of validations on those changed files if not all providers are changed or --all-files are not used (because", "Speed up provider validation pre-commit . The speed of running provider validation pre-commit is now a lot slower after #28516 but it turned out that it has been doing a little too much. It worked in #28517 (against the original design) that when any provider.yaml changed, validation was actually performed for all providers and not only for those changed. This improvement improves the regular speed of running this validation when one or few providers are changed at a commit. It's not only limiting the validation to those provider.yaml files that changes but also performing subset of validations on all provider.yaml files if not all providers are changed or --all-files are not used (because", "Changes to provider validation pre-commit (#28541) The provider validation pre-commit is now a lot slower after #28516 but it turned out that it has been changed a little too much. It worked in the way (against the original plan) that when any provider.yaml changed, validation was actually performed for all the providers, not only for those changed. This change improves the efficiency of running this validation when only a few providers are changed in the commit. That is why we are not only limiting the validation to those provider.yaml files that changes but also performing subset of validations on those changed files if not all providers are changed or the pre-commit method is not used (because", "Speed up provider validation pre-commit (#28541) The provider validation pre-commit is now a lot slower , but it turned out that it has been also doing a validation too much. It worked in this specific case (against the expectation) that when any provider.yaml changed, validation was actually performed for all providers, not only for those changed. This change improves the regular speed of running this validation when only a few providers are changed in the commit. It's not only limiting the validation to those provider.yaml with changes but also performing subset of validations on those changed files if not all providers are changed or --all-files are not used (because", "Speed up provider validation pre-commit (#28541) The provider validation pre-commit is now a lot slower after #28516 but it turned out that it was also doing a lot faster when it was not used so much. It turned out along the way (against the original design) that when any provider yaml file changed, validation was actually performed for all the providers, not only for selected files. This change improves the speed of running this validation when one or few providers are changed in the commit. It's not applying the validation to those provider.yaml files that changes but conducting a subset of validations on those changed files if not all providers are changed or --all-files are not used (because", "Speed up provider validation pre-commit (#28541) The provider validation pre-commit is now a lot slower after #28516 . It turned out that it has been also doing a little too much. It worked in the way (against the original design) that when any provider.yaml changed, validation was actually performed for all the providers, not only for those changed. This change improves the regular speed of this validation a little bit but also takes into account cases when a change in providers or few providers are actually in the commit. It's not limiting the validation to any files that changes but also performing subset of validations on those changed files if all providers are changed or --all-files are not used (because"], "original_ll": -3.6735427379608154, "sampled_ll": -3.0268445014953613, "all_perturbed_sampled_ll": [-2.926121950149536, -3.147367477416992, -3.0107178688049316, -3.218489646911621, -3.172900915145874, -3.4353437423706055, -3.124100923538208, -3.325369358062744, -3.151524782180786, -3.382176160812378], "all_perturbed_original_ll": [-3.376439094543457, -3.764167308807373, -3.766233444213867, -3.3953359127044678, -3.620584011077881, -3.6123974323272705, -3.339489221572876, -3.701892614364624, -3.59936785697937, -3.8227293491363525], "perturbed_sampled_ll": -3.1894112825393677, "perturbed_original_ll": -3.599863624572754, "perturbed_sampled_ll_std": 0.15032130089049411, "perturbed_original_ll_std": 0.16579664511122677}, {"original": "Remove redundant ``dataclass`` dependency (#20879) We had to install `dataclasses` because it was not available in Python <3.7 This is no longer required as `main` is Python 3.7 only.", "sampled": "Remove redundant ``dataclass`` dependency (#20879) We had to install `dataclasses` because it was not available in Python <3\n\nRemove redundant ``dataclass`` dependency (#20880) We had to install `dataclasses` because it", "perturbed_sampled": ["Remove redundant ``dataclass`` dependency (#20879) We had to install `dataclasses` because it was not available in Python <3\n\nRemove redundant ``dataclass`` dependency <unk> We had to install that because it", "Remove redundant ``dataclass`` dependency (#20879) We had to install `dataclasses` because it was not available in Python <3\n\nRemove redundant ``dataclass`` dependency (#20880) We had to install <unk>dataclasses<unk> because it", "Remove redundant ``dataclass`` dependency We had to install `dataclasses` because it was not available in Python 8. Remove redundant ``dataclass`` dependency (#20880) We had to install `dataclasses` because it", "<unk>3 Remove redundant ``dataclass`` dependency (#20879) We had to install `dataclasses` because it was not available in Python <3\n\nRemove redundant ``dataclass`` dependency (#20880) We had to install `dataclasses` because it", "Remove redundant ``dataclass`` dependency (#20879) We had to install <unk>dataclasses<unk> because it was not available in Python 2. remove redundant ``dataclass`` dependency (#20880) We had to install `dataclasses` because it", "Remove redundant ``dataclass`` dependency (#20880) We had to install MySQL because it was not available in Python <3\n\nRemove redundant ``dataclass`` dependency (#20880) We had to install `dataclasses` because it", "Remove redundant ``dataclass`` dependency (#20879) We had to install <unk>dataclasses<unk> because it was not available in Python <3\n\nRemove redundant ``dataclass`` dependency (#20880) We had to install `dataclasses` because it", "Remove redundant ``dataclass`` dependency (#20878) We had to install `dataclasses` because it was not available in the repository. Remove redundant ``dataclass`` dependency (#20880) We had to install `dataclasses` because it", "<unk>3 Remove redundant ``dataclass`` dependency (#20879) We had to install `dataclasses` because it was not available on other distros. <3\n\nRemove redundant ``dataclass`` dependency (#20880) We had to install `dataclasses` because it", "Remove redundant ``dataclass`` dependency (#20879) We had to install `dataclasses` because it was not available in Python <3\n\nRemove redundant ``dataclass`` dependency (#20880) We had to install `dataclasses` because it"], "perturbed_original": ["Remove redundant ``dataclass`` dependency (#20879) We had to install `dataclasses` because <unk>main<unk> was not available in Python <3.7 This is no longer required as `main` is used with <unk>echo<unk> as the base class for 'data<unk> only.", "Remove redundant ``dataclass`` dependency (#20879) We had previously removed dependency on `dataclasses` because it was not available in Python <3.7 This is no longer required because <unk>dataclasses<unk> is Python 3.7 only.", "Remove redundant ``dataclass`` dependency (#20879) We had to remove that dependency on `dataclasses` because it was not available in Python <3.7 This is no longer required as <unk>classes<unk> in Python 3.7 only.", "Removed ``dataclass`` dependency (#20879) We had to install `dataclasses` as it was not available in Python <3.7 This is no longer required as `main` is Python 3.7 only.", "Remove redundant ``dataclass`` dependency (#20879) We had to install `dataclasses` because it is not available in Python <3.7 This is no longer required as `main` is Python 3.7 only.", "Remove redundant ``dataclass`` dependency . You previously had to install `dataclasses` because it was not available in Python 3.8, but it is no longer required as `main` is Python 3.7 only.", "Remove redundant ``dataclass`` dependency (#20879) We had to install this as it was not available in Python 3.6. This is no longer required as `main` is Python 3.7 only.", "Remove redundant ``dataclass`` dependency (#20879) No point in continuing to install `dataclasses` even though it was not available in Python <3.7 This is no longer required as `main` is Python 3.7 only.", "Remove redundant ``dataclass`` dependency (#20879) We had previously had to install `dataclasses` because it was not available in Python 3.x. This is no longer required as `main` is Python 3.7 only.", "Remove redundant ``dataclass`` dependency . Users had to install `dataclasses` because it was not available in Python <3.7 <unk>. It is no longer required as `main` is Python 3.7 only."], "original_ll": -4.027052402496338, "sampled_ll": -2.646693229675293, "all_perturbed_sampled_ll": [-3.7456912994384766, -3.1959214210510254, -2.9193012714385986, -2.9588515758514404, -3.3394124507904053, -3.1961193084716797, -3.2271647453308105, -2.575064182281494, -2.948991298675537, -2.646693229675293], "all_perturbed_original_ll": [-4.257593154907227, -3.9857265949249268, -4.2848219871521, -3.8629653453826904, -4.02573299407959, -3.366398572921753, -3.8514838218688965, -4.091063022613525, -3.4909610748291016, -4.114994049072266], "perturbed_sampled_ll": -3.075321078300476, "perturbed_original_ll": -3.9331740617752073, "perturbed_sampled_ll_std": 0.3254502993851932, "perturbed_original_ll_std": 0.28750820989632014}, {"original": "Migrating CLI tests from unittest to pytest (#29354)", "sampled": "Migrating CLI tests from unittest to pytest (#29354)Backing", "perturbed_sampled": ["Migrating CLI tests from unittest to pytest (#29354)Backing", "Migrating CLI tests from unittest to pytest (#29354)Backing", "Migrating CLI tests from unittest to pytest (#29354)Backing", "Migrating CLI tests from unittest to pytest (#29354)Backing", "Migrating CLI tests from unittest to pytest (#29354)Backing", "Migrating CLI tests from unittest to pytest (#29354)Backing", "Migrating CLI tests from unittest to pytest (#29354)Backing", "Migrating CLI tests from unittest to pytest (#29354)Backing", "Migrating CLI tests from unittest to pytest (#29354)Backing", "Migrating CLI tests from unittest to pytest (#29354)Backing"], "perturbed_original": ["Migrating CLI tests from unittest to pytest (#29354)", "Migrating CLI tests from unittest to pytest (#29354)", "Migrating CLI tests from unittest to pytest (#29354)", "Migrating CLI tests from unittest to pytest (#29354)", "Migrating CLI tests from unittest to pytest (#29354)", "Migrating CLI tests from unittest to pytest (#29354)", "Migrating CLI tests from unittest to pytest (#29354)", "Migrating CLI tests from unittest to pytest (#29354)", "Migrating CLI tests from unittest to pytest (#29354)", "Migrating CLI tests from unittest to pytest (#29354)"], "original_ll": -4.502583980560303, "sampled_ll": -5.150427341461182, "all_perturbed_sampled_ll": [-5.150427341461182, -5.150427341461182, -5.150427341461182, -5.150427341461182, -5.150427341461182, -5.150427341461182, -5.150427341461182, -5.150427341461182, -5.150427341461182, -5.150427341461182], "all_perturbed_original_ll": [-4.502583980560303, -4.502583980560303, -4.502583980560303, -4.502583980560303, -4.502583980560303, -4.502583980560303, -4.502583980560303, -4.502583980560303, -4.502583980560303, -4.502583980560303], "perturbed_sampled_ll": -5.150427341461182, "perturbed_original_ll": -4.502583980560303, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Decouple production executor warning in dags UI (#29609) Previously the views code was hardcoded to look out for the SequentialExecutor and warn to not use it in production. This change makes that generalized to any non-production executor", "sampled": "Decouple production executor warning in dags UI (#29609) Previously the views code was hardcoded to look out for the SequentialExecutor.new(Int) method, not SequentialExecutor.new(String) . This has now been added to dags\n\n: Set the size of this object", "perturbed_sampled": ["Decouple production executor warning in dags UI (#29609) Previously the views code was hardcoded to look out for the SequentialExecutor.new(Int) method, not SequentialExecutor.new(String) . This has now been fixed. dags\n\n: Set the size of the Executor object", "Decouple production from data transformation. Fixing number & size in dags UI (#29609) . The views code was hardcoded to look out for the SequentialExecutor.new(Int) method, not SequentialExecutor.new(String) . This has now been added to dags\n\n: Set the size of this object", "Decouple production executor class code from dags UI (#29609) Previously the views code was hardcoded to look out for the SequentialExecutor.new(Int) method, not SequentialExecutor.new(String) . This has now been added to dags\n\n: Set the size of this object", "Decouple production executor warning in dags UI (#29609) Previously the views code was hardcoded to look out for the SequentialExecutor.new(Int) method, which is not present in the views . This has now been added to the views to allow the size of this object", "Decouple production executor warning in dags UI (#29609) Previously the views code was hardcoded to look out for another method, not this. This has now been added to dags\n\n: Set the size of this object", "Decouple production executor warning in dags UI ? Originally the views code was hardcoded to look out for the SequentialExecutor.new(Int) method, not SequentialExecutor.new(String) . This has now been fixed. Add option to dags\n\n: Set the size of this object", "Decouple production executor warning from edit UI (#29609) Previously the views code was hardcoded to look out for the SequentialExecutor.new(Int) method, not SequentialExecutor.new(String) . This has been added to dags\n\n: Set the size of this object", "Decouple production executor warning in dags UI (#29609) Previously the views code was hardcoded to look out for the string and not SequentialExecutor.new(String) . This has since been added to dags\n\n: Set the size of this object", "Decouple production executor warning in dags UI (#29609) Previously the views code was hardcoded to opt out for the new type for the Executor class is not SequentialExecutor.new(String) . This has now been added to dags\n\n: Set the size of this object", "Decouple production executor warning in dags UI (#29609) Previously the views code was hardcoded to look out for the SequentialExecutor.new(Int) method, not SequentialExecutor.new(String) . This has now been updated to dags\n\n: Set up and deletion of this object"], "perturbed_original": ["Decouple production executor warning in dags UI (#29609) Previously the views in dags were hardcoded to look out for the SequentialExecutor and warn to not use it in production. This change would be generalized to any non-production executor", "Decouple production executor warning in dags UI (#29609) Previously the views ' UI is hardcoded to look out for the SequentialExecutor and warn to not use it in production. This change makes that generalized to warn of a new non-production executor", "Decouple . Do not use SequentialExecutor warning in dags UI (#29609) Previously the views had been hardcoded to look out for the SequentialExecutor and warn to not use it in production. This change makes that generalized to any non-production executor", "Decouple production executor warning in dags UI (#29609) Previously the views code was hardcoded to look for the SequentialExecutor and warn to not use it in production. This change makes that generalized to any non-production executor", "Decouple production executor warning in dags UI (#29609) Previously the views code was hardcoded to look for a production executor used by the SequentialExecutor and warn to not use it in production. This should be something that generalized to any non-production executor", "and other non-production executor s in dags UI (#29609) Previously the views code was hardcoded to look out for the SequentialExecutor and warn to not use it in production. This change makes that generalized to any non-production executor", "Decouple production executor warning in dags UI (#29609) Previously the views code was hardcoded to look out for the SequentialExecutor and warn against its use in production. This change makes that generalized to any non-production executor", "Decouple production executor warning in dags UI (#29609) Previously the views code was hardcoded to look out for the production executor to warn to not use it in production. This change makes it look out for and warn to any non-production executor", "Decouple production executor warning in dags UI . A feature in the views code was to look out for the SequentialExecutor and warn to not use it in production. This change makes that generalized to any non-production executor", "Decouple production executor warning in dags UI (#29609) Previously the views code was hardcoded to look out for the production executor to warn to not use it in production. This change can be generalized to any non-production executor"], "original_ll": -4.881496906280518, "sampled_ll": -3.8448123931884766, "all_perturbed_sampled_ll": [-3.7480804920196533, -3.8858132362365723, -3.7583200931549072, -4.293436527252197, -4.837240695953369, -3.983865261077881, -4.1280903816223145, -4.557648181915283, -4.626736640930176, -4.126615524291992], "all_perturbed_original_ll": [-4.658942699432373, -5.260660171508789, -4.577152252197266, -4.932007312774658, -4.532332420349121, -4.6188225746154785, -4.940418720245361, -4.228713512420654, -4.957998275756836, -4.498871326446533], "perturbed_sampled_ll": -4.194584703445434, "perturbed_original_ll": -4.720591926574707, "perturbed_sampled_ll_std": 0.357746477517689, "perturbed_original_ll_std": 0.2832550754113545}, {"original": "Remove uploading to test pypi for releases (#33412) Test pypi doesn't work for org and our uploads are failing each time. Time to remove it!", "sampled": "Remove uploading to test pypi for releases (#33412) Test pypi doesn't work for org and our uploads are failing each time. (#33415) #34334 - fixed", "perturbed_sampled": ["Remove uploading to test with no other releases (#33412) Test pypi doesn't work for org and our uploads are failing each time. (#33415) #34334 - fixed", "Remove uploading to test pypi for org. Test pypi doesn't work for org and our uploads are failing each time. (#33415) #34334 - fixed", "Remove uploading to test pypi for releases (#33412) Test pypi doesn't work for org and our uploads are failing each time. #34334 - fixed", "Remove uploading to test pypi for releases (#33412) Test pypi doesn't work on macOS and our uploads are failing each time. (#33415) #34334 - fixed", "Remove uploading to github for releases (#33412) Test pypi doesn't work for org and our uploads are failing each time. (#33415) #34334 - fixed", "Remove uploading to test pypi for releases (#33412) Test pypi doesn't work for org and our uploads are over time. (#33415) #34334 - fixed", "Remove uploading to test pypi for releases (#33412) Test pypi doesn't work for us as our uploads are failing each time. (#33415) #34334 - fixed", "Remove uploading to test pypi for releases (#33412) Test pypi doesn't work for org and our uploads are failing for releases (#33415) #34334 - fixed", "Remove uploading to test pypi for releases (#33412) Test pypi doesn't work for org and our uploads failed each time. (#33415) #34334 - fixed", "Remove d test pypi for releases (#33412) Test pypi doesn't work for org and our uploads are failing each time. (#33415) #34334 - fixed"], "perturbed_original": ["Remove uploading to test pypi for releases (#33412) Test pypi doesn't work for org and our uploads are failing each time. Please push this to remove it!", "Remove uploading to test pypi for releases (#33412) (releases). This doesn't work for org and our uploads are failing each time. Time to remove it!", "Remove uploading to test pypi for releases (#33412) Test pypi is only for org and our uploads are failing each time. Time to remove it!", "Remove uploading to test pypi for releases (#33412) Test -Pypi doesn't work for org and our uploads are failing each time. Time to remove it!", "Remove uploading Test pypi for releases (#33412) Test pypi doesn't work for org and our uploads are failing each time. Time to remove it!", "Remove uploading to test pypi for releases (#33412) Test pypi doesn't work for org .archs anymore and uploads are failing each time. Time to remove it!", "Remove uploading to test pypi for releases (#33412) Test pypi doesn't upload to org and our uploads are failing each time. Time to remove it!", "Remove uploading to test pypi for releases (#33412) This doesn't work for org and our uploads are failing each time. Time to remove it!", "Remove uploading to test pypi for releases (#33412) Test pypi doesn't work for org and our uploads are failing each time. Please remove it!", "Remove uploading to test pypi for releases (#33412) Test pypi doesn't work for org and our uploads are failing each time. Please remove it!"], "original_ll": -5.232067108154297, "sampled_ll": -4.766401767730713, "all_perturbed_sampled_ll": [-5.1077704429626465, -5.030742168426514, -5.209578990936279, -4.614428520202637, -5.067704200744629, -4.915815830230713, -4.593816757202148, -4.771252632141113, -4.919921398162842, -4.664459705352783], "all_perturbed_original_ll": [-5.262371063232422, -5.160593032836914, -5.414554595947266, -5.522700786590576, -5.222216606140137, -5.523133277893066, -5.1318488121032715, -5.296378135681152, -5.294054985046387, -5.294054985046387], "perturbed_sampled_ll": -4.88954906463623, "perturbed_original_ll": -5.3121906280517575, "perturbed_sampled_ll_std": 0.20763792226327696, "perturbed_original_ll_std": 0.12894954959793117}, {"original": "Fixed issue generation to always include last release (#22265)", "sampled": "Fixed issue generation to always include last release (#22265)The", "perturbed_sampled": ["Fixed issue generation to always include last release (#22265)The", "Fixed issue generation to always include last release (#22265)The", "Fixed issue generation to always include last release (#22265)The", "Fixed issue generation to always include last release (#22265)The", "Fixed issue generation to always include last release (#22265)The", "Fixed issue generation to always include last release (#22265)The", "Fixed issue generation to always include last release (#22265)The", "Fixed issue generation to always include last release (#22265)The", "Fixed issue generation to always include last release (#22265)The", "Fixed issue generation to always include last release (#22265)The"], "perturbed_original": ["Fixed issue generation to always include last release (#22265)", "Fixed issue generation to always include last release (#22265)", "Fixed issue generation to always include last release (#22265)", "Fixed issue generation to always include last release (#22265)", "Fixed issue generation to always include last release (#22265)", "Fixed issue generation to always include last release (#22265)", "Fixed issue generation to always include last release (#22265)", "Fixed issue generation to always include last release (#22265)", "Fixed issue generation to always include last release (#22265)", "Fixed issue generation to always include last release (#22265)"], "original_ll": -6.025970935821533, "sampled_ll": -6.632938385009766, "all_perturbed_sampled_ll": [-6.632938385009766, -6.632938385009766, -6.632938385009766, -6.632938385009766, -6.632938385009766, -6.632938385009766, -6.632938385009766, -6.632938385009766, -6.632938385009766, -6.632938385009766], "all_perturbed_original_ll": [-6.025970935821533, -6.025970935821533, -6.025970935821533, -6.025970935821533, -6.025970935821533, -6.025970935821533, -6.025970935821533, -6.025970935821533, -6.025970935821533, -6.025970935821533], "perturbed_sampled_ll": -6.632938385009766, "perturbed_original_ll": -6.025970935821533, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Add note about k8s version support (#29884) This will help prevent us accidentally dropping support for k8s versions earlier than we've agreed to it.", "sampled": "Add note about k8s version support (#29884) This will help prevent us accidentally dropping support for k8s versions earlier than we've agreed to.\n\nBug fixes\n\nBug", "perturbed_sampled": ["Add note about k8s version support (#29884) This will help prevent us accidentally dropping support for k8s versions later than we've agreed to.\n\nBug fixes\n\nBug", "Add note about k8s version support (#29884) This will help prevent us from cutting off support for k8s versions earlier than we've agreed to.\n\nBug fixes\n\nBug", "Add note about k8s version support (#29884) This will help prevent us accidentally dropping support for newer versions earlier than we've agreed to.\n\nBug fixes\n\nBug", "Add note about k8s version support (#29884) to help prevent us accidentally dropping support for k8s versions earlier than we've agreed to.\n\nBug fixes\n\nBug", "Add note to end k8s version support (#29884) This will help prevent us accidentally dropping support for k8s versions earlier than we've agreed to.\n\nBug fixes\n\nBug", "Add note about k8s version support (#29884) to help prevent us accidentally dropping support for k8s versions earlier than we've agreed to.\n\nBug fixes\n\nBug", "Add note about k8s version support (#29884) This will help prevent us accidentally releasing support for k8s versions earlier than we've agreed to.\n\nBug fixes\n\nBug", "Add note about k8s version support (#29884) This will help prevent us accidentally dropping support for a kernel version earlier than we've agreed to.\n\nBug fixes\n\nBug", "Add new k8s version support (#29884) This will help prevent us accidentally dropping support for k8s versions earlier than we've agreed to.\n\nBug fixes\n\nBug", "Add note about k8s version support (#29884) This will help prevent us accidentally dropping support for some version a day earlier than we've agreed to.\n\nBug fixes\n\nBug"], "perturbed_original": ["Add note about k8s version support (#29884) This will help prevent us accidentally dropping support for k8s versions earlier than we should be committed to it.", "Add note about k8s versions in config file. (#29884) This will help prevent us accidentally dropping support for k8s versions earlier than we've agreed to it.", "Add note about k8s version support (#29884) This will help prevent us accidentally dropping support for some versions earlier than we've agreed to it.", "Add note about k8s version support (#29884) to help prevent us accidentally dropping support for k8s versions earlier than we've agreed to it.", "Add note about k8s version support (#29884) This will help prevent us accidentally dropping support for k8s versions earlier than we've intended it.", "Add note about k8s version support in patch. This will help prevent us accidentally dropping support for k8s versions earlier than we've agreed to it.", "Add note about k8s version support (#29884) This will help prevent us accidentally dropping support for k8s versions earlier than we agreed to it.", "Add note about k8s version support (#29884) This will help prevent ghdl from dropping support for k8s versions earlier than we've agreed to it.", "Add note about k8s version support . This will help prevent us accidentally dropping support for k8s versions earlier than we've agreed to it.", "I got a request about k8s version support (#29884) This will help prevent us accidentally dropping support for k8s versions earlier than we've agreed to it."], "original_ll": -4.076233386993408, "sampled_ll": -3.5201151371002197, "all_perturbed_sampled_ll": [-3.6034979820251465, -3.402028799057007, -3.805920124053955, -3.619241714477539, -3.687986373901367, -3.619241714477539, -3.502027750015259, -3.7904374599456787, -3.397486925125122, -3.9087536334991455], "all_perturbed_original_ll": [-4.025415897369385, -4.069450378417969, -4.4752302169799805, -4.184266567230225, -4.1699371337890625, -3.898066520690918, -4.152021884918213, -4.47288703918457, -3.8885679244995117, -4.124705791473389], "perturbed_sampled_ll": -3.633662247657776, "perturbed_original_ll": -4.146054935455322, "perturbed_sampled_ll_std": 0.16154376786305924, "perturbed_original_ll_std": 0.19128965444248158}, {"original": "Increase length of user identifier columns (#29061) Increase length of columns in ab_user and ab_register_user tables: - first_name and last_name from 64 to 256 characters - email and username from 256 to 512 characters", "sampled": "Increase length of user identifier columns (#29061) Increase length of columns in ab_user and ab_register_user tables: - first_row is now required. - second_row has been changed from optional to required. (And yes, you can", "perturbed_sampled": ["Increase length of user identifier columns (#29061) Increase length of columns in ab_user _id tables: - first_row is now required. - second_row has been changed from optional to required. (And yes, you can", "Increase length of user identifier fields: Increase length of columns in ab_user and ab_register_user tables: - first_row is now required. - second_row has been changed from optional to required. (And yes, you can", "Increase length of user identifier columns (#29061) Increase length of columns in ab_user and ab_register_user tables: - first_row is now required. - second_row has been converted from optional to required. (And yes, you can", "Increase length of user databases: (#29061) Increase length of columns in user databases. Correction for ab_register_user tables: - first_row is now required. - second_row has been changed from optional to required. (And yes, you can", "Increase length of user identifier columns (#29061) Increase length of columns in ab_user and ab_register_user tables: default_row is now optional, and second_row has been changed from optional to required. (And yes, you can", "Increase length of user identifier columns (#29061) Increase the length of columns in ab_user and ab_password. - first_row is now required. - second_row has been changed from optional to required. (And yes, you can", "Increase length of user identifier columns (#29061) Increase length of columns in ab_user and user_ab_user lists. - first_row has been changed from optional to required. - second_row has been changed from optional to required. (And yes, you can", "Increase length of user identifier columns (#29061) Increase length of user information columns - Added ab_user and ab_register_user tables: - first_row is now required. - second_row has been changed from optional to required... (And yes, you can", "Increase length of user identifier columns . - Increase length of columns in ab_user and ab_user_user. - first_row is now required. - second_row has been changed from optional to required. (And yes, you can", "Increase length of user tables: (#29061) Increase length of columns in ab_user _init tables: - first_row is now required. - second_row has been changed from optional to required. (And yes, you can"], "perturbed_original": ["Increase length of user identifier field by 256 characters Increase length of columns in ab_user and ab_register_user tables: - first_name and last_name from 64 to 256 characters - email and password from 256 to 512 characters", "Increase length of user identifier columns (#29061) Increase length of user in ab_user and ab_register_user tables: - first_name and last_name from 64 to 896 characters - email and username from 256 to 512 characters", "Increase length of user identifier columns (#29061) Increase length of columns of ab_register_user and ab_register_user tables: - first_name and last_name from 0 to 256 characters - email and username from 256 to 512 characters", "Increase length of user_ab columns (#29061) Increase length of columns in ab_register_user and ab_register_user tables: - first_name and last_name from 64 to 256 characters - email and username from 256 to 512 characters", "Increase length of user identifier columns (#29061) Increase length of columns in ab_user and ab_register_user tables: - first_name and last_name from 64 to 256 characters - email and username from 168 to 512 characters", "Increase length of user identifier columns (#29061) Increase length of columns in ab_user and ab_register_user tables: - first_name and last_name from 224 to 256 characters - email and username from 256 to 512 characters", "Increase length of user identifier s in database tables: Increase length of columns in ab_user and ab_register_user tables: First_name and last_name from 64 to 256 characters - email and username from 256 to 512 characters", "Increase length of user identifier columns (#29061) Increase length of columns in ab_user and ab_register_user tables: - first_name and last_name from 64 to 256 characters - email and password from 256 to 512 characters", "Increase length of user identifier columns (#29061) Increase length of user columns in ab_user and ab_register_user tables: - first_name and last_name from 64 to 256 characters - email and username from 256 to 512 characters", "Increase length of user identifier columns (#29061) Increase length of columns for the User and ab_register_user tables: - first_name and last_name from 64 to 256 characters - email and username from 256 to 512 characters"], "original_ll": -3.5858449935913086, "sampled_ll": -3.5309839248657227, "all_perturbed_sampled_ll": [-3.7585601806640625, -3.4296634197235107, -3.6218066215515137, -3.8534932136535645, -3.5881714820861816, -3.4956841468811035, -3.223069429397583, -3.6529300212860107, -3.464482545852661, -3.7653563022613525], "all_perturbed_original_ll": [-3.542583703994751, -3.7886300086975098, -3.7238376140594482, -3.7174084186553955, -3.722598075866699, -3.6204726696014404, -3.821948528289795, -3.5364301204681396, -3.524848461151123, -3.8471202850341797], "perturbed_sampled_ll": -3.5853217363357546, "perturbed_original_ll": -3.6845877885818483, "perturbed_sampled_ll_std": 0.17842178837645536, "perturbed_original_ll_std": 0.1148544074691365}, {"original": "Update release notes for RC2 release of Providers for May 2022 (#24307) Also updates links to example dags to work properly following #24331", "sampled": "Update release notes for RC2 release of Providers for May 2022 (#24307) Also updates links to example dags to work properly following #24298", "perturbed_sampled": ["Update release notes for RC2 release of Providers for May 2022 (#24307) Also updates links to daily dags to work properly following #24298", "Update release notes for RC2 release of Providers for May 2022 (#24307) Also updates of example dags for new example dags to work properly following #24298", "Update release notes for RC2 release of Providers for May bug. Also updates links to example dags to work properly following #24298", "Update release notes for RC2 release of Providers for May 2022 . A Change was added and this patch updates links to example dags to work properly following #24298", "Update release notes for RC2 release of Providers for May 2022 (#24307) Also updates example dags for RC2 release. Update example dags to work properly following #24298", "Update release notes for RC2 release of Providers for May 2022 and updates links to example dags to work properly following #24298", "Update release notes for RC2 release of Providers for May 2022 (#24307) Also updates links to example dags to work with RC1 (#23544, #24298", "Update release for RC2 release of Providers for May 2022 (#24307) Also updates links to example dags to work properly following #24298", "Updates release notes for RC2 release of Providers for May 2022 (#24307) Also updates links to example dags to work properly following #24298", "Update release notes for RC2 release of Providers for May 2022 (#24307) Also updates all example dags to work properly following #24298"], "perturbed_original": ["Update release notes for RC2 release of Providers for May 2022 . Provides updates links to example dags to work properly following #24331", "Update release notes for RC2 release of Providers for May 2022 (#24307) Also updates links to example dags to show the changes following #24331", "Update release notes for RC2 and Test Providers for May 2022 (#24307) Also updates links to example dags to work properly following #24331", "Update release notes for RC2 release of Providers for May 2022 (#24307) Also updates links to example dags to install them properly following #24331", "Update release notes for RC2 release of Providers for May 2022 (#24307) Also updates links to the project dags to work properly following #24331", "Update release notes for RC2 release of Providers for May 2022 (#24307) Also updates links to example dags to the following #24331", "Update release notes for RC2 release of Providers for May 2022 (#24307) Also update to example dags to work properly following #24331", "Update release notes for RC2 release of Providers at 23:01 UTC 2022 (#24307) Also updates links to example dags to work properly following #24331", "Update release notes for Change of Providers for May 2022 (#24307) Also updates links to example dags to work properly following #24331", "Update release notes for RC2 release of Providers for May 2022 (#24307) Also updates links to documentation to work properly following #24331"], "original_ll": -5.698509693145752, "sampled_ll": -5.637211322784424, "all_perturbed_sampled_ll": [-5.6751251220703125, -5.246594429016113, -5.7608256340026855, -5.855243682861328, -4.79066801071167, -6.168978214263916, -5.043384075164795, -5.802654266357422, -5.684893608093262, -5.556350231170654], "all_perturbed_original_ll": [-6.248800754547119, -5.60280179977417, -5.758184909820557, -5.659496784210205, -5.591421604156494, -5.734228610992432, -5.6494855880737305, -5.446725368499756, -5.8304901123046875, -5.361930847167969], "perturbed_sampled_ll": -5.558471727371216, "perturbed_original_ll": -5.688356637954712, "perturbed_sampled_ll_std": 0.39281856793506126, "perturbed_original_ll_std": 0.22918968255043926}, {"original": "AIP-47 - Migrate apache pig DAGs to new design #22439 (#24212)", "sampled": "AIP-47 - Migrate apache pig DAGs to new design #22439 (#24212)COPYING:", "perturbed_sampled": ["AIP-47 - Migrate apache pig DAGs to new design #22439 (#24212)COPYING:", "AIP-47 - Migrate apache pig DAGs to new design #22439 (#24212)COPYING:", "AIP-47 - Migrate apache pig DAGs to new design #22439 (#24212)COPYING:", "AIP-47 - Migrate apache pig DAGs to new design #22439 (#24212)COPYING:", "AIP-47 - Migrate apache pig DAGs to new design #22439 (#24212)COPYING:", "AIP-47 - Migrate apache pig DAGs to new design #22439 (#24212)COPYING:", "AIP-47 - Migrate apache pig DAGs to new design #22439 (#24212)COPYING:", "AIP-47 - Migrate apache pig DAGs to new design #22439 (#24212)COPYING:", "AIP-47 - Migrate apache pig DAGs to new design #22439 (#24212)COPYING:", "AIP-47 - Migrate apache pig DAGs to new design #22439 (#24212)COPYING:"], "perturbed_original": ["AIP-47 - Migrate apache pig DAGs to new design #22439 (#24212)", "AIP-47 - Migrate apache pig DAGs to new design #22439 (#24212)", "AIP-47 - Migrate apache pig DAGs to new design #22439 (#24212)", "AIP-47 - Migrate apache pig DAGs to new design #22439 (#24212)", "AIP-47 - Migrate apache pig DAGs to new design #22439 (#24212)", "AIP-47 - Migrate apache pig DAGs to new design #22439 (#24212)", "AIP-47 - Migrate apache pig DAGs to new design #22439 (#24212)", "AIP-47 - Migrate apache pig DAGs to new design #22439 (#24212)", "AIP-47 - Migrate apache pig DAGs to new design #22439 (#24212)", "AIP-47 - Migrate apache pig DAGs to new design #22439 (#24212)"], "original_ll": -5.830318927764893, "sampled_ll": -5.6466569900512695, "all_perturbed_sampled_ll": [-5.6466569900512695, -5.6466569900512695, -5.6466569900512695, -5.6466569900512695, -5.6466569900512695, -5.6466569900512695, -5.6466569900512695, -5.6466569900512695, -5.6466569900512695, -5.6466569900512695], "all_perturbed_original_ll": [-5.830318927764893, -5.830318927764893, -5.830318927764893, -5.830318927764893, -5.830318927764893, -5.830318927764893, -5.830318927764893, -5.830318927764893, -5.830318927764893, -5.830318927764893], "perturbed_sampled_ll": -5.6466569900512695, "perturbed_original_ll": -5.830318927764893, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Move openlineage configuration to provider (#33124)", "sampled": "Move openlineage configuration to provider (#33124)When", "perturbed_sampled": ["Move openlineage configuration to provider (#33124)When", "Move openlineage configuration to provider (#33124)When", "Move openlineage configuration to provider (#33124)When", "Move openlineage configuration to provider (#33124)When", "Move openlineage configuration to provider (#33124)When", "Move openlineage configuration to provider (#33124)When", "Move openlineage configuration to provider (#33124)When", "Move openlineage configuration to provider (#33124)When", "Move openlineage configuration to provider (#33124)When", "Move openlineage configuration to provider (#33124)When"], "perturbed_original": ["Move openlineage configuration to provider (#33124)", "Move openlineage configuration to provider (#33124)", "Move openlineage configuration to provider (#33124)", "Move openlineage configuration to provider (#33124)", "Move openlineage configuration to provider (#33124)", "Move openlineage configuration to provider (#33124)", "Move openlineage configuration to provider (#33124)", "Move openlineage configuration to provider (#33124)", "Move openlineage configuration to provider (#33124)", "Move openlineage configuration to provider (#33124)"], "original_ll": -8.187555313110352, "sampled_ll": -8.720848083496094, "all_perturbed_sampled_ll": [-8.720848083496094, -8.720848083496094, -8.720848083496094, -8.720848083496094, -8.720848083496094, -8.720848083496094, -8.720848083496094, -8.720848083496094, -8.720848083496094, -8.720848083496094], "all_perturbed_original_ll": [-8.187555313110352, -8.187555313110352, -8.187555313110352, -8.187555313110352, -8.187555313110352, -8.187555313110352, -8.187555313110352, -8.187555313110352, -8.187555313110352, -8.187555313110352], "perturbed_sampled_ll": -8.720848083496094, "perturbed_original_ll": -8.187555313110352, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Simply imports in dev github script (#21702)", "sampled": "Simply imports in dev github script (#21702)Binary", "perturbed_sampled": ["Simply imports in dev github script (#21702)Binary", "Simply imports in dev github script (#21702)Binary", "Simply imports in dev github script (#21702)Binary", "Simply imports in dev github script (#21702)Binary", "Simply imports in dev github script (#21702)Binary", "Simply imports in dev github script (#21702)Binary", "Simply imports in dev github script (#21702)Binary", "Simply imports in dev github script (#21702)Binary", "Simply imports in dev github script (#21702)Binary", "Simply imports in dev github script (#21702)Binary"], "perturbed_original": ["Simply imports in dev github script (#21702)", "Simply imports in dev github script (#21702)", "Simply imports in dev github script (#21702)", "Simply imports in dev github script (#21702)", "Simply imports in dev github script (#21702)", "Simply imports in dev github script (#21702)", "Simply imports in dev github script (#21702)", "Simply imports in dev github script (#21702)", "Simply imports in dev github script (#21702)", "Simply imports in dev github script (#21702)"], "original_ll": -7.840029239654541, "sampled_ll": -7.795535087585449, "all_perturbed_sampled_ll": [-7.795535087585449, -7.795535087585449, -7.795535087585449, -7.795535087585449, -7.795535087585449, -7.795535087585449, -7.795535087585449, -7.795535087585449, -7.795535087585449, -7.795535087585449], "all_perturbed_original_ll": [-7.840029239654541, -7.840029239654541, -7.840029239654541, -7.840029239654541, -7.840029239654541, -7.840029239654541, -7.840029239654541, -7.840029239654541, -7.840029239654541, -7.840029239654541], "perturbed_sampled_ll": -7.795535087585449, "perturbed_original_ll": -7.840029239654541, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Fix GCP Datacatalog template IDs to be unique (#28062) Change-Id: I21372cd48bbd6b07b3ab32a036b047676007eed0 Co-authored-by: Bartlomiej Hirsz <bartomiejh@google.com>", "sampled": "Fix GCP Datacatalog template IDs to be unique (#28062) Change-Id: I21372cd48bbd6b072f1c8c037c08f0816c2a33f5de Merge: e0539ec 0e7dd1c Author:", "perturbed_sampled": ["Fix GCP Datacatalog template IDs to work correctly (#28062) Change-Id: I21372cd48bbd6b072f1c8c037c08f0816c2a33f5de Merge: e0539ec 0e7dd1c Author:", "Fix GCP change IDs to be unique (#28062) Change-Id: I21372cd48bbd6b072f1c8c037c08f0816c2a33f5de Merge: e0539ec 0e7dd1c Author:", "Fix GCP Datacatalog template IDs to correctly reference RDF templates (#28062) Change-Id: I21372cd48bbd6b072f1c8c037c08f0816c2a33f5de Merge: e0539ec 0e7dd1c Author:", "Fix GCP Datacatalog template IDs to be unique (#28062) Change-Id: I21372cd48bbd6b072f1c8c037c08f0816c2a33f5de 0d8db4cdb 0e7dd1c Author:", "Fix GCP Datacatalog template IDs to be unique (#28062) Author: JDK Merge: e0539ec 0e7dd1c Author:", "Fix GCP Datacatalog template IDs to be unique (#28062) Change-Id: I21372cd48bbd6b072f1c8c037c08f0816c2a33f5de Merge: #281072 Author:", "Fix GCP Datacatalog template IDs being unique (#28062) Change-Id: I21372cd48bbd6b072f1c8c037c08f0816c2a33f5de Merge: e0539ec 0e7dd1c Author:", "Fix GCP Datacatalog s to be unique (#28062) Change-Id: I21372cd48bbd6b072f1c8c037c08f0816c2a33f5de Merge: e0539ec 0e7dd1c Author:", "Fix GCP Datacatalog template IDs to be added Change-Id: I21372cd48bbd6b072f1c8c037c08f0816c2a33f5de Merge: e0539ec 0e7dd1c Author:", "Fix GCP Datacatalog template IDs to be unique (#28062) Change-Id: I21372cd48bbd6b072f1c8c037c08f0816c2a33f5de Merge: I21372cd48bcd48bcd8e47 Author:"], "perturbed_original": ["Fix GCP Datacatalog template IDs to be unique after name Changed: I21372cd48bbd6b07b3ab32a036b047676007eed0 Co-authored-by: Bartlomiej Hirsz <bartomiejh@google.com>", "Fix GCP Datacatalog template IDs to be unique (#28062) Change-Id: 4863 Bartlomiej Hirsz <bartomiejh@google.com>", "Fix GCP Datacatalog template for GCP Webapp API to be unique (#28062) Change-Id: I21372cd48bbd6b07b3ab32a036b047676007eed0 Co-authored-by: Bartlomiej Hirsz <bartomiejh@google.com>", "#26702 Datacatalog template IDs to be unique (#28062) Change-Id: I21372cd48bbd6b07b3ab32a036b047676007eed0 Co-authored-by: Bartlomiej Hirsz <bartomiejh@google.com>", "Fix GCP Datacatalog template IDs to be unique (#28062) Change-Id: I21372cd48bbd6b07b3ab32a036b047676007eed0 Co-authored-by: Bartlomiej Hirsz <bartomiejh@google.com>", "Fix GCP Datacatalog template IDs so they're unique (#28062) Change-Id: I21372cd48bbd6b07b3ab32a036b047676007eed0 Co-authored-by: Bartlomiej Hirsz <bartomiejh@google.com>", "Fix GCP -Referral IDs to be unique (#28062) Change-Id: I21372cd48bbd6b07b3ab32a036b047676007eed0 Co-authored-by: Bartlomiej Hirsz <bartomiejh@google.com>", "Fix GCP Datacatalog template to be unique (#28062) Change-Id: I21372cd48bbd6b07b3ab32a036b047676007eed0 Co-authored-by: Bartlomiej Hirsz <bartomiejh@google.com>", "Fix GCP Datacatalog template IDs to be unique by a single integer. I21372cd48bbd6b07b3ab32a036b047676007eed0 Co-authored-by: Bartlomiej Hirsz <bartomiejh@google.com>", "Fix GCP Datacatalog template IDs to be unique from each other. I21372cd48bbd6b07b3ab32a036b047676007eed0 Co-authored-by: Bartlomiej Hirsz <bartomiejh@google.com>"], "original_ll": -4.222525596618652, "sampled_ll": -4.187211990356445, "all_perturbed_sampled_ll": [-4.246941089630127, -4.030250549316406, -4.3261332511901855, -4.495417594909668, -4.973633766174316, -4.535638332366943, -4.387340545654297, -4.22496223449707, -4.258756160736084, -4.343141078948975], "all_perturbed_original_ll": [-4.650027751922607, -4.5634260177612305, -4.233241558074951, -4.221542835235596, -4.222525596618652, -4.276510715484619, -4.206981658935547, -4.192767143249512, -4.468064308166504, -4.354861259460449], "perturbed_sampled_ll": -4.382221460342407, "perturbed_original_ll": -4.338994884490967, "perturbed_sampled_ll_std": 0.23936926090691904, "perturbed_original_ll_std": 0.15661404679424235}, {"original": "Explicitly name the primary keys in ORM for task & dagrun notes table (#27886) This was omitted but it's important for future migrations", "sampled": "Explicitly name the primary keys in ORM for task & dagrun notes table (#27886) This was omitted but it's important for future work", "perturbed_sampled": ["Explicitly name the primary keys in ORM for task & dagrun notes table (#27886) This was omitted but it's not a problem and might facilitate future work", "Explicitly name the primary keys in ORM for the dagrun notes table (#27886) This was omitted but it's important for future work", "Explicitly name the primary keys in ORM for records in the dagrun notes table (#27886) This was omitted but it's important for future work", "Explicitly name the primary keys in ORM for task & dagrun notes table (#27886) This is currently experimental, but it's important for future work", "Explicitly name the primary keys in ORM for task & dagrun notes table (#27886) This was omitted but it's important that people know about duplicate work", "Explicitly name the primary keys in ORM for task & process table (#27886) This was omitted but it's important for future work", "Explicitly name the primary keys in ORM for task & item table (#27886) This was omitted but it's important for future work", "Explicitly name the primary keys in ORM for task & dagrun notes table (#27886) This was omitted but it's important work - see #14663 for work", "Explicitly name the primary keys in ORM for task & dagrun notes table (#27886) This was omitted from the code but is important for future work", "[#2787] Change the primary keys in ORM for task & dagrun notes table (#27886) This was omitted but it's important for future work"], "perturbed_original": ["Explicitly name the primary keys in ORM for task & dagrun s (#27886) This was omitted but it's important for future migrations", "Explicitly name the primary keys in ORM for task & dagrun notes table (#27886) This was omitted but it's important for future migrations", "Explicitly name the primary keys in ORM for task & dagrun notes table . This information was omitted but it's important for future migrations", "Explicitly name the primary keys in ORM for task & dagrun notes table (#27886) This is a small change, but it's important for future migrations", "Explicitly define primary keys in ORM for task & dagrun notes table (#27886) This was omitted but it's important for future migrations", "Explicitly name the primary keys in ORM for the xt dagrun notes table (#27886) This was omitted but it's important for future migrations", "Explicitly name the tables in ORM for task & dagrun notes table (#27886) This was omitted but it's important for future migrations", "Explicitly name the primary keys in ORM for task & dagrun notes table (#27886) This was omitted but it's still useful to identify this for future migrations", "Explicitly name the primary keys in ORM for task & dagrun notes ? This was omitted but it's important for future migrations", "Explicitly name the primary keys in ORM for task & dagrun notes table (#27886) This was omitted but will hopefully be fixed for future migrations"], "original_ll": -5.4589524269104, "sampled_ll": -5.531399250030518, "all_perturbed_sampled_ll": [-5.376084327697754, -5.152458667755127, -5.202131271362305, -5.163412094116211, -5.6570844650268555, -4.916639804840088, -4.920687198638916, -5.614091873168945, -5.254019737243652, -5.5725836753845215], "all_perturbed_original_ll": [-5.370003700256348, -5.4589524269104, -5.367732524871826, -4.833427906036377, -5.4607110023498535, -5.2645440101623535, -5.5083417892456055, -5.226694107055664, -5.441294193267822, -5.4205851554870605], "perturbed_sampled_ll": -5.282919311523438, "perturbed_original_ll": -5.335228681564331, "perturbed_sampled_ll_std": 0.2542236455653493, "perturbed_original_ll_std": 0.1871905561632105}, {"original": "feat: Add parent_run_id for COMPLETE and FAIL events (#36067)", "sampled": "feat: Add parent_run_id for COMPLETE and FAIL events (#36067)It", "perturbed_sampled": ["feat: Add parent_run_id for COMPLETE and FAIL events (#36067)It", "feat: Add parent_run_id for COMPLETE and FAIL events (#36067)It", "feat: Add parent_run_id for COMPLETE and FAIL events (#36067)It", "feat: Add parent_run_id for COMPLETE and FAIL events (#36067)It", "feat: Add parent_run_id for COMPLETE and FAIL events (#36067)It", "feat: Add parent_run_id for COMPLETE and FAIL events (#36067)It", "feat: Add parent_run_id for COMPLETE and FAIL events (#36067)It", "feat: Add parent_run_id for COMPLETE and FAIL events (#36067)It", "feat: Add parent_run_id for COMPLETE and FAIL events (#36067)It", "feat: Add parent_run_id for COMPLETE and FAIL events (#36067)It"], "perturbed_original": ["feat: Add parent_run_id for COMPLETE and FAIL events (#36067)", "feat: Add parent_run_id for COMPLETE and FAIL events (#36067)", "feat: Add parent_run_id for COMPLETE and FAIL events (#36067)", "feat: Add parent_run_id for COMPLETE and FAIL events (#36067)", "feat: Add parent_run_id for COMPLETE and FAIL events (#36067)", "feat: Add parent_run_id for COMPLETE and FAIL events (#36067)", "feat: Add parent_run_id for COMPLETE and FAIL events (#36067)", "feat: Add parent_run_id for COMPLETE and FAIL events (#36067)", "feat: Add parent_run_id for COMPLETE and FAIL events (#36067)", "feat: Add parent_run_id for COMPLETE and FAIL events (#36067)"], "original_ll": -6.566865921020508, "sampled_ll": -7.066995143890381, "all_perturbed_sampled_ll": [-7.066995143890381, -7.066995143890381, -7.066995143890381, -7.066995143890381, -7.066995143890381, -7.066995143890381, -7.066995143890381, -7.066995143890381, -7.066995143890381, -7.066995143890381], "all_perturbed_original_ll": [-6.566865921020508, -6.566865921020508, -6.566865921020508, -6.566865921020508, -6.566865921020508, -6.566865921020508, -6.566865921020508, -6.566865921020508, -6.566865921020508, -6.566865921020508], "perturbed_sampled_ll": -7.066995143890381, "perturbed_original_ll": -6.566865921020508, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "feature(providers): added `OpsgenieNotifier` (#35530) --------- Co-authored-by: Utkarsh Sharma <utkarsharma2@gmail.com> Co-authored-by: Andrey Anshin <Andrey.Anshin@taragol.is>", "sampled": "feature(providers): added `OpsgenieNotifier` (#35530) --------- Co-authored-by: Utkarsh Sharma <utkarsh@gmail.com>, John Schindler<john@schi@schn.net>, Peter J.", "perturbed_sampled": ["feature(providers): added `OpsgenieNotifier` (#35530) --------- Co-authored-by: Utkarsh Sharma <utkarsh@gmail.com>, John Schindler<john@schi@schn.net>, Peter J.", "feature(providers): added `OpsgenieNotifier` (#35530) --------- Co-authored-by: Utkarsh Sharma <utkarsh@gmail.com>, John Schindler<john@schi@schn.net>, Peter J.", "feature(providers): added `OpsgenieNotifier` (#35530) --------- Co-authored-by: Utkarsh Sharma <utkarsh@gmail.com>, John Schindler<john@schi@schn.net>, Peter J.", "feature(providers): added `OpsgenieNotifier` (#35530) --------- Co-authored-by: Utkarsh Sharma <utkarsh@gmail.com>, John Schindler<john@schi@schn.net>, Peter J.", "feature(providers): added `OpsgenieNotifier` (#35530) --------- Co-authored-by: Utkarsh Sharma <utkarsh@gmail.com>, John Schindler<john@schi@schn.net>, Peter J.", "feature(providers): added `OpsgenieNotifier` (#35530) --------- Co-authored-by: Utkarsh Sharma <utkarsh@gmail.com>, John Schindler<john@schi@schn.net>, Peter J.", "feature(providers): added `OpsgenieNotifier` (#35530) --------- Co-authored-by: Utkarsh Sharma <utkarsh@gmail.com>, John Schindler<john@schi@schn.net>, Peter J.", "feature(providers): added `OpsgenieNotifier` (#35530) --------- Co-authored-by: Utkarsh Sharma <utkarsh@gmail.com>, John Schindler<john@schi@schn.net>, Peter J.", "feature(providers): added `OpsgenieNotifier` (#35530) --------- Co-authored-by: Utkarsh Sharma <utkarsh@gmail.com>, John Schindler<john@schi@schn.net>, Peter J.", "feature(providers): added `OpsgenieNotifier` (#35530) --------- Co-authored-by: Utkarsh Sharma <utkarsh@gmail.com>, John Schindler<john@schi@schn.net>, Peter J."], "perturbed_original": ["feature(providers): added `OpsgenieNotifier` (#35530) --------- Co-authored-by: Utkarsh Sharma <utkarsharma2@gmail.com> Co-authored-by: Andrey Anshin <Andrey.Anshin@taragol.is>", "feature(providers): added `OpsgenieNotifier` (#35530) --------- Co-authored-by: Utkarsh Sharma <utkarsharma2@gmail.com> Co-authored-by: Andrey Anshin <Andrey.Anshin@taragol.is>", "feature(providers): added `OpsgenieNotifier` (#35530) --------- Co-authored-by: Utkarsh Sharma <utkarsharma2@gmail.com> Co-authored-by: Andrey Anshin <Andrey.Anshin@taragol.is>", "feature(providers): added `OpsgenieNotifier` (#35530) --------- Co-authored-by: Utkarsh Sharma <utkarsharma2@gmail.com> Co-authored-by: Andrey Anshin <Andrey.Anshin@taragol.is>", "feature(providers): added `OpsgenieNotifier` (#35530) --------- Co-authored-by: Utkarsh Sharma <utkarsharma2@gmail.com> Co-authored-by: Andrey Anshin <Andrey.Anshin@taragol.is>", "feature(providers): added `OpsgenieNotifier` (#35530) --------- Co-authored-by: Utkarsh Sharma <utkarsharma2@gmail.com> Co-authored-by: Andrey Anshin <Andrey.Anshin@taragol.is>", "feature(providers): added `OpsgenieNotifier` (#35530) --------- Co-authored-by: Utkarsh Sharma <utkarsharma2@gmail.com> Co-authored-by: Andrey Anshin <Andrey.Anshin@taragol.is>", "feature(providers): added `OpsgenieNotifier` (#35530) --------- Co-authored-by: Utkarsh Sharma <utkarsharma2@gmail.com> Co-authored-by: Andrey Anshin <Andrey.Anshin@taragol.is>", "feature(providers): added `OpsgenieNotifier` (#35530) --------- Co-authored-by: Utkarsh Sharma <utkarsharma2@gmail.com> Co-authored-by: Andrey Anshin <Andrey.Anshin@taragol.is>", "feature(providers): added `OpsgenieNotifier` (#35530) --------- Co-authored-by: Utkarsh Sharma <utkarsharma2@gmail.com> Co-authored-by: Andrey Anshin <Andrey.Anshin@taragol.is>"], "original_ll": -3.6687123775482178, "sampled_ll": -3.866558790206909, "all_perturbed_sampled_ll": [-3.866558790206909, -3.866558790206909, -3.866558790206909, -3.866558790206909, -3.866558790206909, -3.866558790206909, -3.866558790206909, -3.866558790206909, -3.866558790206909, -3.866558790206909], "all_perturbed_original_ll": [-3.6687123775482178, -3.6687123775482178, -3.6687123775482178, -3.6687123775482178, -3.6687123775482178, -3.6687123775482178, -3.6687123775482178, -3.6687123775482178, -3.6687123775482178, -3.6687123775482178], "perturbed_sampled_ll": -3.866558790206909, "perturbed_original_ll": -3.6687123775482178, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Remove `breeze restart` reference from `BREEZE.rst` (#31326)", "sampled": "Remove `breeze restart` reference from `BREEZE.rst` (#31326)In", "perturbed_sampled": ["Remove `breeze restart` reference from `BREEZE.rst` (#31326)In", "Remove `breeze restart` reference from `BREEZE.rst` (#31326)In", "Remove `breeze restart` reference from `BREEZE.rst` (#31326)In", "Remove `breeze restart` reference from `BREEZE.rst` (#31326)In", "Remove `breeze restart` reference from `BREEZE.rst` (#31326)In", "Remove `breeze restart` reference from `BREEZE.rst` (#31326)In", "Remove `breeze restart` reference from `BREEZE.rst` (#31326)In", "Remove `breeze restart` reference from `BREEZE.rst` (#31326)In", "Remove `breeze restart` reference from `BREEZE.rst` (#31326)In", "Remove `breeze restart` reference from `BREEZE.rst` (#31326)In"], "perturbed_original": ["Remove `breeze restart` reference from `BREEZE.rst` (#31326)", "Remove `breeze restart` reference from `BREEZE.rst` (#31326)", "Remove `breeze restart` reference from `BREEZE.rst` (#31326)", "Remove `breeze restart` reference from `BREEZE.rst` (#31326)", "Remove `breeze restart` reference from `BREEZE.rst` (#31326)", "Remove `breeze restart` reference from `BREEZE.rst` (#31326)", "Remove `breeze restart` reference from `BREEZE.rst` (#31326)", "Remove `breeze restart` reference from `BREEZE.rst` (#31326)", "Remove `breeze restart` reference from `BREEZE.rst` (#31326)", "Remove `breeze restart` reference from `BREEZE.rst` (#31326)"], "original_ll": -4.732458114624023, "sampled_ll": -5.209416389465332, "all_perturbed_sampled_ll": [-5.209416389465332, -5.209416389465332, -5.209416389465332, -5.209416389465332, -5.209416389465332, -5.209416389465332, -5.209416389465332, -5.209416389465332, -5.209416389465332, -5.209416389465332], "all_perturbed_original_ll": [-4.732458114624023, -4.732458114624023, -4.732458114624023, -4.732458114624023, -4.732458114624023, -4.732458114624023, -4.732458114624023, -4.732458114624023, -4.732458114624023, -4.732458114624023], "perturbed_sampled_ll": -5.209416389465332, "perturbed_original_ll": -4.732458114624023, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Bring back wrong \"hook-class-names\" check (#33662) Continuation of #33640 - there were one more wrong check in the provider, that missed \"hook-class-names\" check", "sampled": "Bring back wrong \"hook-class-names\" check (#33662) Continuation of #33640 - there were one more wrong check in the hook-class-names code! Also added hook-functions/hook-type-definitions/hook-type-classification", "perturbed_sampled": ["Bring back wrong \"hook-class-names\" check (#33662) Continuation of changes - there were one more wrong check in the hook-class-names code! Also added hook-functions/hook-type-definitions/hook-type-classification", "Bring back wrong \"hook-class-names\" check (#33662) Fixed in #33640 - there were one more wrong check in the hook-class-names code! Also added hook-functions/hook-type-definitions/hook-type-classification", "Bring back hook-class-names check (#33662) Continuation of #33640 - there were one more wrong check in the hook-class-names code! Also added hook-functions/hook-type-definitions/hook-type-classification", "Bring back the \"hook-class-names\" check (#33662) Continuation of #33640 - there were one more wrong check in the hook-class-names code! Also added hook-functions/hook-type-definitions/hook-type-classification", "Bring back wrong \"hook-class-names\" check (#33662) Continuation of #33640 - there were one more wrong check in hook-class-names code! Also added hook-functions/hook-type-definitions/hook-type-classification", "Bring back wrong \"hook-class-names\" check (#33662) Continuation of #33640 - there were one or more cases of introducing a wrong check in the hook-class-names code! Also added hook-functions/hook-type-definitions/hook-type-classification", "Bring back wrong \"hook-class-names\" check (#33662) Continuation of #33640 - there were one more wrong check in that code! Also added hook-functions/hook-type-definitions/hook-type-classification", "Bring back wrong \"hook-class-names\" check (#33662) Continuation of #33662 discussion, fixing two other code problem - there were one more wrong check in the hook-class-names code! Also added hook-functions/hook-type-definitions/hook-type-classification", "Bring in the \"hook-class-names\" check (#33662) Continuation of #33640 - there were one more wrong check in the hook-class-names code! Also added hook-functions/hook-type-definitions/hook-type-classification", "Bring back right method check (#33662) Continuation of #33640 - there were one more wrong check in the hook-class-names code! Also added hook-functions/hook-type-definitions/hook-type-classification"], "perturbed_original": ["Bring back wrong \"hook-class-names\" check (#33662) Continuation of #33640 - there were no wrong check in the provider, that missed \"hook-class-names\" check", "Bring back wrong \"hook-class-names\" check (#33662) Continuation of #33640 - Adding one more wrong check in the provider, that missed \"hook-class-names\" check", "Bring back wrong \"hook-class-names\" check (#33662) Continuation of #33640 There were one more wrong check in the provider, that missed \"hook-class-names\" check", "Bring back wrong \"hook-class-names\" check (#33662) Continuation of #33640 - there were one more mistake in the provider, that missed \"hook-class-names\" check", "Bring back wrong \"hook-class-names\" check (#33662) Continuation of #33640 - there were one extra check in the provider, that missed \"hook-class-names\" check", "Bring back wrong \"hook-class-names\" check from provider. Revert of #33640 - there were one more wrong check in the provider, that missed \"hook-class-names\" check", "Bring back wrong \"hook-class-names\" check (#33662) Continuation of #33640 - there were one or more wrong check in the provider, that missed \"hook-class-names\" check", "Bring back wrong \"hook-class-names\" check (#33662) Continuation of #33662 - there were one more wrong check in the provider, that missed \"hook-class-names\" check", "Bring back wrong \"hook-class-names\" check (#33662) Continuation of the work - there were one more wrong check in the provider, that missed \"hook-class-names\" check", "Bring back wrong \"hook-class-names\" check (#33662) Continuation of #33640 There were one more wrong check in the provider, that missed \"hook-class-names\" check"], "original_ll": -4.593257427215576, "sampled_ll": -3.8454577922821045, "all_perturbed_sampled_ll": [-3.901226758956909, -3.86398983001709, -3.91316556930542, -3.7276744842529297, -3.9374711513519287, -3.804690361022949, -4.186310291290283, -3.9727728366851807, -3.8204410076141357, -4.2656168937683105], "all_perturbed_original_ll": [-4.606910705566406, -4.6262006759643555, -4.6816534996032715, -4.679370403289795, -4.616802215576172, -4.396973133087158, -4.480732440948486, -4.344871997833252, -4.612955570220947, -4.6816534996032715], "perturbed_sampled_ll": -3.9393359184265138, "perturbed_original_ll": -4.572812414169311, "perturbed_sampled_ll_std": 0.15920343510412846, "perturbed_original_ll_std": 0.11574193363724192}, {"original": "Fix BigQueryDataTransferServiceHook.get_transfer_run() request parameter (#21293)", "sampled": "Fix BigQueryDataTransferServiceHook.get_transfer_run() request parameter (#21293)GUIDump(0xC9E3F9C8,", "perturbed_sampled": ["Fix BigQueryDataTransferServiceHook.get_transfer_run() request parameter (#21293)GUIDump(0xC9E3F9C8,", "Fix BigQueryDataTransferServiceHook.get_transfer_run() request parameter (#21293)GUIDump(0xC9E3F9C8,", "Fix BigQueryDataTransferServiceHook.get_transfer_run() request parameter (#21293)GUIDump(0xC9E3F9C8,", "Fix BigQueryDataTransferServiceHook.get_transfer_run() request parameter (#21293)GUIDump(0xC9E3F9C8,", "Fix BigQueryDataTransferServiceHook.get_transfer_run() request parameter (#21293)GUIDump(0xC9E3F9C8,", "Fix BigQueryDataTransferServiceHook.get_transfer_run() request parameter (#21293)GUIDump(0xC9E3F9C8,", "Fix BigQueryDataTransferServiceHook.get_transfer_run() request parameter (#21293)GUIDump(0xC9E3F9C8,", "Fix BigQueryDataTransferServiceHook.get_transfer_run() request parameter (#21293)GUIDump(0xC9E3F9C8,", "Fix BigQueryDataTransferServiceHook.get_transfer_run() request parameter (#21293)GUIDump(0xC9E3F9C8,", "Fix BigQueryDataTransferServiceHook.get_transfer_run() request parameter (#21293)GUIDump(0xC9E3F9C8,"], "perturbed_original": ["Fix BigQueryDataTransferServiceHook.get_transfer_run() request parameter (#21293)", "Fix BigQueryDataTransferServiceHook.get_transfer_run() request parameter (#21293)", "Fix BigQueryDataTransferServiceHook.get_transfer_run() request parameter (#21293)", "Fix BigQueryDataTransferServiceHook.get_transfer_run() request parameter (#21293)", "Fix BigQueryDataTransferServiceHook.get_transfer_run() request parameter (#21293)", "Fix BigQueryDataTransferServiceHook.get_transfer_run() request parameter (#21293)", "Fix BigQueryDataTransferServiceHook.get_transfer_run() request parameter (#21293)", "Fix BigQueryDataTransferServiceHook.get_transfer_run() request parameter (#21293)", "Fix BigQueryDataTransferServiceHook.get_transfer_run() request parameter (#21293)", "Fix BigQueryDataTransferServiceHook.get_transfer_run() request parameter (#21293)"], "original_ll": -5.907197952270508, "sampled_ll": -5.012745380401611, "all_perturbed_sampled_ll": [-5.012745380401611, -5.012745380401611, -5.012745380401611, -5.012745380401611, -5.012745380401611, -5.012745380401611, -5.012745380401611, -5.012745380401611, -5.012745380401611, -5.012745380401611], "all_perturbed_original_ll": [-5.907197952270508, -5.907197952270508, -5.907197952270508, -5.907197952270508, -5.907197952270508, -5.907197952270508, -5.907197952270508, -5.907197952270508, -5.907197952270508, -5.907197952270508], "perturbed_sampled_ll": -5.012745380401611, "perturbed_original_ll": -5.907197952270508, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Fix deferrable mode execution in WasbPrefixSensor (#31411)", "sampled": "Fix deferrable mode execution in WasbPrefixSensor (#31411)Branch:", "perturbed_sampled": ["Fix deferrable mode execution in WasbPrefixSensor (#31411)Branch:", "Fix deferrable mode execution in WasbPrefixSensor (#31411)Branch:", "Fix deferrable mode execution in WasbPrefixSensor (#31411)Branch:", "Fix deferrable mode execution in WasbPrefixSensor (#31411)Branch:", "Fix deferrable mode execution in WasbPrefixSensor (#31411)Branch:", "Fix deferrable mode execution in WasbPrefixSensor (#31411)Branch:", "Fix deferrable mode execution in WasbPrefixSensor (#31411)Branch:", "Fix deferrable mode execution in WasbPrefixSensor (#31411)Branch:", "Fix deferrable mode execution in WasbPrefixSensor (#31411)Branch:", "Fix deferrable mode execution in WasbPrefixSensor (#31411)Branch:"], "perturbed_original": ["Fix deferrable mode execution in WasbPrefixSensor (#31411)", "Fix deferrable mode execution in WasbPrefixSensor (#31411)", "Fix deferrable mode execution in WasbPrefixSensor (#31411)", "Fix deferrable mode execution in WasbPrefixSensor (#31411)", "Fix deferrable mode execution in WasbPrefixSensor (#31411)", "Fix deferrable mode execution in WasbPrefixSensor (#31411)", "Fix deferrable mode execution in WasbPrefixSensor (#31411)", "Fix deferrable mode execution in WasbPrefixSensor (#31411)", "Fix deferrable mode execution in WasbPrefixSensor (#31411)", "Fix deferrable mode execution in WasbPrefixSensor (#31411)"], "original_ll": -7.354725360870361, "sampled_ll": -7.058056831359863, "all_perturbed_sampled_ll": [-7.058056831359863, -7.058056831359863, -7.058056831359863, -7.058056831359863, -7.058056831359863, -7.058056831359863, -7.058056831359863, -7.058056831359863, -7.058056831359863, -7.058056831359863], "all_perturbed_original_ll": [-7.354725360870361, -7.354725360870361, -7.354725360870361, -7.354725360870361, -7.354725360870361, -7.354725360870361, -7.354725360870361, -7.354725360870361, -7.354725360870361, -7.354725360870361], "perturbed_sampled_ll": -7.058056831359863, "perturbed_original_ll": -7.354725360870361, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Unpin ``argcomplete`` and ``colorlog`` (#20878) For Both of these libraries, the only breaking changes are dropping support for old Python version. - https://github.com/kislyuk/argcomplete/blob/develop/Changes.rst - https://github.com/borntyping/python-colorlog/releases", "sampled": "Unpin ``argcomplete`` and ``colorlog`` (#20878) For Both of these libraries, the only breaking changes are dropping support for old versions of Python (e.g., 3.2 or", "perturbed_sampled": ["396) and ``colorlog`` (#20878) For Both of these libraries, the only breaking changes are dropping support for old versions of Python (e.g., 3.2 or", "Unpin ``argcomplete`` and ``colorlog`` (#20878) For Both of these libraries, the only breaking changes are dropping support for the older version of Python (e.g., 3.2 or", "Unpin ``argcomplete`` and ``colorlog`` (#20878) For both of these libraries, the only breaking changes are dropping support for old versions of Python (e.g., 3.2 or", "Unpin ``argcomplete`` and ``colorlog`` (#20878) For the git packages released with these libraries, the only breaking changes are dropping support for old versions of Python (e.g., 3.2 or", "Unpin ``argcomplete`` and <unk>argcomplete<unk>. For Both of these libraries, the only breaking changes are dropping support for old versions of Python (e.g., 3.2 or", "Unpin ``argcomplete`` and ``colorlog`` (#20878) For Both of these libraries, the only breaking changes are dropping support for old versions of Xcode up to version 3.2 or", "Unpin ``argcomplete`` and ``colorlog`` : Both of these libraries, the only breaking changes are dropping support for old versions of Python (e.g., 3.2 or", "Unpin ``argcomplete`` and ``colorlog`` (#20878) For Both of these libraries, the only breaking changes are dropping support for old versions of Python (e.g., 3.2 or", "Unpin ``argcomplete`` and ``colorlog`` (#20878) For Both of these libraries, the only breaking changes are dropping support for other versions of Python (e.g., 3.2 or", "Unpin ``argcomplete`` and ``colorlog`` (#20878) For all of these libraries, the only breaking changes are dropping support for old versions of Python (e.g., 3.2 or"], "perturbed_original": ["Unpin ``argcomplete`` and ``colorlog`` (#20878) For Both of these libraries, the only breaking changes are change for support for old Python version. - https://github.com/kislyuk/argcomplete/blob/develop/Changes.rst - https://github.com/borntyping/python-colorlog/releases", "Unpin ``argcomplete`` and ``colorlog`` (#20878) For Both of these libraries, the only breaking changes are dropping the old Python version. - https://github.com/kislyuk/argcomplete/blob/develop/Changes.rst - https://github.com/borntyping/python-colorlog/releases", "Unpin ``argcomplete`` and ``colorlog`` (#20878) For Both of these libraries, the only breaking changes are dropping support for the old colorlog version. - https://github.com/kislyuk/argcomplete/blob/develop/Changes.rst - https://github.com/borntyping/python-colorlog/releases", "Unpin ``argcomplete`` and ``colorlog`` (#20878) For Both for the new libraries, the only breaking changes are dropping support for old Python version. - https://github.com/kislyuk/argcomplete/blob/develop/Changes.rst - https://github.com/borntyping/python-colorlog/releases", "Unpin ``argcomplete`` and <unk>python<unk> libraries from old Python Version. For Both of these libraries, the only breaking changes are dropping support for old Python version. - https://github.com/kislyuk/argcomplete/blob/develop/Changes.rst - https://github.com/borntyping/python-colorlog/releases", "Unpin ``argcomplete`` and ``colorlog`` (#20878) For Both of these libraries, Latest breaking changes are dropping support for old Python version. - https://github.com/kislyuk/argcomplete/blob/develop/Changes.rst - https://github.com/borntyping/python-colorlog/releases", "Unpin ``argcomplete`` and ``colorlog`` (#20878) For Both of these libraries, the only breaking changes are dropping support for old Python version. Available Here: - https://github.com/borntyping/python-colorlog/releases", "Unpin ``argcomplete`` and ``colorlog`` (#20878) For Both of these libraries, the only breaking changes are dropping support and updating the Python version. - https://github.com/kislyuk/argcomplete/blob/develop/Changes.rst - https://github.com/borntyping/python-colorlog/releases", "Unpin ``argcomplete`` and ``colorlog`` (#20878) on your development repository. With the recent release of these libraries, the only breaking changes are dropping support for old Python version. - https://github.com/kislyuk/argcomplete/blob/develop/Changes.rst - https://github.com/borntyping/python-colorlog/releases", "Unpin Python Library ``colorlog`` (#20878) For Both of these libraries, the only breaking changes are dropping support for old Python version. - https://github.com/kislyuk/argcomplete/blob/develop/Changes.rst - https://github.com/borntyping/python-colorlog/releases"], "original_ll": -3.6338605880737305, "sampled_ll": -4.222329139709473, "all_perturbed_sampled_ll": [-4.13109016418457, -4.356990337371826, -4.0122971534729, -4.409447193145752, -4.249764442443848, -4.642510890960693, -4.067075252532959, -4.222329139709473, -4.2601165771484375, -4.041815757751465], "all_perturbed_original_ll": [-3.7070465087890625, -3.67366099357605, -3.5874149799346924, -3.810194253921509, -3.813295364379883, -3.769737482070923, -4.0908942222595215, -3.6604156494140625, -3.5964090824127197, -3.8674278259277344], "perturbed_sampled_ll": -4.239343690872192, "perturbed_original_ll": -3.757649636268616, "perturbed_sampled_ll_std": 0.1838782155015856, "perturbed_original_ll_std": 0.14253219852760066}, {"original": "Fix some typos in the cluster policies docs (#31031)", "sampled": "Fix some typos in the cluster policies docs (#31031)We", "perturbed_sampled": ["Fix some typos in the cluster policies docs (#31031)We", "Fix some typos in the cluster policies docs (#31031)We", "Fix some typos in the cluster policies docs (#31031)We", "Fix some typos in the cluster policies docs (#31031)We", "Fix some typos in the cluster policies docs (#31031)We", "Fix some typos in the cluster policies docs (#31031)We", "Fix some typos in the cluster policies docs (#31031)We", "Fix some typos in the cluster policies docs (#31031)We", "Fix some typos in the cluster policies docs (#31031)We", "Fix some typos in the cluster policies docs (#31031)We"], "perturbed_original": ["Fix some typos in the cluster policies docs (#31031)", "Fix some typos in the cluster policies docs (#31031)", "Fix some typos in the cluster policies docs (#31031)", "Fix some typos in the cluster policies docs (#31031)", "Fix some typos in the cluster policies docs (#31031)", "Fix some typos in the cluster policies docs (#31031)", "Fix some typos in the cluster policies docs (#31031)", "Fix some typos in the cluster policies docs (#31031)", "Fix some typos in the cluster policies docs (#31031)", "Fix some typos in the cluster policies docs (#31031)"], "original_ll": -5.174689769744873, "sampled_ll": -5.8528571128845215, "all_perturbed_sampled_ll": [-5.8528571128845215, -5.8528571128845215, -5.8528571128845215, -5.8528571128845215, -5.8528571128845215, -5.8528571128845215, -5.8528571128845215, -5.8528571128845215, -5.8528571128845215, -5.8528571128845215], "all_perturbed_original_ll": [-5.174689769744873, -5.174689769744873, -5.174689769744873, -5.174689769744873, -5.174689769744873, -5.174689769744873, -5.174689769744873, -5.174689769744873, -5.174689769744873, -5.174689769744873], "perturbed_sampled_ll": -5.8528571128845215, "perturbed_original_ll": -5.174689769744873, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Add skip_on_exit_code also to ExternalPythonOperator (#30738) The change ##30690 and #30692 added skip_on_exit_code to the PythonVirtualenvOperator, but it skipped the - very closely related - ExternalPythonOperator. This change brings the same functionality to ExternalPythonOperator, moves it to the base class for both operators, it also adds separate Test class for ExternalPythonOperator, also introducing a common base class and moving the test methods that are common to both operators there.", "sampled": "Add skip_on_exit_code also to ExternalPythonOperator (#30738) The change ##30690 and #30692 added skip_on_exit_code in ExternalPythonOperator class. It's better practice to put it there. To change the value of internal_handler: - python /usr/bin/ExternalPythonOperator.external_handler = True - python /usr/bin/ExternalPythonOperator.internal_handler = True It's important to be aware that the default value to get external_handler, ExternalPythonOperator.external_handler, will be False. If you want it to be True, change the value of external_handler here instead:", "perturbed_sampled": ["Add optional return value to ExternalPythonOperator (#30738) The change ##30690 and ##30820 removes skip_on_exit_code in ExternalPythonOperator class. It's better practice to have it there. To change the value , add the following: - python /usr/bin/ExternalPythonOperator.external_handler = True - python /usr/bin/ExternalPythonOperator.internal_handler = True It's important to be aware that the default value to get external_handler, ExternalPythonOperator.external_handler, will be False. If you want it to be True, change the value of external_handler here instead:", "Add skip_on_exit_code also to ExternalPythonOperator (#30738) The change ##30690 and #30692 should re-implement it in ExternalPythonOperator class. It's better practice to put it there. To change the value of internal_handler: - python /usr/bin/ExternalPythonOperator.external_handler = True - python /usr/bin/ExternalPythonOperator.internal_handler = False It's important to be aware that the default value to get external_handler, ExternalPythonOperator.external_handler, will be False. If you want it to be True, change the value to a value here instead:", "Add skip_on_exit_code also to ExternalPythonOperator (#30738) The change ##30690 and #30692 added skip_on_exit_code in ExternalPythonOperator class. The best practice would be to place it there. To change the value of internal_handler: - python /usr/bin/ExternalPythonOperator.external_handler = True - python /usr/bin/ExternalPythonOperator.internal_handler = True It's important to understand that the default value to get external_handler, ExternalPythonOperator.external_handler, will be False. If you want it to be True, change the value of external_handler here instead:", "Add skip_on_exit_code also to ExternalPythonOperator class and change ##30690 i've added skip_on_exit_code in ExternalPythonOperator class. It's better practice to put it there. I changed even the value of internal_handler: - python input_code = True - python /usr/bin/ExternalPythonOperator.internal_handler = True It's important to be aware that the default value to get external_handler, ExternalPythonOperator.external_handler, will be False. If you want it to be True, change the value of external_handler here instead:", "Add skip_on_exit_code also to ExternalPythonOperator (#30738) The change ##30690 and #30692 is in ExternalPythonOperator class. It's better practice to put it there. To change the value of external_handler, python /usr/bin/ExternalPythonOperator.external_handler = True - a external_handler = True It's important to be aware that the default value to get external_handler, ExternalPythonOperator.external_handler, will end with True. If you want it to be True, change the value of external_handler here instead:", "Add skip_on_exit_code also to ExternalPythonOperator class. Please also change ##30690 and add skip_on_exit_code in ExternalPythonOperator class. It's better practice to put it there. To change the default value to get internal_handler: - python /usr/bin/ExternalPythonOperator.external_handler = True - python /usr/bin/ExternalPythonOperator.internal_handler = True You have to be aware that the default value to get external_handler, ExternalPythonOperator.external_handler, will be False. If you want it to be True, change the value of external_handler here instead:", "Add skip_on_exit_code also to this method. The change ##30690 and #30692 added internal_handler to the ExternalPythonOperator class. In practice to put it there. To change the value of internal_handler: - python /usr/bin/ExternalPythonOperator.external_handler = True - python /usr/bin/ExternalPythonOperator.internal_handler = True It's important to be aware that the default value to get external_handler, ExternalPythonOperator.external_handler, will be False. If you want it to be True, change the value of external_handler here instead:", "Add skip_on_exit_code also to ExternalPythonOperator class. See also change ##30690 and #30692 added skip_on_exit_code in ExternalPythonOperator class. It's a good practice to put it there. To change the value of internal_handler: - python /usr/bin/ExternalPythonOperator.external_handler = True - python /usr/bin/ExternalPythonOperator.internal_handler = True It's good to be aware that the default value to get external_handler, ExternalPythonOperator.external_handler, is False. If you want it to be True, change the value of external_handler here instead:", "Add skip_on_exit_code also to ExternalPythonOperator (#30738) The change ##30690 will added skip_on_exit_code in ExternalPythonOperator class. It's better practice to use it , not change the value of internal_handler: - python internal_handler = True - python /usr/bin/ExternalPythonOperator.internal_handler = True It's important to be aware that the default value to get external_handler, ExternalPythonOperator.external_handler, will be False. If you want it to be True, change the value of external_handler here instead:", "Add Handler to ExternalPythonOperator (#30738) The change ##30690 and #30692 have changed value in ExternalPythonOperator class. It's better practice to put it there. To change the value , follow these two lines: - python /usr/bin/ExternalPythonOperator.external_handler = True - python /usr/bin/ExternalPythonOperator.internal_handler = False It is important to be aware that the default value to get external_handler, ExternalPythonOperator.external_handler, will be True. If you want it to be True, change the value of external_handler here instead:"], "perturbed_original": ["Add skip_on_exit_code also to ExternalPythonOperator (#30738) The change ##30690 and #30692 added skip_on_exit_code to the PythonVirtualenvOperator, but it skipped the - very closely related - ExternalPythonOperator. This change brings the new test methods to ExternalPythonOperator, moves them back into the base class for both operators, it also adds the base class for ExternalPythonOperator, also introducing a common base class and moving the test methods that are common to both operators there.", "Add s skip_on_exit_code to ExternalPythonOperator (#30738) The change ##30690 and #30692 added skip_on_exit_code to the PythonVirtualenvOperator, but it skipped an operator that is very closely related - ExternalPythonOperator. This change brings the same functionality to ExternalPythonOperator, moves it to the base class for both operators, it also adds separate Test class for both operators, introducing a common base class for both, implementing all the test methods that are common to both operators there.", "Add s Tests to ExternalPythonOperator (#30738) The change ##30690 and #30692 added skip_on_exit_code to the PythonVirtualenvOperator, but it skipped the - very closely related - ExternalPythonOperator. This change adds the same functionality to ExternalPythonOperator, moves it to the base class for the operators, and it also adds separate Test s to ExternalPythonOperator, also introducing a common base class for the two and moving the test methods that are common to both operators there.", "Add skip_on_exit_code also to ExternalPythonOperator (#30738) The change ##30690 and #30692 added this to the PythonVirtualenvOperator, but unfortunately skipped the - very closely related - ExternalPythonOperator. This change brings the behavior to ExternalPythonOperator, moves it to the same base class as for PythonVirtualenvOperator, and it also adds separate Test class for ExternalPythonOperator, also introducing a common base class and moving the test methods that are common to both operators there.", "Add skip_on_exit_code also to ExternalPythonOperator (#30738) The change ##30690 and #30692 added skip_on_exit_code to PythonVirtualenvOperator, but it skipped the - very closely related - behavior for ExternalPythonOperator. This change adds the same functionality to ExternalPythonOperator, moves it to the base class for both operators, it also adds separate Test class for ExternalPythonOperator, also introducing a Test class and moving the test methods that are common in both operators there.", "Add skip_on_exit_code also to ExternalPythonOperator (#30738) The change in commit #30692 added skip_on_exit_code to the PythonVirtualenvOperator, but it skipped the - very important - ExternalPythonOperator. This change brings the same functionality to both operators by not only adding it to the base class for both operators, it also adds separate Test Operation classes for the ExternalPythonOperator, also introducing a common base class and all the test methods that are common to both operators there.", "class. also to ExternalPythonOperator (#30738) The change ##30690 and #30692 added skip_on_exit_code to the BaseOperator but it skipped the - very different class - ExternalPythonOperator. This change brings the same functionality to ExternalPythonOperator, moves it to the base class for both operators, it also adds a Test class for ExternalPythonOperator, also introducing a TestOperator class and moving the test methods that are common to both operators there.", "Add skip_on_exit_code also to ExternalPythonOperator (#30738) The change ##30690 already added skip_on_exit_code to the PythonVirtualenvOperator, but it skipped the - very closely related - ExternalPythonOperator. This change brings the same functionality to ExternalPythonOperator, adding a test class to the base class for both cases. The change also adds separate Test class for the both operators, introducing a new Test class and moving the test methods that are common to both operators there.", "Add skip_on_exit_code also to ExternalPythonOperator (#30738) The #16090 and #30692 added skip_on_exit_code to the PythonVirtualenvOperator, but it skipped the - very closely related - ExternalPythonOperator. This extension enables the same features for ExternalPythonOperator, moves it to the base class for both operators, it also adds separate Test class for ExternalPythonOperator, also introducing a separate UnitOperator class and moving the test methods that are common to both operators there.", "Add skip_on_exit_code also to ExternalPythonOperator (#30738) The change ##30690 and then the original change ##3106 added skip_on_exit_code to the PythonVirtualenvOperator, but also to the - very closely related - ExternalPythonOperator. This change brings the same functionality to ExternalPythonOperator, moves it to the base class for both operators, it also adds a Test class for ExternalPythonOperator, also introducing a common base class for the test methods that are common to all operators there."], "original_ll": -3.7170519828796387, "sampled_ll": -2.535095691680908, "all_perturbed_sampled_ll": [-2.745168685913086, -2.7810075283050537, -2.5594491958618164, -3.0558645725250244, -3.2410895824432373, -2.54374361038208, -2.8222057819366455, -2.482689380645752, -3.006946563720703, -2.807720422744751], "all_perturbed_original_ll": [-3.7680704593658447, -3.6579184532165527, -3.8921213150024414, -3.9550445079803467, -3.700613260269165, -3.6901731491088867, -3.8631715774536133, -3.726745843887329, -3.861072063446045, -3.5897858142852783], "perturbed_sampled_ll": -2.804588532447815, "perturbed_original_ll": -3.7704716444015505, "perturbed_sampled_ll_std": 0.23038684371287232, "perturbed_original_ll_std": 0.11145799271324115}, {"original": "Fix failing main due to new release of jsonschema (#32405)", "sampled": "Fix failing main due to new release of jsonschema (#32405)Atomizer::register()/register_all()", "perturbed_sampled": ["Fix failing main due to new release of jsonschema (#32405)Atomizer::register()/register_all()", "Fix failing main due to new release of jsonschema (#32405)Atomizer::register()/register_all()", "Fix failing main due to new release of jsonschema (#32405)Atomizer::register()/register_all()", "Fix failing main due to new release of jsonschema (#32405)Atomizer::register()/register_all()", "Fix failing main due to new release of jsonschema (#32405)Atomizer::register()/register_all()", "Fix failing main due to new release of jsonschema (#32405)Atomizer::register()/register_all()", "Fix failing main due to new release of jsonschema (#32405)Atomizer::register()/register_all()", "Fix failing main due to new release of jsonschema (#32405)Atomizer::register()/register_all()", "Fix failing main due to new release of jsonschema (#32405)Atomizer::register()/register_all()", "Fix failing main due to new release of jsonschema (#32405)Atomizer::register()/register_all()"], "perturbed_original": ["Fix failing main due to new release of jsonschema (#32405)", "Fix failing main due to new release of jsonschema (#32405)", "Fix failing main due to new release of jsonschema (#32405)", "Fix failing main due to new release of jsonschema (#32405)", "Fix failing main due to new release of jsonschema (#32405)", "Fix failing main due to new release of jsonschema (#32405)", "Fix failing main due to new release of jsonschema (#32405)", "Fix failing main due to new release of jsonschema (#32405)", "Fix failing main due to new release of jsonschema (#32405)", "Fix failing main due to new release of jsonschema (#32405)"], "original_ll": -5.7758660316467285, "sampled_ll": -5.05717658996582, "all_perturbed_sampled_ll": [-5.05717658996582, -5.05717658996582, -5.05717658996582, -5.05717658996582, -5.05717658996582, -5.05717658996582, -5.05717658996582, -5.05717658996582, -5.05717658996582, -5.05717658996582], "all_perturbed_original_ll": [-5.7758660316467285, -5.7758660316467285, -5.7758660316467285, -5.7758660316467285, -5.7758660316467285, -5.7758660316467285, -5.7758660316467285, -5.7758660316467285, -5.7758660316467285, -5.7758660316467285], "perturbed_sampled_ll": -5.05717658996582, "perturbed_original_ll": -5.7758660316467285, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Re-enable `pymsql` on ARM as it now builds cleanly (#28530)", "sampled": "Re-enable `pymsql` on ARM as it now builds cleanly (#28530)\"", "perturbed_sampled": ["Re-enable `pymsql` on ARM as it now builds cleanly (#28530)\"", "Re-enable `pymsql` on ARM as it now builds cleanly (#28530)\"", "Re-enable `pymsql` on ARM as it now builds cleanly (#28530)\"", "Re-enable `pymsql` on ARM as it now builds cleanly (#28530)\"", "Re-enable `pymsql` on ARM as it now builds cleanly (#28530)\"", "Re-enable `pymsql` on ARM as it now builds cleanly (#28530)\"", "Re-enable `pymsql` on ARM as it now builds cleanly (#28530)\"", "Re-enable `pymsql` on ARM as it now builds cleanly (#28530)\"", "Re-enable `pymsql` on ARM as it now builds cleanly (#28530)\"", "Re-enable `pymsql` on ARM as it now builds cleanly (#28530)\""], "perturbed_original": ["Re-enable `pymsql` on ARM as it now builds cleanly (#28530)", "Re-enable `pymsql` on ARM as it now builds cleanly (#28530)", "Re-enable `pymsql` on ARM as it now builds cleanly (#28530)", "Re-enable `pymsql` on ARM as it now builds cleanly (#28530)", "Re-enable `pymsql` on ARM as it now builds cleanly (#28530)", "Re-enable `pymsql` on ARM as it now builds cleanly (#28530)", "Re-enable `pymsql` on ARM as it now builds cleanly (#28530)", "Re-enable `pymsql` on ARM as it now builds cleanly (#28530)", "Re-enable `pymsql` on ARM as it now builds cleanly (#28530)", "Re-enable `pymsql` on ARM as it now builds cleanly (#28530)"], "original_ll": -5.322982311248779, "sampled_ll": -5.735334873199463, "all_perturbed_sampled_ll": [-5.735334873199463, -5.735334873199463, -5.735334873199463, -5.735334873199463, -5.735334873199463, -5.735334873199463, -5.735334873199463, -5.735334873199463, -5.735334873199463, -5.735334873199463], "all_perturbed_original_ll": [-5.322982311248779, -5.322982311248779, -5.322982311248779, -5.322982311248779, -5.322982311248779, -5.322982311248779, -5.322982311248779, -5.322982311248779, -5.322982311248779, -5.322982311248779], "perturbed_sampled_ll": -5.735334873199463, "perturbed_original_ll": -5.322982311248779, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "migrated some part of test always to pytest (#29375)", "sampled": "migrated some part of test always to pytest (#29375)This", "perturbed_sampled": ["migrated some part of test always to pytest (#29375)This", "migrated some part of test always to pytest (#29375)This", "migrated some part of test always to pytest (#29375)This", "migrated some part of test always to pytest (#29375)This", "migrated some part of test always to pytest (#29375)This", "migrated some part of test always to pytest (#29375)This", "migrated some part of test always to pytest (#29375)This", "migrated some part of test always to pytest (#29375)This", "migrated some part of test always to pytest (#29375)This", "migrated some part of test always to pytest (#29375)This"], "perturbed_original": ["migrated some part of test always to pytest (#29375)", "migrated some part of test always to pytest (#29375)", "migrated some part of test always to pytest (#29375)", "migrated some part of test always to pytest (#29375)", "migrated some part of test always to pytest (#29375)", "migrated some part of test always to pytest (#29375)", "migrated some part of test always to pytest (#29375)", "migrated some part of test always to pytest (#29375)", "migrated some part of test always to pytest (#29375)", "migrated some part of test always to pytest (#29375)"], "original_ll": -6.302485466003418, "sampled_ll": -6.804668426513672, "all_perturbed_sampled_ll": [-6.804668426513672, -6.804668426513672, -6.804668426513672, -6.804668426513672, -6.804668426513672, -6.804668426513672, -6.804668426513672, -6.804668426513672, -6.804668426513672, -6.804668426513672], "all_perturbed_original_ll": [-6.302485466003418, -6.302485466003418, -6.302485466003418, -6.302485466003418, -6.302485466003418, -6.302485466003418, -6.302485466003418, -6.302485466003418, -6.302485466003418, -6.302485466003418], "perturbed_sampled_ll": -6.804668426513672, "perturbed_original_ll": -6.302485466003418, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Refactor python operators/sensor tests (#28493)", "sampled": "Refactor python operators/sensor tests (#28493)R.py:", "perturbed_sampled": ["Refactor python operators/sensor tests (#28493)R.py:", "Refactor python operators/sensor tests (#28493)R.py:", "Refactor python operators/sensor tests (#28493)R.py:", "Refactor python operators/sensor tests (#28493)R.py:", "Refactor python operators/sensor tests (#28493)R.py:", "Refactor python operators/sensor tests (#28493)R.py:", "Refactor python operators/sensor tests (#28493)R.py:", "Refactor python operators/sensor tests (#28493)R.py:", "Refactor python operators/sensor tests (#28493)R.py:", "Refactor python operators/sensor tests (#28493)R.py:"], "perturbed_original": ["Refactor python operators/sensor tests (#28493)", "Refactor python operators/sensor tests (#28493)", "Refactor python operators/sensor tests (#28493)", "Refactor python operators/sensor tests (#28493)", "Refactor python operators/sensor tests (#28493)", "Refactor python operators/sensor tests (#28493)", "Refactor python operators/sensor tests (#28493)", "Refactor python operators/sensor tests (#28493)", "Refactor python operators/sensor tests (#28493)", "Refactor python operators/sensor tests (#28493)"], "original_ll": -6.936947822570801, "sampled_ll": -6.842353820800781, "all_perturbed_sampled_ll": [-6.842353820800781, -6.842353820800781, -6.842353820800781, -6.842353820800781, -6.842353820800781, -6.842353820800781, -6.842353820800781, -6.842353820800781, -6.842353820800781, -6.842353820800781], "all_perturbed_original_ll": [-6.936947822570801, -6.936947822570801, -6.936947822570801, -6.936947822570801, -6.936947822570801, -6.936947822570801, -6.936947822570801, -6.936947822570801, -6.936947822570801, -6.936947822570801], "perturbed_sampled_ll": -6.842353820800781, "perturbed_original_ll": -6.936947822570801, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Allow wildcarded CORS origins (#25553) '*' is a valid 'Access-Control-Allow-Origin' response, but was being dropped as it failed to match the Origin header sent in requests.", "sampled": "Allow wildcarded CORS origins (#25553) '*' is a valid 'Access-Control-Allow-Origin' response, but was originally intended to only work for HTTPS URLs using cors-crypt (#5665) '*' should", "perturbed_sampled": ["Allow wildcarded CORS origins (#25553) '*' is a valid 'Access-Control-Allow-Origin' response, but was originally intended to only process HTTPS URLs using cors-crypt (#5665) '*' should", "Allow wildcarded CORS origins (#25553) '*' is a valid 'Access-Control-Allow-Origin' response, but was originally crafted to only work for HTTPS URLs using cors-crypt (#5665) '*' should", "Allow wildcarded CORS origins (#25553) '*' is a valid 'Access-Control-Allow-Origin' response, but was originally intended to only work for HTTPS URLs using cors-crypt o -- which it should", "Allow wildcarded CORS origins (#25553) '*' is a valid 'Access-Control-Allow-Origin' wildcard. This was originally intended to only work for HTTPS URLs using cors-crypt (#5665) '*' should", "Allow wildcarded CORS origins (#25553) '*' is a valid 'Access-Control-Allow-Origin' wildcard that was originally intended to only work for HTTPS URLs using cors-crypt (#5665) '*' should", "Allow wildcarded CORS origins (#25553) '*' is a valid 'Access-Control-Allow-Origin' response, which was originally intended to only work for HTTPS URLs using cors-crypt (#5665) '*' should", "Allow wildcarded CORS origins (#25553) '*' is a valid 'Access-Control-Allow-Origin' response, but was also changed to only work for HTTPS URLs using cors-crypt (#5665) '*' should", "Allow wildcarded CORS origins (#25553) '*' is a valid 'Access-Control-Allow-Origin' response, but was originally intended to only work for HTTPS URLs using cors-crypt (#5665) '*' should", "Allow wildcarded CORS origins (#25553) '*' is a valid 'Access-Control-Allow-Origin' response, but was originally intended to only work for HTTPS URLs using cors-crypt os. This should", "Allow wildcarded CORS origins (#25553) This is now a valid 'Access-Control-Allow-Origin' response, but was originally intended to only work for HTTPS URLs using cors-crypt (#5665) '*' should"], "perturbed_original": ["Allow no origins (#25553) '*' is a valid 'Access-Control-Allow-Origin' response, but was being dropped as it failed to match the Origin header sent in requests.", "Allow me origins (#25553) '*' is a valid 'Access-Control-Allow-Origin' response, but was being dropped as it failed to match the Origin header sent in requests.", "Allow wildcarded CORS origins (#25553) '*' header was a valid 'Access-Control-Allow-Origin' response, but was being dropped as it failed to match the Origin header sent in requests.", "Allow wildcarded CORS origins (#25553) '*' is a valid 'Access-Control-Allow-Origin' response, but was being dropped as it failed to conform to the CORS X-Cost-Less-Certificates Forbidden Origin header sent in requests.", "Allow wildcarded CORS origins (#25553) '*' was returning a valid 'Access-Control-Allow-Origin' response, but was being dropped as it failed to match the Origin header sent in requests.", "Allow wildcarded CORS origins (#25553) sent a valid 'Access-Control-Allow-Origin' response, but was being dropped as it failed to match the Origin header sent in requests.", "Allow wildcarded CORS origins ? This is a valid 'Access-Control-Allow-Origin' response, but was being dropped as it failed to match the Origin header sent in requests.", "Allow wildcarded queries. (#25553) '*' is a valid 'Access-Control-Allow-Origin' response, but was being dropped as it failed to match the Origin header sent in requests.", "Allow wildcarded CORS origins (#25553) '*' is a valid 'Access-Control-Allow-Origin' response, but was being dropped as it failed to match the Origin header in CORS DIR requests.", "Allow wildcarded CORS origins (#25553) '*' is a request response, but was being dropped as it failed to match the Origin header sent in requests."], "original_ll": -3.887397289276123, "sampled_ll": -3.6816861629486084, "all_perturbed_sampled_ll": [-3.8289377689361572, -3.776143789291382, -4.169802188873291, -3.582643508911133, -3.704636573791504, -3.71213436126709, -3.7198238372802734, -3.6816861629486084, -4.079235076904297, -3.8031978607177734], "all_perturbed_original_ll": [-3.903693199157715, -3.905686616897583, -3.977088689804077, -4.1133317947387695, -3.830317497253418, -4.048722267150879, -3.8740062713623047, -3.679969072341919, -3.89746356010437, -4.8095221519470215], "perturbed_sampled_ll": -3.805824112892151, "perturbed_original_ll": -4.003980112075806, "perturbed_sampled_ll_std": 0.1732882577054432, "perturbed_original_ll_std": 0.2909777803202053}, {"original": "Use iterative loop to look for mapped parent (#34622)", "sampled": "Use iterative loop to look for mapped parent (#34622)ImageOptimizer:", "perturbed_sampled": ["Use iterative loop to look for mapped parent (#34622)ImageOptimizer:", "Use iterative loop to look for mapped parent (#34622)ImageOptimizer:", "Use iterative loop to look for mapped parent (#34622)ImageOptimizer:", "Use iterative loop to look for mapped parent (#34622)ImageOptimizer:", "Use iterative loop to look for mapped parent (#34622)ImageOptimizer:", "Use iterative loop to look for mapped parent (#34622)ImageOptimizer:", "Use iterative loop to look for mapped parent (#34622)ImageOptimizer:", "Use iterative loop to look for mapped parent (#34622)ImageOptimizer:", "Use iterative loop to look for mapped parent (#34622)ImageOptimizer:", "Use iterative loop to look for mapped parent (#34622)ImageOptimizer:"], "perturbed_original": ["Use iterative loop to look for mapped parent (#34622)", "Use iterative loop to look for mapped parent (#34622)", "Use iterative loop to look for mapped parent (#34622)", "Use iterative loop to look for mapped parent (#34622)", "Use iterative loop to look for mapped parent (#34622)", "Use iterative loop to look for mapped parent (#34622)", "Use iterative loop to look for mapped parent (#34622)", "Use iterative loop to look for mapped parent (#34622)", "Use iterative loop to look for mapped parent (#34622)", "Use iterative loop to look for mapped parent (#34622)"], "original_ll": -6.205062389373779, "sampled_ll": -5.74837589263916, "all_perturbed_sampled_ll": [-5.74837589263916, -5.74837589263916, -5.74837589263916, -5.74837589263916, -5.74837589263916, -5.74837589263916, -5.74837589263916, -5.74837589263916, -5.74837589263916, -5.74837589263916], "all_perturbed_original_ll": [-6.205062389373779, -6.205062389373779, -6.205062389373779, -6.205062389373779, -6.205062389373779, -6.205062389373779, -6.205062389373779, -6.205062389373779, -6.205062389373779, -6.205062389373779], "perturbed_sampled_ll": -5.74837589263916, "perturbed_original_ll": -6.205062389373779, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Add URI to dataset event response (#25250) Also, update the `extra` fields to return as JSON in the REST API.", "sampled": "Add URI to dataset event response (#25250) Also, update the `extra` fields to return as JSON in the REST API.I", "perturbed_sampled": ["Add URI to dataset event response (#25250) Also, update the dataset event response to return as JSON in the REST API.I", "Add URI to dataset event response (#25250) and to add the `extra` fields to return as JSON in the REST API.I", "Add URI to dataset event response (#25250) Also, update the `extra` fields to return as JSON in the API.I", "Add URI to dataset event . Also, update the `extra` fields to return as JSON in the REST API.I", "Add URI to dataset event response to update the `extra` fields to return as JSON in the REST API.I", "Add URI to dataset event response (#25250) Also, update the `extra` parameters; they return as JSON in the REST API.I", "Add URI to dataset event response (#25250) Also, update the `extra` object to return as JSON in the REST API.I", "Add URI to dataset event response (#25250) Also, update the `extra` fields to return as JSON in the API.I", "Add URI to dataset event . Also, update the `extra` fields to return as JSON in the REST API.I", "Add URI to dataset event response (#25250) Also, update the `extra` fields to return as JSON in the git API.I"], "perturbed_original": ["Add URI to dataset event response (#25250) Also, Add `extra` fields to return as JSON in the REST API.", "Add URI to dataset event response (#25250) Also, update the `extra` fields to return as JSON object. Added URI to dataset endpoint REST API.", "Add URI to dataset event response (#25250) for the `extra` fields to return as JSON in the REST API.", "Add URI to dataset event response (#25250) Also, support `extra` fields to return as JSON in the REST API.", "Add URI to dataset event response (#25250) Also, update REST fields to return as JSON in the REST API.", "Add URI to dataset event response , update the `extra` fields to return as JSON in the REST API.", "Add URI to dataset event response (#25250) Also, update the `extra` fields to return the dataset ID in the REST API.", "Add URI to dataset event response (#25250) is one of the `extra` fields to return as JSON in the REST API.", "Add URI to each response (#25250) Also, update the `extra` fields to return as JSON in the REST API.", ", add vars to dataset event response (#25250) Also, update the `extra` fields to return as JSON in the REST API."], "original_ll": -5.271572589874268, "sampled_ll": -5.556675434112549, "all_perturbed_sampled_ll": [-5.218902587890625, -5.559602737426758, -5.670729637145996, -5.432898998260498, -5.6100382804870605, -5.73471736907959, -5.574557304382324, -5.670729637145996, -5.432898998260498, -5.837928295135498], "all_perturbed_original_ll": [-5.490691661834717, -5.150778293609619, -5.397630214691162, -5.478330135345459, -5.582829475402832, -5.587308406829834, -5.1701436042785645, -5.143191814422607, -4.781949043273926, -5.1492919921875], "perturbed_sampled_ll": -5.574300384521484, "perturbed_original_ll": -5.293214464187622, "perturbed_sampled_ll_std": 0.1678153949082083, "perturbed_original_ll_std": 0.24384074912345813}, {"original": "Sync context.py with context.pyi (#27770)", "sampled": "Sync context.py with context.pyi (#27770)By", "perturbed_sampled": ["Sync context.py with context.pyi (#27770)By", "Sync context.py with context.pyi (#27770)By", "Sync context.py with context.pyi (#27770)By", "Sync context.py with context.pyi (#27770)By", "Sync context.py with context.pyi (#27770)By", "Sync context.py with context.pyi (#27770)By", "Sync context.py with context.pyi (#27770)By", "Sync context.py with context.pyi (#27770)By", "Sync context.py with context.pyi (#27770)By", "Sync context.py with context.pyi (#27770)By"], "perturbed_original": ["Sync context.py with context.pyi (#27770)", "Sync context.py with context.pyi (#27770)", "Sync context.py with context.pyi (#27770)", "Sync context.py with context.pyi (#27770)", "Sync context.py with context.pyi (#27770)", "Sync context.py with context.pyi (#27770)", "Sync context.py with context.pyi (#27770)", "Sync context.py with context.pyi (#27770)", "Sync context.py with context.pyi (#27770)", "Sync context.py with context.pyi (#27770)"], "original_ll": -5.322444438934326, "sampled_ll": -6.01880407333374, "all_perturbed_sampled_ll": [-6.01880407333374, -6.01880407333374, -6.01880407333374, -6.01880407333374, -6.01880407333374, -6.01880407333374, -6.01880407333374, -6.01880407333374, -6.01880407333374, -6.01880407333374], "all_perturbed_original_ll": [-5.322444438934326, -5.322444438934326, -5.322444438934326, -5.322444438934326, -5.322444438934326, -5.322444438934326, -5.322444438934326, -5.322444438934326, -5.322444438934326, -5.322444438934326], "perturbed_sampled_ll": -6.01880407333374, "perturbed_original_ll": -5.322444438934326, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Clean local tags in tag_providers for network issues with Github (#34951)", "sampled": "Clean local tags in tag_providers for network issues with Github (#34951)Moved", "perturbed_sampled": ["Clean local tags in tag_providers for network issues with Github (#34951)Moved", "Clean local tags in tag_providers for network issues with Github (#34951)Moved", "Clean local tags in tag_providers for network issues with Github (#34951)Moved", "Clean local tags in tag_providers for network issues with Github (#34951)Moved", "Clean local tags in tag_providers for network issues with Github (#34951)Moved", "Clean local tags in tag_providers for network issues with Github (#34951)Moved", "Clean local tags in tag_providers for network issues with Github (#34951)Moved", "Clean local tags in tag_providers for network issues with Github (#34951)Moved", "Clean local tags in tag_providers for network issues with Github (#34951)Moved", "Clean local tags in tag_providers for network issues with Github (#34951)Moved"], "perturbed_original": ["Clean local tags in tag_providers for network issues with Github (#34951)", "Clean local tags in tag_providers for network issues with Github (#34951)", "Clean local tags in tag_providers for network issues with Github (#34951)", "Clean local tags in tag_providers for network issues with Github (#34951)", "Clean local tags in tag_providers for network issues with Github (#34951)", "Clean local tags in tag_providers for network issues with Github (#34951)", "Clean local tags in tag_providers for network issues with Github (#34951)", "Clean local tags in tag_providers for network issues with Github (#34951)", "Clean local tags in tag_providers for network issues with Github (#34951)", "Clean local tags in tag_providers for network issues with Github (#34951)"], "original_ll": -6.204710960388184, "sampled_ll": -6.4350080490112305, "all_perturbed_sampled_ll": [-6.4350080490112305, -6.4350080490112305, -6.4350080490112305, -6.4350080490112305, -6.4350080490112305, -6.4350080490112305, -6.4350080490112305, -6.4350080490112305, -6.4350080490112305, -6.4350080490112305], "all_perturbed_original_ll": [-6.204710960388184, -6.204710960388184, -6.204710960388184, -6.204710960388184, -6.204710960388184, -6.204710960388184, -6.204710960388184, -6.204710960388184, -6.204710960388184, -6.204710960388184], "perturbed_sampled_ll": -6.4350080490112305, "perturbed_original_ll": -6.204710960388184, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "AIP-47 - Migrate google leveldb DAGs to new design ##22447 (#24233)", "sampled": "AIP-47 - Migrate google leveldb DAGs to new design ##22447 (#24233)You", "perturbed_sampled": ["AIP-47 - Migrate google leveldb DAGs to new design ##22447 (#24233)You", "AIP-47 - Migrate google leveldb DAGs to new design ##22447 (#24233)You", "AIP-47 - Migrate google leveldb DAGs to new design ##22447 (#24233)You", "AIP-47 - Migrate google leveldb DAGs to new design ##22447 (#24233)You", "AIP-47 - Migrate google leveldb DAGs to new design ##22447 (#24233)You", "AIP-47 - Migrate google leveldb DAGs to new design ##22447 (#24233)You", "AIP-47 - Migrate google leveldb DAGs to new design ##22447 (#24233)You", "AIP-47 - Migrate google leveldb DAGs to new design ##22447 (#24233)You", "AIP-47 - Migrate google leveldb DAGs to new design ##22447 (#24233)You", "AIP-47 - Migrate google leveldb DAGs to new design ##22447 (#24233)You"], "perturbed_original": ["AIP-47 - Migrate google leveldb DAGs to new design ##22447 (#24233)", "AIP-47 - Migrate google leveldb DAGs to new design ##22447 (#24233)", "AIP-47 - Migrate google leveldb DAGs to new design ##22447 (#24233)", "AIP-47 - Migrate google leveldb DAGs to new design ##22447 (#24233)", "AIP-47 - Migrate google leveldb DAGs to new design ##22447 (#24233)", "AIP-47 - Migrate google leveldb DAGs to new design ##22447 (#24233)", "AIP-47 - Migrate google leveldb DAGs to new design ##22447 (#24233)", "AIP-47 - Migrate google leveldb DAGs to new design ##22447 (#24233)", "AIP-47 - Migrate google leveldb DAGs to new design ##22447 (#24233)", "AIP-47 - Migrate google leveldb DAGs to new design ##22447 (#24233)"], "original_ll": -6.01706075668335, "sampled_ll": -6.3519768714904785, "all_perturbed_sampled_ll": [-6.3519768714904785, -6.3519768714904785, -6.3519768714904785, -6.3519768714904785, -6.3519768714904785, -6.3519768714904785, -6.3519768714904785, -6.3519768714904785, -6.3519768714904785, -6.3519768714904785], "all_perturbed_original_ll": [-6.01706075668335, -6.01706075668335, -6.01706075668335, -6.01706075668335, -6.01706075668335, -6.01706075668335, -6.01706075668335, -6.01706075668335, -6.01706075668335, -6.01706075668335], "perturbed_sampled_ll": -6.3519768714904785, "perturbed_original_ll": -6.01706075668335, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "removed unnecessary dependence on bcrypt (#22498) Co-authored-by: Matt Rixman <MatrixManAtYrService@users.noreply.github.com>", "sampled": "removed unnecessary dependence on bcrypt (#22498) Co-authored-by: Matt Rixman <MatrixManAtYrService@users.sourceforge.net>", "perturbed_sampled": ["removed unnecessary dependence on bcrypt (#22498) Co-authored-by: Matt Rixman <MatrixManAtYrService@users.sourceforge.net>", "removed unnecessary dependence on bcrypt (#22498) Co-authored-by: Matt Rixman <MatrixManAtYrService@users.sourceforge.net>", "removed unnecessary dependence on bcrypt (#22498) Co-authored-by: Matt Rixman <MatrixManAtYrService@users.sourceforge.net>", "removed unnecessary dependence on bcrypt (#22498) Co-authored-by: Matt Rixman <MatrixManAtYrService@users.sourceforge.net>", "removed unnecessary dependence on bcrypt (#22498) Co-authored-by: Matt Rixman <MatrixManAtYrService@users.sourceforge.net>", "removed unnecessary dependence on bcrypt (#22498) Co-authored-by: Matt Rixman <MatrixManAtYrService@users.sourceforge.net>", "removed unnecessary dependence on bcrypt (#22498) Co-authored-by: Matt Rixman <MatrixManAtYrService@users.sourceforge.net>", "removed unnecessary dependence on bcrypt (#22498) Co-authored-by: Matt Rixman <MatrixManAtYrService@users.sourceforge.net>", "removed unnecessary dependence on bcrypt (#22498) Co-authored-by: Matt Rixman <MatrixManAtYrService@users.sourceforge.net>", "removed unnecessary dependence on bcrypt (#22498) Co-authored-by: Matt Rixman <MatrixManAtYrService@users.sourceforge.net>"], "perturbed_original": ["removed unnecessary dependence on bcrypt (#22498) Co-authored-by: Matt Rixman <MatrixManAtYrService@users.noreply.github.com>", "removed unnecessary dependence on bcrypt (#22498) Co-authored-by: Matt Rixman <MatrixManAtYrService@users.noreply.github.com>", "removed unnecessary dependence on bcrypt (#22498) Co-authored-by: Matt Rixman <MatrixManAtYrService@users.noreply.github.com>", "removed unnecessary dependence on bcrypt (#22498) Co-authored-by: Matt Rixman <MatrixManAtYrService@users.noreply.github.com>", "removed unnecessary dependence on bcrypt (#22498) Co-authored-by: Matt Rixman <MatrixManAtYrService@users.noreply.github.com>", "removed unnecessary dependence on bcrypt (#22498) Co-authored-by: Matt Rixman <MatrixManAtYrService@users.noreply.github.com>", "removed unnecessary dependence on bcrypt (#22498) Co-authored-by: Matt Rixman <MatrixManAtYrService@users.noreply.github.com>", "removed unnecessary dependence on bcrypt (#22498) Co-authored-by: Matt Rixman <MatrixManAtYrService@users.noreply.github.com>", "removed unnecessary dependence on bcrypt (#22498) Co-authored-by: Matt Rixman <MatrixManAtYrService@users.noreply.github.com>", "removed unnecessary dependence on bcrypt (#22498) Co-authored-by: Matt Rixman <MatrixManAtYrService@users.noreply.github.com>"], "original_ll": -4.536611557006836, "sampled_ll": -4.9109601974487305, "all_perturbed_sampled_ll": [-4.9109601974487305, -4.9109601974487305, -4.9109601974487305, -4.9109601974487305, -4.9109601974487305, -4.9109601974487305, -4.9109601974487305, -4.9109601974487305, -4.9109601974487305, -4.9109601974487305], "all_perturbed_original_ll": [-4.536611557006836, -4.536611557006836, -4.536611557006836, -4.536611557006836, -4.536611557006836, -4.536611557006836, -4.536611557006836, -4.536611557006836, -4.536611557006836, -4.536611557006836], "perturbed_sampled_ll": -4.9109601974487305, "perturbed_original_ll": -4.536611557006836, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Remove redundand catch exception in Amazon Log Task Handlers (#26442)", "sampled": "Remove redundand catch exception in Amazon Log Task Handlers (#26442)Forces", "perturbed_sampled": ["Remove redundand catch exception in Amazon Log Task Handlers (#26442)Forces", "Remove redundand catch exception in Amazon Log Task Handlers (#26442)Forces", "Remove redundand catch exception in Amazon Log Task Handlers (#26442)Forces", "Remove redundand catch exception in Amazon Log Task Handlers (#26442)Forces", "Remove redundand catch exception in Amazon Log Task Handlers (#26442)Forces", "Remove redundand catch exception in Amazon Log Task Handlers (#26442)Forces", "Remove redundand catch exception in Amazon Log Task Handlers (#26442)Forces", "Remove redundand catch exception in Amazon Log Task Handlers (#26442)Forces", "Remove redundand catch exception in Amazon Log Task Handlers (#26442)Forces", "Remove redundand catch exception in Amazon Log Task Handlers (#26442)Forces"], "perturbed_original": ["Remove redundand catch exception in Amazon Log Task Handlers (#26442)", "Remove redundand catch exception in Amazon Log Task Handlers (#26442)", "Remove redundand catch exception in Amazon Log Task Handlers (#26442)", "Remove redundand catch exception in Amazon Log Task Handlers (#26442)", "Remove redundand catch exception in Amazon Log Task Handlers (#26442)", "Remove redundand catch exception in Amazon Log Task Handlers (#26442)", "Remove redundand catch exception in Amazon Log Task Handlers (#26442)", "Remove redundand catch exception in Amazon Log Task Handlers (#26442)", "Remove redundand catch exception in Amazon Log Task Handlers (#26442)", "Remove redundand catch exception in Amazon Log Task Handlers (#26442)"], "original_ll": -7.047425746917725, "sampled_ll": -7.479809284210205, "all_perturbed_sampled_ll": [-7.479809284210205, -7.479809284210205, -7.479809284210205, -7.479809284210205, -7.479809284210205, -7.479809284210205, -7.479809284210205, -7.479809284210205, -7.479809284210205, -7.479809284210205], "all_perturbed_original_ll": [-7.047425746917725, -7.047425746917725, -7.047425746917725, -7.047425746917725, -7.047425746917725, -7.047425746917725, -7.047425746917725, -7.047425746917725, -7.047425746917725, -7.047425746917725], "perturbed_sampled_ll": -7.479809284210205, "perturbed_original_ll": -7.047425746917725, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Fix security model link (#33597)", "sampled": "Fix security model link (#33597)This", "perturbed_sampled": ["Fix security model link (#33597)This", "Fix security model link (#33597)This", "Fix security model link (#33597)This", "Fix security model link (#33597)This", "Fix security model link (#33597)This", "Fix security model link (#33597)This", "Fix security model link (#33597)This", "Fix security model link (#33597)This", "Fix security model link (#33597)This", "Fix security model link (#33597)This"], "perturbed_original": ["Fix security model link (#33597)", "Fix security model link (#33597)", "Fix security model link (#33597)", "Fix security model link (#33597)", "Fix security model link (#33597)", "Fix security model link (#33597)", "Fix security model link (#33597)", "Fix security model link (#33597)", "Fix security model link (#33597)", "Fix security model link (#33597)"], "original_ll": -7.620337009429932, "sampled_ll": -8.281484603881836, "all_perturbed_sampled_ll": [-8.281484603881836, -8.281484603881836, -8.281484603881836, -8.281484603881836, -8.281484603881836, -8.281484603881836, -8.281484603881836, -8.281484603881836, -8.281484603881836, -8.281484603881836], "all_perturbed_original_ll": [-7.620337009429932, -7.620337009429932, -7.620337009429932, -7.620337009429932, -7.620337009429932, -7.620337009429932, -7.620337009429932, -7.620337009429932, -7.620337009429932, -7.620337009429932], "perturbed_sampled_ll": -8.281484603881836, "perturbed_original_ll": -7.620337009429932, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Adjust some wording in the release process (#29278) This rewords the header in our testing issue, and fixes the rat section of the helm vote email.", "sampled": "Adjust some wording in the release process (#29278) This rewords the header in our testing issue, and fixes the rat section of the helm vote. Make", "perturbed_sampled": ["Adjust some wording in the release process (#29278) , includes the header in our testing issue, and fixes the rat section of the helm vote. Make", "Adjust some wording in the release process (#29278) This rewords the header in our testing issue, and amends the rat section of the helm vote. Make", "Adjust some wording in the release process (#29278) This rewords some language in our testing issue, and fixes the rat section of the helm vote. Make", "Adjust some wording in the release process , rewords the header in our testing issue, and fixes the rat section of the helm vote. Make", "Adjust some wording in the release process (#29278) This rewords the release process to match our testing issue, and fixes the rat section of the helm vote. Make", "Adjust some wording in the release process (#29278) This rewords the header in our testing issue, and fixes the rat section around a helm vote. Make", "Adjust some wording in the release process (#29278) This rewords the header in our process and fixes the rat section of the helm vote. Make", "rewording of wording in the release process (#29278) This rewords the header in our testing issue, and fixes the rat section of the helm vote. Make", "Adjust ing header in the release process (#29278) This rewords the header in our testing issue, and fixes the rat section of the helm vote. Make", "Adjust some wording in the release process (#29278) This rewords the header in our testing issue, and fixes the rat section in the helm vote. Make"], "perturbed_original": ["Adjust some wording in the release process (#29278) This rewords the header in our testing issue, and fixes the rat ification bug in the helm vote email.", "the wording in the release process (#29278) This rewords the header in our testing issue, and fixes the rat section of the helm vote email.", "Adjust some wording in the release process (#29278) This rewords the header of the release procedure in the testing issue, and fixes the rat section of the helm vote email.", "Adjust some wording in the testing process (#29278) This rewords the header in our testing issue, and fixes the rat section of the helm vote email.", "Adjust some wording in the release process (#29278) This rewords the header in our testing issue, and fixes the heading in a section of the helm vote email.", "Adjust some wording in the release process (#29278) This rewords the header in our testing issue, and fixes the rat section of the vote email.", "Adjust some errata for the release process (#29278) This rewords the header in our testing issue, and fixes the rat section of the helm vote email.", "Adjust some wording in the release process (#29278) This rewords the header in our testing issue, and fixes a typo in the Release section of the helm vote email.", "Adjust some wording in the release process (#29278) This rewords the header in our testing issue, and fixes a typo in the last section of the helm vote email.", "Adjust some wording in the release process (#29278) This rewords the header in our release process email and fixes the rat section of the helm vote email."], "original_ll": -5.740546226501465, "sampled_ll": -5.632903099060059, "all_perturbed_sampled_ll": [-5.642666816711426, -5.580130577087402, -5.452979564666748, -5.620932102203369, -5.222486972808838, -5.874784469604492, -5.714994430541992, -5.749011993408203, -6.0945000648498535, -5.616901874542236], "all_perturbed_original_ll": [-5.931901931762695, -5.9233574867248535, -5.3400139808654785, -5.629655361175537, -5.383009433746338, -5.4326863288879395, -5.656334400177002, -5.079762935638428, -5.0558180809021, -5.558364391326904], "perturbed_sampled_ll": -5.656938886642456, "perturbed_original_ll": -5.4990904331207275, "perturbed_sampled_ll_std": 0.22138539147200842, "perturbed_original_ll_std": 0.2877725044872509}, {"original": "Upgrade utils files to typescript (#25089) * Migrate utils to typescript. * Use PropsWithChildren for typing props.", "sampled": "Upgrade utils files to typescript (#25089) * Migrate utils to typescript. * Use PropsWithChildren for typing (#23954)", "perturbed_sampled": ["Upgrade core to typescript (#25089) * Migrate utils to typescript. * Use PropsWithChildren for typing (#23954)", "Upgrade utils files to typescript. * Migrate utils to typescript. * Use PropsWithChildren for typing (#23954)", "Upgrade utils files to typescript (#25089) * Migrate utils to typescript (#25099) * Use PropsWithChildren for typing (#23954)", "Upgrade utils files to typescript (#25089) * Migrate utils to typescript (#25398) * Use PropsWithChildren for typing (#23954)", "Upgrade utils files to typescript (#25089) * Migrate utils to typescript. * Modify typescript for typing (#23954)", "Upgrade utils files to typescript (#25089) * Migrate utils to typescript. * Use PropsWithChildren for typing (#23954)", "Upgrade utils to typescript (#25089) * Migrate utils to typescript. * Use PropsWithChildren for typing (#23954)", "Upgrade utils files to typescript (#25089) * Migrate utils to typescript. * Add documentation for typing (#23954)", "Upgrade utils files to typescript (#25089) * Migrate typescript binaries to typescript. * Use PropsWithChildren for typing (#23954)", "Upgrade utils files to typescript (#25089) * Migrate utils to typescript. * Use PropsWithChildren for typing (#23954)"], "perturbed_original": ["Upgrade utils files to typescript (#25089) * Upgrade utils files to typescript. * Use PropsWithChildren for typing props.", "Upgrade utils files to typescript (#25089) * Migrate utils to typescript. * Use PropsWithChildren for typing props.", "Upgrade utils files to typescript (#25089) * Migrate utils to typescript * Use PropsWithChildren for typing props.", "Upgrade utils files to typescript (#25089) * Migrate utils to typescript files, * Use PropsWithChildren for typing props.", "Upgrade utils files to typescript (#25089) * Migrate utils to typescript * Use PropsWithChildren for typing props.", "Upgrade utils files to typescript (#25089) | Upgrade utils to typescript. * Use PropsWithChildren for typing props.", "Upgrade utils files to typescript (#25089) * Migrate utils to typescript (#25089) * Use PropsWithChildren for typing props.", "Upgrade utils files to typescript (#25089) Upgrade utils to typescript. * Use PropsWithChildren for typing props.", "(#25088) ** Migrate files to typescript (#25089) * Migrate utils to typescript. * Use PropsWithChildren for typing props.", "Upgrade utils , props and some props from ruby to typescript (#25089) * Migrate utils to typescript. * Use PropsWithChildren for typing props."], "original_ll": -4.185390472412109, "sampled_ll": -4.104963779449463, "all_perturbed_sampled_ll": [-4.251850605010986, -4.100603103637695, -3.809354543685913, -3.8578546047210693, -3.637465715408325, -4.104963779449463, -3.9419238567352295, -3.840580940246582, -4.251641750335693, -4.104963779449463], "all_perturbed_original_ll": [-4.084544658660889, -4.185390472412109, -4.322810649871826, -4.489638328552246, -4.322810649871826, -4.516203880310059, -3.819998264312744, -4.42376184463501, -3.992949962615967, -4.214179039001465], "perturbed_sampled_ll": -3.990120267868042, "perturbed_original_ll": -4.237228775024414, "perturbed_sampled_ll_std": 0.1935720452664506, "perturbed_original_ll_std": 0.21243002832532148}, {"original": "Fix docs building for workday example. (#30664) The #30660 was merged to quickly as it results in doc building failure. This PR fixes it.", "sampled": "Fix docs building for workday example. (#30664) The #30660 was merged to quickly as it results in doc building failure. This PR is to", "perturbed_sampled": ["Fix docs building for example. (#30664) The #30660 was merged to quickly as it results in doc building failure. This PR is to", "Fix docs building for workday example. (#30664) The #30660 was resolved too quickly as it results in doc building failure. This PR is to", "Fix docs building for workday example. (#30664) This PR was merged to quickly as it results in doc building failure. This PR is to", "Fix docs building for workday example. (#30664) The #30660 was merged to quickly as it results in doc building failure. The correct way to fix them is to", "Fix docs building for workday example. (#30664) The #30660 was merged to quickly as it was still in doc building failure. This PR is to", "Fix docs building for workday example. (#30664) The PR was merged to quickly as it results in doc building failure. This PR is to", "Fix docs building for workday example. (#30664) The #30660 was merged to quickly as it would result in doc building failure. This PR is to", "Fix docs building failure as example. (#30664) The #30660 was merged to quickly as it results in doc building failure. This PR is to", "Fix docs building failure on RDF for example. (#30664) The #30660 was merged to quickly as it results in doc building failure. This PR is to", "Fix docs building for workday example. (#30664) The #30660 was merged to quickly as it results in a failure. This PR is to"], "perturbed_original": ["Fix docs building for workday example. (#30664) The #30660 was merged to quickly as it results in a docs-building failure. This PR fixes it.", "Fix docs building for workday example. (#30664) The #30660 was pulled quickly as it results in doc building failure. This PR fixes it.", "Fix docs building for workday example. (#30664) The #30660 was merged to quickly as it results in doc building failure. The #30664-5 fixes it.", "Fix docs building for workday example. PR #30660 was merged to quickly as it results in doc building failure. This PR fixes it.", "Fix docs building failure, for example. (#30664) The #30660 was merged to quickly as it results in doc building failure. This PR fixes it.", "Fix docs building for workday example. (#30664) The fix was merged to quickly as it results in doc building failure. This PR fixes it.", "Fix docs building for workday example. (#30664) The #30660 was merged to the project, but it results in doc building failure. This PR fixes it.", "Fix docs building for workday example. (#30664) : This change was merged to quickly as it results in doc building failure. This PR fixes it.", "Fix docs building for workday example. (#30664) The #30660 was merged to quickly as it results in doc building failure. This fixes it.", "Revert Doc building for workday example. (#30664) The #30660 was merged to quickly as it results in doc building failure. This PR fixes it."], "original_ll": -5.234345436096191, "sampled_ll": -5.387862205505371, "all_perturbed_sampled_ll": [-5.307504653930664, -5.125551700592041, -5.296611785888672, -5.019769668579102, -5.410767555236816, -5.350138187408447, -5.143316268920898, -5.16663122177124, -5.060051918029785, -5.361485481262207], "all_perturbed_original_ll": [-4.997773170471191, -5.099656581878662, -5.018621444702148, -5.38415002822876, -4.812620639801025, -5.434370994567871, -4.698139667510986, -5.364665508270264, -5.22800350189209, -5.395288467407227], "perturbed_sampled_ll": -5.224182844161987, "perturbed_original_ll": -5.143329000473022, "perturbed_sampled_ll_std": 0.13039267410959096, "perturbed_original_ll_std": 0.2466882080379078}, {"original": "Use compat data interval shim in log handlers (#21289)", "sampled": "Use compat data interval shim in log handlers (#21289)Misc.", "perturbed_sampled": ["Use compat data interval shim in log handlers (#21289)Misc.", "Use compat data interval shim in log handlers (#21289)Misc.", "Use compat data interval shim in log handlers (#21289)Misc.", "Use compat data interval shim in log handlers (#21289)Misc.", "Use compat data interval shim in log handlers (#21289)Misc.", "Use compat data interval shim in log handlers (#21289)Misc.", "Use compat data interval shim in log handlers (#21289)Misc.", "Use compat data interval shim in log handlers (#21289)Misc.", "Use compat data interval shim in log handlers (#21289)Misc.", "Use compat data interval shim in log handlers (#21289)Misc."], "perturbed_original": ["Use compat data interval shim in log handlers (#21289)", "Use compat data interval shim in log handlers (#21289)", "Use compat data interval shim in log handlers (#21289)", "Use compat data interval shim in log handlers (#21289)", "Use compat data interval shim in log handlers (#21289)", "Use compat data interval shim in log handlers (#21289)", "Use compat data interval shim in log handlers (#21289)", "Use compat data interval shim in log handlers (#21289)", "Use compat data interval shim in log handlers (#21289)", "Use compat data interval shim in log handlers (#21289)"], "original_ll": -7.320357799530029, "sampled_ll": -7.052872180938721, "all_perturbed_sampled_ll": [-7.052872180938721, -7.052872180938721, -7.052872180938721, -7.052872180938721, -7.052872180938721, -7.052872180938721, -7.052872180938721, -7.052872180938721, -7.052872180938721, -7.052872180938721], "all_perturbed_original_ll": [-7.320357799530029, -7.320357799530029, -7.320357799530029, -7.320357799530029, -7.320357799530029, -7.320357799530029, -7.320357799530029, -7.320357799530029, -7.320357799530029, -7.320357799530029], "perturbed_sampled_ll": -7.052872180938721, "perturbed_original_ll": -7.320357799530029, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Mask task attribute on task detail view (#31125)", "sampled": "Mask task attribute on task detail view (#31125)In", "perturbed_sampled": ["Mask task attribute on task detail view (#31125)In", "Mask task attribute on task detail view (#31125)In", "Mask task attribute on task detail view (#31125)In", "Mask task attribute on task detail view (#31125)In", "Mask task attribute on task detail view (#31125)In", "Mask task attribute on task detail view (#31125)In", "Mask task attribute on task detail view (#31125)In", "Mask task attribute on task detail view (#31125)In", "Mask task attribute on task detail view (#31125)In", "Mask task attribute on task detail view (#31125)In"], "perturbed_original": ["Mask task attribute on task detail view (#31125)", "Mask task attribute on task detail view (#31125)", "Mask task attribute on task detail view (#31125)", "Mask task attribute on task detail view (#31125)", "Mask task attribute on task detail view (#31125)", "Mask task attribute on task detail view (#31125)", "Mask task attribute on task detail view (#31125)", "Mask task attribute on task detail view (#31125)", "Mask task attribute on task detail view (#31125)", "Mask task attribute on task detail view (#31125)"], "original_ll": -6.254473686218262, "sampled_ll": -6.977399826049805, "all_perturbed_sampled_ll": [-6.977399826049805, -6.977399826049805, -6.977399826049805, -6.977399826049805, -6.977399826049805, -6.977399826049805, -6.977399826049805, -6.977399826049805, -6.977399826049805, -6.977399826049805], "all_perturbed_original_ll": [-6.254473686218262, -6.254473686218262, -6.254473686218262, -6.254473686218262, -6.254473686218262, -6.254473686218262, -6.254473686218262, -6.254473686218262, -6.254473686218262, -6.254473686218262], "perturbed_sampled_ll": -6.977399826049805, "perturbed_original_ll": -6.254473686218262, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Remove sensitive information from Celery executor warning (#34954)", "sampled": "Remove sensitive information from Celery executor warning (#34954)This", "perturbed_sampled": ["Remove sensitive information from Celery executor warning (#34954)This", "Remove sensitive information from Celery executor warning (#34954)This", "Remove sensitive information from Celery executor warning (#34954)This", "Remove sensitive information from Celery executor warning (#34954)This", "Remove sensitive information from Celery executor warning (#34954)This", "Remove sensitive information from Celery executor warning (#34954)This", "Remove sensitive information from Celery executor warning (#34954)This", "Remove sensitive information from Celery executor warning (#34954)This", "Remove sensitive information from Celery executor warning (#34954)This", "Remove sensitive information from Celery executor warning (#34954)This"], "perturbed_original": ["Remove sensitive information from Celery executor warning (#34954)", "Remove sensitive information from Celery executor warning (#34954)", "Remove sensitive information from Celery executor warning (#34954)", "Remove sensitive information from Celery executor warning (#34954)", "Remove sensitive information from Celery executor warning (#34954)", "Remove sensitive information from Celery executor warning (#34954)", "Remove sensitive information from Celery executor warning (#34954)", "Remove sensitive information from Celery executor warning (#34954)", "Remove sensitive information from Celery executor warning (#34954)", "Remove sensitive information from Celery executor warning (#34954)"], "original_ll": -6.454169750213623, "sampled_ll": -6.964117050170898, "all_perturbed_sampled_ll": [-6.964117050170898, -6.964117050170898, -6.964117050170898, -6.964117050170898, -6.964117050170898, -6.964117050170898, -6.964117050170898, -6.964117050170898, -6.964117050170898, -6.964117050170898], "all_perturbed_original_ll": [-6.454169750213623, -6.454169750213623, -6.454169750213623, -6.454169750213623, -6.454169750213623, -6.454169750213623, -6.454169750213623, -6.454169750213623, -6.454169750213623, -6.454169750213623], "perturbed_sampled_ll": -6.964117050170898, "perturbed_original_ll": -6.454169750213623, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Fix wrong cron syntax (#31666)", "sampled": "Fix wrong cron syntax (#31666)It's", "perturbed_sampled": ["Fix wrong cron syntax (#31666)It's", "Fix wrong cron syntax (#31666)It's", "Fix wrong cron syntax (#31666)It's", "Fix wrong cron syntax (#31666)It's", "Fix wrong cron syntax (#31666)It's", "Fix wrong cron syntax (#31666)It's", "Fix wrong cron syntax (#31666)It's", "Fix wrong cron syntax (#31666)It's", "Fix wrong cron syntax (#31666)It's", "Fix wrong cron syntax (#31666)It's"], "perturbed_original": ["Fix wrong cron syntax (#31666)", "Fix wrong cron syntax (#31666)", "Fix wrong cron syntax (#31666)", "Fix wrong cron syntax (#31666)", "Fix wrong cron syntax (#31666)", "Fix wrong cron syntax (#31666)", "Fix wrong cron syntax (#31666)", "Fix wrong cron syntax (#31666)", "Fix wrong cron syntax (#31666)", "Fix wrong cron syntax (#31666)"], "original_ll": -6.577479839324951, "sampled_ll": -6.962238311767578, "all_perturbed_sampled_ll": [-6.962238311767578, -6.962238311767578, -6.962238311767578, -6.962238311767578, -6.962238311767578, -6.962238311767578, -6.962238311767578, -6.962238311767578, -6.962238311767578, -6.962238311767578], "all_perturbed_original_ll": [-6.577479839324951, -6.577479839324951, -6.577479839324951, -6.577479839324951, -6.577479839324951, -6.577479839324951, -6.577479839324951, -6.577479839324951, -6.577479839324951, -6.577479839324951], "perturbed_sampled_ll": -6.962238311767578, "perturbed_original_ll": -6.577479839324951, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Migrate Google example gcs_to_gdrive to new design AIP-47 (#24949) related: #22447, #22430", "sampled": "Migrate Google example gcs_to_gdrive to new design AIP-47 (#24949) related: #22447, #22452,", "perturbed_sampled": ["Migrate Google example gcs_to_gdrive to new design AIP-47 (#24949) related: #22447, #22452,", "Migrate Google example gcs_to_gdrive to new design AIP-47 (#24949) related: #22447, #22452,", "Migrate Google example gcs_to_gdrive to new design AIP-47 (#24949) related: #22447, #22452,", "Migrate Google example gcs_to_gdrive to new design AIP-47 (#24949) related: #22447, #22452,", "Migrate Google example gcs_to_gdrive to new design AIP-47 (#24949) related: #22447, #22452,", "Migrate Google example gcs_to_gdrive to new design AIP-47 (#24949) related: #22447, #22452,", "Migrate Google example gcs_to_gdrive to new design AIP-47 (#24949) related: #22447, #22452,", "Migrate Google example gcs_to_gdrive to new design AIP-47 (#24949) related: #22447, #22452,", "Migrate Google example gcs_to_gdrive to new design AIP-47 (#24949) related: #22447, #22452,", "Migrate Google example gcs_to_gdrive to new design AIP-47 (#24949) related: #22447, #22452,"], "perturbed_original": ["Migrate Google example gcs_to_gdrive to new design AIP-47 (#24949) related: #22447, #22430", "Migrate Google example gcs_to_gdrive to new design AIP-47 (#24949) related: #22447, #22430", "Migrate Google example gcs_to_gdrive to new design AIP-47 (#24949) related: #22447, #22430", "Migrate Google example gcs_to_gdrive to new design AIP-47 (#24949) related: #22447, #22430", "Migrate Google example gcs_to_gdrive to new design AIP-47 (#24949) related: #22447, #22430", "Migrate Google example gcs_to_gdrive to new design AIP-47 (#24949) related: #22447, #22430", "Migrate Google example gcs_to_gdrive to new design AIP-47 (#24949) related: #22447, #22430", "Migrate Google example gcs_to_gdrive to new design AIP-47 (#24949) related: #22447, #22430", "Migrate Google example gcs_to_gdrive to new design AIP-47 (#24949) related: #22447, #22430", "Migrate Google example gcs_to_gdrive to new design AIP-47 (#24949) related: #22447, #22430"], "original_ll": -5.8944315910339355, "sampled_ll": -5.673274040222168, "all_perturbed_sampled_ll": [-5.673274040222168, -5.673274040222168, -5.673274040222168, -5.673274040222168, -5.673274040222168, -5.673274040222168, -5.673274040222168, -5.673274040222168, -5.673274040222168, -5.673274040222168], "all_perturbed_original_ll": [-5.8944315910339355, -5.8944315910339355, -5.8944315910339355, -5.8944315910339355, -5.8944315910339355, -5.8944315910339355, -5.8944315910339355, -5.8944315910339355, -5.8944315910339355, -5.8944315910339355], "perturbed_sampled_ll": -5.673274040222168, "perturbed_original_ll": -5.8944315910339355, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Fix EC2Hook get_instance for client_type api (#35960)", "sampled": "Fix EC2Hook get_instance for client_type api (#35960)From", "perturbed_sampled": ["Fix EC2Hook get_instance for client_type api (#35960)From", "Fix EC2Hook get_instance for client_type api (#35960)From", "Fix EC2Hook get_instance for client_type api (#35960)From", "Fix EC2Hook get_instance for client_type api (#35960)From", "Fix EC2Hook get_instance for client_type api (#35960)From", "Fix EC2Hook get_instance for client_type api (#35960)From", "Fix EC2Hook get_instance for client_type api (#35960)From", "Fix EC2Hook get_instance for client_type api (#35960)From", "Fix EC2Hook get_instance for client_type api (#35960)From", "Fix EC2Hook get_instance for client_type api (#35960)From"], "perturbed_original": ["Fix EC2Hook get_instance for client_type api (#35960)", "Fix EC2Hook get_instance for client_type api (#35960)", "Fix EC2Hook get_instance for client_type api (#35960)", "Fix EC2Hook get_instance for client_type api (#35960)", "Fix EC2Hook get_instance for client_type api (#35960)", "Fix EC2Hook get_instance for client_type api (#35960)", "Fix EC2Hook get_instance for client_type api (#35960)", "Fix EC2Hook get_instance for client_type api (#35960)", "Fix EC2Hook get_instance for client_type api (#35960)", "Fix EC2Hook get_instance for client_type api (#35960)"], "original_ll": -6.085536479949951, "sampled_ll": -6.530787467956543, "all_perturbed_sampled_ll": [-6.530787467956543, -6.530787467956543, -6.530787467956543, -6.530787467956543, -6.530787467956543, -6.530787467956543, -6.530787467956543, -6.530787467956543, -6.530787467956543, -6.530787467956543], "all_perturbed_original_ll": [-6.085536479949951, -6.085536479949951, -6.085536479949951, -6.085536479949951, -6.085536479949951, -6.085536479949951, -6.085536479949951, -6.085536479949951, -6.085536479949951, -6.085536479949951], "perturbed_sampled_ll": -6.530787467956543, "perturbed_original_ll": -6.085536479949951, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Disable Flower by default from docker-compose (#23685)", "sampled": "Disable Flower by default from docker-compose (#23685)What's", "perturbed_sampled": ["Disable Flower by default from docker-compose (#23685)What's", "Disable Flower by default from docker-compose (#23685)What's", "Disable Flower by default from docker-compose (#23685)What's", "Disable Flower by default from docker-compose (#23685)What's", "Disable Flower by default from docker-compose (#23685)What's", "Disable Flower by default from docker-compose (#23685)What's", "Disable Flower by default from docker-compose (#23685)What's", "Disable Flower by default from docker-compose (#23685)What's", "Disable Flower by default from docker-compose (#23685)What's", "Disable Flower by default from docker-compose (#23685)What's"], "perturbed_original": ["Disable Flower by default from docker-compose (#23685)", "Disable Flower by default from docker-compose (#23685)", "Disable Flower by default from docker-compose (#23685)", "Disable Flower by default from docker-compose (#23685)", "Disable Flower by default from docker-compose (#23685)", "Disable Flower by default from docker-compose (#23685)", "Disable Flower by default from docker-compose (#23685)", "Disable Flower by default from docker-compose (#23685)", "Disable Flower by default from docker-compose (#23685)", "Disable Flower by default from docker-compose (#23685)"], "original_ll": -5.969259262084961, "sampled_ll": -6.405317783355713, "all_perturbed_sampled_ll": [-6.405317783355713, -6.405317783355713, -6.405317783355713, -6.405317783355713, -6.405317783355713, -6.405317783355713, -6.405317783355713, -6.405317783355713, -6.405317783355713, -6.405317783355713], "all_perturbed_original_ll": [-5.969259262084961, -5.969259262084961, -5.969259262084961, -5.969259262084961, -5.969259262084961, -5.969259262084961, -5.969259262084961, -5.969259262084961, -5.969259262084961, -5.969259262084961], "perturbed_sampled_ll": -6.405317783355713, "perturbed_original_ll": -5.969259262084961, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Cleanup references to selective checks (#24649) Selective checks docs have been moved to breeze as part of #24610 but some of the references were still left. This PR cleans it up.", "sampled": "Cleanup references to selective checks (#24649) Selective checks docs have been moved to breeze as part of #24610 but some of the references have moved as well. (#25468)\n\nDocumentation for checkers (#26425", "perturbed_sampled": ["Cleanup references to selective checks (#24649) Selective checks docs have been moved to the docs as part of #24610 but some of the references in this commit are broken as well. (#25468)\n\nDocumentation for checkers (#26425", "Cleanup references to selective checks (#24649) Selective checks have been moved to a separate topic. This was part of #24610 but some of the references have moved as well. (#25468)\n\nDocumentation for checkers (#26425", "Cleanup references to selective checks (#24649) Selective checks docs have been moved to breeze as of #24610 but some of the references have moved as well. Clean up references to docs for checkers (#26425", "Cleanup references to selective checks (#24649) Selective checks have been moved to breeze r in kb of #24610 but some of the references have moved as well. (#25468)\n\nDocumentation for checkers (#26425", "Cleanup references to selective checks (#24649) Selective checks docs have moved to breeze as part of #24610 but some of the references have moved as well. (#25468)\n\nDocumentation for checkers (#26425", "Cleanup references to selective checks (#24649) Selective checks docs have been moved to the same release as part of #24610 but apparently all the references have moved as well. (#25468)\n\nDocumentation for checkers (#26425", "Cleanup of selective checks (#24649) Selective checks docs have been moved to #24944 as part of #24610 but some of the references have moved as well. (#25468)\n\nDocumentation for checkers (#26425", "Cleanup references to selective checks (#24649) Selective checks docs have been moved to breeze head as of #24610 and most of the references have moved as well. (#25468)\n\nDocumentation for checkers (#26425", "Cleanup references to selective checks documents. Some of the checks docs have been moved to breeze as part of #24610 but some of the references have moved as well. Fix references to selective checkers (#26425", "Cleanup references to selective checks (#24649) Selective checks have been moved to breeze as part of #24610 but some of the references have been moved there as well. (#25468)\n\nDocumentation for checkers (#26425"], "perturbed_original": ["Cleanup references to selective checks (#24649) Selective checks docs have been scanned with a breeze as part of #24610 but some of the references were still left. This PR cleans it up.", "Cleanup of selective checks (#24649) Selective checks docs have been moved to breeze as part of this PR, but some of the references were still left. This PR cleans it up.", "Cleanup references to selective checks . The selective checks docs have been simplified into a breeze as part of #24610 but some of the references were still left. This PR cleans it up.", "Cleanup references to selective checks (#24649) Selective checks docs have been cleaned up with breeze .code as of #24610 but some of the references were still left. This PR cleans it up.", "Cleanup references to selective checks (#24649) Selective checks docs have been moved to breeze as part of #24610 but some of the references were still around. This PR cleans it up.", "Cleanup references to selective checks manual. Selective checks docs have been moved to breeze as part of #24610 but some of the references were still left. This PR cleans it up.", "Cleanup references to selective checks (#24649) Selective checks have been moved to breeze as part of #24610 but some referencing references were still left. This PR cleans it up.", "Cleanup of selective checks (#24649) Selective checks docs have been moved to breeze as part of #24610 but some of the references were indexed incorrectly. This PR cleans it up.", "Cleanup references to selective checks (#24649) Selective checks docs have been moved to breeze as part of #24610 but some of the references are left. This cleans it up.", "Cleanup references to selective checks . The selective checks docs have been moved to breeze as part of #24610 but some of the references are left. This PR cleans it up."], "original_ll": -4.773475646972656, "sampled_ll": -4.243875026702881, "all_perturbed_sampled_ll": [-4.016223430633545, -3.7106242179870605, -4.663503646850586, -4.609856128692627, -4.309088706970215, -4.1971845626831055, -3.905277729034424, -4.400545597076416, -4.783407211303711, -3.8912370204925537], "all_perturbed_original_ll": [-4.784109592437744, -4.449658393859863, -4.836083889007568, -4.904888153076172, -4.725261211395264, -4.894819736480713, -4.8366193771362305, -4.827911853790283, -4.88198709487915, -4.992855548858643], "perturbed_sampled_ll": -4.248694825172424, "perturbed_original_ll": -4.813419485092163, "perturbed_sampled_ll_std": 0.34742695322252987, "perturbed_original_ll_std": 0.13932205773319614}, {"original": "Fix expand/collapse all buttons (#23590) * communicate via customevents * Handle open group logic in wrapper * fix tests * Make grid action buttons sticky * Add default toggle fn * fix splitting task id by '.' * fix missing dagrun ids", "sampled": "Fix expand/collapse all buttons (#23590) * communicate via customevents * Handle open group logic in wrapper * fix tests * Make app more robust * Fixes * Fixes for testing * Documentation bug fix * Added support for using 'app_theme' parameter *", "perturbed_sampled": ["Fix expand/collapse all buttons (#23590) * communicate via customevents * Handle many bugs * fix use of logic in wrapper * fix tests * Make app more robust * Fixes bug for testing * Documentation bug fix * Improve support for using 'app_theme' parameter *", "Fix expand/collapse all buttons (#23590) * communicate via customevents * Handle custom events logic in wrapper * fix other bugs * Make app more robust * Fixes * Fixes for testing * Documentation bug fix * Added support for the 'app_theme' parameter *", "Fix expand/collapse all buttons (#23590) * communicate via customevents * improve group logic * group logic in wrapper * fix tests * Make app more robust * Fixes * Fixes for testing * Bug fix * Added support for using 'app_theme' parameter *", "Fix expand/collapse button (#23590) * communicate via customevents * Add group ing/segregation wrapper * fix tests * Make app more robust * Fixes * Fixes for testing * Documentation bug fix * Added support for using 'app_theme' parameter *", "Fix expand/collapse all tabs * make app more robust * communicate via customevents * Handle event logic in wrapper * fix tests * Make app more robust * Fixes * Fixes bugs * Documentation bug fix * Added support for using 'app_theme' parameter *", "* Send custom event to all buttons (#23590) * Push notifications via customevents * Handle open group logic in wrapper * More tests * Make app more robust * Fixes * Fixes for testing * Documentation bug fix * Added support for using 'app_theme' parameter *", "Fix expand/collapse all functions * communicate via customevents * Handle open group logic in wrapper * More stable * More stable, more reliable * more robust * Fixes * Fixes for testing * Documentation bug fix * Added support for using 'app_theme' parameter *", "Fix expand/collapse all buttons (#23590) * communicate in form * Handle open () in wrapper * fix tests * Make app more robust * Add some Fixes for testing * Documentation bug fix * Added support for using 'app_theme' parameter *", "Fix expand/collapse bug (#23590) * communicate via customevents * Handle open group logic in wrapper * fix tests * Make app more dynamic * fix testing * Fixes * Fixes * Fixes * Readability fix * Documentation bug fix * Added support for using 'app_theme' parameter *", "Fix expand/collapse all buttons (#23590) * communicate via wrapper * Handle open group logic in wrapper * fix tests * Make app more robust * Fixes bug for testing * Documentation bug fix * Validation for using 'app_theme' parameter *"], "perturbed_original": ["for all buttons (#23590) * communicate via customevents * Handle open group logic in wrapper * fix missing testset validation tests * Make grid action buttons sticky * Add default toggle fn * fix replaced button id by '.' * fix missing dagrun ids", "Fix expand/collapse all buttons * communicate with class members more transparently * Handle open group logic in wrapper * fix tests * Make grid action buttons sticky * Add default toggle fn * fix splitting task function '.' * fix missing dagrun ids", "toggle all buttons (#23590) * communicate via customevents * open group logic in wrapper * fix tests * Make grid action buttons sticky * Use defaults by default * toggle fn * fix splitting task id by '.' * fix missing dagrun ids", "Fix expand/collapse all buttons (#23590) * fix customevents * Handle open button in wrapper * fix tests * Make grid action buttons sticky * Add default toggle fn * fix splitting task id by '.' * fix splitting task ids", "Fix expand/collapse all buttons (#23590) * communicate test case * Handle open group logic in wrapper * fix tests * Make grid action buttons sticky * Use inline toggle fn * fix splitting task id by '.' * fix sharing task ids", "Fix expand/collapse all buttons * communicate via customevents * Handle open group with a wrapper * fix grid action buttons sticky * Make grid action buttons sticky * Add default toggle fn * fix splitting task id by '.' * fix missing dagrun ids", "Fix expand/collapse all buttons (#23590) * Handle asynchronous events via customevents * Handle open group logic via customevents * fix tests * Make grid action buttons * Add default toggle fn * fix splitting task id by '.' * fix missing dagrun ids", "* support using callbacks for all buttons (#23590) * communicate via customevents * Handle open group logic in wrapper * fix tests * Make grid action buttons sticky * Fix default toggle fn * fix splitting task id by '.' * fix creating task ids", "Fix expand/collapse all buttons (#23590) * communicate via customevents * Handle open group logic in wrapper * fix tests * Make grid action buttons as snaps * Add new custom event fn * Fix missing task id by '.' * fix missing dagrun ids", "Fix expand/collapse all buttons (#23590) * communicate via customevents * Handle open group logic in wrapper * fix tests * Make grid action buttons a child button * Add default value * fix missing default id by '.' * fix missing dagrun ids"], "original_ll": -5.661814212799072, "sampled_ll": -4.729923248291016, "all_perturbed_sampled_ll": [-4.630722522735596, -4.503602504730225, -4.64146089553833, -4.8907694816589355, -4.425739288330078, -4.532698631286621, -4.56467342376709, -4.679150581359863, -4.522202968597412, -4.8598856925964355], "all_perturbed_original_ll": [-5.823060035705566, -5.6321516036987305, -5.817099571228027, -5.1590704917907715, -5.395066261291504, -5.310060501098633, -5.241526126861572, -5.4821271896362305, -5.691665172576904, -5.61517333984375], "perturbed_sampled_ll": -4.625090599060059, "perturbed_original_ll": -5.516700029373169, "perturbed_sampled_ll_std": 0.1435997454386239, "perturbed_original_ll_std": 0.22361679513350277}, {"original": "\ud83d\udcdd Update release documentation (#31631)", "sampled": "\ud83d\udcdd Update release documentation (#31631)Bugs", "perturbed_sampled": ["\ud83d\udcdd Update release documentation (#31631)Bugs", "\ud83d\udcdd Update release documentation (#31631)Bugs", "\ud83d\udcdd Update release documentation (#31631)Bugs", "\ud83d\udcdd Update release documentation (#31631)Bugs", "\ud83d\udcdd Update release documentation (#31631)Bugs", "\ud83d\udcdd Update release documentation (#31631)Bugs", "\ud83d\udcdd Update release documentation (#31631)Bugs", "\ud83d\udcdd Update release documentation (#31631)Bugs", "\ud83d\udcdd Update release documentation (#31631)Bugs", "\ud83d\udcdd Update release documentation (#31631)Bugs"], "perturbed_original": ["\ud83d\udcdd Update release documentation (#31631)", "\ud83d\udcdd Update release documentation (#31631)", "\ud83d\udcdd Update release documentation (#31631)", "\ud83d\udcdd Update release documentation (#31631)", "\ud83d\udcdd Update release documentation (#31631)", "\ud83d\udcdd Update release documentation (#31631)", "\ud83d\udcdd Update release documentation (#31631)", "\ud83d\udcdd Update release documentation (#31631)", "\ud83d\udcdd Update release documentation (#31631)", "\ud83d\udcdd Update release documentation (#31631)"], "original_ll": -5.688473701477051, "sampled_ll": -5.9729533195495605, "all_perturbed_sampled_ll": [-5.9729533195495605, -5.9729533195495605, -5.9729533195495605, -5.9729533195495605, -5.9729533195495605, -5.9729533195495605, -5.9729533195495605, -5.9729533195495605, -5.9729533195495605, -5.9729533195495605], "all_perturbed_original_ll": [-5.688473701477051, -5.688473701477051, -5.688473701477051, -5.688473701477051, -5.688473701477051, -5.688473701477051, -5.688473701477051, -5.688473701477051, -5.688473701477051, -5.688473701477051], "perturbed_sampled_ll": -5.9729533195495605, "perturbed_original_ll": -5.688473701477051, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Add note in UPDATING re non-JSON-serializable params deprecation (#21135)", "sampled": "Add note in UPDATING re non-JSON-serializable params deprecation (#21135)From", "perturbed_sampled": ["Add note in UPDATING re non-JSON-serializable params deprecation (#21135)From", "Add note in UPDATING re non-JSON-serializable params deprecation (#21135)From", "Add note in UPDATING re non-JSON-serializable params deprecation (#21135)From", "Add note in UPDATING re non-JSON-serializable params deprecation (#21135)From", "Add note in UPDATING re non-JSON-serializable params deprecation (#21135)From", "Add note in UPDATING re non-JSON-serializable params deprecation (#21135)From", "Add note in UPDATING re non-JSON-serializable params deprecation (#21135)From", "Add note in UPDATING re non-JSON-serializable params deprecation (#21135)From", "Add note in UPDATING re non-JSON-serializable params deprecation (#21135)From", "Add note in UPDATING re non-JSON-serializable params deprecation (#21135)From"], "perturbed_original": ["Add note in UPDATING re non-JSON-serializable params deprecation (#21135)", "Add note in UPDATING re non-JSON-serializable params deprecation (#21135)", "Add note in UPDATING re non-JSON-serializable params deprecation (#21135)", "Add note in UPDATING re non-JSON-serializable params deprecation (#21135)", "Add note in UPDATING re non-JSON-serializable params deprecation (#21135)", "Add note in UPDATING re non-JSON-serializable params deprecation (#21135)", "Add note in UPDATING re non-JSON-serializable params deprecation (#21135)", "Add note in UPDATING re non-JSON-serializable params deprecation (#21135)", "Add note in UPDATING re non-JSON-serializable params deprecation (#21135)", "Add note in UPDATING re non-JSON-serializable params deprecation (#21135)"], "original_ll": -5.195656776428223, "sampled_ll": -5.553794860839844, "all_perturbed_sampled_ll": [-5.553794860839844, -5.553794860839844, -5.553794860839844, -5.553794860839844, -5.553794860839844, -5.553794860839844, -5.553794860839844, -5.553794860839844, -5.553794860839844, -5.553794860839844], "all_perturbed_original_ll": [-5.195656776428223, -5.195656776428223, -5.195656776428223, -5.195656776428223, -5.195656776428223, -5.195656776428223, -5.195656776428223, -5.195656776428223, -5.195656776428223, -5.195656776428223], "perturbed_sampled_ll": -5.553794860839844, "perturbed_original_ll": -5.195656776428223, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Clarify \"significant\" newsfragment vs significant newsfragment _type_ (#24450) Previously was tiny bit ambiguous and could make it appear that any newsfragment type could have summary + body. Also I remove the word \"simply\" just because it's a pet peeve of mine.", "sampled": "Clarify \"significant\" newsfragment vs significant newsfragment _type_ (#24450) Previously was tiny bit ambiguous and could make your app appear to crash on startup. Please fix and fix again. (#24472)\n\n\n- Fixes bug #25029 in test-net-app-1 (#24463)\n\n- Fixed bug #341018 in lib/base64/data.h in", "perturbed_sampled": ["Clarify \"significant\" newsfragment vs \"large\" newsfragment _type_ (#24450) Previously was tiny bit ambiguous and could make your app appear to crash . Please test the fix again. (#24472)\n\n\n- Fixes bug #25029 in test-net-app-1 (#24463)\n\n- Fixed bug #341018 in lib/base64/data.h in", "Clarify \"significant\" newsfragment vs significant newsfragment _type_ . A bug fixed was tiny , and could make your app appear to crash on startup. Please fix and fix again. (#24472)\n\n\n- Fixes bug #164303 in test-net-app-1 (#24463)\n\n- Fixed bug #341018 in lib/base64/data.h in", "Clarify \"significant\" newsfragment vs significant newsfragment _type_ (#24450) Previously that was a bit ambiguous and could make your app appear to crash on large fragment size. Fix, fix and fix again. (#24472)\n\n\n- Fixes bug #25029 2. (#24463)\n\n- Fixed bug #341018 in lib/base64/data.h in", "Clarify \"significant\" newsfragment vs significant newsfragment _type_ (#24450) Previously was tiny bit ambiguous and could make your app to crash on startup. Please report bug to fix this. - Fixes bug #25029 in test-net-app-1 (#24463)\n\n- Fixed bug #341018 in lib/base64/data.h in", "Clarify \"significant\" newsfragment vs significant newsgroup (#24450) Previously was tiny bit ambiguous and could make your app appear to crash on startup. Please fix and test. (#24472)\n\n\n- Fixes bug #25029 in test-net-app-1 in test-net-app/sapk and bug #341018 in lib/base64/data.h in", "Clarify \"significant\" newsfragment vs significant newsfragment _type_ distinction. The distinction was tiny bit ambiguous and some of your app appear to crash on startup. Please fix and fix again. (#24472)\n\n\n- Fixes bug #341018 in test-net.h in test-net-app-1 (#24463)\n\n- Fixed bug #341018 in lib/base64/data.h in", "Clarify message fragment vs significant newsfragment _type_ (#24450) Previously was tiny bit ambiguous and could make your app appear to crash on startup. Please fix and fix and fix (#24471) Fixes bug #25029 4 (#24463)\n\n- Fixed bug #341018 in lib/base64/data.h in", "Clarify \"significant\" newsfragment vs . _type_ (#24450) Previously was tiny newsfragment and could make the app appear to crash on startup. Please fix and fix again. (#24472)\n\n\n- Fixes bug #25029 in test-net-app-1 (#24463)\n\n- Fixed bug #341018 in lib/base64/data.h in", "(#23285) - Fixed important newsfragment vs significant newsfragment _type_ (#24450) Previously was tiny bit ambiguous and could make your app appear to crash . Please fix and fix again. (#24472)\n\n\n- Fixes bug #341018 in test-net-app-1 (#24463)\n\n- Fixed bug #341018 in lib/base64/data.h in", "Clarify \"significant\" newsfragment vs significant newsfragment _type_ (#24450) Previously was tiny bit confusion, could make your application to crash on startup. Please fix and fix again. (#24472)\n\n\n- Fixed bug #25029 in test-net-app-1 (#24463)\n\n- Fixed bug #341018 in lib/base64/data.h in"], "perturbed_original": ["Clarify \"significant\" newsfragment vs significant newsfragment _type_ (#24450) Previously was tiny bit ambiguous and could make it appear that any newsfragment type was summary + body. Also I remove the word \"significant\" from the comment. Just deleting it because it's a pet peeve of mine.", "Clarify \"significant\" newsfragment . The word newsfragment _type_ (#24450) is a tiny bit ambiguous and could make it appear that any newsfragment type could have summary + body. Also I remove the word \"simply\" just because it's a pet peeve of mine.", "Clarify \"significant\" newsfragment vs significant newsfragment _type_ (#24450) Previously was tiny bit ambiguous and made it appear significant newsfragment type could have summary + body. Also I remove the word \"simply\" just because it's a minor alteration of mine.", "Clarify \"significant\" newsfragment vs significant newsfragment _type_ (#24450) Previously was tiny bit ambiguous and could make it appear that significant type could have summary . Also I remove the word \"simply\" just because it's a personal preference of mine.", "Clarify summarize vs significant newsfragment _type_ (#24450) Previously was tiny bit ambiguous , but now make it appear that any newsfragment type can include news summary + body. Also I remove the word \"simply\" just because it's a pet peeve of mine.", "Clarify \"significant\" newsfragment vs significant newsfragment _type_ . To me it was tiny bit ambiguous and could make it seem that any newsfragment type could be body + body. Also I remove the word \"simply\" just because it's a pet peeve of mine.", "Clarify summary vs significant newsfragment _type_ (#24450) Previously was tiny bit ambiguous in details but now I make it appear that any newsfragment type could have summary + body. Also I remove the word body because it's a pet peeve of mine.", "Clarify \"significant\" newsfragment as newsfragment _type_ (#24450) Previously was tiny bit ambiguous and could make it appear that any newsfragment type could have summary + body. Also , keep the word \"simply\" just because it's a pet peeve of mine.", "Clarify \"significant\" newsfragment vs significant newsfragment _type_ (#24450) Previously was tiny bit ambiguous and could make me wrong that any newsfragment type could have summary element. Also I remove the word \"simply\" just because it's a pet peeve of mine.", "summary + newsfragment vs significant newsfragment _type_ (#24450) Previously a bit ambiguous and could make it appear that any newsfragment type could have summary + newsfragment. I remove the word \"simply\" just because it's a pet peeve of mine."], "original_ll": -4.279038906097412, "sampled_ll": -3.7323856353759766, "all_perturbed_sampled_ll": [-3.8143160343170166, -3.9022626876831055, -3.899881362915039, -4.074547290802002, -4.065441608428955, -3.6880688667297363, -4.393795490264893, -3.6755549907684326, -3.8888015747070312, -3.9010674953460693], "all_perturbed_original_ll": [-4.241794586181641, -3.9616501331329346, -4.710793495178223, -4.772549629211426, -4.7319159507751465, -3.9564945697784424, -4.744550704956055, -4.3135666847229, -4.426662921905518, -3.8351080417633057], "perturbed_sampled_ll": -3.930373740196228, "perturbed_original_ll": -4.369508671760559, "perturbed_sampled_ll_std": 0.19879884690202532, "perturbed_original_ll_std": 0.3458515834591387}, {"original": "Fix task log is not captured (#23684) when StandardTaskRunner runs tasks with exec Issue: https://github.com/apache/airflow/issues/23540", "sampled": "Fix task log is not captured (#23684) when StandardTaskRunner runs tasks with exec Issue: https://github.com/apache/airflow-server/pull/23684", "perturbed_sampled": ["Fix task log is not captured (#23684) when StandardTaskRunner runs tasks . Issue: https://github.com/apache/airflow-server/pull/23684", "Fix task log is not captured when StandardTaskRunner runs tasks with exec Issue: https://github.com/apache/airflow-server/pull/23684", "Fix task log is not captured when StandardTaskRunner runs tasks with exec Issue: https://github.com/apache/airflow-server/pull/23684", "Fix task log is ignored (#23684) when StandardTaskRunner runs tasks with exec Issue: https://github.com/apache/airflow-server/pull/23684", "Fix task run/error. Errors are not captured (#23684) when StandardTaskRunner runs tasks with exec Issue: https://github.com/apache/airflow-server/pull/23684", "Fix task execution is not captured (#23684) when StandardTaskRunner runs tasks with exec Issue: https://github.com/apache/airflow-server/pull/23684", "Fix task log is not captured (#23684) when StandardTaskRunner runs for <unk>State> exec Issue: https://github.com/apache/airflow-server/pull/23684", "Fix task log is ignored (#23684) when StandardTaskRunner runs tasks with exec Issue: https://github.com/apache/airflow-server/pull/23684", "Fix task log is not captured (#23684) when StandardTaskRunner runs via exec Issue: https://github.com/apache/airflow-server/pull/23684", "Fix task log is not nailed down (#23684) when StandardTaskRunner runs tasks with exec Issue: https://github.com/apache/airflow-server/pull/23684"], "perturbed_original": ["Fix task log is not displayed when StandardTaskRunner runs tasks with exec Issue: https://github.com/apache/airflow/issues/23540", "The TaskRunner log is not captured (#23684) when StandardTaskRunner runs tasks with exec Issue: https://github.com/apache/airflow/issues/23540", "Fix task log is not captured (#23684) when StandardTaskRunner runs on an exec Issue: https://github.com/apache/airflow/issues/23540", "Fix task log is emptied (#23684) when StandardTaskRunner runs tasks with exec Issue: https://github.com/apache/airflow/issues/23540", "Fix task log is not captured (#23684) After script runs tasks with exec Issue: https://github.com/apache/airflow/issues/23540", "Fix task log is not captured (#23684) Fixed a problem where airflow runs tasks with exec Issue: https://github.com/apache/airflow/issues/23540", "Fix : Either message is not captured (#23684) when StandardTaskRunner runs tasks with exec Issue: https://github.com/apache/airflow/issues/23540", "Fix task log is not captured (#23684) when starting tasks with exec Issue: https://github.com/apache/airflow/issues/23540", "Fix task log is not captured when StandardTaskRunner runs tasks with exec Issue: https://github.com/apache/airflow/issues/23540", "Fix task log is not ignored when StandardTaskRunner runs tasks with exec Issue: https://github.com/apache/airflow/issues/23540"], "original_ll": -4.714484214782715, "sampled_ll": -4.4636101722717285, "all_perturbed_sampled_ll": [-4.397983074188232, -4.56829833984375, -4.56829833984375, -4.395248889923096, -4.441440105438232, -4.413171291351318, -4.985081672668457, -4.395248889923096, -4.5090131759643555, -4.512303352355957], "all_perturbed_original_ll": [-4.4433183670043945, -4.678681373596191, -4.642031192779541, -4.806640625, -4.655858516693115, -4.862378120422363, -4.660462856292725, -4.389596462249756, -4.579680919647217, -4.493670463562012], "perturbed_sampled_ll": -4.518608713150025, "perturbed_original_ll": -4.621231889724731, "perturbed_sampled_ll_std": 0.16873791884228848, "perturbed_original_ll_std": 0.14223418130713295}, {"original": "Update providers metadata 2023-12-28 (#36459)", "sampled": "Update providers metadata 2023-12-28 (#36459)\"", "perturbed_sampled": ["Update providers metadata 2023-12-28 (#36459)\"", "Update providers metadata 2023-12-28 (#36459)\"", "Update providers metadata 2023-12-28 (#36459)\"", "Update providers metadata 2023-12-28 (#36459)\"", "Update providers metadata 2023-12-28 (#36459)\"", "Update providers metadata 2023-12-28 (#36459)\"", "Update providers metadata 2023-12-28 (#36459)\"", "Update providers metadata 2023-12-28 (#36459)\"", "Update providers metadata 2023-12-28 (#36459)\"", "Update providers metadata 2023-12-28 (#36459)\""], "perturbed_original": ["Update providers metadata 2023-12-28 (#36459)", "Update providers metadata 2023-12-28 (#36459)", "Update providers metadata 2023-12-28 (#36459)", "Update providers metadata 2023-12-28 (#36459)", "Update providers metadata 2023-12-28 (#36459)", "Update providers metadata 2023-12-28 (#36459)", "Update providers metadata 2023-12-28 (#36459)", "Update providers metadata 2023-12-28 (#36459)", "Update providers metadata 2023-12-28 (#36459)", "Update providers metadata 2023-12-28 (#36459)"], "original_ll": -6.336345672607422, "sampled_ll": -7.023155212402344, "all_perturbed_sampled_ll": [-7.023155212402344, -7.023155212402344, -7.023155212402344, -7.023155212402344, -7.023155212402344, -7.023155212402344, -7.023155212402344, -7.023155212402344, -7.023155212402344, -7.023155212402344], "all_perturbed_original_ll": [-6.336345672607422, -6.336345672607422, -6.336345672607422, -6.336345672607422, -6.336345672607422, -6.336345672607422, -6.336345672607422, -6.336345672607422, -6.336345672607422, -6.336345672607422], "perturbed_sampled_ll": -7.023155212402344, "perturbed_original_ll": -6.336345672607422, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Fix breeze images (failing main build) (#26569)", "sampled": "Fix breeze images (failing main build) (#26569)The", "perturbed_sampled": ["Fix breeze images (failing main build) (#26569)The", "Fix breeze images (failing main build) (#26569)The", "Fix breeze images (failing main build) (#26569)The", "Fix breeze images (failing main build) (#26569)The", "Fix breeze images (failing main build) (#26569)The", "Fix breeze images (failing main build) (#26569)The", "Fix breeze images (failing main build) (#26569)The", "Fix breeze images (failing main build) (#26569)The", "Fix breeze images (failing main build) (#26569)The", "Fix breeze images (failing main build) (#26569)The"], "perturbed_original": ["Fix breeze images (failing main build) (#26569)", "Fix breeze images (failing main build) (#26569)", "Fix breeze images (failing main build) (#26569)", "Fix breeze images (failing main build) (#26569)", "Fix breeze images (failing main build) (#26569)", "Fix breeze images (failing main build) (#26569)", "Fix breeze images (failing main build) (#26569)", "Fix breeze images (failing main build) (#26569)", "Fix breeze images (failing main build) (#26569)", "Fix breeze images (failing main build) (#26569)"], "original_ll": -6.754697322845459, "sampled_ll": -7.359457015991211, "all_perturbed_sampled_ll": [-7.359457015991211, -7.359457015991211, -7.359457015991211, -7.359457015991211, -7.359457015991211, -7.359457015991211, -7.359457015991211, -7.359457015991211, -7.359457015991211, -7.359457015991211], "all_perturbed_original_ll": [-6.754697322845459, -6.754697322845459, -6.754697322845459, -6.754697322845459, -6.754697322845459, -6.754697322845459, -6.754697322845459, -6.754697322845459, -6.754697322845459, -6.754697322845459], "perturbed_sampled_ll": -7.359457015991211, "perturbed_original_ll": -6.754697322845459, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Add Jira Notifier implementation (#35397) * Add Jira Notifier implementation * Add tests for Jira notifier * Add documentation for the Jira notifier * Apply suggestions from code review Co-authored-by: Andrey Anshin <Andrey.Anshin@taragol.is> --------- Co-authored-by: Andrey Anshin <Andrey.Anshin@taragol.is>", "sampled": "Add Jira Notifier implementation (#35397) * Add Jira Notifier implementation * Add tests for Jira notifier * Add documentation for the jira service * Add docs for add Jira service implementation * Add documentation for add Jira service", "perturbed_sampled": ["Add Jira Notifier implementation (#35397) * Add tests for Jira Notifier implementation * Add tests for Jira notifier * Add documentation for add jira service * Add docs for add Jira service implementation * Add documentation for add Jira service", "Add Jira Notifier implementation (#35397) * Fix missing tests for Jira Notifier implementation * Fix missing tests for Jira notifier * Add documentation for the jira service * Add docs for add Jira service implementation * Add documentation for add Jira service", "Add Jira Notifier implementation (#35397) * Add Jira Notifier implementation * Add tests to jira notifier * Add documentation for the jira service * Add docs for add Jira notifier implementation * Add documentation for add Jira service", "Add Jira Notifier implementation (#35397) * Add Jira Notifier implementation in jira * Add tests for Jira notifier * Add documentation for the jira notifier * Add docs for add Jira service implementation * Add documentation for add Jira service", "Add Jira service implementation (#35397) * Add Jira Notifier implementation * Add tests for Jira notifier * Add documentation for the jira service * Add docs for add Jira service implementation * Add documentation for add Jira service", "Add Jira Notifier implementation (#35397) * Add Jira Notifier implementation * Add tests for Jira notifier * Add documentation for the jira service * Add docs for add Jira Notifier implementation * Add documentation for add Jira service", "Add Jira Notifier implementation (#35397) * Add Jira Notifier implementation * Add tests for Jira notifier implementation * Add documentation for the jira service * Add docs for add Jira service implementation * Add documentation for add Jira service", "Add Jira notifier (#35397) * Add Jira Service support (#48770) * Add tests for Jira notifier * Add documentation for the jira service * Add docs for add Jira service implementation * Add documentation for add Jira service", "Add Jira Notifier implementation (#35397) * Add Jira Notifier implementation * Add tests for Jira notifier * Add documentation for the jira service notifier * Add docs for add Jira service implementation * Add documentation for add Jira service", "Add Jira Notifier * Add tests for Jira Notifier * Add Jira Notifier implementation * Add tests for Jira notifier * Add documentation for the jira service * Add docs for add Jira service implementation * Add documentation for add Jira service"], "perturbed_original": ["Add Jira Notifier implementation * Add Jira Notifier implementation * Add tests for Jira notifier * Add documentation for the Jira notifier * Apply suggestions from code review Co-authored-by: Andrey Anshin <Andrey.Anshin@taragol.is> --------- Co-authored-by: Andrey Anshin <Andrey.Anshin@taragol.is>", "Add Jira Notifier implementation (#35397) * Add Jira Notifier implementation * Add tests for Jira notifier * Add documentation for the Jira notifier * Apply suggestions from code review Co-authored-by: Andrey Anshin --------- Co-authored-by: Andrey Anshin <Andrey.Anshin@taragol.is>", "Add Jira Notifier implementation (#35397) * Add Jira Notifier implementation * Add tests for Jira notifier * Add documentation for the Jira notifier * Apply suggestions from previous contributors Co-authored-by: Andrey Anshin <Andrey.Anshin@taragol.is> . Andrey Anshin <Andrey.Anshin@taragol.is>", "Add Jira Notifier implementation (#35397) * Add test case implementation * Add tests for implementation * Add documentation for the Jira notifier * Apply suggestions from code review Co-authored-by: Andrey Anshin <Andrey.Anshin@taragol.is> --------- Co-authored-by: Andrey Anshin <Andrey.Anshin@taragol.is>", "Add Jira Notifier implementation (#35397) * Add Jira Notifier implementation * Add tests for Jira notifier * Add documentation for the Jira notifier * Apply changes from code review Co-authored-by: Andrey Anshin * Co-authored-by: Andrey Anshin <Andrey.Anshin@taragol.is>", "Add Jira Notifier implementation (#35397) * Add Jira Notifier configuration * Add tests for Jira notifier * Add documentation for Jira notifier * Apply suggestions from code review Co-authored-by: Andrey Anshin <Andrey.Anshin@taragol.is> --------- Co-authored-by: Andrey Anshin <Andrey.Anshin@taragol.is>", "Add Jira Notifier implementation (#35397) * Add Jira Notifier implementation * Add tests for Jira notifier * Add documentation for Jira notifier * Apply suggestions to implementation for review Co-authored-by: Andrey Anshin <Andrey.Anshin@taragol.is> --------- Co-authored-by: Andrey Anshin <Andrey.Anshin@taragol.is>", "Add Jira Notifier (#35397) * Add Jira Notifier implementation * Add tests for Jira notifier * Add documentation for the Jira notifier * Apply suggestions from code review ers * Andrey Anshin <Andrey.Anshin@taragol.is> --------- Co-authored-by: Andrey Anshin <Andrey.Anshin@taragol.is>", "Add Jira Notifier implementation (#35397) * Add Jira Notifier implementation * Add tests for Jira notifier * Update the documentation for the Jira notifier * Apply suggestions from code review Co-authored-by: Andrey Anshin <Andrey.Anshin@taragol.is> --------- ------------------------ Added by: Andrey Anshin <Andrey.Anshin@taragol.is>", "Add Jira Notifier - Features * Add Jira Notifier implementation * Add tests for Jira notifier * Add documentation for the Jira notifier * Apply suggestions from the users --------- Co-authored-by: Andrey Anshin <Andrey.Anshin@taragol.is> --------- Co-authored-by: Andrey Anshin <Andrey.Anshin@taragol.is>"], "original_ll": -2.7866814136505127, "sampled_ll": -2.9520719051361084, "all_perturbed_sampled_ll": [-2.813943862915039, -2.896324872970581, -2.9922564029693604, -2.8361093997955322, -3.187713623046875, -2.852760076522827, -2.8839426040649414, -3.0980889797210693, -2.9151244163513184, -2.451939105987549], "all_perturbed_original_ll": [-2.6225695610046387, -3.3400118350982666, -2.9708569049835205, -3.0655972957611084, -3.1393775939941406, -2.821284294128418, -2.867612600326538, -3.112760305404663, -3.0004687309265137, -2.711733818054199], "perturbed_sampled_ll": -2.8928203344345094, "perturbed_original_ll": -2.9652272939682005, "perturbed_sampled_ll_std": 0.18573962361782692, "perturbed_original_ll_std": 0.20391837516516523}, {"original": "Use `isdisjoint` instead of `not intersection` (#32616)", "sampled": "Use `isdisjoint` instead of `not intersection` (#32616)In", "perturbed_sampled": ["Use `isdisjoint` instead of `not intersection` (#32616)In", "Use `isdisjoint` instead of `not intersection` (#32616)In", "Use `isdisjoint` instead of `not intersection` (#32616)In", "Use `isdisjoint` instead of `not intersection` (#32616)In", "Use `isdisjoint` instead of `not intersection` (#32616)In", "Use `isdisjoint` instead of `not intersection` (#32616)In", "Use `isdisjoint` instead of `not intersection` (#32616)In", "Use `isdisjoint` instead of `not intersection` (#32616)In", "Use `isdisjoint` instead of `not intersection` (#32616)In", "Use `isdisjoint` instead of `not intersection` (#32616)In"], "perturbed_original": ["Use `isdisjoint` instead of `not intersection` (#32616)", "Use `isdisjoint` instead of `not intersection` (#32616)", "Use `isdisjoint` instead of `not intersection` (#32616)", "Use `isdisjoint` instead of `not intersection` (#32616)", "Use `isdisjoint` instead of `not intersection` (#32616)", "Use `isdisjoint` instead of `not intersection` (#32616)", "Use `isdisjoint` instead of `not intersection` (#32616)", "Use `isdisjoint` instead of `not intersection` (#32616)", "Use `isdisjoint` instead of `not intersection` (#32616)", "Use `isdisjoint` instead of `not intersection` (#32616)"], "original_ll": -4.591207981109619, "sampled_ll": -5.202871799468994, "all_perturbed_sampled_ll": [-5.202871799468994, -5.202871799468994, -5.202871799468994, -5.202871799468994, -5.202871799468994, -5.202871799468994, -5.202871799468994, -5.202871799468994, -5.202871799468994, -5.202871799468994], "all_perturbed_original_ll": [-4.591207981109619, -4.591207981109619, -4.591207981109619, -4.591207981109619, -4.591207981109619, -4.591207981109619, -4.591207981109619, -4.591207981109619, -4.591207981109619, -4.591207981109619], "perturbed_sampled_ll": -5.202871799468994, "perturbed_original_ll": -4.591207981109619, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Move around overflow, position and padding (#23044)", "sampled": "Move around overflow, position and padding (#23044)If", "perturbed_sampled": ["Move around overflow, position and padding (#23044)If", "Move around overflow, position and padding (#23044)If", "Move around overflow, position and padding (#23044)If", "Move around overflow, position and padding (#23044)If", "Move around overflow, position and padding (#23044)If", "Move around overflow, position and padding (#23044)If", "Move around overflow, position and padding (#23044)If", "Move around overflow, position and padding (#23044)If", "Move around overflow, position and padding (#23044)If", "Move around overflow, position and padding (#23044)If"], "perturbed_original": ["Move around overflow, position and padding (#23044)", "Move around overflow, position and padding (#23044)", "Move around overflow, position and padding (#23044)", "Move around overflow, position and padding (#23044)", "Move around overflow, position and padding (#23044)", "Move around overflow, position and padding (#23044)", "Move around overflow, position and padding (#23044)", "Move around overflow, position and padding (#23044)", "Move around overflow, position and padding (#23044)", "Move around overflow, position and padding (#23044)"], "original_ll": -6.686253547668457, "sampled_ll": -7.482696056365967, "all_perturbed_sampled_ll": [-7.482696056365967, -7.482696056365967, -7.482696056365967, -7.482696056365967, -7.482696056365967, -7.482696056365967, -7.482696056365967, -7.482696056365967, -7.482696056365967, -7.482696056365967], "all_perturbed_original_ll": [-6.686253547668457, -6.686253547668457, -6.686253547668457, -6.686253547668457, -6.686253547668457, -6.686253547668457, -6.686253547668457, -6.686253547668457, -6.686253547668457, -6.686253547668457], "perturbed_sampled_ll": -7.482696056365967, "perturbed_original_ll": -6.686253547668457, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Add backward compatibility for elasticsearch<8 (#33281) * Add backward compatibility for elasticsearch<8", "sampled": "Add backward compatibility for elasticsearch<8 (#33281) * Add backward compatibility for elasticsearch<8[b][c]", "perturbed_sampled": ["Add backward compatibility for elasticsearch<8 (#33281) * Add backward compatibility for elasticsearch<8[b][c]", "Add backward compatibility for elasticsearch<8 (#33281) * Add backward compatibility for elasticsearch<8[b][c]", "Add backward compatibility for elasticsearch<8 (#33281) * Add backward compatibility for elasticsearch<8[b][c]", "Add backward compatibility for elasticsearch<8 (#33281) * Add backward compatibility for elasticsearch<8[b][c]", "Add backward compatibility for elasticsearch<8 (#33281) * Add backward compatibility for elasticsearch<8[b][c]", "Add backward compatibility for elasticsearch<8 (#33281) * Add backward compatibility for elasticsearch<8[b][c]", "Add backward compatibility for elasticsearch<8 (#33281) * Add backward compatibility for elasticsearch<8[b][c]", "Add backward compatibility for elasticsearch<8 (#33281) * Add backward compatibility for elasticsearch<8[b][c]", "Add backward compatibility for elasticsearch<8 (#33281) * Add backward compatibility for elasticsearch<8[b][c]", "Add backward compatibility for elasticsearch<8 (#33281) * Add backward compatibility for elasticsearch<8[b][c]"], "perturbed_original": ["Add backward compatibility for elasticsearch<8 (#33281) * Add backward compatibility for elasticsearch<8", "Add backward compatibility for elasticsearch<8 (#33281) * Add backward compatibility for elasticsearch<8", "Add backward compatibility for elasticsearch<8 (#33281) * Add backward compatibility for elasticsearch<8", "Add backward compatibility for elasticsearch<8 (#33281) * Add backward compatibility for elasticsearch<8", "Add backward compatibility for elasticsearch<8 (#33281) * Add backward compatibility for elasticsearch<8", "Add backward compatibility for elasticsearch<8 (#33281) * Add backward compatibility for elasticsearch<8", "Add backward compatibility for elasticsearch<8 (#33281) * Add backward compatibility for elasticsearch<8", "Add backward compatibility for elasticsearch<8 (#33281) * Add backward compatibility for elasticsearch<8", "Add backward compatibility for elasticsearch<8 (#33281) * Add backward compatibility for elasticsearch<8", "Add backward compatibility for elasticsearch<8 (#33281) * Add backward compatibility for elasticsearch<8"], "original_ll": -4.006695747375488, "sampled_ll": -4.0681047439575195, "all_perturbed_sampled_ll": [-4.0681047439575195, -4.0681047439575195, -4.0681047439575195, -4.0681047439575195, -4.0681047439575195, -4.0681047439575195, -4.0681047439575195, -4.0681047439575195, -4.0681047439575195, -4.0681047439575195], "all_perturbed_original_ll": [-4.006695747375488, -4.006695747375488, -4.006695747375488, -4.006695747375488, -4.006695747375488, -4.006695747375488, -4.006695747375488, -4.006695747375488, -4.006695747375488, -4.006695747375488], "perturbed_sampled_ll": -4.0681047439575195, "perturbed_original_ll": -4.006695747375488, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Make static checks generated file more stable accross the board (#29080) There were couple of problems with static checks generating source files including generated stubs in the common.sql package: * black formatting was implemented in multiple separate scripts making it harded to fix problems in all of them * generated stub files were not formatted with is_pyi=True and black had no way to figure it out because it was working on strings * black formatting was not consistently applied in all places * EOL at the end of generated stub file was missing, leading to EOL fixer adding them after generation leading to multiple pre-commit passes needed * there was (already unused) deprecated dev dict generator that used its own black formatting. There were also couple of problems with the files generated by stubgen itself: * Union was missing in the generated stubs (this is a known issue with stubgen: https://github.com/python/mypy/issues/12929 * Intellij complained on Incomplete import from _typeshed missing This PR fixes all the problems:", "sampled": "Make static checks generated file more stable accross the board (#29080) There were couple of problems with static checks generating source files including generated stubs and error messages. Now static checking is performed on all files generated in this way. Additionally, it's now possible to have the build run a specific release type. (The \"release-type\" can be either: stable \u2013 where all tests take place \u2013 static files are produced and then released on unstable, or \u2013 which only takes place in one release, either stable mode on release or stable-mode without \u2013 where if two test files are generated in the same build.\n\n- where all tests take place \u2013 static files are produced and then released on unstable, or \u2013 which only takes place in one release, either stable mode on release or stable-mode without \u2013 where if two test files are generated in the same build. debug \u2013 where testing is done on the debug builds, not during the build.\n\n- where testing is done", "perturbed_sampled": ["Make static checks generated file more stable accross the board (#29080) There were couple of problems with static checks generating source files including generated stubs and error messages. Static checking is performed on all files generated this way. Additionally, it's now possible to do the build run a new release type. (The \"release-type\" can be a release or release-stack type) stable \u2013 where all tests take place \u2013 static tests are produced and then released on unstable, or \u2013 which only takes place in one release, either stable mode on release or stable-mode without \u2013 where if two test files are generated in the same build.\n\n- where all tests take place \u2013 static tests are produced and then released on unstable, or \u2013 which only takes place in one release, either stable mode on release or stable-mode without \u2013 where if two test files are generated in the same build. debug \u2013 where testing is done on the debug builds, not during the build.\n\n- where testing is done", "Make static checks generated file more stable accross the board (#29080) There were couple of problems with static checks generating source files since generated stubs and error messages. Now static checking is available on all files generated in this way. Additionally, it's now possible to have the build run a specific release type. (The \"release-type\" can be either: stable-mode or unstable.) - where all tests take place \u2013 static files are produced and then released on stable, or \u2013 which only takes place in one release, either stable mode on release or stable-mode without \u2013 where two test files are generated in the same build.\n\n- where all tests take place \u2013 static files are produced and then released on unstable, or \u2013 which only takes place in one release, either stable mode on release or stable-mode without \u2013 where two test files are generated in the same build. debug \u2013 where testing is done during the tests or debug builds, not during the build.\n\n- where testing is done", "Make static checks generated file more stable accross the board (#29080) There were couple of problems with static checks generating source files including incorrect naming and error messages. Now static checking is performed on all files generated this way. Additionally, it's possible to have the build run on version 1 and release again. \"release-type\" can be either: stable \u2013 where all tests are run on stable \u2013 static files are produced and then released on stable, or \u2013 which only takes place in one release, either stable mode on release or stable-mode without \u2013 where if two test files are generated in the same build. unstable \u2013 where all tests are run on unstable \u2013 static files are produced and then released on unstable, or \u2013 which only takes place in one release, either stable mode on release or stable-mode without \u2013 where if two test files are generated in the same build. debug \u2013 where testing is done on the debug builds, not during the build.\n\n- where testing is done", "builds make checks generated file more stable . Originally from the Debian Idea board (#29080) There were some problems with Xcode generating source files including generated stubs and error messages. Now checking is done against all files generated in this way. Additionally, it's possible to have the build run a different version of sources for each release type. (The \"release-type\" can be either: stable \u2013 where all tests take place \u2013 static files are produced and then released on unstable, or \u2013 which only takes place in one release, either stable mode on release or stable-mode without \u2013 where if two test files are generated in the same build.\n\n- where all tests take place \u2013 static files are produced and then released on unstable, or \u2013 which only takes place in one release, either stable mode on release or stable-mode without \u2013 where if two test files are generated in the same build. debug \u2013 where testing is done on the debug builds, not during the build.\n\n- where testing is done", "Make static checks generated file more stable accross the board (#29080) There were couple of problems with static checks generating unstable asynchronous test files, including generated stubs and messages. Now static checking is performed on all files generated this way. Additionally, it's now possible to specify to have the build run a specific release type. (The \"release-type\" can be either: stable \u2013 where all tests take place \u2013 static files are produced and then released on unstable, or \u2013 which only takes place in one release, either stable mode on release or stable-mode without \u2013 where if two test files are generated in the same build.\n\n- where all tests take place \u2013 static files are produced and then released on unstable, or \u2013 which only takes place in one release, either stable mode on release or stable-mode without \u2013 where if two test files are generated in the same build. debug \u2013 where testing is done on debugging builds, not during the release phase. fix \u2013 where testing is done", "Make static checks generated file on release accross the board (#29080) \u2013 Fixed a couple of problems with static checking \u2013 when generating source files from stubs , generated files generated messages. Now static checking is performed on files generated in this way. Additionally, it's now possible to have a build run a specific release type. (The \"release-type\" can be either: stable \u2013 where all tests take place \u2013 static files are produced and then released on unstable, or \u2013 which only takes place in one release, either stable mode on release or stable-mode without \u2013 where if two test files are generated in the same build.\n\n- where all tests take place \u2013 static files are produced and then released on unstable, or \u2013 which only takes place in one release, either stable mode on release or stable-mode without \u2013 where if two test files are generated in the same build. debug \u2013 where all testing is done on the debug builds, not during the build.\n\n- where testing is done", "Make static checks generated file more stable accross the board (#29080) There were couple of problems with static checks generating source files including generated stubs and emitted stub messages. Now static checking is performed on all files generated in one build. Additionally, it's more efficient to have the build run a specific release type. (The \"release-type\" setting must be specific as well, and either: - where all tests take place \u2013 static files are produced and then released on stable, or \u2013 which only takes place in one release, either stable mode on release or stable-mode without \u2013 where if two test files are generated in the same build.\n\n- where all tests take place \u2013 static files are produced and then released on unstable, or \u2013 which only takes place in one release, either stable mode on release or stable-mode without \u2013 where if two test files are generated in the same build. debug \u2013 where testing is done on the debug builds, without using the build.\n\n- where testing is done", "Make static checks generated file more stable for development board (#29080) There were couple of problems with static checking when generating source files including generated stubs and patch files. Now static checking is performed on all files generated in this way. Additionally, it's now possible to have the build run a specific release type. (The \"release-type\" can be either: stable \u2013 where all tests take place \u2013 static files are produced and then released on unstable, or \u2013 which only takes place in one release, either stable mode on release or stable-mode without \u2013 where if two test files are generated in the same build.\n\n- where all tests take place - static files are produced and then released on unstable, or \u2013 which only takes place in one release, either stable mode on release or stable-mode without \u2013 where if two test files are generated in the same build. debug \u2013 where testing is done on the debug builds, not during the production builds. stable-mode \u2013 where all testing is done", "Make static checks generated file more consistent across the board (#29080) There were couple of problems with static checks generating source files which contained stubs and error messages. Now , all static checks are done on source files, and also all error-handling is performed on all files generated in this way. Additionally, it's now possible to have the build run a specific release type. (The \"release-type\" can be either: stable \u2013 where all tests take place \u2013 static files are produced and then released on unstable, or \u2013 which only takes place in one release, either stable mode on release or stable-mode without \u2013 where if two test files are generated in the same build.\n\n- where all tests take place \u2013 static files are produced and then released on unstable, or \u2013 which only takes place in one release, either stable mode on release or stable-mode without \u2013 where if two test files are generated in the same build. debug \u2013 where testing is done on between builds, not during the build.\n\n- where testing is done", "Make static checks generated file more stable - board (#29080) There were couple of problems with static checking generated source files including generated stubs and error messages. Now static checking is performed on all files generated in this way. Additionally, it's now possible to have the build run a specific release type. The types can be : stable \u2013 where all tests take place \u2013 static files are produced and then released on unstable, or \u2013 which only takes place in one release, either stable mode on stable or stable-mode without \u2013 where if two test files are generated in the same build.\n\n- where all tests take place \u2013 static files are produced and then released on stable, or \u2013 which only takes place in one release, either stable mode on stable or stable-mode without \u2013 where if two test files are generated in the same build. debug \u2013 where testing is done on the debug builds, not during the build.\n\n- where testing is done"], "perturbed_original": ["Make static checks generated file more stable accross the board (#29080) There were couple of problems with static checks generating source files including generated stubs in the common.sql package: * black formatting was implemented in multiple separate scripts making it harded to fix problems in all of them * generated stub files were not formatted with is_pyi=True and there was no way to figure it out because it was working on strings anyway * black formatting was not consistently applied in all places * white formatting at the end of generated stub file was missing, the EOL fixer adding them after leading to multiple pre-commit passes needed * stubgen was (already ) broken by different dev tests because of that , not changing its own black formatting. There were also couple of problems with the files generated by stubgen itself: * Union was missing in the generated stubs (this is a known issue with stubgen: https://github.com/python/mypy/issues/12929 * Intellij complained on top of it that white formatting from _typeshed missing This PR fixes all the problems:", "Make static checks generated source files more stable accross the board (#29080) There were couple of problems with static checks generating source files including problem in the common.sql package: * black formatting was implemented in several ways and needed separate scripts making it harded to fix problems in all of them * generated stub files were not formatted with is_pyi=True and black had no way to figure it out * when black was working on strings <unk>_pyi=True formatting was not consistently applied in all places * some dicts at the end of generated source was missing, leading to EOL fixer adding them after generation leading to multiple pre-commit passes needed * there was an (inherently unused) deprecated dev dict generator that used its own black formatting. There were also couple of problems with static checks generating source files generated by stubgen itself: * Union was missing in the generated stubs (this is a known issue with stubgen: https://github.com/python/mypy/issues/12929 * Intellij complained on Incomplete import from _typeshed missing This PR fixes all the problems:", "Make static checks generated file more stable accross the whole system There were several problems with static checks generating source files including generated stubs in the common.sql package: * generate stub was implemented in multiple separate scripts making it harded to fix problems in various of them * generated stub files were not formatted with is_pyi=True and there was no way to figure it out because it was working fine in some cases * black formatting was not consistently applied in all places * at least 2 pieces of generated stub file was missing leading to EOL fixer adding them after generation leading to multiple pre-commit passes needed * there was (already unused) deprecated dev dict generator that had its own black formatting. There were also couple of problems with the files generated by stubgen itself: * Union was missing in the generated stubs (this is a known issue with stubgen: * Intellij complained at some time about import from _typeshed missing This PR fixes all the problems:", "Make static checks generated file more stable accross the board (#29080) There were couple of problems with static checks generating file, including generated stubs in the common.sql package: * black formatting was implemented in separate scripts and leading to harded coding problems in all of them * some files were not formatted using black formatting and black had no way to figure out what was wrong because it was working on strings . * black formatting was not consistently applied in all places * EOL at the end of dev file was missing, leading to EOL fixer adding them after generation leading to multiple pre-commit passes needed * there was (already unused) deprecated dev dict generator that used its own black formatting. There were couple of problems with the files generated by static checks: * no binary fixer * Union was missing in the generated file (this is a known issue with stubgen: https://github.com/python/mypy/issues/12929 * Intellij complained on Incomplete import from _typeshed missing This PR fixes all the problems:", "Make static checks generated file more stable -- bring code generation issue on board (#29080) There were couple of problems with static checks generating source files with stubs in the common.sql package: * black formatting was implemented in separate packages making it harded to fix problems in all of them * generated stub files were not formatted with is_pyi=True and there was no way to figure it out because it was only working on strings * black formatting was not consistently applied in all places * EOL at the end of generated source files was missing, leading to EOL fixer adding them after generation leading to multiple pre-commit passes needed * there was (already unused) deprecated dev dict generator that used its own black formatting. There were couple of problems with the files generated by stubgen itself: * Union was missing in the generated stubs (this is a known issue with stubgen: https://github.com/python/mypy/issues/12929 * Intellij complained on Incomplete import from _typeshed in some stub files (i.e. PR #2998) fixes the problems:", "Make static checks generated file more stable accross the board There were couple of problems with static checks generating source files including generated stubs in the common.sql package: * black formatting was implemented in multiple separate scripts making it harded to fix problems in all of them * generated stub files were not formatted correctly and black had no way to figure it out because it was working on strings * black formatting was not the same in all places * EOL at the end of generated stub file was missing, leading to EOL fixer adding them after generation leading to multiple pre-commit passes needed * there was (already unused) deprecated black formatting * stub generator was using its own black formatting There were also couple of problems with the files generated by stubgen itself: * the EOL was missing in the generated stubs (this is a known issue with stubgen: stubgen) * Intellij complained on this issue * warning file from _typeshed missing This PR fixes all the problems:", "Make static checks generated file more stable for testing across the board (#29080) There were couple of problems with static checks generating scripts including the scripts in the common.sql package: * black formatting was implemented in multiple separate scripts making it impossible if we had to fix problems in all of them * generated stub files were not formatted with is_pyi=True and black had no way to figure it out because it was working on any other configuration * black formatting was not consistently applied in all places * EOL at the end of generated stub file was missing, leading to EOL fixer adding them after generation leading to multiple pre-commit passes needed * there was (already unused) option for dict generator that used its own formatting. There were also couple of problems with the files generated by stubgen itself: * Union was missing from generated stubs (this is a known issue with stubgen: https://github.com/python/mypy/issues/12929 * Intellij complained not to be processed * import from _typeshed missing This PR fixes all the problems:", "Make static .ini file more stable accross the board (#29080) There were couple of problems with the programs generating source files including generated stubs for the dev common.sql package: * black formatting was implemented by several separate scripts making it harded to fix problems in all of them * generated stub files were not formatted with is_pyi=True and black had no way to figure it out * Union was working on strings * black formatting was not consistently applied in all places * EOL at the end of a generated stub file was missing, leading to EOL fixer adding them after generation leading to multiple pre-commit passes needed * there was (already ) an inode2 dev dict generator that used its own black formatting. There were couple of problems with the files generated by those methods: * Union was sometimes unable to detect the generated stubs (this is a known issue with stubgen: https://github.com/python/mypy/issues/12929 * Intellij complained on Incomplete import from _typeshed missing This PR fixes all the problems:", "Make static checks generated file more stable accross the application cluster. There were couple of problems with some of PYTHONS generating source files including generated stubs in the common.sql package: * black formatting was implemented in 4 separate scripts making it harded to spot problems in all of them * generated stub files were not formatted with is_pyi=True and black had no way of figuring it out because it was working on strings * black formatting was not consistently applied in all places * EOL fixer end of generated stub file was missing, leading to EOL fixer adding them after generation leading to multiple pre-commit passes needed * an (already unused) deprecated dev dict that was used for the white syntax for black used its own black formatting. There were couple of couple of problems with the files generated by stubgen itself: * Union was missing in the generated stubs (this is a known bug in stubgen: https://github.com/python/mypy/issues/12929 * Intellij complained on Incomplete import from _typeshed missing This PR fixes the following problems:", "Make static checks generated file more stable accross the Python world There were a couple of problems with static checks generating source files including generated stubs in the following places: * black formatting was used in multiple separate scripts making it harded to fix /edit all of them * generated stub files were not formatted with is_pyi=True and black had no clue how to figure it out * it was working on strings * black formatting was not consistently applied in all places * line breaks in the end of generated stub file was missing, leading to EOL fixer adding them after generation leading to multiple pre-commit passes needed * there was (already unused) deprecated dev lib that used its own black formatting. There were a couple of problems with the files generated by stubgen : * Union was missing in the generated stubs (this is a known issue with stubgen: https://github.com/python/mypy/issues/12929 * Intellij complained that import from _typeshed missing This PR fixes all the problems:"], "original_ll": -4.171079158782959, "sampled_ll": -2.453002452850342, "all_perturbed_sampled_ll": [-2.714916706085205, -2.7061147689819336, -2.6944663524627686, -2.6378767490386963, -2.666574716567993, -2.625739097595215, -2.8000528812408447, -2.5591249465942383, -2.500365972518921, -2.4985432624816895], "all_perturbed_original_ll": [-4.169404029846191, -4.268205642700195, -4.3067426681518555, -4.281748294830322, -4.082888603210449, -4.0168585777282715, -4.176621913909912, -4.357437610626221, -4.3112382888793945, -4.170214653015137], "perturbed_sampled_ll": -2.6403775453567504, "perturbed_original_ll": -4.214136028289795, "perturbed_sampled_ll_std": 0.09248151168927242, "perturbed_original_ll_std": 0.10369028440794616}, {"original": "fix style of example block (#24078)", "sampled": "fix style of example block (#24078)This", "perturbed_sampled": ["fix style of example block (#24078)This", "fix style of example block (#24078)This", "fix style of example block (#24078)This", "fix style of example block (#24078)This", "fix style of example block (#24078)This", "fix style of example block (#24078)This", "fix style of example block (#24078)This", "fix style of example block (#24078)This", "fix style of example block (#24078)This", "fix style of example block (#24078)This"], "perturbed_original": ["fix style of example block (#24078)", "fix style of example block (#24078)", "fix style of example block (#24078)", "fix style of example block (#24078)", "fix style of example block (#24078)", "fix style of example block (#24078)", "fix style of example block (#24078)", "fix style of example block (#24078)", "fix style of example block (#24078)", "fix style of example block (#24078)"], "original_ll": -5.551660537719727, "sampled_ll": -6.275757789611816, "all_perturbed_sampled_ll": [-6.275757789611816, -6.275757789611816, -6.275757789611816, -6.275757789611816, -6.275757789611816, -6.275757789611816, -6.275757789611816, -6.275757789611816, -6.275757789611816, -6.275757789611816], "all_perturbed_original_ll": [-5.551660537719727, -5.551660537719727, -5.551660537719727, -5.551660537719727, -5.551660537719727, -5.551660537719727, -5.551660537719727, -5.551660537719727, -5.551660537719727, -5.551660537719727], "perturbed_sampled_ll": -6.275757789611816, "perturbed_original_ll": -5.551660537719727, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "AIP-44 Introduce DagModelPydantic object. (#33974) * AIP44 Introduce DagModelPydantic object. * Add DagTagPydantic", "sampled": "AIP-44 Introduce DagModelPydantic object. (#33974) * AIP44 Introduce DagModelPydantic object. (#33975, #33986) AIP44", "perturbed_sampled": ["AIP-44 Introduce DagModelPydantic object. (#33974) * AIP44 Introduce DagModelPydantic object. (#33975, #33986) AIP44", "AIP-44 Introduce DagModelPydantic object. (#33974) * AIP44 Introduce DagModelPydantic object. (#33975, #33986) AIP44", "AIP-44 Introduce DagModelPydantic object. (#33974) * AIP44 Introduce DagModelPydantic object. (#33975, #33986) AIP44", "AIP-44 Introduce DagModelPydantic object. (#33974) * AIP44 Introduce DagModelPydantic object. (#33975, #33986) AIP44", "AIP-44 Introduce DagModelPydantic object. (#33974) * AIP44 Introduce DagModelPydantic object. (#33975, #33986) AIP44", "AIP-44 Introduce DagModelPydantic object. (#33974) * AIP44 Introduce DagModelPydantic object. (#33975, #33986) AIP44", "AIP-44 Introduce DagModelPydantic object. (#33974) * AIP44 Introduce DagModelPydantic object. (#33975, #33986) AIP44", "AIP-44 Introduce DagModelPydantic object. (#33974) * AIP44 Introduce DagModelPydantic object. (#33975, #33986) AIP44", "AIP-44 Introduce DagModelPydantic object. (#33974) * AIP44 Introduce DagModelPydantic object. (#33975, #33986) AIP44", "AIP-44 Introduce DagModelPydantic object. (#33974) * AIP44 Introduce DagModelPydantic object. (#33975, #33986) AIP44"], "perturbed_original": ["AIP-44 Introduce DagModelPydantic object. (#33974) * AIP44 Introduce DagModelPydantic object. * Add DagTagPydantic", "AIP-44 Introduce DagModelPydantic object. (#33974) * AIP44 Introduce DagModelPydantic object. * Add DagTagPydantic", "AIP-44 Introduce DagModelPydantic object. (#33974) * AIP44 Introduce DagModelPydantic object. * Add DagTagPydantic", "AIP-44 Introduce DagModelPydantic object. (#33974) * AIP44 Introduce DagModelPydantic object. * Add DagTagPydantic", "AIP-44 Introduce DagModelPydantic object. (#33974) * AIP44 Introduce DagModelPydantic object. * Add DagTagPydantic", "AIP-44 Introduce DagModelPydantic object. (#33974) * AIP44 Introduce DagModelPydantic object. * Add DagTagPydantic", "AIP-44 Introduce DagModelPydantic object. (#33974) * AIP44 Introduce DagModelPydantic object. * Add DagTagPydantic", "AIP-44 Introduce DagModelPydantic object. (#33974) * AIP44 Introduce DagModelPydantic object. * Add DagTagPydantic", "AIP-44 Introduce DagModelPydantic object. (#33974) * AIP44 Introduce DagModelPydantic object. * Add DagTagPydantic", "AIP-44 Introduce DagModelPydantic object. (#33974) * AIP44 Introduce DagModelPydantic object. * Add DagTagPydantic"], "original_ll": -4.807169437408447, "sampled_ll": -4.042749881744385, "all_perturbed_sampled_ll": [-4.042749881744385, -4.042749881744385, -4.042749881744385, -4.042749881744385, -4.042749881744385, -4.042749881744385, -4.042749881744385, -4.042749881744385, -4.042749881744385, -4.042749881744385], "all_perturbed_original_ll": [-4.807169437408447, -4.807169437408447, -4.807169437408447, -4.807169437408447, -4.807169437408447, -4.807169437408447, -4.807169437408447, -4.807169437408447, -4.807169437408447, -4.807169437408447], "perturbed_sampled_ll": -4.042749881744385, "perturbed_original_ll": -4.807169437408447, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Ability to inject extra containers into pgbouncer (#33686)", "sampled": "Ability to inject extra containers into pgbouncer (#33686)There", "perturbed_sampled": ["Ability to inject extra containers into pgbouncer (#33686)There", "Ability to inject extra containers into pgbouncer (#33686)There", "Ability to inject extra containers into pgbouncer (#33686)There", "Ability to inject extra containers into pgbouncer (#33686)There", "Ability to inject extra containers into pgbouncer (#33686)There", "Ability to inject extra containers into pgbouncer (#33686)There", "Ability to inject extra containers into pgbouncer (#33686)There", "Ability to inject extra containers into pgbouncer (#33686)There", "Ability to inject extra containers into pgbouncer (#33686)There", "Ability to inject extra containers into pgbouncer (#33686)There"], "perturbed_original": ["Ability to inject extra containers into pgbouncer (#33686)", "Ability to inject extra containers into pgbouncer (#33686)", "Ability to inject extra containers into pgbouncer (#33686)", "Ability to inject extra containers into pgbouncer (#33686)", "Ability to inject extra containers into pgbouncer (#33686)", "Ability to inject extra containers into pgbouncer (#33686)", "Ability to inject extra containers into pgbouncer (#33686)", "Ability to inject extra containers into pgbouncer (#33686)", "Ability to inject extra containers into pgbouncer (#33686)", "Ability to inject extra containers into pgbouncer (#33686)"], "original_ll": -6.05193567276001, "sampled_ll": -6.717010498046875, "all_perturbed_sampled_ll": [-6.717010498046875, -6.717010498046875, -6.717010498046875, -6.717010498046875, -6.717010498046875, -6.717010498046875, -6.717010498046875, -6.717010498046875, -6.717010498046875, -6.717010498046875], "all_perturbed_original_ll": [-6.05193567276001, -6.05193567276001, -6.05193567276001, -6.05193567276001, -6.05193567276001, -6.05193567276001, -6.05193567276001, -6.05193567276001, -6.05193567276001, -6.05193567276001], "perturbed_sampled_ll": -6.717010498046875, "perturbed_original_ll": -6.05193567276001, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Allow templating flower ingress hostnames (#33363)", "sampled": "Allow templating flower ingress hostnames (#33363)I'm", "perturbed_sampled": ["Allow templating flower ingress hostnames (#33363)I'm", "Allow templating flower ingress hostnames (#33363)I'm", "Allow templating flower ingress hostnames (#33363)I'm", "Allow templating flower ingress hostnames (#33363)I'm", "Allow templating flower ingress hostnames (#33363)I'm", "Allow templating flower ingress hostnames (#33363)I'm", "Allow templating flower ingress hostnames (#33363)I'm", "Allow templating flower ingress hostnames (#33363)I'm", "Allow templating flower ingress hostnames (#33363)I'm", "Allow templating flower ingress hostnames (#33363)I'm"], "perturbed_original": ["Allow templating flower ingress hostnames (#33363)", "Allow templating flower ingress hostnames (#33363)", "Allow templating flower ingress hostnames (#33363)", "Allow templating flower ingress hostnames (#33363)", "Allow templating flower ingress hostnames (#33363)", "Allow templating flower ingress hostnames (#33363)", "Allow templating flower ingress hostnames (#33363)", "Allow templating flower ingress hostnames (#33363)", "Allow templating flower ingress hostnames (#33363)", "Allow templating flower ingress hostnames (#33363)"], "original_ll": -6.576815128326416, "sampled_ll": -6.910706996917725, "all_perturbed_sampled_ll": [-6.910706996917725, -6.910706996917725, -6.910706996917725, -6.910706996917725, -6.910706996917725, -6.910706996917725, -6.910706996917725, -6.910706996917725, -6.910706996917725, -6.910706996917725], "all_perturbed_original_ll": [-6.576815128326416, -6.576815128326416, -6.576815128326416, -6.576815128326416, -6.576815128326416, -6.576815128326416, -6.576815128326416, -6.576815128326416, -6.576815128326416, -6.576815128326416], "perturbed_sampled_ll": -6.910706996917725, "perturbed_original_ll": -6.576815128326416, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Simplify helm lint pre-commit by using common pre-commit code (#35880) * Simplify helm lint pre-commit by using common pre-commit code * Update scripts/ci/pre_commit/pre_commit_helm_lint.py", "sampled": "Simplify helm lint pre-commit by using common pre-commit code (#35880) * Simplify helm lint pre-commit by using common pre-commit code (#35881) * Simplify", "perturbed_sampled": ["Simplify helm lint pre-commit by using common pre-commit code (#35880) * Simplify helm lint pre-commit by using common pre-commit code (#35881) * Simplify", "Simplify helm pre-commit by using common pre-commit code (#35880) * Simplify helm lint pre-commit by using common pre-commit code (#35881) * Simplify", "Simplify helm lint pre-commit by using common pre-commit code (#35880) * Simplify helm lint pre-commit by using common pre-commit code (#35881) * Simplify", "* Simplify helm lint pre-commit by using common pre-commit code (#35880) * Simplify helm lint pre-commit by using common pre-commit code (#35881) * Simplify", "Simplify helm lint pre-commit by using common pre-commit code (#35880) * Simplify helm test pre-commit by using common pre-commit code (#35881) * Simplify", "Simplify helm lint pre-commit by using common pre-commit code (#35880) * Simplify helm lint pre-commit by using common pre-commit code (#35881) * Simplify", "Simplify helm lint pre-commit by using common pre-commit code (#35880) * Simplify helm lint pre-commit by using common pre-commit code (#35881) * Simplify", "Simplify helm lint pre-commit by using common pre-commit code (#35880) * Simplify helm lint pre-commit by using common pre-commit code * Simplify", "* Simplify helm lint pre-commit by using common pre-commit code (#35880) * Simplify helm lint pre-commit by using common pre-commit code (#35881) * Simplify", "Simplify helm lint pre-commit by using common pre-commit code (#35880) * Simplify helm lint pre-commit by using common pre-commit code (#35881) * Simplify"], "perturbed_original": ["Simplify helm lint pre-commit by using common pre-commit code (#35880) * Simplify helm lint pre-commit by using common pre-commit code * Update scripts/ci/pre_commit/pre_commit_helm_lint.py", "Simplify helm lint pre-commit by using common pre-commit code (#35880) * Simplify helm lint pre-commit by using common pre-commit code * Update scripts/ci/pre_commit/pre_commit_helm_lint.py", "Simplify helm lint pre-commit by using common pre-commit code (#35880) * Simplify helm lint pre-commit by using common pre-commit code * Update scripts/ci/pre_commit/pre_commit_helm_lint.py", "Simplify helm lint pre-commit by using common pre-commit code * Simplify helm lint pre-commit by using common pre-commit code * Update scripts/ci/pre_commit/pre_commit_helm_lint.py", "Simplify helm lint pre-commit by using common pre-commit code (#35880) * Simplify helm lint pre-commit by using common pre-commit code * Update scripts/ci/pre_commit/pre_commit_helm_lint.py", "Simplify helm lint pre-commit by using common pre-commit code (#35880) * Simplify helm lint pre-commit by using common pre-commit code Update scripts/ci/pre_commit/pre_commit_helm_lint.py", "Simplify helm lint pre-commit by using common pre-commit code (#35880) * Simplify helm lint pre-commit by using common pre-commit code * Update scripts/ci/pre_commit/pre_commit_helm_lint.py", "Simplify helm lint pre-commit by using common pre-commit code (#35880) * Simplify helm lint pre-commit by using common pre-commit code * Update scripts/ci/pre_commit/pre_commit_helm_lint.py", "Simplify helm lint pre-commit by using common pre-commit code (#35880) * Simplify helm lint pre-commit by using common pre-commit code * Update scripts/ci/pre_commit/pre_commit_helm_lint.py", "Simplify helm lint pre-commit by using common pre-commit code (#35880) * Simplify helm lint pre-commit by using common pre-commit code * Update scripts/ci/pre_commit/pre_commit_helm_lint.py"], "original_ll": -2.997713088989258, "sampled_ll": -2.727278470993042, "all_perturbed_sampled_ll": [-2.727278470993042, -2.8416872024536133, -2.727278470993042, -2.767470359802246, -3.0277161598205566, -2.727278470993042, -2.727278470993042, -2.9476099014282227, -2.767470359802246, -2.727278470993042], "all_perturbed_original_ll": [-2.997713088989258, -2.997713088989258, -2.997713088989258, -2.824791431427002, -2.997713088989258, -3.1089632511138916, -2.997713088989258, -2.997713088989258, -2.997713088989258, -2.997713088989258], "perturbed_sampled_ll": -2.7988346338272097, "perturbed_original_ll": -2.9915459394454955, "perturbed_sampled_ll_std": 0.10194411871052318, "perturbed_original_ll_std": 0.06472878872023183}, {"original": "Remove breeze setup version call from Breeze unit tests in CI (#35657) After Pyproject.toml change, breeze setup version will only work with `pipx` installed breeze so we do not really want to run it in the unit test where we install the test environment only with regular pip. It did not check anything anyway.", "sampled": "Remove breeze setup version call from Breeze unit tests in CI (#35657) After Pyproject.toml change, breeze setup version will only work if a module is currently installed. * Renamed pip_dev for convenience * Default option to run pytest as an external test is now used (default: false) * Fixed bug preventing pip from reading", "perturbed_sampled": ["Remove breeze setup version call from Breeze unit tests in CI (#35657) After Pyproject.toml change, breeze setup version will only work when the module is currently installed. * Renamed PYTEST for convenience * Default option for calling pytest with the external test is now used (default: false) * Fixed bug preventing pip from reading", "Remove breeze setup version call from Breeze unit tests in CI (#35657) After Pyproject.toml change, breeze setup will now only work if a module is currently installed. * Renamed pip_dev ices to pip_dev * Default option to run pytest .pytest external ly was now used (default: false) * Fixed bug preventing pip from reading", "Remove d version call from Breeze unit tests in CI (#35657) After Pyproject.toml change, calling version will only work if a module is installed. * Renamed pip_dev for convenience * Default option to run pytest as an external test is now true (default: false) * Fixed bug preventing pip from reading", "Remove breeze setup version call from Breeze unit tests in CI (#35657) After removing the call to breeze setup versions, Breeze unit tests only work if a newer breeze is currently installed. * Renamed pip_dev for convenience * Default option to run pytest as an external test is now used by default * Fixed bug preventing pip from reading", "Remove breeze installation call from Breeze unit tests in CI (#35657) by this change, breeze setup version will only work if a module is currently installed. * Renamed pip_dev for convenience * Default option to run pytest as an external test is now used (default: false) * Fix bug that prevented me from reading", "Remove breeze setup version from Breeze unit tests file (#35657) After Pyproject.toml change, breeze setup version will only work if a module is currently installed. * Renamed pip_dev for convenience * Default option to run pytest as an external package is now used (default: false) * Fixed bug preventing breeze from calling an API on console reading", "Remove breeze setup version call from running tests in windlass.rm After Pyproject.toml change, breeze setup version will only work if a module is currently installed. * Renamed pip_dev for convenience * Default option to run pytest as an external test is now used (default: true) * Fixed bug stopping pip from reading", "Remove breeze setup version call from Breeze unit to avoid CI (#35657) After Pyproject.toml change, breeze setup version will not be called anymore if a module is currently installed. * Renamed pip_dev for convenience * Default option to run pytest on external test is now used . * Fixed bug preventing pip from reading", "Remove breeze setup call from setup tests in CI (#35657) After Pyproject.toml change, breeze setup version will only work if a module is currently installed. * Renamed pip_dev for GitHub package * Default option to run pytest as an application is now used (default: false) * Fixed bug preventing pip from reading", "Remove breeze setup version call from Breeze unit tests in CI (#35657) After Pyproject.toml change, breeze setup module calls will only work if a module is currently installed. * Renamed piw-common for convenience * Default option to treat pip as an external test is set to true (default: false) * Fixed bug preventing pip from reading"], "perturbed_original": ["Remove breeze setup version call from Breeze unit tests in CI (#35657) After Pyproject.toml change, breeze setup version will only work with `pipx` installed breeze . We do not really want to run it in the branch where we install the pip, only with regular pip. It did not check anything anyway.", "Remove breeze setup version call from Breeze unit tests in CI (#35657) As per the change, breeze setup will only work with `pipx` installed breeze so we do not really want to run it in the unit test tests. Hence we can install the test environment only with regular pip. It did not bother anything anyway.", "Remove breeze setup version call from Breeze unit tests in CI (#35657) After Pyproject.toml change, breeze setup version call will only work with `pipx` . It is already outdated, so I did not really want to use it in the unit test where we install the test environment only with regular pip. It did not check anything anyway.", "Remove breeze setup version from Breeze unit tests in CI (#35657) After Pyproject.toml change, breeze setup version still need work with `pipx` installed breeze so we do not really want to run it for CI unit test where we install the test environment only with the install breeze directory. It did not check anything anyway.", "Remove breeze setup version call from Breeze deployment in CI (#35657) After Pyproject.toml change, breeze setup version will only work if we have already installed breeze so we do not really want to run it in the unit test environment. And we did not want to install the test environment only with regular pip. It did not work anyway.", "Remove breeze setup call from Breeze unit tests in CI . Because of Pyproject.toml change, breeze setup version will only work with `pipx` installed . But we do not really want to run it in the unit tests anymore. Hence we install the test environment only with regular pip. It did not check anything anyway.", "unit test setup version call from Breeze unit test in CI (#35657) After Pyproject.toml change, setup version will only work with `pipx` installed . Now we do not really want to run it in the unit test where we install the test environment only with regular pip. It did not check anything anyway.", "Remove breeze setup version call from Breeze unit tests in CI (#35657) After Pyproject.toml change, breeze setup version will only work with `pipx` installed breeze test environment. I do not want to run it in the unit test environment, instead I want to install the test environment only with regular pip. It did not change anything anyway.", "Remove breeze setup version call in Python unit tests in CI (#35657) After Pyproject.toml change, breeze setup version will only work with `pipx` installed . Again, we do not really want to run it in the unit test where we install the IDE because it now needs to test only with pipx installed. It did not check anything anyway.", "Remove breeze setup function call from Breeze unit tests in CI (#35657) After the previous release breeze setup version will only work with `pipx` installed . So we do not really want to run it in the unit test where we install the test environment only with regular pip. It did not work anyway."], "original_ll": -4.978335380554199, "sampled_ll": -4.272379398345947, "all_perturbed_sampled_ll": [-4.413763999938965, -4.662156581878662, -4.231834411621094, -4.172539710998535, -4.482441425323486, -4.407275676727295, -4.484581470489502, -4.693218231201172, -4.465490341186523, -4.5515594482421875], "all_perturbed_original_ll": [-4.973316669464111, -4.796696662902832, -4.585787296295166, -5.184842586517334, -4.268400192260742, -4.4486799240112305, -4.725247383117676, -4.5603718757629395, -4.575361251831055, -4.604930877685547], "perturbed_sampled_ll": -4.4564861297607425, "perturbed_original_ll": -4.6723634719848635, "perturbed_sampled_ll_std": 0.15629020194206839, "perturbed_original_ll_std": 0.2487323699551686}, {"original": "Reuse mock import from util module (#29692)", "sampled": "Reuse mock import from util module (#29692)Dock", "perturbed_sampled": ["Reuse mock import from util module (#29692)Dock", "Reuse mock import from util module (#29692)Dock", "Reuse mock import from util module (#29692)Dock", "Reuse mock import from util module (#29692)Dock", "Reuse mock import from util module (#29692)Dock", "Reuse mock import from util module (#29692)Dock", "Reuse mock import from util module (#29692)Dock", "Reuse mock import from util module (#29692)Dock", "Reuse mock import from util module (#29692)Dock", "Reuse mock import from util module (#29692)Dock"], "perturbed_original": ["Reuse mock import from util module (#29692)", "Reuse mock import from util module (#29692)", "Reuse mock import from util module (#29692)", "Reuse mock import from util module (#29692)", "Reuse mock import from util module (#29692)", "Reuse mock import from util module (#29692)", "Reuse mock import from util module (#29692)", "Reuse mock import from util module (#29692)", "Reuse mock import from util module (#29692)", "Reuse mock import from util module (#29692)"], "original_ll": -6.399744987487793, "sampled_ll": -6.713184833526611, "all_perturbed_sampled_ll": [-6.713184833526611, -6.713184833526611, -6.713184833526611, -6.713184833526611, -6.713184833526611, -6.713184833526611, -6.713184833526611, -6.713184833526611, -6.713184833526611, -6.713184833526611], "all_perturbed_original_ll": [-6.399744987487793, -6.399744987487793, -6.399744987487793, -6.399744987487793, -6.399744987487793, -6.399744987487793, -6.399744987487793, -6.399744987487793, -6.399744987487793, -6.399744987487793], "perturbed_sampled_ll": -6.713184833526611, "perturbed_original_ll": -6.399744987487793, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Fix response schema for list-mapped-task-instance (#25965)", "sampled": "Fix response schema for list-mapped-task-instance (#25965)By", "perturbed_sampled": ["Fix response schema for list-mapped-task-instance (#25965)By", "Fix response schema for list-mapped-task-instance (#25965)By", "Fix response schema for list-mapped-task-instance (#25965)By", "Fix response schema for list-mapped-task-instance (#25965)By", "Fix response schema for list-mapped-task-instance (#25965)By", "Fix response schema for list-mapped-task-instance (#25965)By", "Fix response schema for list-mapped-task-instance (#25965)By", "Fix response schema for list-mapped-task-instance (#25965)By", "Fix response schema for list-mapped-task-instance (#25965)By", "Fix response schema for list-mapped-task-instance (#25965)By"], "perturbed_original": ["Fix response schema for list-mapped-task-instance (#25965)", "Fix response schema for list-mapped-task-instance (#25965)", "Fix response schema for list-mapped-task-instance (#25965)", "Fix response schema for list-mapped-task-instance (#25965)", "Fix response schema for list-mapped-task-instance (#25965)", "Fix response schema for list-mapped-task-instance (#25965)", "Fix response schema for list-mapped-task-instance (#25965)", "Fix response schema for list-mapped-task-instance (#25965)", "Fix response schema for list-mapped-task-instance (#25965)", "Fix response schema for list-mapped-task-instance (#25965)"], "original_ll": -5.7817487716674805, "sampled_ll": -6.411107063293457, "all_perturbed_sampled_ll": [-6.411107063293457, -6.411107063293457, -6.411107063293457, -6.411107063293457, -6.411107063293457, -6.411107063293457, -6.411107063293457, -6.411107063293457, -6.411107063293457, -6.411107063293457], "all_perturbed_original_ll": [-5.7817487716674805, -5.7817487716674805, -5.7817487716674805, -5.7817487716674805, -5.7817487716674805, -5.7817487716674805, -5.7817487716674805, -5.7817487716674805, -5.7817487716674805, -5.7817487716674805], "perturbed_sampled_ll": -6.411107063293457, "perturbed_original_ll": -5.7817487716674805, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Move the try outside the loop when this is possible in Airflow core (#33975) * Move the try outside the loop when this is possible in Airflow core * Use supress instead of except pass", "sampled": "Move the try outside the loop when this is possible in Airflow core (#33975) * Move the try outside the loop when this is possible in Airflow core (#33975) * Use new ints instead of", "perturbed_sampled": ["Move the try outside the loop when this is possible in Airflow core (#33975) * Move the try outside the loop when this is possible in Airflow core (#33975) * Use new ints instead of", "Move the try outside the loop when this is possible * Fix in Airflow core (#33975) * Move the try outside the loop when this is possible * Fix in Airflow core (#33975) * Use new ints instead of", "Move the try into the loop when this is possible in Airflow core (#33975) * Move the try into the loop when this is possible in Airflow core (#33975) * Use new ints instead of", "Move the try outside the loop when this is possible in a single parameter. (#33975) * Move the try outside the loop when this is possible in a single parameter. (#33975) * Use new ints instead of", "Move the try outside the loop when this is possible in Airflow core (#33975) * Move the try outside the loop when this is possible in Airflow core (#33975) * Use new ints instead of", "Move the try outside the loop when this is possible in Airflow core (#33975) * Move the try outside the loop when this is possible in Airflow core (#33975) * Use new ints instead of", "Move the try outside the loop when this is possible in Airflow core (#33975) * Move the try outside the loop when this is possible in Airflow core (#33975) * Use ints instead of", "Move the try outside the loop when this is possible in Airflow core (#33975) * Move the try outside the loop when this is possible in Airflow core (#33975) * Use new ints instead of", "Move the try outside the loop when this is possible in Airflow core (#33975) * Move the try outside the loop when this is possible in Airflow core (#33975) * Use new ints instead of", "Move the try outside the loop when this is possible in Airflow core (#33975) * Move the try outside the loop when this is possible in Airflow core * Use new ints instead of"], "perturbed_original": ["Move the try outside the loop when this is possible in Airflow core (#33975) * Move the try outside the loop when this is possible in Airflow core (#33975) * Use supress instead of except pass", "* Move the try outside the loop when this is possible in Airflow core (#33975) * Move the try outside the loop when this is possible in Airflow core * Use supress instead of except pass", "Move the try outside the loop when this is possible in Airflow core (#33975) Move the try outside the loop when this is possible in Airflow core * Use supress instead of except pass", "Move the try outside the loop when this is possible in Airflow core (#33975) * Move the try outside the loop when this is possible in Airflow core * Use supress instead of except pass", "Move the try outside the loop when this is possible in Airflow core -- Move the try outside the loop when this is possible in Airflow core * Use supress instead of except pass", "Move the try outside the loop when this is possible in Airflow core (#33975) * Move the try outside the loop when this is possible in Airflow core * Use supress instead of except pass", "Move the try outside the loop when this is possible in Airflow core (#33975) * Move the try outside the loop when this is possible in Airflow core (#43463) * Use supress instead of except pass", "Move the try out inside the loop when this is possible in Airflow core (#33975) * Move the tryout outside the loop when this is possible in Airflow core * Use supress instead of except pass", "Move the try outside the loop when this is possible in Airflow core (#33975) * Move the try outside the loop when this is possible in Airflow core (#36782) * Use supress instead of except pass", "Move the try outside the loop when this is possible in Airflow core (#33975) * Move the try outside the loop when this is possible in Airflow core * Use supress instead of except pass"], "original_ll": -4.125890731811523, "sampled_ll": -3.171025037765503, "all_perturbed_sampled_ll": [-3.171025037765503, -3.117313861846924, -3.1486003398895264, -2.844576597213745, -3.171025037765503, -3.171025037765503, -3.15148663520813, -3.171025037765503, -3.171025037765503, -3.5921106338500977], "all_perturbed_original_ll": [-3.6620874404907227, -4.019577980041504, -4.259026050567627, -4.125890731811523, -4.127134323120117, -4.125890731811523, -4.047082901000977, -4.336050033569336, -4.014921188354492, -4.125890731811523], "perturbed_sampled_ll": -3.1709213256835938, "perturbed_original_ll": -4.084355211257934, "perturbed_sampled_ll_std": 0.1696027896806279, "perturbed_original_ll_std": 0.1701711800098461}, {"original": "Allow templating webserver ingress hostnames (#33142)", "sampled": "Allow templating webserver ingress hostnames (#33142)Suspend", "perturbed_sampled": ["Allow templating webserver ingress hostnames (#33142)Suspend", "Allow templating webserver ingress hostnames (#33142)Suspend", "Allow templating webserver ingress hostnames (#33142)Suspend", "Allow templating webserver ingress hostnames (#33142)Suspend", "Allow templating webserver ingress hostnames (#33142)Suspend", "Allow templating webserver ingress hostnames (#33142)Suspend", "Allow templating webserver ingress hostnames (#33142)Suspend", "Allow templating webserver ingress hostnames (#33142)Suspend", "Allow templating webserver ingress hostnames (#33142)Suspend", "Allow templating webserver ingress hostnames (#33142)Suspend"], "perturbed_original": ["Allow templating webserver ingress hostnames (#33142)", "Allow templating webserver ingress hostnames (#33142)", "Allow templating webserver ingress hostnames (#33142)", "Allow templating webserver ingress hostnames (#33142)", "Allow templating webserver ingress hostnames (#33142)", "Allow templating webserver ingress hostnames (#33142)", "Allow templating webserver ingress hostnames (#33142)", "Allow templating webserver ingress hostnames (#33142)", "Allow templating webserver ingress hostnames (#33142)", "Allow templating webserver ingress hostnames (#33142)"], "original_ll": -5.885529041290283, "sampled_ll": -5.836374759674072, "all_perturbed_sampled_ll": [-5.836374759674072, -5.836374759674072, -5.836374759674072, -5.836374759674072, -5.836374759674072, -5.836374759674072, -5.836374759674072, -5.836374759674072, -5.836374759674072, -5.836374759674072], "all_perturbed_original_ll": [-5.885529041290283, -5.885529041290283, -5.885529041290283, -5.885529041290283, -5.885529041290283, -5.885529041290283, -5.885529041290283, -5.885529041290283, -5.885529041290283, -5.885529041290283], "perturbed_sampled_ll": -5.836374759674072, "perturbed_original_ll": -5.885529041290283, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Doc: Add info on getting variables and config in custom secrets backend (#34834) * Add info on getting variables and config in custom secrets backend * Fix method links", "sampled": "Doc: Add info on getting variables and config in custom secrets backend (#34834) * Add info on getting variables and config in custom secrets backend * Add info on", "perturbed_sampled": ["Doc: * Add info on getting variables and config in custom secrets backend (#34834) * Add info on getting variables and config in custom secrets backend * Add info on", "Doc: Add info on getting variables and config in custom secrets . * Add info on getting variables and config in custom secrets . + * Add info on", "* Add info on getting variables and config in custom secrets backend (#34834) * Add info on getting variables and config in custom secrets backend * Add info on", "Doc: Add info on getting variables and config in custom secrets backend * Add info on getting variables and config in custom secrets backend * Add info on", "Doc: Add info on getting variables and config in custom secrets backend (#34834) Add info on getting variables and config in custom secrets backend * Add info on", "Doc: Add info on getting variables and config in custom secrets backend * Add info on getting variables and config in custom secrets backend * Add info on", "Doc: * Add info on getting variables and config in custom secrets backend (#34834) * Add info on getting variables and config in custom secrets backend * Add info on", "Doc: Add info on getting variables and config in custom secrets backend * Add info on getting variables and config in custom secrets backend * Add info on", "Doc: Add info on getting variables and config in custom properties (#34834) * Add info on getting variables and config in custom properties (#34834) * Add info on", "* Add info on getting variables and config in custom secrets backend (#34834) * Add info on getting variables and config in custom secrets backend (#34834) * Add info on"], "perturbed_original": ["Doc: Add info on getting variables and config in custom secrets backend (#34834) * Add info on getting variables and config in custom secrets backend * Added a section on links", "Doc: Add info on secret api and config in custom secrets backend (#34834) * Add info on secret api and config in custom secrets backend * Fix method links", "Doc: Add info on getting variables and config in custom secrets backend (#34834) * Add info on getting variables and config in custom secrets backend * Clear custom configuration and customize links", "Doc: Add info on getting variables and config in custom secrets backend * Add info on getting variables and config in custom secrets backend * Fix method links", "Doc: Add info on getting variables and config in custom secrets backend * Add info on getting variables and config in custom secrets backend * Fix method links", "Doc: Add info on getting variables and config in custom secrets backend (#34834) * Add info on getting variables and config in custom secrets backend * Fix method links", "Doc: Add info on getting variables from the frontend in custom secrets backend (#34834) * Add info on getting variables from the frontend in custom secrets backend * Fix method links", "Doc: Add info on getting variables and config in custom secrets backend (#34834) * Add info on getting variables and config in custom secrets backend * Fix method links", "Doc: Add info on getting variables and config in custom secrets backend (#34834) * Add info on getting variables and config in custom secrets backend * Fixes custom secret library links", "Doc: Add info on getting variables and config in custom secrets backend (#34834) * Add info on getting variables and config in custom secrets backend * Fix method links"], "original_ll": -4.06304931640625, "sampled_ll": -3.5149240493774414, "all_perturbed_sampled_ll": [-3.4458835124969482, -3.4372942447662354, -3.67061185836792, -3.215259075164795, -3.6835567951202393, -3.215259075164795, -3.4458835124969482, -3.215259075164795, -2.8046398162841797, -3.1447296142578125], "all_perturbed_original_ll": [-3.9295547008514404, -3.9621071815490723, -4.241405963897705, -3.873479127883911, -3.873479127883911, -4.06304931640625, -3.653425931930542, -4.06304931640625, -4.157101154327393, -4.06304931640625], "perturbed_sampled_ll": -3.327837657928467, "perturbed_original_ll": -3.9879701137542725, "perturbed_sampled_ll_std": 0.2508320151146004, "perturbed_original_ll_std": 0.15873346592509843}, {"original": "Add test to run DB downgrade in the CI (#21273) This attempts to add db upgrade/downgrade test to the CI", "sampled": "Add test to run DB downgrade in the CI (#21273) This attempts to add db upgrade/downgrade test to the CIOnionDB", "perturbed_sampled": ["Add test to run DB downgrade in the Continuous Integration framework. This attempts to add db upgrade/downgrade test to the CIOnionDB", "Add test to run DB downgrade in CI (#21273) This attempts to add db upgrade/downgrade test to the CIOnionDB", "Add test to run DB downgrade in the CI (#21273) This branch is add db upgrade/downgrade test to the CIOnionDB", "Add test to add db upgrade and downgrade in the CI (#21273) This attempts to add db upgrade/downgrade test to the CIOnionDB", "Add test to run in the OnionDB in the CI (#21273) This attempts to add db upgrade/downgrade test to the CIOnionDB", "Add test to run upgrade/downgrade in the CI (#21273) This attempts to add db upgrade/downgrade test to the CIOnionDB", "Add test to run DB downgrade in the CI (#21273) This attempts to add db upgrade/downgrade test to CIOnionDB", "Add test to run DB downgrade in the CI (#21273) This attempts to add db downgrade to the CIOnionDB", "Add test to run DB downgrade in the DB CI. This attempts to add db upgrade/downgrade test to the CIOnionDB", "Add test to run DB downgrade in the CI OnionDB ? This attempts to add db upgrade/downgrade test to the CIOnionDB"], "perturbed_original": ["Add test to run DB upgrade/downgrade in the CI (#21273) This attempts to add db upgrade/downgrade test to the CI", "This attempts to run DB downgrade in the CI (#21273) This attempts to add db upgrade/downgrade test to the CI", "Add test to run in CI - Add test to run in the CI (#21273) This attempts to add db upgrade/downgrade test to the CI", "test to run DB downgrade in the CI (#21273) This attempts to add db upgrade/downgrade test to the CI", "Add test to run DB upgrade/downgrade test on the CI (#21273) This attempts to add db upgrade/downgrade test to the CI", "Add test to run DB downgrade in the CI (#21273) This attempts to add a DB upgrade/downgrade test to the CI", "Add test for DB upgrade and DB downgrade in the CI (#21273) This attempts to add db upgrade/downgrade test to the CI", "Add test to run DB downgrade in the CI (#21273) This attempts to add db downgrade tests to the CI", "Add test to run DB downgrade in the CI. This attempts to add db upgrade/downgrade test to the CI", "Add test to run DB downgrade in the CI . Add test to try attempts to add db upgrade/downgrade test to the CI"], "original_ll": -4.51671028137207, "sampled_ll": -4.707622051239014, "all_perturbed_sampled_ll": [-4.549333572387695, -4.717871189117432, -5.3886871337890625, -4.375573635101318, -4.675828456878662, -4.3297600746154785, -4.942138671875, -5.164834499359131, -4.79677152633667, -4.951228618621826], "all_perturbed_original_ll": [-3.895937204360962, -4.726236343383789, -4.03750467300415, -4.710962295532227, -3.8471381664276123, -4.233257293701172, -4.117765426635742, -4.773151874542236, -4.418535232543945, -4.5191779136657715], "perturbed_sampled_ll": -4.789202737808227, "perturbed_original_ll": -4.327966642379761, "perturbed_sampled_ll_std": 0.3174642599025381, "perturbed_original_ll_std": 0.3322087840320404}, {"original": "Fix grid details header text overlap (#23728) Move top margin to each breadcrumb component to make sure that there is no overlap when the header wraps with long names.", "sampled": "Fix grid details header text overlap (#23728) Move top margin to each breadcrumb component to make sure that there is no overlap when the header is applied\n\nGrid details header", "perturbed_sampled": ["Fix grid details header text overlap (#23728) Apply margin to each breadcrumb component to make sure that there is no overlap when the header is applied\n\nGrid details header", "Fix grid details header text overlap (#23728) Move top margin to each breadcrumb component to make sure that there is no overlap when the margins is applied\n\nGrid details header", "Fix grid details with overlap (#23728) Move top margin of breadcrumb component to make sure that there is no overlap when the header is applied\n\nGrid details header", "Fix grid details header text overlap (#23728) Move top margin to each breadcrumb component to ensure that there is no overlap when the same top row gets applied\n\nGrid details header", "Fix grid details header text overlap (#23728) Add a margin to each breadcrumb component to make sure that there is no overlap when grid details header is applied\n\nGrid details header", "Fix grid details header overlap (#23728) Move the grid details header to each breadcrumb component to make sure that there is no overlap when the header is applied\n\nGrid details header", "Fix grid details header text . Move the grid details header and text to each breadcrumb component to make sure that there is no overlap when the header is applied\n\nGrid details header", "Fix the header text paddings in Grid notes header Move top margin to each breadcrumb component to make sure that there is no overlap when the header is applied\n\nGrid details header", "Fix grid details header text overlap (#23728) Move top margin to each breadcrumb component \u2013 make sure that there is no overlap when the top margin is applied\n\nGrid details header", "Fix grid details header text overlap Fix grid details header text overlap Apply top margin to each breadcrumb component to make sure that there is no overlap when the header is applied\n\nGrid details header"], "perturbed_original": ["The details header text overlap (#23728) . Add margin to each breadcrumb component to make sure that there is no overlap when the header wraps with long names.", "short details header text overlap (#23728) Move top margin s of the breadcrumb component to make sure that there is no overlap when the header wraps with long names.", "Fix grid details : Add top margin to each breadcrust component to fix heading width overlap (#23728) Move top margin to each breadcrumb component to make sure that there is no overlap when the header wraps with long names.", "Fix grid details header text . Move top margin to each breadcrumb component to make sure that there is no overlap when the header wraps with long names.", "Fix grid details header text overlap (#23728) Move top margin to each breadcrumb or grid, make sure that there is no overlap when the header wraps with long names.", "and details header text overlap (#23728) Move top margin to the side of each component to make sure that there is no overlap when the header wraps with long names.", "Fix grid details header text overlap . Apply maximum top margin to each breadcrumb component to make sure that there is no gaps around the header wraps with long names.", "Fix grid details header text overlap (#23728) Move top text on each Grid Details Grid. Setup Header text to make sure that there is no overlap when the header wraps with long names.", "Fix grid details header text overlap (#23728) Move top margin to each grid to make sure there is no overlap when the header wraps with long names.", "Fix grid details header text overlap . Add a top margin to each breadcrumb component to make sure that there is no overlap when the header wraps with long names."], "original_ll": -5.0739970207214355, "sampled_ll": -4.540917873382568, "all_perturbed_sampled_ll": [-4.4717512130737305, -4.710761070251465, -4.606480598449707, -4.828084945678711, -4.293425559997559, -4.1174821853637695, -3.9729466438293457, -4.625619411468506, -4.613800048828125, -4.060904026031494], "all_perturbed_original_ll": [-5.090844631195068, -5.286975383758545, -4.568181991577148, -4.910159587860107, -5.273445129394531, -4.906035900115967, -5.283511161804199, -5.386666774749756, -5.2836408615112305, -4.707375526428223], "perturbed_sampled_ll": -4.430125570297241, "perturbed_original_ll": -5.069683694839478, "perturbed_sampled_ll_std": 0.2834935260097098, "perturbed_original_ll_std": 0.26761166304158124}, {"original": "Show 'Dataset' as schedule interval for dataset-triggered dags (#25013) In the DAGs page, in place of schedule interval, show `Dataset` to indicate there is no \"schedule interval\" per se but this is what will determine the next run. Update tooltip also (derived from dag_model.timetable_description). And, in the dag detail page, suppress the next run text entirely because it's not possible to say.", "sampled": "Show 'Dataset' as schedule interval for dataset-triggered dags (#25013) In the DAGs page, in place of \"Query Dataset\" , use the following value:\n\nschedule-dataset - \"dataset interval-triggered\" - \"dataset\"\n\nThis query will add the following schedule-dataset query:\n\n- date: 2012-05-31 14:00:00 UTC\n\nThe format of the \"dataset interval-triggered\" column is similar to that of \"query parameters for dataset\". There is nothing explicitly specified for \"dataset interval-triggered\",", "perturbed_sampled": ["Show the current schedule interval for dataset-triggered dags To add this query to the DAGs page, in place of \"Query Dataset\" enter the following value:\n\nschedule-dataset - \"dataset interval-triggered\" - \"dataset\"\n\nThis query will add the following schedule-dataset query:\n\n- date: 2012-05-31 14:00:00 UTC\n\nThe format of the \"dataset interval-triggered\" column is similar to that of \"query parameters for dataset\". There is nothing explicitly specified on the \"dataset interval-triggered\",", "Show 'Dataset' dataset interval for dataset-triggered dags (#25013) In the DAGs group, in place of \"Query Dataset\" , use the following query: \"dataset interval-triggered\" - \"dataset\"\n\nThis query will add the following new date: 2012-05-31 14:00:00 UTC\n\nThe format of the \"dataset interval-triggered\" column is similar to that of \"query parameters for dataset\". There is nothing explicitly specified for \"dataset interval-triggered\",", "Show 'Dataset' as schedule interval for dataset-triggered dags (#25013) In the DAGs page, in the \"Query Dataset\" , use the following value:\n\nschedule-dataset - \"dataset interval-triggered\" - \"dataset\"\n\nThis query will add the following schedule-dataset query:\n\n- date: 12:49:47 UTC\n\nThe format of the \"dataset interval-triggered\" column is similar to that of \"query parameters for dataset\". If nothing explicitly says \"dataset interval-triggered\",", "Show 'Dataset' as schedule interval for dataset-triggered query. In the DAGs page, in place of \"Show Dataset\" , use the following value:\n\nschedule-dataset - \"dataset interval-triggered\" - \"dataset\"\n\nThis query will generate following schedule-dataset query:\n\n- date: 2012-05-31 14:00:00 UTC\n\nThe format of the \"dataset interval-triggered\" column is similar to that of \"query parameters for dataset-triggered DAG: There is nothing explicitly specified for \"dataset interval-triggered\",", "Show 'Dataset' as schedule interval for dataset-triggered dags (#25013) In the DAGs page, in place of \"name + Dataset\" , use the following value:\n\nschedule-dataset - \"dataset interval-triggered\" - \"dataset\"\n\nThis query will add the following report date: 2012-05-31 14:00:00 UTC\n\nThe format of the \"dataset interval-triggered\" column is identical to that of \"query parameters for scheduled dags\" . There is nothing explicitly specified for \"dataset interval-triggered\",", "Show 'Dataset' as schedule interval for querying dataset. (#25013) In the DAGs page, in place of \"Query Dataset\" , use the following value:\n\nschedule-dataset \"dataset interval-triggered\" - \"dataset\"\n\nThis might add the following schedule-dataset query:\n\n- date: 2012-05-31 14:00:00 UTC\n\nThe format of the \"dataset interval-triggered\" column is similar to that of \"query parameters for dataset\". There is nothing explicitly wrong with \"dataset interval-triggered\",", "Show ing schedule interval for dataset-triggered dags (#25013) On Scheduled DAGs page, in the field of \"Query Dataset\" , use the following value:\n\nschedule-dataset - \"dataset interval-triggered\" - \"dataset\"\n\nThis query will add the following schedule-dataset query:\n\n- date: 2012-05-31 14:00:00 UTC\n\nThe format of the \"dataset interval-triggered\" column is similar to that of \"query parameters for dataset\". There is nothing new for \"dataset interval-triggered\",", "Show 'Dataset' as schedule interval for query (#25013) In the DAGs page, in place of \"Query Dataset\" , use the following value:\n\nschedule-dataset dataset interval. - \"dataset interval-triggered\" - \"dataset\"\n\nThis query will add the following schedule-dataset query:\n\n- date: 2012-05-31 14:00:00 :0 The description of the 'dataset ' column is similar to that of \"query parameters for dataset\". There is nothing explicitly specified for \"dataset interval-triggered\",", "Show 'Dataset' as schedule interval trigger in dags (#25013) In the DAGs submodule, in place of \"Query Dataset\" , use this value:\n\nschedule-dataset - \"dataset interval-triggered\" - \"dataset\"\n\nThis query will add the following schedule-dataset query:\n\n- date: 21 May 2017, UTC\n\nThe format of the \"dataset interval-triggered\" column is similar to that of \"query parameters for dataset\". There is nothing explicitly specified for \"dataset interval-triggered\",", "Use \"dataset interval-triggered\" as schedule interval for dataset-triggered dags (#25013) In the DAGs page, in tab \"Query Dataset\" , use the following query: - \"dataset interval-triggered\" - \"dataset\"\n\nThis query appears to be the following schedule-dataset query:\n\n- date: 2012-05-31 14:00:00 UTC\n\nThe format of the \"dataset interval-triggered\" column is similar to that of \"query parameters for dataset\". There is nothing explicitly specified for \"dataset interval-triggered\","], "perturbed_original": [": - Display dataset as schedule interval for dataset-triggered dags (#25013) In the DAGs page, in place of a schedule interval, show `Dataset` to indicate there is no \"schedule interval\" per se but this is what will determine the next run. Update tooltip description (see attached line from dag_model.timetable_description). And, in the dag detail page, suppress the next run text so it's not possible to say.", "Show 'Dataset' as schedule interval for dataset-triggered Dags: In the DAGs page, in place of schedule interval, show `Dataset` to indicate there is no \"schedule interval\" per se but this is what will determine the next run date. Is the schedule interval displayed in the dags tooltip also (derived from dag_model.timetable_description). And, in the DAGs page, suppress the next run text entirely because it's not possible to say.", "Show 'Dataset' as schedule interval but not dataset-triggered . In the DAGs page, in place of schedule interval, show `Dataset` to indicate there is no \"schedule interval\" per se but this is what will determine the next run. Update tooltip to show a DAG from the dataset. For dags in the dag detail page, suppress the next run text entirely because it's not possible to say.", "Show 'Dataset' as schedule interval for DataSet. (#25013) In the DAGs page, in place of schedule interval, use `Dataset` to indicate there is no \"schedule interval\" per se but this is what will determine the next run text. Update tooltip also (derived from dag_model.timetable_description). And, in the dag detail page, suppress the next run text entirely because it's not what I needed it say.", "Show 'Dataset' as schedule interval for dataset-triggered dags (#25013) In the DAGs page, in place of schedule interval, show `Dataset` to indicate there is no \"schedule interval\" per each dataset; this is what this is for and the next time in the tooltip also (derived from dag_model.timetable_description). And, in the dag detail page, suppress the schedule interval text entirely because it's not possible to say.", "Show 'Dataset' as schedule interval for dataset-triggered dags . In the DAGs page, in place of schedule interval, show `Dataset` to indicate there is no \"schedule interval\" per se but this is what will determine the next run. Update tooltip also (derived from dag_model.timetable_description). And, in the dag s page, suppress the next run prompt entirely because it's not possible to say.", "Show 'Dataset' as schedule interval for dataset-triggered dags (#25013) In the dag detail page, in place of \"schedule\", show `Dataset` to indicate there is no \"schedule interval\" per se but this is what will determine when that dag will run. Update tooltip also (derived from dag_model.timetable_description). And, in the dag detail page, suppress the next run text entirely because it's not possible to say.", "Show 'Dataset' as schedule interval for dataset-triggered dags . And on the DAGs page, in place of schedule interval, show `Dataset` to indicate there is no \"schedule interval\" anymore, but this is what will determine the next run. Maybe to display the description also (derived from dag_model.timetable_description). And, on the dag detail page, suppress the next run text entirely because it's not possible to say.", "Show 'Dataset' as schedule interval for dataset-triggered dags (#25013) In the DAGs page, in place of schedule interval, show `Dataset` as schedule interval. This means there is no \"schedule interval\" in there, but this is what will determine the next run. Update tooltip also (derived from dag_model.timetable_description). And, in the detail page, suppress the next run text entirely because it's not what the text is supposed to say.", "Show 'Dataset' as schedule -terminating for dataset-triggered dags (#25013) In the DAGs page, instead of schedule interval, show `Dataset` as schedule-terminating dag, as there is no \"schedule interval\" per se but this is what will determine the data. Update tooltip also (derived from dag_model.timetable_description). And, in the dag detail page, suppress the next run text entirely because it's not possible to say."], "original_ll": -4.295583248138428, "sampled_ll": -2.487938404083252, "all_perturbed_sampled_ll": [-2.406055450439453, -2.766563892364502, -2.7063398361206055, -2.4211843013763428, -2.7376139163970947, -2.6517505645751953, -2.7270843982696533, -3.0609004497528076, -2.8366127014160156, -2.5822064876556396], "all_perturbed_original_ll": [-4.398064613342285, -3.9243946075439453, -4.051167964935303, -4.306473731994629, -4.220831871032715, -4.28839635848999, -4.316329479217529, -4.211643218994141, -3.860161304473877, -4.525023937225342], "perturbed_sampled_ll": -2.689631199836731, "perturbed_original_ll": -4.210248708724976, "perturbed_sampled_ll_std": 0.18297575600646998, "perturbed_original_ll_std": 0.19765426568766378}, {"original": "Fix copy artifacts to svn command (#31975) This fix uses bash -c to run the svn copy command. Tested it and it works", "sampled": "Fix copy artifacts to svn command (#31975) This fix uses bash -c to run the svn copy command. Tested it and it worked", "perturbed_sampled": ["Fix copy artifacts to svn command (#31975) This fix uses bash -c to run the svn command in a shell environment. Tested it and it worked", "Fix copy artifacts to svn command (#31975) This fix uses bash to run the svn copy command. Tested it and it worked", "Fix copy artifacts to svn command (#31975) This fix uses bash -c to run the copy command. Tested it and it worked", "Fix copy artifacts to svn command (#31975) This fix uses bash -c to launch the svn copy command. Tested it and it worked", "Fix copy artifacts to svn command (#31975) This patch added my bash -c to run the svn copy command. Tested it and it worked", "Fix copy artifacts when running pkg copy command (#31975) This fix uses bash -c to run the svn copy command. Tested it and it worked", "Fix copy artifacts to svn command (#31975) This fix tries to use -c to run the svn copy command. Tested it and it worked", "Fix copy artifacts to svn command (#31975) This fix uses bash -c to run the svn copy command. I tried it and it worked", "Fix copy artifacts to svn . This fix uses bash -c to run the svn copy command. Tested it and it worked", "Fix copy artifacts to svn command (#31975) This fix uses bash to run the svn copy command. Tested it and it worked"], "perturbed_original": ["Fix copy artifacts to svn command (#31975) This fix uses bash -c to run the svn command. Tested it and it works", "Fix copy artifacts to svn command (#31975) This fix uses bash -c to run the fix for copy command. Tested it and it works", "Fix add bash -c to svn command (#31975) This fix uses bash -c to run the svn copy command. Tested it and it works", "Fix copy artifacts to svn command (#31975) . My plugin is 2.7.0.3 and it uses bash -c to run the svn copy command. Tested it and it works", "Fix copy artifacts to svn command (#31975) This fix uses bash to run the svn copy command. Tested it and it works", "Fix copy artifacts to svn command (#31975) This fix uses bash -c to write artifacts from the svn copy command. Tested it and it works", "Fix copy artifacts to new dcc files (#31975) This fix uses bash -c to run the svn copy command. Tested it and it works", "Fix bash copy to svn command (#31975) This fix uses bash -c to run the svn copy command. Tested it and it works", "Fix copy artifacts to svn command (#31975) This fix uses bash -c to copy files to the svn copy command. Tested it and it works", "Fix copy artifacts to svn command (#31975) This fix uses bash -c to run the svn command. Tested it and it works"], "original_ll": -4.220693588256836, "sampled_ll": -4.2440361976623535, "all_perturbed_sampled_ll": [-4.108465671539307, -4.3777055740356445, -4.459601879119873, -4.3583149909973145, -4.421746730804443, -4.3151421546936035, -4.27970027923584, -4.1554484367370605, -4.000389099121094, -4.3777055740356445], "all_perturbed_original_ll": [-4.250183582305908, -4.64246129989624, -3.9030473232269287, -4.120301246643066, -4.350961685180664, -4.272745609283447, -4.616883277893066, -4.087474346160889, -4.022927284240723, -4.250183582305908], "perturbed_sampled_ll": -4.285422039031983, "perturbed_original_ll": -4.251716923713684, "perturbed_sampled_ll_std": 0.141998386021016, "perturbed_original_ll_std": 0.22682260870667376}, {"original": "Add `EC2CreateInstanceOperator`, `EC2TerminateInstanceOperator` (#29548) * Add EC2CreateInstanceOperator and EC2TerminteInstanceOperator Change system test to use the new operators Add unit tests for new operators * Add support for multiple ids to EC2TerminateInstanceOperator Change system test to terminate without stopping instances * Fix failing tests for terminate operator * Update doc strings to add that the operators can create/terminate multiple instances Add tests for creating/terminating multiple", "sampled": "Add `EC2CreateInstanceOperator`, `EC2TerminateInstanceOperator` (#29548) * Add EC2CreateInstanceOperator/EC2TerminateInstanceOperator to `#29550` (#295542) * Add EC2CreateInstanceOperator/EC2CloseInstanceOperator to `#295799' (#295607) * Allow `EC2CreateInstanceOperator` to be used in `#29858` (#296640) * `EC2CreateInstanceOperator` is no longer deprecated (#296715)\n\nAdd `ec2crypto` to `#297728` (#297730) * `EC2Crypto` is no longer deprecated (#297842)\n\n* `ec2crypto` now accepts type bool (new for the future) * Add `Eq` (#298970) * `EC2Encryption` is no longer deprecated (#297113) *", "perturbed_sampled": ["Add `EC2CreateInstanceOperator`, `EC2TerminateInstanceOperator` (#29548) * Add EC2CreateInstanceOperator/EC2TerminateInstanceOperator to `#29550` (#295542) * Add EC2CreateInstanceOperator/EC2CloseInstanceOperator to <unk>#29558<unk> (#295607) * Allow `EC2CreateInstanceOperator` to be used in `#29858` (#296640) * `EC2CreateInstanceOperator` is no longer deprecated (#296715)\n\nAdd `ec2crypto` to `#297728` (#297730) * `EC2Crypto` is no longer deprecated (use `ec2crypto` now ; we'll add bool in the future) * Add `Eq` (#298970) * `EC2Encryption` is no longer deprecated (#297113) *", "Add `EC2CreateInstanceOperator`, `EC2TerminateInstanceOperator` (#29548) * Add EC2CreateInstanceOperator/EC2TerminateInstanceOperator to `#29550` (#295542) * Add EC2CreateInstanceOperator/EC2CloseInstanceOperator to `#295799' (#295607) * Allow ECLs to be used in `#29858` (#296640) * `EC2CreateInstanceOperator` is no longer deprecated (#296715)\n\nAdd `ec2crypto` to `#297728` (#297730) * `EC2Crypto` is no longer deprecated (#297842)\n\n* `ec2crypto` now accepts type bool (in the future) * Add `Eq` (#298970) * <unk>Eq<unk> is no longer deprecated (#297113) *", "Add `EC2CreateInstanceOperator`, `EC2TerminateInstanceOperator` (#29548) * Add EC2CreateInstanceOperator/EC2TerminateInstanceOperator to `#29550` (#295542) * Add EC2CreateInstanceOperator/EC2CloseInstanceOperator to <unk>#29550<unk> (#295607) * Allow `EC2CreateInstanceOperator` to be used in (#296640) * <unk>EC2CloseInstanceOperator<unk> is no longer deprecated (#296715)\n\nAdd it to `#297728` (#297730) * `EC2Crypto` is no longer deprecated (#297842)\n\n* `ec2crypto` now accepts type bool (new for the future) * Add `Eq` (#298970) * `EC2Encryption` is no longer deprecated (#297113) *", "Add `EC2CreateInstanceOperator`, `EC2TerminateInstanceOperator` (#29548) * Add EC2CreateInstanceOperator/EC2TerminateInstanceOperator to <unk>#295496' (#295542) * Add EC2CreateInstanceOperator/EC2CloseInstanceOperator to `#295799' (#295607) * Allow <unk>EC2TerminateInstanceOperator<unk> to be used in `#29858` (#296640) * `EC2CreateInstanceOperator` is no longer deprecated (#296715)\n\nAdd `ec2crypto` to `#297728` (#297730) * `EC2Crypto` is no longer deprecated (#297842)\n\n* `ec2crypto` now accepts type bool (new for the future) * Add `Eq` (#298970) * `EC2Encryption` is no longer deprecated (#297113) *", "Add `EC2CreateInstanceOperator`, `EC2TerminateInstanceOperator` (#29548) * Add EC2CreateInstanceOperator/EC2TerminateInstanceOperator to `#29550` (#295542) * Add EC2CreateInstanceOperator/EC2CloseInstanceOperator to `#295799' (#295607) * Allow `EC2CreateInstanceOperator` to be used in `#29858` (#296640) * `EC2CreateInstanceOperator` is no longer defined (#296967) * Add `ec2crypto` to `#297728` (#297730) * `EC2Crypto` is no longer deprecated (#297842)\n\n* Now accepts type bool (should accept type regular in the future) * Add `Eq` (#298970) * `EC2Encryption` is no longer defined (#297113) *", "Add `EC2CreateInstanceOperator`, `EC2TerminateInstanceOperator` (#29548) * Add EC2CreateInstanceOperator/EC2TerminateInstanceOperator to <unk>#295397' (#295792) * Add EC2CreateInstanceOperator/EC2CloseInstanceOperator to `#295799' (#295607) * Allow `EC2CreateInstanceOperator` to be used in `#29858` (#296640) * `EC2CreateInstanceOperator` is no longer deprecated (#296715)\n\nAdd `ec2crypto` to `#297728` (#297730) * `EC2Crypto` is no longer deprecated (#297842)\n\n* `ec2crypto` now accepts type bool (new for the future) * Add `Eq` to <unk>#297024<unk> * `EC2Encryption` is no longer deprecated (#297113) *", "Add `EC2CreateInstanceOperator`, `EC2TerminateInstanceOperator` (#29548) * Add EC2CreateInstanceOperator/EC2TerminateInstanceOperator to `#29550` (#295542) * Add <unk>EC2TerminateInstanceOperator<unk> to `#295799' (#295607) * Allow `EC2CreateInstanceOperator` to be used in `#29858` (#296640) * EC2TerminateInstanceOperator is no longer deprecated (#296715)\n\nAdd `ec2crypto` to `#297728` (#297730) * `EC2Crypto` is no longer deprecated (#297842)\n\n* `ec2crypto` now accepts type bool (new for the future) * Add `Eq` when `EC2Encryption` is no longer valid *", "Add `EC2CreateInstanceOperator`, `EC2TerminateInstanceOperator` (#29548) * Add EC2CreateInstanceOperator/EC2TerminateInstanceOperator to `#29550` (#295542) * Add EC2CreateInstanceOperator/EC2CloseInstanceOperator to `#295799' (#295607) * Allow `EC2CreateInstanceOperator` to be used in `#29858` (#296640) * `EC2CreateInstanceOperator` is no longer deprecated (#296715)\n\nAdd `ec2crypto` to `#297728` (#297730) * <unk>ec2crypto<unk> is no longer deprecated (#297842)\n\n* `ec2crypto` now accepts type bool (new for the new EC2 version) Add `Eq` (#298970) * `EC2Encryption` is no longer deprecated (#297113) *", "Add `EC2CreateInstanceOperator`, `EC2TerminateInstanceOperator` (#29548) * Add EC2CreateInstanceOperator/EC2TerminateInstanceOperator to `#29550` (#295542) * Add EC2CreateInstanceOperator/EC2CloseInstanceOperator to `#295799' (#295607) * Allow `EC2CreateInstanceOperator` to be used in the future (#295711) * `EC2CreateInstanceOperator` is no longer supported (#296715)\n\nAdd `ec2crypto` to `#297728` (#297730) * `EC2Crypto` is no longer deprecated (#297842)\n\n* `ec2crypto` now accepts type bool (new for the future) * Add `Eq` (#298970) * <unk>Eq<unk> is no longer supported (#297113) *", "Add `EC2TerminateInstanceOperator` (#29548) * Add EC2CreateInstanceOperator/EC2TerminateInstanceOperator to `#29550` (#295492) * Add EC2CreateInstanceOperator/EC2CloseInstanceOperator to `#295799' (#295607) * Allow `EC2CreateInstanceOperator` to be moved to `#29858` (#296640) * `EC2CreateInstanceOperator` is no longer deprecated (#296715)\n\nAdd `ec2crypto` to `#297728` (#297730) * `EC2Crypto` is no longer deprecated (#297842)\n\n* `ec2crypto` now accepts type bool (new for the future) * Add `Eq` (#298970) * `EC2Encryption` is no longer deprecated (#297113) *"], "perturbed_original": ["Add `EC2CreateInstanceOperator`, `EC2TerminateInstanceOperator` (#29548) * Implement EC2CreateInstanceOperator and EC2TerminteInstanceOperator in C++ * Update system test to use the new operators Add unit tests for new operators * Add support for multiple ids to EC2TerminateInstanceOperator Change system test to create without stopping instances * Fix failing tests for terminate operator * Update doc strings to add that the operators can create/terminate multiple instances * Add tests for creating/terminating multiple", "Add `EC2TerminateInstanceOperator` operator Add EC2CreateInstanceOperator and EC2TerminteInstanceOperator Change system test to use the new operators Add unit tests for new operators * Add support for multiple ids to EC2TerminateInstanceOperator Change system test to use the existing operators Add tests to create and terminate without stopping instances * Fix failing tests for terminate operator * Update doc strings to add that the operators should terminate multiple instances Add tests for creating/terminating multiple", "Add `EC2CreateInstanceOperator`, `EC2TerminateInstanceOperator` (#29548) * Add EC2CreateInstanceOperator and EC2TerminteInstanceOperator Change system test to use the new operators Complete unit tests for new operators * Fix failing unit test for create instance operator * Move to EC2TerminateInstanceOperator Change system test to terminate without stopping instances * Fix failing unit test for terminate operator * Update doc strings to add that the operators can create/terminate multiple instances Add tests for creating/terminating multiple", "Add `EC2CreateInstanceOperator`, to the operators * Add EC2CreateInstanceOperator and modify system test to use the new operators Add unit tests for new operators * Add support for multiple ids to EC2TerminateInstanceOperator Change system test to terminate without stopping instances * Update failing tests for terminate operator * Update unit tests to add that the operators can create/terminate multiple instances Add tests for creating/terminating multiple", "* Add `EC2TerminateInstanceOperator` (#29548) * Add EC2CreateInstanceOperator and EC2TerminateInstanceOperator * Change system test to use the new operators Add unit tests to use the new operators * Add support for multiple instances * Add EC2TerminateInstanceOperator Change system test to terminate without stopping instances * Fix failing tests for terminate operator * Update doc strings to add that the operators can create/terminate multiple instances Add tests for creating/terminating multiple", "Add an experimental GC Operator (#29548) * Add EC2CreateInstanceOperator and EC2TerminteInstanceOperator Change system test to use the new operators Add unit tests for new operators * Add tests for multiple ids to EC2TerminateInstanceOperator Change tests to terminate without an id. * Fix failing tests for terminate operator * Update doc strings to add that the operators can create/terminate multiple instances Add tests for creating/terminating multiple", "Add `EC2CreateInstanceOperator`, `EC2TerminateInstanceOperator` (#29548) * Add EC2CreateInstanceOperator and EC2TerminteInstanceOperator Change system test to use the new operators Add unit tests for create operator * Add unit tests for multiple instances * Add EC2TerminateInstanceOperator Change system test to handle the Operators without stopping instances * Fix failing tests for terminate operator * Update doc strings to add that the operators can create/terminate multiple instances Add tests for creating/terminating multiple", "Add `EC2CreateInstanceOperator`, `EC2TerminateInstanceOperator` (#29548) * Add support for EC2CreateInstanceOperator and EC2TerminteInstanceOperator Change system test to use the new operators Change tests for new operators * Add support for create/terminate * Add to EC2TerminateInstanceOperator Change system test to terminate without stopping instances * Fix failing tests for terminate operator * Update doc strings to add that the operators can create/terminate multiple instances Add tests for creating/terminating multiple", "Add `EC2CreateInstanceOperator`, `EC2TerminateInstanceOperator` (#29548) * Add multiple ids to EC2TerminteInstanceOperator Change system test to use the new operators Add unit tests for the new operators * Add support for multiple ids to EC2TerminateInstanceOperator Change system test to terminate without stopping instances * Fix failing tests for terminate operator * Update doc strings to add that the operators can create/terminate multiple instances * Add unit tests for creating/terminating multiple", "Add `EC2CreateInstanceOperator`, `EC2TerminateInstanceOperator` (#29548) * Add EC2CreateInstanceOperator and EC2TerminteInstanceOperator Change system test for the operators to create new instances * Add unit tests for new operators * Add support for multiple ids to EC2TerminateInstanceOperator Change system test to terminate without stopping instances * Fix failing tests for terminate operator * Use strings to add that the operators can create/terminate multiple instances Add tests for creating/terminating multiple"], "original_ll": -3.414724588394165, "sampled_ll": -1.7951102256774902, "all_perturbed_sampled_ll": [-2.07761812210083, -2.0798768997192383, -2.164996385574341, -2.1250975131988525, -2.0080058574676514, -2.0904793739318848, -2.135822296142578, -1.9907441139221191, -2.012941360473633, -2.030660629272461], "all_perturbed_original_ll": [-3.3826475143432617, -3.8547523021698, -3.2456724643707275, -3.810394287109375, -3.313021421432495, -3.875950336456299, -3.3075966835021973, -3.341796398162842, -3.399489402770996, -3.4593505859375], "perturbed_sampled_ll": -2.071624255180359, "perturbed_original_ll": -3.4990671396255495, "perturbed_sampled_ll_std": 0.05645288226712384, "perturbed_original_ll_std": 0.23467872155917543}, {"original": "Correctly apply defaults to mapped task flow (#22683) Co-authored-by: Ash Berlin-Taylor <ash_github@firemirror.com>", "sampled": "Correctly apply defaults to mapped task flow (#22683) Co-authored-by: Ash Berlin-Taylor <ash_github@firemirror.ch>\n\n738", "perturbed_sampled": ["Correctly apply defaults to mapped task flow (#22683) Co-authored-by: Ash Berlin-Taylor <ash_github@firemirror.ch>\n\n738", "Correctly apply defaults to mapped task flow (#22683) Co-authored-by: Ash Berlin-Taylor <ash_github@firemirror.ch>\n\n738", "Correctly apply defaults to mapped task flow (#22683) Co-authored-by: Ash Berlin-Taylor <ash_github@firemirror.ch>\n\n738", "Correctly apply defaults to mapped task flow (#22683) Co-authored-by: Ash Berlin-Taylor <ash_github@firemirror.ch>\n\n738", "Correctly apply defaults to mapped task flow (#22683) Co-authored-by: Ash Berlin-Taylor <ash_github@firemirror.ch>\n\n738", "Correctly apply defaults to mapped task flow (#22683) Co-authored-by: Ash Berlin-Taylor <ash_github@firemirror.ch>\n\n738", "Correctly apply defaults to mapped task flow (#22683) Co-authored-by: Ash Berlin-Taylor <ash_github@firemirror.ch>\n\n738", "Correctly apply defaults to mapped task flow (#22683) Co-authored-by: Ash Berlin-Taylor <ash_github@firemirror.ch>\n\n738", "Correctly apply defaults to mapped task flow (#22683) Co-authored-by: Ash Berlin-Taylor <ash_github@firemirror.ch>\n\n738", "Correctly apply defaults to mapped task flow (#22683) Co-authored-by: Ash Berlin-Taylor <ash_github@firemirror.ch>\n\n738"], "perturbed_original": ["Correctly apply defaults to mapped task flow (#22683) Co-authored-by: Ash Berlin-Taylor <ash_github@firemirror.com>", "Correctly apply defaults to mapped task flow (#22683) Co-authored-by: Ash Berlin-Taylor <ash_github@firemirror.com>", "Correctly apply defaults to mapped task flow (#22683) Co-authored-by: Ash Berlin-Taylor <ash_github@firemirror.com>", "Correctly apply defaults to mapped task flow (#22683) Co-authored-by: Ash Berlin-Taylor <ash_github@firemirror.com>", "Correctly apply defaults to mapped task flow (#22683) Co-authored-by: Ash Berlin-Taylor <ash_github@firemirror.com>", "Correctly apply defaults to mapped task flow (#22683) Co-authored-by: Ash Berlin-Taylor <ash_github@firemirror.com>", "Correctly apply defaults to mapped task flow (#22683) Co-authored-by: Ash Berlin-Taylor <ash_github@firemirror.com>", "Correctly apply defaults to mapped task flow (#22683) Co-authored-by: Ash Berlin-Taylor <ash_github@firemirror.com>", "Correctly apply defaults to mapped task flow (#22683) Co-authored-by: Ash Berlin-Taylor <ash_github@firemirror.com>", "Correctly apply defaults to mapped task flow (#22683) Co-authored-by: Ash Berlin-Taylor <ash_github@firemirror.com>"], "original_ll": -5.281473159790039, "sampled_ll": -5.130245208740234, "all_perturbed_sampled_ll": [-5.130245208740234, -5.130245208740234, -5.130245208740234, -5.130245208740234, -5.130245208740234, -5.130245208740234, -5.130245208740234, -5.130245208740234, -5.130245208740234, -5.130245208740234], "all_perturbed_original_ll": [-5.281473159790039, -5.281473159790039, -5.281473159790039, -5.281473159790039, -5.281473159790039, -5.281473159790039, -5.281473159790039, -5.281473159790039, -5.281473159790039, -5.281473159790039], "perturbed_sampled_ll": -5.130245208740234, "perturbed_original_ll": -5.281473159790039, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Revert \"respect soft_fail argument when ExternalTaskSensor runs in deferrable mode (#33196)\" (#33458) This reverts commit a1b5bdb25a6f9565ac5934a9a458e9b079ccf3ae.", "sampled": "Revert \"respect soft_fail argument when ExternalTaskSensor runs in deferrable mode (#33196)\" (#33458) This reverts commit c4d0fdc89fc90870cea9c57ed4b4fefb814ff2e4.", "perturbed_sampled": ["Revert \"respect soft_fail argument when ExternalTaskSensor runs while running in offline mode (#33196)\" (#33458) This reverts commit c4d0fdc89fc90870cea9c57ed4b4fefb814ff2e4.", "Revert \"respect ing internal accesses when ExternalTaskSensor runs in deferrable mode (#33196)\" (#33458) This reverts commit c4d0fdc89fc90870cea9c57ed4b4fefb814ff2e4.", "Revert \"respect soft_fail argument when ExternalTaskSensor in deferrable mode (#33196)\" (#33458) This reverts commit c4d0fdc89fc90870cea9c57ed4b4fefb814ff2e4.", "Revert \"respect soft_fail ure flag when ExternalTaskSensor runs in deferrable mode (#33196)\" (#33458) This reverts commit c4d0fdc89fc90870cea9c57ed4b4fefb814ff2e4.", "Revert \"respect soft_fail argument when ExternalTaskSensor runs in deferrable mode (#33196)\" (#33458) revert commit c4d0fdc89fc90870cea9c57ed4b4fefb814ff2e4.", "Revert \"respect soft_fail argument when failing in deferrable mode (#33196)\" (#33458) This reverts commit c4d0fdc89fc90870cea9c57ed4b4fefb814ff2e4.", "Revert \"respect soft_fail argument when ExternalTaskSensor runs in soft fail (#33196)\" (#33458) This reverts commit c4d0fdc89fc90870cea9c57ed4b4fefb814ff2e4.", "Revert \"respect soft_fail argument when ExternalTaskSensor runs in deferrable \" (#33458) This reverts commit c4d0fdc89fc90870cea9c57ed4b4fefb814ff2e4.", "Revert \"respect soft_fail argument when running in deferrable mode (#33196)\" (#33458) This reverts commit c4d0fdc89fc90870cea9c57ed4b4fefb814ff2e4.", "Revert \"respect soft_fail argument when ExternalTaskSensor runs in deferrable mode (#33196)\" This patch reverts commit c4d0fdc89fc90870cea9c57ed4b4fefb814ff2e4."], "perturbed_original": ["Revert \"respect soft_fail argument when ExternalTaskSensor runs in deferrable thread\" (#33458) This reverts commit a1b5bdb25a6f9565ac5934a9a458e9b079ccf3ae.", "Revert \"respect soft_fail argument when ExternalTaskSensor runs in deferrable mode\" (#33458) This reverts commit a1b5bdb25a6f9565ac5934a9a458e9b079ccf3ae.", "Revert \"respect soft_fail argument when passing in deferrable mode (#33196)\" (#33458) This reverts commit a1b5bdb25a6f9565ac5934a9a458e9b079ccf3ae.", "Revert \"respect soft_fail argument when ExternalTaskSensor runs in test mode (#33196)\" (#33458) This reverts commit a1b5bdb25a6f9565ac5934a9a458e9b079ccf3ae.", "Revert \"respect soft_fail argument when working in deferrable mode (#33196)\" (#33458) This reverts commit a1b5bdb25a6f9565ac5934a9a458e9b079ccf3ae.", "Revert \"respect soft_fail ures while ExternalTaskSensor runs in deferrable mode (#33196)\" (#33458) This reverts commit a1b5bdb25a6f9565ac5934a9a458e9b079ccf3ae.", "Revert \"respect soft_fail argument when ExternalTaskSensor runs in deferrable mode \" This reverts commit a1b5bdb25a6f9565ac5934a9a458e9b079ccf3ae.", "Revert \"respect soft_fail argument when ExternalTaskSensor runs in deferrable mode (#33196)\" (#33458) This changes test path to a1b5bdb25a6f9565ac5934a9a458e9b079ccf3ae.", "Revert \"respect soft_fail argument when ExternalTaskSensor runs in deferrable mode \". This reverts commit a1b5bdb25a6f9565ac5934a9a458e9b079ccf3ae.", "Revert \"respect soft_fail argument when ExternalTaskSensor runs in deferrable mode \". This reverts commit a1b5bdb25a6f9565ac5934a9a458e9b079ccf3ae."], "original_ll": -4.929256439208984, "sampled_ll": -4.826379776000977, "all_perturbed_sampled_ll": [-4.8468732833862305, -4.866362571716309, -4.896758079528809, -4.919351100921631, -5.154050827026367, -4.554765224456787, -4.901501655578613, -5.036914825439453, -4.5198869705200195, -4.8724188804626465], "all_perturbed_original_ll": [-4.997971534729004, -4.896226406097412, -4.721724987030029, -4.943859100341797, -4.653079509735107, -5.06883430480957, -5.022486686706543, -5.291772842407227, -4.954442501068115, -4.954442501068115], "perturbed_sampled_ll": -4.856888341903686, "perturbed_original_ll": -4.950484037399292, "perturbed_sampled_ll_std": 0.18261330176192406, "perturbed_original_ll_std": 0.16784622532111815}, {"original": "Merge WasbBlobAsyncSensor to WasbBlobSensor (#30488)", "sampled": "Merge WasbBlobAsyncSensor to WasbBlobSensor (#30488)Atlas", "perturbed_sampled": ["Merge WasbBlobAsyncSensor to WasbBlobSensor (#30488)Atlas", "Merge WasbBlobAsyncSensor to WasbBlobSensor (#30488)Atlas", "Merge WasbBlobAsyncSensor to WasbBlobSensor (#30488)Atlas", "Merge WasbBlobAsyncSensor to WasbBlobSensor (#30488)Atlas", "Merge WasbBlobAsyncSensor to WasbBlobSensor (#30488)Atlas", "Merge WasbBlobAsyncSensor to WasbBlobSensor (#30488)Atlas", "Merge WasbBlobAsyncSensor to WasbBlobSensor (#30488)Atlas", "Merge WasbBlobAsyncSensor to WasbBlobSensor (#30488)Atlas", "Merge WasbBlobAsyncSensor to WasbBlobSensor (#30488)Atlas", "Merge WasbBlobAsyncSensor to WasbBlobSensor (#30488)Atlas"], "perturbed_original": ["Merge WasbBlobAsyncSensor to WasbBlobSensor (#30488)", "Merge WasbBlobAsyncSensor to WasbBlobSensor (#30488)", "Merge WasbBlobAsyncSensor to WasbBlobSensor (#30488)", "Merge WasbBlobAsyncSensor to WasbBlobSensor (#30488)", "Merge WasbBlobAsyncSensor to WasbBlobSensor (#30488)", "Merge WasbBlobAsyncSensor to WasbBlobSensor (#30488)", "Merge WasbBlobAsyncSensor to WasbBlobSensor (#30488)", "Merge WasbBlobAsyncSensor to WasbBlobSensor (#30488)", "Merge WasbBlobAsyncSensor to WasbBlobSensor (#30488)", "Merge WasbBlobAsyncSensor to WasbBlobSensor (#30488)"], "original_ll": -6.088519096374512, "sampled_ll": -6.3120012283325195, "all_perturbed_sampled_ll": [-6.3120012283325195, -6.3120012283325195, -6.3120012283325195, -6.3120012283325195, -6.3120012283325195, -6.3120012283325195, -6.3120012283325195, -6.3120012283325195, -6.3120012283325195, -6.3120012283325195], "all_perturbed_original_ll": [-6.088519096374512, -6.088519096374512, -6.088519096374512, -6.088519096374512, -6.088519096374512, -6.088519096374512, -6.088519096374512, -6.088519096374512, -6.088519096374512, -6.088519096374512], "perturbed_sampled_ll": -6.3120012283325195, "perturbed_original_ll": -6.088519096374512, "perturbed_sampled_ll_std": 1, "perturbed_original_ll_std": 1}, {"original": "Continue on exception when retrieving metadata (#27665) There are cases where just retrieval of package metadata during entrypoint discovery will cause an error (example https://github.com/apache/airflow/discussions/27596). In this case we should skip the package and continue discovery, while logging a warning rather than crash.", "sampled": "Continue on exception when retrieving metadata (#27665) There are cases where just retrieval of package metadata during entrypoint discovery will cause an error (example https://bugs.launchpad.net/ubuntu/+source/pipermail/ubuntu-ppa/+bug/1229799). This is currently due to the pkg metadata system that is used, where the default behavior relies on", "perturbed_sampled": ["Continue on exception when retrieving metadata (#27665) There are cases where just retrieval of package metadata without package discovery will cause an error (example https://bugs.launchpad.net/ubuntu/+source/pipermail/ubuntu-ppa/+bug/1229799). This is due to the pkg metadata query that is used, where the default behavior relies on", "Continue on exception when retrieving metadata : Seems like there are cases where just retrieving package metadata during entrypoint discovery will cause an error (example https://bugs.launchpad.net/ubuntu/+source/pipermail/ubuntu-ppa/+bug/1229799). This is due to the pkg metadata system that is used, where the default behavior relies on", "Continue on exception when retrieving metadata (#27665) There are cases where just retrieval of package metadata during file parsing will cause a serious exception (example https://bugs.launchpad.net/ubuntu/+source/pipermail/ubuntu-ppa/+bug/1229799). This is currently due to the pkg parse method that is used, where the default behavior relies on", "Continue on exception when retrieving metadata (#27665) There are cases where the retrieval of package metadata during entrypoint discovery will cause an error (example https://bugs.launchpad.net/ubuntu/+source/pipermail/ubuntu-ppa/+bug/1229799). This is due to the pkg metadata system that is used, where the default value of \"-scan on", "Continue on exception when doing nothing (#27665) There are cases where just retrieval of package metadata instead of discovery will cause an error (example https://bugs.launchpad.net/ubuntu/+source/pipermail/ubuntu-ppa/+bug/1229799). This is currently due to the pkg metadata system that is used, where some package data behavior relies on", "Continue on exception when retrieving metadata (#27665) There are cases where just retrieval of metadata during entrypoint discovery will cause an error (example https://bugs.launchpad.net/ubuntu/+source/pipermail/ubuntu-ppa/+bug/1229799). This is currently due to the pkg metadata system that is installed by the default s and dependencies on", "Continue on exception when retrieving metadata (#27665) There are cases where a request of package metadata during entrypoint discovery will cause an error (example https://bugs.launchpad.net/ubuntu/+source/pipermail/ubuntu-ppa/+bug/1229799). This is currently due to the pkg metadata system that is used, which is rather default . Continue on", "Continue on exception when retrieving metadata (#27665) There are cases where retrieval of package metadata during entrypoint s can cause an error (example https://bugs.launchpad.net/ubuntu/+source/pipermail/ubuntu-ppa/+bug/1229799). This is currently due to the pkg metadata system that is developed that the default behavior relies on", "Continue on exception when retrieving metadata (#27665) There are occasions where just retrieval of package metadata , or based on package discovery will cause an error (example https://bugs.launchpad.net/ubuntu/+source/pipermail/ubuntu-ppa/+bug/1229799). This is currently due to the pkg metadata system that is used, where the default behavior relies on", "Continue on exception when retrieving metadata (#27665) There have been cases where just retrieval of package metadata during entrypoint execution could cause an error (example https://bugs.launchpad.net/ubuntu/+source/pipermail/ubuntu-ppa/+bug/1229799). This is currently due to the pkg metadata system that is used, the current default behavior relies on"], "perturbed_original": ["Continue discovery even when retrieving metadata (#27665) There are cases where just retrieval of package metadata (or executing an airflow discovery ) should lead to an error (example https://github.com/apache/airflow/discussions/27596). In this case we should skip the package and continue discovery, while logging a warning rather than crash.", "Continue on exception when retrieving metadata (#27665) There are times when just retrieval of metadata during entrypoint discovery will cause an error (example https://github.com/apache/airflow/discussions/27596). In this case we should skip the package and continue discovery, while logging a warning rather than crash.", "Continue on exception when retrieving metadata (#27665) There are cases where just retrieval of package metadata during entrypoint discovery will cause an error (example https://github.com/apache/airflow/discussions/27596). In this case the test should skip the package and continue by logging a warning rather than crash.", "Continue on exception when retrieving metadata (#27665) There are cases where just retrieval of metadata during entrypoint discovery will cause an error (example https://github.com/apache/airflow/discussions/27596). In such cases we should skip the package and continue discovery, while logging a warning on a crash.", "Continue on exception when retrieving metadata . There are cases where just retrieval of metadata during entrypoint discovery will cause an error (example https://github.com/apache/airflow/discussions/27596). In this case we should skip the package and continue discovery, while logging a warning rather than crash.", "Continue on exception when retrieving metadata (#27665) There are cases where just retrieval of metadata during entrypoint discovery will cause an error (example https://github.com/apache/airflow/discussions/27596). In this case we \u2019d just remove the package and continue discovery, while logging the error rather than crash.", "Continue on exception when retrieving metadata (#27665) There are instances where just retrieval of package metadata during entrypoint discovery will cause an error (example https://github.com/apache/airflow/discussions/27596). In this case we would need to continue on the exception, and continue discovery, while logging a warning rather than crash.", "Continue on for retrieving metadata (#27665) There are cases where just retrieval of package metadata to continue discovery will cause an error (example https://github.com/apache/airflow/discussions/27596). In this case we should attempt to find the whole package and continue discovery, while logging a warning rather than crash.", "Continue on exception when retrieving metadata (#27665) There are cases where just retrieval of package metadata during entrypoint discovery will cause an error (example #27659) In this case we should skip the package and path metadata while logging in rather than crash.", "Continue on exception when retrieving package. There are cases where just retrieval of package from airflow entrypoint discovery will cause an error (example https://github.com/apache/airflow/discussions/27596). In this case we should skip the package and continue discovery, only returning a warning rather than crash."], "original_ll": -4.062112808227539, "sampled_ll": -3.1690614223480225, "all_perturbed_sampled_ll": [-3.0166337490081787, -3.034085273742676, -3.2274363040924072, -3.138411283493042, -3.300931692123413, -3.3163256645202637, -3.2922048568725586, -3.251307487487793, -3.2177236080169678, -3.1820266246795654], "all_perturbed_original_ll": [-4.047562599182129, -4.08397102355957, -4.0268235206604, -4.088597774505615, -4.032092571258545, -4.361983299255371, -3.9457578659057617, -3.9942941665649414, -4.512927055358887, -4.1106672286987305], "perturbed_sampled_ll": -3.1977086544036863, "perturbed_original_ll": -4.120467710494995, "perturbed_sampled_ll_std": 0.10056566294435205, "perturbed_original_ll_std": 0.16826637072528153}], "metrics": {"roc_auc": 0.5922375, "fpr": [0.0, 0.0, 0.005, 0.005, 0.01, 0.01, 0.03, 0.03, 0.045, 0.045, 0.065, 0.065, 0.07, 0.07, 0.08, 0.08, 0.085, 0.085, 0.095, 0.095, 0.115, 0.115, 0.12, 0.12, 0.13, 0.13, 0.14, 0.14, 0.15, 0.15, 0.16, 0.16, 0.175, 0.175, 0.185, 0.185, 0.19, 0.19, 0.205, 0.205, 0.79, 0.79, 0.81, 0.81, 0.82, 0.82, 0.83, 0.83, 0.84, 0.84, 0.845, 0.845, 0.865, 0.865, 0.88, 0.88, 0.89, 0.89, 0.925, 0.925, 0.935, 0.935, 0.955, 0.955, 0.975, 0.975, 0.98, 0.98, 0.99, 0.99, 1.0, 1.0], "tpr": [0.0, 0.005, 0.005, 0.075, 0.075, 0.115, 0.115, 0.12, 0.12, 0.15, 0.15, 0.16, 0.16, 0.175, 0.175, 0.18, 0.18, 0.185, 0.185, 0.19, 0.19, 0.2, 0.2, 0.245, 0.245, 0.26, 0.26, 0.265, 0.265, 0.27, 0.27, 0.275, 0.275, 0.29, 0.29, 0.295, 0.295, 0.3, 0.3, 0.31, 0.895, 0.905, 0.905, 0.91, 0.91, 0.915, 0.915, 0.92, 0.92, 0.93, 0.93, 0.935, 0.935, 0.94, 0.94, 0.945, 0.945, 0.95, 0.95, 0.96, 0.96, 0.965, 0.965, 0.97, 0.97, 0.985, 0.985, 0.99, 0.99, 0.995, 0.995, 1.0]}, "pr_metrics": {"pr_auc": 0.6167154440792286, "precision": [0.5, 0.49874686716791977, 0.5, 0.5012594458438288, 0.5, 0.5012658227848101, 0.5025380710659898, 0.5012722646310432, 0.5025510204081632, 0.5012787723785166, 0.5, 0.4987146529562982, 0.5, 0.5012919896640827, 0.5025906735751295, 0.5038961038961038, 0.5026041666666666, 0.5039164490861618, 0.5052356020942408, 0.5065616797900262, 0.5078947368421053, 0.5065963060686016, 0.5079365079365079, 0.5092838196286472, 0.5079787234042553, 0.5066666666666667, 0.5080213903743316, 0.5093833780160858, 0.510752688172043, 0.5121293800539084, 0.5135135135135135, 0.5149051490514905, 0.5163043478260869, 0.5149863760217984, 0.5163934426229508, 0.5178082191780822, 0.5164835164835165, 0.5179063360881543, 0.5193370165745856, 0.5207756232686981, 0.5194444444444445, 0.520891364902507, 0.5223463687150838, 0.5238095238095238, 0.5252808988764045, 0.523943661971831, 0.5254237288135594, 0.5240793201133145, 0.5227272727272727, 0.5242165242165242, 0.5257142857142857, 0.5243553008595988, 0.5258620689655172, 0.5273775216138329, 0.5260115606936416, 0.527536231884058, 0.5290697674418605, 0.5276967930029155, 0.5292397660818714, 0.530791788856305, 0.5323529411764706, 0.5339233038348082, 0.5325443786982249, 0.5311572700296736, 0.6019417475728155, 0.5980392156862745, 0.594059405940594, 0.6, 0.6060606060606061, 0.6122448979591837, 0.6082474226804123, 0.6145833333333334, 0.6105263157894737, 0.6170212765957447, 0.6236559139784946, 0.6195652173913043, 0.6153846153846154, 0.6111111111111112, 0.6179775280898876, 0.625, 0.632183908045977, 0.627906976744186, 0.6352941176470588, 0.6428571428571429, 0.6385542168674698, 0.6463414634146342, 0.654320987654321, 0.65, 0.6582278481012658, 0.6666666666666666, 0.6623376623376623, 0.6578947368421053, 0.6533333333333333, 0.6621621621621622, 0.6712328767123288, 0.6666666666666666, 0.6619718309859155, 0.6571428571428571, 0.6521739130434783, 0.6470588235294118, 0.6417910447761194, 0.6363636363636364, 0.6307692307692307, 0.625, 0.6349206349206349, 0.6290322580645161, 0.6229508196721312, 0.6333333333333333, 0.6440677966101694, 0.6551724137931034, 0.6666666666666666, 0.6607142857142857, 0.6727272727272727, 0.6851851851851852, 0.6792452830188679, 0.6923076923076923, 0.6862745098039216, 0.7, 0.7142857142857143, 0.7083333333333334, 0.7021276595744681, 0.6956521739130435, 0.7111111111111111, 0.7045454545454546, 0.6976744186046512, 0.7142857142857143, 0.7317073170731707, 0.75, 0.7692307692307693, 0.7631578947368421, 0.7567567567567568, 0.75, 0.7428571428571429, 0.7352941176470589, 0.7272727272727273, 0.75, 0.7741935483870968, 0.8, 0.7931034482758621, 0.8214285714285714, 0.8518518518518519, 0.8846153846153846, 0.92, 0.9166666666666666, 0.9130434782608695, 0.9090909090909091, 0.9047619047619048, 0.9, 0.8947368421052632, 0.8888888888888888, 0.8823529411764706, 0.9375, 0.9333333333333333, 0.9285714285714286, 0.9230769230769231, 0.9166666666666666, 0.9090909090909091, 0.9, 0.8888888888888888, 0.875, 0.8571428571428571, 0.8333333333333334, 0.8, 0.75, 0.6666666666666666, 0.5, 1.0, 1.0], "recall": [1.0, 0.995, 0.995, 0.995, 0.99, 0.99, 0.99, 0.985, 0.985, 0.98, 0.975, 0.97, 0.97, 0.97, 0.97, 0.97, 0.965, 0.965, 0.965, 0.965, 0.965, 0.96, 0.96, 0.96, 0.955, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.945, 0.945, 0.945, 0.94, 0.94, 0.94, 0.94, 0.935, 0.935, 0.935, 0.935, 0.935, 0.93, 0.93, 0.925, 0.92, 0.92, 0.92, 0.915, 0.915, 0.915, 0.91, 0.91, 0.91, 0.905, 0.905, 0.905, 0.905, 0.905, 0.9, 0.895, 0.31, 0.305, 0.3, 0.3, 0.3, 0.3, 0.295, 0.295, 0.29, 0.29, 0.29, 0.285, 0.28, 0.275, 0.275, 0.275, 0.275, 0.27, 0.27, 0.27, 0.265, 0.265, 0.265, 0.26, 0.26, 0.26, 0.255, 0.25, 0.245, 0.245, 0.245, 0.24, 0.235, 0.23, 0.225, 0.22, 0.215, 0.21, 0.205, 0.2, 0.2, 0.195, 0.19, 0.19, 0.19, 0.19, 0.19, 0.185, 0.185, 0.185, 0.18, 0.18, 0.175, 0.175, 0.175, 0.17, 0.165, 0.16, 0.16, 0.155, 0.15, 0.15, 0.15, 0.15, 0.15, 0.145, 0.14, 0.135, 0.13, 0.125, 0.12, 0.12, 0.12, 0.12, 0.115, 0.115, 0.115, 0.115, 0.115, 0.11, 0.105, 0.1, 0.095, 0.09, 0.085, 0.08, 0.075, 0.075, 0.07, 0.065, 0.06, 0.055, 0.05, 0.045, 0.04, 0.035, 0.03, 0.025, 0.02, 0.015, 0.01, 0.005, 0.005, 0.0]}, "loss": 0.3832845559207714}